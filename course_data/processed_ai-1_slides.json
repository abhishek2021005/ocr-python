[
    {
        "slideContent": "\nPrerequisites for AI-1\n\n▷Content Prerequisites\n                The mandatory\ncourses\n                in CS@FAU; Sem. 1-4, in particular:\n\n\n▷Course\n                “Algorithmen und Datenstrukturen”.(Algorithms & Data Structures)\n\n\n▷Course\n                “Grundlagen der Logik in der Informatik” (GLOIN).(Logic in CS)\n\n\n▷Course\n                “Berechenbarkeit und Formale Sprachen”.(Theoretical CS)\n\n\n▷Skillset Prerequisite\n                Coping with\nmathematical\n                formulation of the structures\n\n\n▷Mathematics\n                is the language of science(in particular\ncomputer science)\n\n\n▷It allows us to be very precise about what we mean.\n(good for you)\n\n\n▷Intuition\n(take them with a kilo of salt)\n\n\n▷This is what I assume you know!(I have to assume something)\n\n\n▷In most cases, the dependency on these is partial and “in spirit”.\n\n\n▷If you have not taken these (or do not remember), read up on them as needed!\n\n\n▷Real Prerequisites\n                Motivation, interest, curiosity, hard work.(AI-1 is non-trivial)\n\n\n▷You can do this course if you want!(and I hope you are successful)\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "520979b6",
        "archive": "courses/FAU/AI/course",
        "filepath": "course/slides/prerequisites.en.xhtml"
    },
    {
        "slideContent": "\nAssessment, Grades\n\n▷Overall (Module) Grade\n\n\n▷Grade\n                  via the\nexam\n                  (Klausur)\n⤳\n100%\n                  of the\ngrade.\n\n\n▷Up to\n10%\n                  bonus on-top for an\nexam\n                  with\n≥50%\n                  points.(<50%\n⤳\n                      no bonus)\n\n\n▷Bonus points\n=^\npercentage\nsum\n                  of the best 10\nprepquizzes\n                  divided by 100.\n\n\n▷Exam\n                  90 minutes\nexam\n                  conducted in presence on paper!(∼\n                      April 1. 2025)\n\n\n▷Retake Exam\n                  90 min\nexam\n                  six months later.(∼\n                      October 1. 2025)\n\n\n▷\n                  Register for\nexams\n                  in\nhttps://campo.fau.de.\n(there is a deadine!)\n\n\n▷Note\n                  You can de-register from an\nexam\n                  on\nhttps://campo.fau.de\n                  up to three working days before\nexam.(do not miss that if you are not prepared)\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "520979b6",
        "archive": "courses/FAU/AI/course",
        "filepath": "course/slides/grading.en.xhtml"
    },
    {
        "slideContent": "\nPreparedness Quizzes\n\n▷PrepQuizzes\n                  Every tuesday 16:15 we start the\nlecture\n                  with a 10 min online\nquiz\n                  — the\nPrepQuiz\n                  — about the material from the previous week.(starts in week 2)\n\n\n▷Motivations\n                  We do this to\n\n\n▷keep you prepared and working continuously.(primary)\n\n\n▷update the\nALeA\nlearner model\n(fringe benefit)\n\n\n▷The\nprepquiz\n              will be given in the\nALeA\n              system\n\n\n\n▷https://courses.voll-ki.fau.de/quiz-dash/ai-1\n\n\n▷You have to be\nlogged into\nALeA!(via\nFAU IDM)\n\n\n▷You can take the\nprepquiz\n                                on your laptop or phone, ...\n\n▷...in the\nlecture\n                                or at home ...\n\n▷...via WLAN or 4G Network.\n(do not overload)\n\n\n▷Prepquizzes\n                                will only be available 16:15-16:25!\n\n\n\n\n\n\n\n\n \n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "520979b6",
        "archive": "courses/FAU/AI/course",
        "filepath": "course/slides/prepquiz.en.xhtml"
    },
    {
        "slideContent": "\nThis Thursday: Pretest\n\n▷\n                  This thursday we will try out the\nprepquiz\n                  infrastructure with a\npretest!\n\n\n▷Presence: bring your laptop or cellphone.\n\n\n▷Online: you can and should take the\npretest\n                  as well.\n\n\n▷Have a recent\nfirefox\n                  or\nchrome\n(chrome: younger than March 2023)\n\n\n▷Make sure that you are\nlogged into\nALeA\n(via\nFAU IDM; see below)\n\n\n▷\n                  A\npretest\n                  is an\nassessment\n                  for evaluating the preparedness of\nlearners\n                  for further studies.\n\n\n▷Concretely\n                  This\npretest\n\n\n▷establishes a baseline for the\ncompetency\n                  expectations in AI-1 and\n\n\n▷tests the\nALeA\nquiz\n                  infrastructure for the\nprepquizzes.\n\n\n▷Participation in the\npretest\n              is optional; it will not influence grades in any way.\n\n\n▷The\npretest\n              covers the prerequisites of AI-1 and some of the material that may have been covered in other\ncourses.\n\n\n▷The test will be also used to refine the\nALeA\nlearner model, which may make learning experience in\nALeA\n              better.(see below)\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-15\n",
        "sectionId": "520979b6",
        "archive": "courses/FAU/AI/course",
        "filepath": "course/slides/pretest.en.xhtml"
    },
    {
        "slideContent": "\n\n\n              Special Admin Conditions\n\n\n\n▷Some\ndegree programs\n            do not “import” the\ncourse\n            Artificial Intelligence 1, and thus you may not be able to register for the\nexam\n            via\nhttps://campo.fau.de.\n\n\n▷Just send me an e-mail and come to the\nexam,\n(we do the necessary admin)\n\n\n▷Tell your\nprogram\n            coordinator about AI-1/2 so that they remedy this situation\n\n\n▷In “Wirtschafts-Informatik” you can only take AI-1 and AI-2 together in the “Wahlpflichtbereich”.\n\n\n▷ECTS\ncredits\n            need to be divisible by five\n\n⇝\n\n7.5+7.5=15.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-15\n",
        "sectionId": "520979b6",
        "archive": "courses/FAU/AI/course",
        "filepath": "course/slides/special-admin.en.xhtml"
    },
    {
        "slideContent": "\n〈〈coursecronym〉〉\n            Homework Assignments\n\n▷Goal\nHomework assignments\n                reinforce what was taught in\nlectures.\n\n\n▷Homework Assignments\n                Small individual problem/programming/proof task\n\n\n▷but take time to solve(at least read them directly\n⤳\n                    questions)\n\n\n▷Didactic Intuition\nHomework assignments\n                give you material to test your understanding and show you how to apply it.\n\n\n▷\nHomeworks\n                give no points, but without trying you are unlikely to pass the\nexam.\n\n\n▷Homeworks\n            will be mainly\npeer-graded\n            in the\nALeA\n            system.\n\n\n▷Didactic Motivation\n                Through\npeer grading\nstudents\n                are able to see\nmistakes\n                in their thinking and can correct any problems in future\nassignments. By\ngrading\nassignments,\nstudents\n                may\nlearn\n                how to complete\nassignments\n                more accurately and how to improve their future results.(not just us being lazy)\n\n\n\n:\n12024-12-14\n",
        "sectionId": "6f4d08a0",
        "archive": "courses/FAU/meta-inf",
        "filepath": "admin/slides/homeworks-alea.en.xhtml"
    },
    {
        "slideContent": "\n〈〈coursecronym〉〉\n            Homework Assignments — Howto\n\n▷Homework Workflow\n                in\nALeA\n(see below)\n\n\n▷Homework assignments\n                will be published on thursdays: see\n〈〈hwURL〉〉\n\n\n▷Submission of solutions via the\nALeA\n                system in the week after\n\n\n▷Peer grading/feedback\n                (and master solutions) via answer classes.\n\n\n▷Quality Control\nTAs\n                and\ninstructors\n                will monitor and supervise\npeer grading.\n\n\n▷Experiment\n                Can we motivate enough of you to make\npeer assessment\n                self-sustaining?\n\n\n▷I am appealing to your sense of community responsibility here ...\n\n▷You should only expect other’s to\ngrade\n                your submission if you\ngrade\n                their’s(cf. Kant’s “Moral Imperative”)\n\n\n▷Make no mistake: The\ngrader\n                usually\nlearns\n                at least as much as the\ngradee.\n\n\n▷Homework/Tutorial Discipline\n\n\n▷Start early!(many\nassignments\n                    need more than one evening’s work)\n\n\n▷Don’t start by sitting at a blank screen\n(talking &\nstudy groups\n                    help)\n\n\n▷Humans will be trying to understand the text/code/math when\ngrading\n                it.\n\n\n▷Go to the\ntutorials, discuss with your\nTA!(they are there for you!)\n\n\n\n:\n22024-12-14\n",
        "sectionId": "6f4d08a0",
        "archive": "courses/FAU/meta-inf",
        "filepath": "admin/slides/homeworks-alea.en.xhtml"
    },
    {
        "slideContent": "\nTutorials for Artificial Intelligence 1\n\n▷Approach\n                Weekly\ntutorials\n                and\nhomework assignments(first one in week two)\n\n\n▷Goal 1\n                Reinforce what was taught in the\nlectures.(you need practice)\n\n\n▷Goal 2\n                Allow you to ask any question you have in a protected environment.\n\n\n▷Instructor/Lead TAFlorian Rabe(KWARC\n                    Postdoc)\n\n\n▷Room: 11.137 @ Händler building,\nflorian.rabe@fau.de\n\n\n▷Tutorials\n                One each taught by Florian Rabe (lead); Yasmeen Shawat, Hatem Mousa, Xinyuan Tu, and Florian Guthmann.\n\n\n▷Life-saving Advice\n                Go to your\ntutorial, and prepare for it by having looked at the slides and the\nhomework assignments!\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-16\n",
        "sectionId": "6f4d08a0",
        "archive": "courses/FAU/AI/course",
        "filepath": "course/slides/uebungen.en.xhtml"
    },
    {
        "slideContent": "\nCollaboration\n\n▷\n\n\n▷In\nlearning\n            situations, the benefit is “better\nlearning”.\n\n\n▷Observation\n                In\ncollaborative\nlearning, the overall result can be significantly better than in\ncompetitive\nlearning.\n\n\n▷Good Practice\n                Form\nstudy groups.\n(long- or short-term)\n\n\n1.\n                those\nlearners\n                who work most,\nlearn\n                most!\n\n\n2.\n                freeloaders — individuals who only watch —\nlearn\n                very little!\n\n\n▷It is OK to\ncollaborate\n            on\nhomework assignments\n            in\n〈〈coursecronym〉〉!(no bonus points)\n\n\n▷Choose your\nstudy group\n                well!\n(We will (eventually) help via\nALeA)\n\n\n\n:\n12024-12-15\n",
        "sectionId": "6f4d08a0",
        "archive": "courses/FAU/meta-inf",
        "filepath": "admin/slides/collaboration.en.xhtml"
    },
    {
        "slideContent": "\nDo I need to attend the\n〈〈coursecronym〉〉\nLectures\n\n▷Attendance is not mandatory for the\n〈〈coursecronym〉〉\ncourse.(official version)\n\n\n▷Note\n                There are two ways of learning:(both are OK, your mileage may vary)\n\n\n▷Approach\nB: Read\na book/papers(here:\nlecture notes)\n\n\n▷Approach\nI: come to the\nlectures, be\ninvolved, interrupt the\ninstructor\n                whenever you have a question.\n\n\nThe only advantage of\nI\n                over\nB\n                is that books/papers do not answer questions\n\n\n▷Approach\nS: come to the\nlectures\n            and\nsleep\ndoes not work!\n\n\n▷The closer you get to research, the more we need to\ndiscuss!\n\n\n\n:\n12024-12-14\n",
        "sectionId": "6f4d08a0",
        "archive": "courses/FAU/meta-inf",
        "filepath": "admin/slides/attendance.en.xhtml"
    },
    {
        "slideContent": "\nTextbook, Handouts and Information, Forums, Videos\n\n▷Textbook\nRussel/Norvig: Artificial Intelligence, A modern Approach\n                  [RN09].\n\n\n▷basically “broad but somewhat shallow”\n\n\n▷great to get intuitions on the basics of\nAI\n\n\nMake sure that you read the\nedition\n≥3\n\n⇝\n\n                  vastly improved over\n≤2.\n\n\n▷Lecture notes\n                  will be posted at\nhttps://kwarc.info/teaching/AI\n\n\n▷more detailed than [RN09] in some areas\n\n\n▷I mostly prepare them as we go along(semantically preloaded\n⤳\n                      research resource)\n\n\n▷please e-mail me any errors/shortcomings you notice.\n(improve for the group)\n\n\n▷Course Videos\n                  AI-1 will be streamed/recorded at\nhttps://fau.tv/course/id/4047\n\n\n▷Organized: Video course nuggets are available at\nhttps://fau.tv/course/id/1690(short; organized by topic)\n\n\n▷Backup: The\nlectures\n                  from WS 2016/17 to SS 2018 have been recorded (in English and German), see\nhttps://www.fau.tv/search/term.html?q=Kohlhase\n\n\n▷Do not let the videos mislead you\n                  Coming to\nclass\n                  is highly correlated with passing the\nexam!\n\n\n▷StudOn Forum\nhttps://www.studon.fau.de/crs5832535.html\n                  for\n\n\n▷announcements,\nhomeworks(my view on the forum)\n\n\n▷questions, discussion among your fellow\nstudents(your forum too, use it!)\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-16\n",
        "sectionId": "58a544a0",
        "archive": "courses/FAU/AI/course",
        "filepath": "course/slides/resources.en.xhtml"
    },
    {
        "slideContent": "\nPractical recommendations on\nLecture Videos\n\n▷Excellent Guide\n                [Nor+18a] (German version at [Nor+18b])\n\n\n\n\n\n:\n12024-12-15\n",
        "sectionId": "58a544a0",
        "archive": "courses/FAU/meta-inf",
        "filepath": "admin/slides/resources-guide.en.xhtml"
    },
    {
        "slideContent": "\nNOT a Resource for : LLMs — AI-based tools like ChatGPT\n\n▷\n                  A\nlarge language model\n                  (LLM) is a computational model capable of language generation or other natural language processing tasks.\n\n\n▷\n                  OpenAI’s GPT, Google’s Bard, and Meta’s Llama.\n\n\n▷\n                  A\nchatbot\n                  is a software application or web interface that is designed to mimic human conversation through text or voice interactions. Modern\nchatbots\n                  are usually based on\nLLMs.\n\n\n▷ChatGPT talks about AI-1(but remains vague)\n\n\n\n\n▷Note\nLLM-based\nchatbots\n                  invent\nevery word!(suprpisingly often correct)\n\n\n▷In the AI-1 exam\n                  ChatGPT scores ca.\n50%\n                  of the points.\n\n\n▷ChatGPT can almost pass the exam ...(We could award it a Master’s degree)\n\n\n▷But can you?\n(the AI-1 exams will be in person on paper)\n\n\nYou will only pass the exam, if you can do AI-1 yourself!\n\n\n▷Intuition\n                  AI tools like GhatGPT, CoPilot, etc.(see also [She24])\n\n\n▷can help you solve problems,\n(valuable tools in production situations)\n\n\n▷hinders\nlearning\n                  if used for homeworks/quizzes, etc.\n(like driving instead of jogging)\n\n\n▷What (not) to do\n(to get most of the brave new AI-supported world)\n\n\n▷try out these tools to get a first-hand intuition what they can/cannot do\n\n\n▷challenge yourself while learning so that you can also do it\n(mind over matter!)\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "58a544a0",
        "archive": "courses/FAU/AI/course",
        "filepath": "course/slides/llms-not.en.xhtml"
    },
    {
        "slideContent": "\nALeA: Adaptive Learning Assistant\n\n▷Idea\n                  Use\nAI\n                  methods to help\nteach/learn\nAI(AI4AI)\n\n\n▷Concretely\n                  Provide\nHTML\n                  versions of the  slides/lecture notes\n                  and embed\nlearning support services\n                  into them.\n(for pre/postparation of\nlectures)\n\n\n▷\n                  Call a\ndocument\nactive, iff it is\ninteractive\n                  and adapts to specific\ninformation needs\n                  of the\nreaders.\n(lecture notes\n                      on steroids)\n\n\n▷Intuition\nALeA\n                  serves\nactive course materials.(PDF\n                      mostly\ninactive)\n\n\n▷Goal\n                  Make\nALeA\n                  more like a\ninstructor\n                  +\nstudy group\n                  than like a book!\n\n\n▷Course Notes\n=^\n                  Slides + Comments\n\n\n\n\n⤳\n                  yellow parts in table of contents (left) already covered in\nlectures.\n\n\n\n:\n12024-12-15\n",
        "sectionId": "abae1049",
        "archive": "talks/voll-ki",
        "filepath": "slides/alea-ai.en.xhtml"
    },
    {
        "slideContent": "\nVoLL-KI\n              Portal at\nhttps://courses.voll-ki.fau.de\n\n▷Portal for\nALeA\nCourses\nhttps://courses.voll-ki.fau.de\n\n\n\n\n▷\n                    in\nALeA\n\n\n▷All details for the\ncourse.\n\n\n▷recorded syllabus\n(keep track of material covered in\ncourse)\n\n\n▷syllabus of the last\nsemesters\n                  (for over/preview)\n\n\n▷ALeA\n                    Status\n                  The\nALeA\n                  system is deployed at FAU for over 1000\nstudents\n                  taking eight\ncourses\n\n\n▷(some)\nstudents\n                  use the system actively\n(our logs tell us)\n\n\n▷reviews are mostly positive/enthusiastic\n(error reports pour in)\n\n\n\n:\n12024-12-14\n",
        "sectionId": "abae1049",
        "archive": "talks/voll-ki",
        "filepath": "slides/course-portal.en.xhtml"
    },
    {
        "slideContent": "\nLearning Support Services in\nALeA\n\n▷Idea\n                  Embed\nlearning support services\n                  into\nactive\ncourse materials.\n\n\n▷Definition on Hover\n                  Hovering on a (cyan)\nterm reference\n                  reminds us of its definition.(even works recursively)\n\n\n\n\n▷More Definitions on Click\n                  Clicking on a (cyan)\nterm reference\n                  shows us more definitions from other contexts.\n\n\n\n\n\n\n\n\n▷Guided Tour\n                  A\nguided tour\n                  for a concept\n𝑐\n                  assembles definitions/etc. into a self-contained mini-course culminating at\n𝑐.\n\n\n\n\n𝑐=\ncountable\n⤳\n\n\n\n\n\n\n\n \n\n▷...your idea here ...(the sky is the limit)\n\n\n\n:\n12024-12-15\n",
        "sectionId": "abae1049",
        "archive": "talks/voll-ki",
        "filepath": "slides/alea-lss.en.xhtml"
    },
    {
        "slideContent": "\n(Practice/Remedial) Problems Everywhere\n\n▷Problem\nLearning\n                requires a mix of understanding and test-driven practice.\n\n\n▷Idea\nALeA\n                supplies targeted practice problems everywhere.\n\n\n▷Concretely\n                Revision markers at the end of sections.\n\n\n▷A relatively non-intrusive overview over\ncompetency\n\n\n\n\n▷Click to extend it for details.\n\n\n\n\n▷Practice problems as usual.(targeted to your specific\ncompetency)\n\n\n\n\n\n:\n12024-12-14\n",
        "sectionId": "abae1049",
        "archive": "talks/voll-ki",
        "filepath": "slides/problems-everywhere.en.xhtml"
    },
    {
        "slideContent": "\nLocalized Interactions with the Community\n\n▷\n                Selecting\ntext\n                brings up\nlocalized\n                — i.e. anchored on the selection —\ninteractions:\n\n\n\n\n\n\n▷post a (public) comment or take (private) note\n\n\n▷report an\nerror\n                                  to the\ncourse\n                                  authors/instructors\n\n\n\n\n \n\n▷\nLocalized\n                comments induce a thread in the\nALeA\n                forum\n(like the StudOn Forum, but targeted towards specific\nlearning objects.)\n\n\n\n\n▷Answering questions gives\nkarma\n=^\n            a public measure of\nuser\n            helpfulness.\n\n\n▷Notes can be anonymous(⤳\n                generate no\nkarma)\n\n\n\n:\n12024-12-14\n",
        "sectionId": "abae1049",
        "archive": "talks/voll-ki",
        "filepath": "slides/alea-forum.en.xhtml"
    },
    {
        "slideContent": "\nALeA=^\n              Data-Driven & AI-enabled Learning Assistance\n\n\n\n▷Idea\n                                  Do what a teacher does!Use/maintain four models:\n\n\n▷Ingredient 1\nDomain model\n=^\n                                  knowledge/theory graph\n\n\n▷Ingredient 2\nLearner model\n=^\n                                  adding\ncompetency\n                                  estimations\n\n\n▷Ingredient 3\n                                  A collection of ready-formulated\nlearning objects\n\n\n▷Ingredient 4\n                                  Educational dialogue planner\n⤳\nguided tours\n\n\n\n\n\n\n\n\nDomainModel  \n\nLearnerModel  \n\nFormulationModel  \n\nRhetoric/DidacticModel  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDyBN  \n\nPOMDP  \n\nMDP  \n\ntime  \n\npref  \n\nℕ  \n\n≤  \n\nutility  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDyBN   \n\n\n\n\n\nPOMDP   \n\n\n\n\n\nMDP   \n\n\n\n\n\ntime   \n\n\n\n\n\npref   \n\n\n\n\n\n〈ℕ,≤〉   \n\n\n\n\n\nposet   \n\n\n\n\n\nutility   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n            (Good) teachers\n\n\n▷understand the objects and their properties they are talking about\n\n\n▷have readimade formulations how to convey them best\n\n\n▷and understand how these best work together\n\n\n▷model what the\nlearners\n              already\nknow/understand and adapts them accordingly\n\n\nA\ntheory graph\n            provides(modular representation of the\ndomain)\n\n\n▷symbols\n              with\nURIs\n              for all concepts, objects, and relations\n\n\n▷definitions, notations, and verbalizations for all symbols\n\n\n▷“object-oriented inheritance” and views between theories.\n\n\nThe\nlearner model\n            is a\nfunction\n            from\nlearner\n            IDs\n×\nsymbol\nURIs\n            to\ncompetency\n            values\n\n\n▷competency\n              comes in six\ncognitive dimensions:\nremember,\nunderstand,\nanalyze,\nevaluate,\napply, and\ncreate.\n\n\n▷ALeA\n              logs all\nlearner\ninteractions\n(keeps data\nlearner-private)\n\n\n▷each\ninteraction\n              updates the\nlearner model\n              function.\n\n\nLearning objects\n            are the\ntext\n            fragments\nlearners\n            see and\ninteract\n            with; they are structured by\n\n\n▷didactic relations, e.g. tasks have prerequisites and learning objectives\n\n\n▷rhetoric relations, e.g. introduction, elaboration, and transition\n\n\nThe dialogue planner assembles\nlearning objects\n            into\nactive course material\n            using\n\n\n▷the\ndomain model\n              and didactic relations to determine the order of\nLOs\n\n\n▷the\nlearner model\n              to determine what to show\n\n\n▷the rhetoric relations to make the dialogue coherent\n\n\n\n:\n12024-12-16\n",
        "sectionId": "abae1049",
        "archive": "talks/voll-ki",
        "filepath": "slides/gt-ingredients.en.xhtml"
    },
    {
        "slideContent": "\nNew Feature:\nDrilling\n            with\nFlashcards\n\n▷Flashcards\n            challenge you with a\ntask\n            (term/problem) on the\nfront...\n\n\n\n\n...and the definition/answer is on the\nback.\n\n\n▷Self-assessment\n            updates the\nlearner model(before/after)\n\n\n▷Idea\n                Challenge yourself to a\ncard stack, keep drilling/assessing\nflashcards\n                until the\nlearner model\n                eliminates all.\n\n\n▷Bonus\nFlashcards\n                can be generated from existing semantic markup(educational equivalent to free beer)\n\n\n\n:\n12024-12-15\n",
        "sectionId": "abae1049",
        "archive": "talks/voll-ki",
        "filepath": "slides/flashcards.en.xhtml"
    },
    {
        "slideContent": "\nLearner Data and Privacy in\nALeA\n\n▷Observation\nLearning support services\n                  in\nALeA\n                  use the\nlearner model; they\n\n\n▷need the\nlearner model\n                  data to adapt to the invidivual\nlearner!\n\n\n▷collect\nlearner\n                  interaction data(to update the\nlearner model)\n\n\n▷Consequence\n                  You need to be\nlogged in\n                  (via your\nFAU IDM\n                  credentials) for useful\nlearning support services!\n\n\n▷Problem\nLearner model\n                  data is highly sensitive\npersonal data!\n\n\n▷ALeA\n                    Promise\n                  The\nALeA\n                  team does the utmost to keep your\npersonal data\n                  safe.\n(SSO\n                      via\nFAU IDM/eduGAIN,\nALeA\ntrust zone)\n\n\n▷ALeA\n                    Privacy Axioms\n\n\n1.ALeA\n                  only collects\nlearner models\n                  data about\nlogged in\nusers.\n\n\n2.Personally identifiable\nlearner model\n                  data is only accessible to its subject\n(delegation possible)\n\n\n3.Learners\n                  can always query the\nlearner model\n                  about its data.\n\n\n4.All\nlearner model\n                  data can be purged without negative consequences (except usability deterioration)\n\n\n5.Logging into\nALeA\n                  is completely optional.\n\n\n▷Observation\nAuthentication\n                  for bonus\nquizzes\n                  are somewhat less optional, but you can always purge the\nlearner model\n                  later.\n\n\n\n:\n12024-12-16\n",
        "sectionId": "abae1049",
        "archive": "talks/voll-ki",
        "filepath": "slides/alea-privacy.en.xhtml"
    },
    {
        "slideContent": "\nConcrete Todos for\nALeA\n\n▷Recall\n                You will use\nALeA\n                for the\nprepquizzes(or lose bonus points)All other use is optional.\n(but\nAI-supported pre/postparation can be helpful)\n\n\n▷\n                To use the\nALeA\n                system, you will have to\nlog in\n                via\nSSO:(do it now)\n\n\n▷go to\n〈〈aleaURL〉〉,\n\n\n▷in the upper right hand corner you see\n,\n\n\n▷log in\n                via your\nFAU IDM\ncredentials.\n(you should have them by now)\n\n\n▷You get access to your personal\nALeA\n                profile via\n(plus feature notifications, manual, and language chooser)\n\n\n▷Problem\n                Most\nALeA\n                services depend on the\nlearner model.(to adapt to you)\n\n\n▷Solution\n                Initialize your\nlearner model\n                with your\neducational\n                history!\n\n\n▷Concretely: enter taken\nCS\ncourses\n                (FAU equivalents) and\ngrades.\n\n\n▷ALeA\n                uses that to estimate your\nCS/AI\ncompetencies.(for your benefit)\n\n\n▷then\nALeA\n                knows about you; I don’t!\n(ALeA\ntrust zone)\n\n\n\n:\n12024-12-14\n",
        "sectionId": "abae1049",
        "archive": "courses/FAU/meta-inf",
        "filepath": "ALeA/slides/alea-todos.en.xhtml"
    },
    {
        "slideContent": "\nPlot for this\ndocument\n\n▷Motivation, overview, and finding out what you already know\n\n\n▷What is\nArtificial Intelligence?\n\n\n▷What has\nAI\n            already achieved?\n\n\n▷A (very) quick walk through the AI-1 topics.\n\n\n▷How can you get involved with\nAI\n            at\nKWARC?\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-15\n",
        "sectionId": "c19417e6",
        "archive": "courses/FAU/AI/course",
        "filepath": "course/slides/plot.en.xhtml"
    },
    {
        "slideContent": "\nAI1SysProj: A Systems/Project Supplement to AI-1\n\n▷\n                The AI-1\ncourse\n                concentrates on concepts, theory, and\nalgorithms\n                of\nsymbolic AI.\n\n\n▷Problem\n                Engineering/Systems Aspects of\nAI\n                are very important as well.\n\n\n▷Partial Solution\n                Getting your hands dirty in the homeworks and the Kalah Challenge\n\n\n▷Full Solution\n                AI1SysProj: AI-1 Systems Project\n(10\nECTS, 30-50places)\n\n\n▷For each Topic of AI-1, where will be a mini-project in AI1SysProj\n\n\n▷e.g. for game-play there will be Chinese Checkers(more difficult than Kalah)\n\n\n▷e.g. for CSP we will schedule TechFak\ncourses\n                or\nexams(from real data)\n\n\n▷solve challenges by\nimplementing\n                the AI-1\nalgorithms\n                or use SoA systems\n\n\n▷Question\n                Should I take AI1SysProj in my first\nsemester?(i.e. now)\n\n\n▷Answer\n                It depends ...(on your situation)\n\n\n▷most master’s\nprograms\n                require a 10-ECTS\n                “Master’s Project”(Master AI: two)\n\n\n▷there will be a great pressure on project places(so reserve one early)\n\n\n▷BUT 10\nECTS\n=^\n                250-300 hours involvement by definition(1/3 of your time/ECTS)\n\n\n▷BTW\n                There will also be an AI2SysProj next\nsemester!\n(another chance)\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "c19417e6",
        "archive": "courses/FAU/AI/course",
        "filepath": "course/slides/ai1sysproj.en.xhtml"
    },
    {
        "slideContent": "\nWhat is Artificial Intelligence? Definition\n\n\n\n▷According to Wikipedia\nArtificial Intelligence\n                                  (AI) is intelligence exhibited by machines\n\n\n▷also\nArtificial Intelligence\n                                  (AI) is a sub-field of\ncomputer science\n                                  that is concerned with the automation of intelligent behavior.\n\n\n▷BUT\n                                  it is already difficult to define\nintelligence\n                                  precisely.\n\n\n▷Elaine Rich\nArtificial Intelligence\n                                  (AI) studies how we can make the\ncomputer\n                                  do things that humans can still do better at the moment.\n\n\n\n\n\n\n\n\n \n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "b848763f",
        "archive": "courses/FAU/AI/course",
        "filepath": "intro/slides/whatisai.en.xhtml"
    },
    {
        "slideContent": "\nWhat is Artificial Intelligence? Components\n\n▷Elaine Rich\nAI\n                studies how we can make the\ncomputer\n                do things that humans can still do better at the moment.\n\n\n▷This needs a combination of\n\n\nthe ability to learn\n\n\n\nInference\n\n\n\nPerception\n\n\n\nLanguage understanding\n\n\n\nEmotion\n\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-15\n",
        "sectionId": "b848763f",
        "archive": "courses/FAU/AI/course",
        "filepath": "intro/slides/whatisai-parts.en.xhtml"
    },
    {
        "slideContent": "\nArtificial Intelligence is here today!\n\n\n\n▷in outer space\n\n\n▷in outer space systems need autonomous control:\n\n\n▷remote control impossible due to time lag\n\n\n▷in artificial limbs\n\n\n▷the user controls the prosthesis via existing nerves, can e.g. grip a sheet of paper.\n\n\n▷in household appliances\n\n\n▷The iRobot Roomba vacuums, mops, and sweeps in corners, ..., parks, charges, and discharges.\n\n\n▷general robotic household help is on the horizon.\n\n\n▷in hospitals\n\n\n▷in the USA\n90%\n                              of the prostate operations are carried out by RoboDoc\n\n\n▷Paro is a cuddly robot that eases solitude in nursing homes.\n\n\n▷for safety/security\n\n\n▷e.g. Intel verifies\ncorrectness\n                              of all chips after the “Pentium 5 disaster”\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-16\n",
        "sectionId": "71113176",
        "archive": "courses/FAU/AI/course",
        "filepath": "intro/slides/aiexists.en.xhtml"
    },
    {
        "slideContent": "\nThe\nAI\n              Conundrum\n\n▷Observation\n                  Reserving the\nterm\n                  “Artificial Intelligence” has been quite a land grab!\n\n\n▷But\n                  researchers at the\nDartmouth Conference\n                  (1956) really\nthought\n                  they would solve/reach\nAI\n                  in two/three decades.\n\n\n▷Consequence\nAI\n                  still asks the big\nquestions.(and still promises answers soon)\n\n\n▷Another Consequence\nAI\n                  as a field is an incubator for many innovative technologies.\n\n\n▷AI Conundrum\n                  Once\nAI\n                  solves a subfield it is called “computer science”.(becomes a separate subfield of\nCS)\n\n\n▷\n                  Functional/Logic Programming,\nautomated theorem proving,\nPlanning,\nmachine learning,\nKnowledge Representation, ...\n\n▷Still Consequence\nAI\n                  research was alternatingly flooded with money and cut off brutally.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-16\n",
        "sectionId": "71113176",
        "archive": "courses/FAU/AI/course",
        "filepath": "intro/slides/ai-conundrum.en.xhtml"
    },
    {
        "slideContent": "\nThe current AI Hype ― Part of a longer Story\n\n▷The history of\nAI\n              as a\ndiscipline\n              has been very much tied to the amount of funding — that allows us to do research and development.\n\n\n▷Funding levels are tied to public perception of success(especially for\nAI)\n\n\n▷\n                  An\nAI winter\n                  is a time period of low public perception and funding for\nAI,\nmostly because\nAI\n                  has failed to deliver on its — sometimes overblown — promisesAn\nAI summer\n                  is a time period of high public perception and funding for\nAI\n\n\n▷A potted history of\nAI\n(AI summers\n                  and\nsummers)\n\n\n\n\n\n\n\n\n\n\n\n\nAI becomes scarily effective, ubiquitous\n   \n\n\n\n\nExcitement fades; some applications profit a lot\n   \n\n\n\n\nAI-bubble bursts, the next AI winter comes\n   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1950  \n1960  \n1970  \n1980  \n1990  \n2000  \n2010  \n2021  \n\n\n\n\n  \nTuring Test  \n\n\n\n\n  \n\nDartmouth Conference  \n\n\n\n\n  \n\nLighthill report  \n\n\n\n\n  \n\nAI Winter 11974-1980   \n\n\n\n\n  \n\nAI Winter 21987-1994   \n\n\n\n\n  \n\n\nWWW\n⤳\n                                                              Data/Computing Explosion\n  \n\n\n\n\n  \n\n\nAI-consequences, Biases, Regulation\n  \n\n\n\n \n\n\n:\n12024-12-16\n",
        "sectionId": "71113176",
        "archive": "mkohlhase/talks",
        "filepath": "AI/slides/ai-summer-winter.en.xhtml"
    },
    {
        "slideContent": "\nTwo ways of reaching Artificial Intelligence?\n\n▷We can classify the\nAI\n              approaches by their coverage and the analysis depth(they are complementary)\n\n\nDeep symbolic not there yet AI-1 cooperation?Shallow no-one wants this statistical/sub symbolicAI-2Analysis ↑ vs. Narrow Wide Coverage → \n\n\nThis semester\n                  we will cover foundational aspects of\nsymbolic AI\n(deep/narrow processing)\n\n\n▷\n\n▷next semester\n                  concentrate on\nstatistical/subsymbolic AI.\n(shallow/wide-coverage)\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "cc59afff",
        "archive": "courses/FAU/AI/course",
        "filepath": "intro/slides/ai-state.en.xhtml"
    },
    {
        "slideContent": "\nEnvironmental Niches for both Approaches to\nAI\n\n▷Observation\n                  There are two kinds of applications/tasks in\nAI\n\n\n▷Consumer tasks: consumer grade applications have tasks that must be fully generic and wide coverage.\n(\n                        e.g. machine translation like\nGoogle Translate)\n\n\n▷Producer tasks: producer grade applications must be high-precision, but can be domain-specific\n(e.g. multilingual documentation, machinery-control, program verification, medical technology)\n\n\nPrecision 100% Producer Tasks 50% Consumer Tasks 103±1 Concepts 106±1 Concepts Coverage\n\n\nafter Aarne Ranta [Ran17].\n\n\n▷General Rule\nSubsymbolic AI\n                  is well suited for\nconsumer tasks, while\nsymbolic AI\n                  is better suited for\nproducer tasks.\n\n\n▷A domain of\nproducer tasks\n              I am interested in:\nmathematical/technical documents.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "cc59afff",
        "archive": "courses/FAU/AI/course",
        "filepath": "intro/slides/ai-producer-consumer.en.xhtml"
    },
    {
        "slideContent": "\nStrong AI vs. Narrow AI\n\n▷\n                  With the term\nnarrow AI\n                  (also\nweak AI,\ninstrumental AI,\napplied AI) we refer to the use of software to study or accomplish\nspecific\n                  problem solving or reasoning tasks\n(e.g. playing\nchess/go, controlling elevators, composing music, ...)\n\n\n▷\n                  With the term\nstrong AI\n                  (also\nfull AI,\nAGI) we denote the quest for software performing at the full range of human cognitive abilities.\n\n\n▷\n                  Problems requiring\nstrong AI\n                  to solve are called\nAI hard, and\nAI complete, iff\nAGI\n                  should be able to solve them all.\n\n\n▷In short\n                  We can characterize the difference intuitively:\n\n\n▷narrow AI: What (most)\ncomputer scientists\n                  think AI is / should be.\n\n\n▷strong AI: What\nHollywood\n                  authors think AI is / should be.\n\n\n▷Needless to saywe are only going to cover\nnarrow AI\n                  in this\ncourse!\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "f818be76",
        "archive": "courses/FAU/AI/course",
        "filepath": "intro/slides/ai-strong-weak.en.xhtml"
    },
    {
        "slideContent": "\nA few words on AGI...\n\n▷The conceptual and\nmathematical\n              framework (agents,\nenvironments\n              etc.) is the same for\nstrong AI\n              and\nweak AI.\n\n\n▷AGI\n              research focuses mostly on\nabstract\n              aspects of machine learning (reinforcement learning, neural nets) and decision/game theory (“which\ngoals\n              should an AGI pursue?”).\n\n\n▷Academic respectability of\nAGI\n              fluctuates massively, recently increased (again).\n(correlates somewhat with AI winters and golden years)\n\n\n▷Public attention increasing due to talk of “existential risks of\nAI”\n(e.g. Hawking, Musk, Bostrom, Yudkowsky, Obama, ...)\n\n\n▷Kohlhase’s View\nWeak AI\n                  is here,\nstrong AI\n                  is very far off.\n(not in my lifetime)\n\n\n▷\n\n                  But even if that is\ntrue,\nweak AI\n                  will affect all of us deeply in everyday life.\n\n\n▷\n                  You should not train to be an accountant or truck driver!(bots will replace you soon)\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-16\n",
        "sectionId": "f818be76",
        "archive": "courses/FAU/AI/course",
        "filepath": "intro/slides/agi.en.xhtml"
    },
    {
        "slideContent": "\nAGI Research and Researchers\n\n▷“Famous” research(ers) / organizations\n\n\n▷MIRI (Machine Intelligence Research Institute), Eliezer Yudkowsky\n(Formerly known as “Singularity Institute”)\n\n\n▷Future of Humanity Institute Oxford (Nick Bostrom),\n\n\n▷Google (Ray Kurzweil),\n\n\n▷AGIRI / OpenCog (Ben Goertzel),\n\n\n▷petrl.org\n              (People for the Ethical Treatment of Reinforcement Learners).\n(Obviously somewhat tongue-in-cheek)\n\n\n\n                  Be highly skeptical about any claims with respect to\nAGI!(Kohlhase’s View)\n\n\n▷\n\n\nMichael Kohlhase:\nArtificial Intelligence 122024-12-16\n",
        "sectionId": "f818be76",
        "archive": "courses/FAU/AI/course",
        "filepath": "intro/slides/agi.en.xhtml"
    },
    {
        "slideContent": "\nTopics of AI-1 (Winter Semester)\n\n▷Getting Started\n\n\n▷What is\nArtificial Intelligence?(situating ourselves)\n\n\n▷Logic programming\n              in\nProlog(An influential\nparadigm)\n\n\n▷Intelligent Agents(a unifying framework)\n\n\n▷Problem Solving\n\n\n▷Problem Solving and\nsearch(Black Box World States and Actions)\n\n\n▷Adversarial search\n              (Game playing)(A nice application of\nsearch)\n\n\n▷constraint satisfaction problems\n(Factored World States)\n\n\n▷Knowledge and Reasoning\n\n\n▷Formal Logic as the\nmathematics\n              of Meaning\n\n\n▷Propositional logic\n              and\nsatisfiability(Atomic Propositions)\n\n\n▷First-order logic\n              and\ntheorem proving(Quantification)\n\n\n▷Logic programming(Logic + Search⤳\n                  Programming)\n\n\n▷Description logics\n              and\nsemantic web\n\n\n▷Planning\n\n\n▷Planning Frameworks\n\n\n▷Planning Algorithms\n\n\n▷Planning and Acting in the real world\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "f9e5eb14",
        "archive": "courses/FAU/AI/course",
        "filepath": "course/slides/ai1-topics.en.xhtml"
    },
    {
        "slideContent": "\nTopics of AI-2 (Summer Semester)\n\n▷Uncertain\n            Knowledge and Reasoning\n\n\n▷Uncertainty\n\n\n▷Probabilistic reasoning\n\n\n▷Making Decisions in Episodic Environments\n\n\n▷Problem Solving in Sequential Environments\n\n\n▷Foundations of\nmachine learning\n\n\n▷Learning from Observations\n\n\n▷Knowledge in Learning\n\n\n▷Statistical Learning Methods\n\n\n▷Communication(If there is time)\n\n\n▷Natural Language Processing\n\n\n▷Natural Language\n            for Communication\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-16\n",
        "sectionId": "f9e5eb14",
        "archive": "courses/FAU/AI/course",
        "filepath": "course/slides/ai2-topics.en.xhtml"
    },
    {
        "slideContent": "\nThe\nKWARC\n              Research Group\n\n▷Observation\n                  The ability to\nrepresent knowledge\n                  about the world and to\ndraw logical inferences\n                  is one of the central components of\nintelligent behavior.\n\n\n▷Thus\n                  reasoning components of some form are at the heart of many AI systems.\n\n\n▷KWARC Angle\n                  Scaling up (web-coverage) without dumbing down (too much)\n\n\n▷Content markup\n                  instead of full formalization(too tedious)\n\n\n▷User support\n                  and\nquality control\n                  instead of “The Truth”(elusive anyway)\n\n\n▷use\nMathematics\n                  as a test tube(\nMathematics\n=^\n                        Anything Formal\n\n                    )\n\n\n▷care more about applications than about philosophy(we cannot help getting this right anyway as logicians)\n\n\n▷The\nKWARC\n              group was established at Jacobs Univ. in 2004, moved to FAU Erlangen in 2016\n\n\n▷see\nhttp://kwarc.info\n              for projects, publications, and links\n\n\n\n:\n12024-12-14\n",
        "sectionId": "b22e51b3",
        "archive": "mkohlhase/talks",
        "filepath": "kwarc/slides/nutshell.en.xhtml"
    },
    {
        "slideContent": "\nOverview: KWARC Research and Projects\n\n\nApplications:\neMath 3.0, Active Documents, Active Learning, Semantic Spreadsheets/CAD/CAM, Change Mangagement, Global Digital Math Library, Math Search Systems,\n𝖲𝖬𝖦𝗅𝗈𝖬: Semantic Multilingual Math Glossary, Serious Games, ...\n\nFoundations of Math:\n\n▷MathML,\n𝑂𝑝𝑒𝑛𝑀𝑎𝑡ℎ\n\n\n▷advanced Type Theories\n\n\n▷Mmt: Meta Meta Theory\n\n\n▷Logic Morphisms/Atlas\n\n\n▷Theorem Prover/CAS Interoperability\n\n\n▷Mathematical Models/Simulation\n\n\n\n\nKM & Interaction:\n\n▷Semantic Interpretation (aka. Framing)\n\n\n▷math-literate interaction\n\n\n▷𝖬𝖺𝗍𝗁𝖧𝗎𝖻: math archives & active docs\n\n\n▷Active documents: embedded semantic services\n\n\n▷Model-based Education\n\n\n\n\nSemantization:\n\n▷\nLATEXML\n:\nLATEX\n⤳\nXML\n\n\n▷STEX: Semantic\nLATEX\n\n\n▷invasive editors\n\n\n▷Context-Aware IDEs\n\n\n▷Mathematical Corpora\n\n\n▷Linguistics of Math\n\n\n▷ML for Math Semantics Extraction\n\n\n\n\nFoundations: Computational Logic, Web Technologies,\n𝖮𝖬𝖣𝗈𝖼/Mmt\n\n\n\n\n\n:\n12024-12-15\n",
        "sectionId": "b22e51b3",
        "archive": "mkohlhase/talks",
        "filepath": "kwarc/slides/projectplan.en.xhtml"
    },
    {
        "slideContent": "\nResearch Topics in the KWARC Group\n\n▷We are always looking for bright, motivated KWARCies.\n\n\n▷We have topics in for all levels!\n(Enthusiast, Bachelor, Master, Ph.D.)\n\n\n▷List of current topics:\nhttps://gl.kwarc.info/kwarc/thesis-projects/\n\n\n▷Automated Reasoning: Maths Representation in the Large\n\n\n▷Logics development, (Meta)\n𝑛\n-Frameworks\n\n\n▷Math Corpus Linguistics: Semantics Extraction\n\n\n▷Serious Games, Cognitive Engineering, Math Information Retrieval, Legal Reasoning, ...\n\n▷...last but not least: KWARC is the home of\nALeA!\n\n\n▷We always try to find a topic at the intersection of your and our interests.\n\n\n▷We also sometimes have positions!.\n(HiWi, Ph.D.:\n12\n                E-13, PostDoc: full E-13)\n\n\n\n:\n12024-12-14\n",
        "sectionId": "b22e51b3",
        "archive": "mkohlhase/talks",
        "filepath": "kwarc/slides/topics.en.xhtml"
    },
    {
        "slideContent": "\nEnough philosophy about “Intelligence” (Artificial or Natural)\n\n▷So far we had a nice philosophical chat, about “intelligence” et al.\n\n\n▷As of today, we look at technical stuff!\n\n\n▷Before we go into the\nalgorithms\n            and\ndata structures\n            proper, we will\n\n\n1.introduce a\nprogramming language\n            for AI-1\n\n\n2.prepare a conceptual framework in which we can think about “intelligence” (natural and artificial), and\n\n\n3.recap some methods and results from theoretical\ncomputer science.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-16\n",
        "sectionId": "707e8051",
        "archive": "courses/FAU/AI/course",
        "filepath": "course/slides/enough.en.xhtml"
    },
    {
        "slideContent": "\nLogic Programming\n\n▷Idea\n                  Use\nlogic\n                  as a\nprogramming language!\n\n\n▷We state what we know about a problem (the\nprogram) and then ask for results (what the\nprogram\n              would compute).\n\n\n▷\n\nProgram Leibniz is human 𝑥+0=𝑥Sokrates is human If 𝑥+𝑦=𝑧 then 𝑥+𝑠(𝑦)=𝑠(𝑧)Sokrates is a greek 3 is primeEvery human is fallible Query Are there fallible greeks? is there a 𝑧 with 𝑠(𝑠(0))+𝑠(0)=𝑧Answer Yes, Sokrates! yes 𝑠(𝑠(𝑠(0)))\n\n\n▷How to achieve this?\n                  Restrict a\nlogic calculus\n                  sufficiently that it can be used as computational procedure.\n\n\n▷Remark\n                  This idea leads a totally new\nprogramming paradigm:\nlogic programming.\n\n\n▷Slogan\nComputation = Logic + Control(Robert Kowalski 1973; [Kow97])\n\n\n▷We will use the\nprogramming language\nProlog\n              as an example.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "ca07c077",
        "archive": "courses/FAU/AI/course",
        "filepath": "prolog/slides/logic-programming-intro.en.xhtml"
    },
    {
        "slideContent": "\nProlog\nTerms\n              and\nLiterals\n\n▷\nProlog\n                  expresses\nknowledge\n                  about the world via\n\n\n▷constants\n                  denoted by\nlowercase\nstrings,\n\n\n▷variables\n                  denoted by\nstrings\n                  starting with an\nuppercase\nletter\n                  or\n_, and\n\n\n▷functions\n                  and\npredicates\n                  (lowercase\nstrings) applied to\nterms.\n\n\n▷\n                  A\nProlog\nterm\n                  is\n\n\n▷a\nProlog\nvariable, or\nconstant, or\n\n\n▷a\nProlog\nfunction\n                  applied to\nterms.\n\n\nA\nProlog\nliteral\n                  is a\nconstant\n                  or a\npredicate\n                  applied to\nterms.\n\n\n▷\n                  The following are\n\n\n▷Prolog\nterms:\njohn,\nX,\n_,\nfather(john), ...\n\n▷Prolog\nliterals:\nloves(john,mary),\nloves(john,_),\nloves(john,wife_of(john)),...\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "ca07c077",
        "archive": "courses/FAU/AI/course",
        "filepath": "prolog/slides/prolog-terms.en.xhtml"
    },
    {
        "slideContent": "\nProlog Programs:\nFacts\n              and\nRules\n\n▷A\nProlog program\n                  is a sequence of\nclauses, i.e.\n\n\n▷facts\n                  of the form\n𝑙., where\n𝑙\n                  is a\nliteral,(a\nliteral\n                      and a dot)\n\n\n▷rules\n                  of the form\nℎ:―𝑏1,...,𝑏𝑛., where\nℎ\n                  is called the\nhead literal\n                  (or simply\nhead) and the\n𝑏𝑖\n                  are together called the\nbody\n                  of the\nrule.\n\n\nA\nrule\nℎ:―𝑏1,...,𝑏𝑛., should be read as\nℎ\n                    (is\ntrue) if\n𝑏1\n                    and\n...\n                    and\n𝑏𝑛\n                    are.\n\n\n▷Write “something is a car if it has a motor and four wheels” ascar(X) :― has_motor(X),has_wheels(X,4).(variables\n                      are\nuppercase)This is just an\nASCII\n                  notation for\n𝑚(𝑥)∧𝑤(𝑥,4)⇒𝑐𝑎𝑟(𝑥).\n\n\n▷\n                  The following is a\nProlog\nprogram:\n\n\nhuman(leibniz).\nhuman(sokrates).\ngreek(sokrates).\nfallible(X):―human(X).\n\nThe first three lines are\nProlog\nfacts\n                  and the last a\nrule.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "ca07c077",
        "archive": "courses/FAU/AI/course",
        "filepath": "prolog/slides/facts-rules.en.xhtml"
    },
    {
        "slideContent": "\nProlog Programs:\nKnowledge bases\n\n▷Intuition\n                  The\nknowledge base\n                  given by a\nProlog\nprogram\n                  is the set of\nfacts\n                  that can be derived from it under the if/and reading above.\n\n\n▷\n                  The\nknowledge base\n                  given by\nProlog\nprogram\n                  is that\nset\n                  of\nfacts\n                  that can be\nderived\n                  from it by Modus Ponens (MP),\n∧𝐼\n                  and instantiation.\n𝐴𝐴⇒𝐵𝐵MP𝐴𝐵𝐴∧𝐵∧𝐼𝐀[𝐁/𝑋](𝐀)Subst\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "ca07c077",
        "archive": "courses/FAU/AI/course",
        "filepath": "prolog/slides/prolog-kb.en.xhtml"
    },
    {
        "slideContent": "\nQuerying\n              the\nKnowledge Base: Size Matters\n\n▷Idea\n                  We want to see whether a\nfact\n                  is in the\nknowledge base.\n\n\n▷\n                  A\nquery\n                  is a list of\nProlog\nliterals\n                  called\ngoal literal\n                  (also\nsubgoals\n                  or simply\ngoals). We write a\nquery\n                  as\n?―𝐴1,...,𝐴𝑛.\n                  where\n𝐴𝑖\n                  are\ngoals.\n\n\n▷Problem\nKnowledge bases\n                  can be big and even\ninfinite.(cannot pre-compute)\n\n\n▷\n                  The\nknowledge base\n                  induced by the\nProlog\nprogram\n\n\nnat(zero).\nnat(s(X)) :― nat(X).\n\ncontains the\nfacts\nnat(zero),\nnat(s(zero)),\nnat(s(s(zero))), ...\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "ca07c077",
        "archive": "courses/FAU/AI/course",
        "filepath": "prolog/slides/kb-query.en.xhtml"
    },
    {
        "slideContent": "\nQuerying\n              the\nKnowledge Base:\nBackchaining\n\n▷\n                  Given a\nquery\n𝑄:\n?― 𝐴1,...,𝐴𝑛.\n                  and\nrule\n𝑅:\nℎ:― 𝑏1,...,𝑏𝑛,\nbackchaining\n                  computes a new\nquery\n                  by\n\n\n1.finding\nterms\n                  for all\nvariables\n                  in\nℎ\n                  to make\nℎ\n                  and\n𝐴1\n                  equal and\n\n\n2.replacing\n𝐴1\n                  in\n𝑄\n                  with the\nbody\nliterals\n                  of\n𝑅, where all\nvariables\n                  are suitably replaced.\n\n\n▷Backchaining\n              motivates the names\ngoal/subgoal:\n\n\n▷the\nliterals\n              in the\nquery\n              are “goals” that have to be satisfied,\n\n\n▷backchaining\n              does that by replacing them by new “goals”.\n\n\n\n                  The\nProlog\ninterpreter\n                  keeps\nbackchaining\n                  from the top to the bottom of the\nprogram\n                  until the\nquery\n\n\n▷▷succeeds, i.e. contains no more\ngoals, or\n(answer:\ntrue)\n\n\n▷fails, i.e.\nbackchaining\n                  becomes impossible.(answer:\nfalse)\n\n\nBackchaining\n                  We continue\n??\n\n\n?― nat(s(s(zero))).\n?― nat(s(zero)).\n?― nat(zero).\ntrue\n\n▷\n\n\nMichael Kohlhase:\nArtificial Intelligence 122024-12-14\n",
        "sectionId": "ca07c077",
        "archive": "courses/FAU/AI/course",
        "filepath": "prolog/slides/kb-query.en.xhtml"
    },
    {
        "slideContent": "\nQuerying the Knowledge Base: Failure\n\n▷If no instance of a\nquery\n              can be derived from the\nknowledge base, then the\nProlog\ninterpreter\n              reports\nfailure.\n\n\n▷\n                  We vary\n??\n                  using\n0\n                  instead of\nzero.\n\n\n?― nat(s(s(0))).\n?― nat(s(0)).\n?― nat(0).\nFAIL\nfalse\n\n\nMichael Kohlhase:\nArtificial Intelligence 132024-12-14\n",
        "sectionId": "ca07c077",
        "archive": "courses/FAU/AI/course",
        "filepath": "prolog/slides/kb-query.en.xhtml"
    },
    {
        "slideContent": "\nQuerying\n              the\nKnowledge base:\nAnswer Substitutions\n\n▷\n                  If a\nquery\n                  contains\nvariables, then\nProlog\n                  will return an\nanswer substitution\n                  as the\nresult\n                  to the\nquery, i.e the\nvalues\n                  for all the\nquery\nvariables\n                  accumulated during repeated\nbackchaining.\n\n\n▷\n                  We talk about (Bavarian) cars for a change, and use a\nquery\n                  with a\nvariables\n\n\nhas_wheels(mybmw,4).\nhas_motor(mybmw).\ncar(X):―has_wheels(X,4),has_motor(X).\n?― car(Y) % query\n?― has_wheels(Y,4),has_motor(Y). % substitution X = Y\n?― has_motor(mybmw). % substitution Y = mybmw\nY = mybmw % answer substitution\ntrue\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "ca07c077",
        "archive": "courses/FAU/AI/course",
        "filepath": "prolog/slides/answersubst.en.xhtml",
        "video_name": "AI1_25thDec.m4v",
        "start_time": 3906.6,
        "end_time": 3927.7
    },
    {
        "slideContent": "\nPROLOG: Are there Fallible Greeks?\n\n▷Program\n\n\nhuman(leibniz).\nhuman(sokrates).\ngreek(sokrates).\nfallible(X):―human(X).\n\n▷Query\n?―fallible(X),greek(X).\n\n\n▷Answer substitution\n[sokrates/𝑋]\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "ca07c077",
        "archive": "courses/FAU/AI/course",
        "filepath": "prolog/slides/fallible-greeks.en.xhtml"
    },
    {
        "slideContent": "\nDepth-First Search\n              with\nBacktracking\n\n▷So far, all the examples led to direct\nsuccess\n              or to\nfailure.\n(simple KB)\n\n\n▷Prolog\n                    Search Procedure\n                  The\nProlog\ninterpreter\n                  employs top-down, left-right\ndepth first search, concretely,\nProlog search:\n\n\n▷works on the\nsubgoals\n                  in left right order.\n\n\n▷matches\n                  first\nquery\n                  with the\nhead\nliterals\n                  of the\nclauses\n                  in the\nprogram\n                  in top-down order.\n\n\n▷if there are no\nmatches,\nfail\n                  and\nbacktracks\n                  to the (chronologically) last\nbacktrack point.\n\n\n▷otherwise\nbackchain\n                  on the first\nmatch, keep the other\nmatches\n                  in mind for\nbacktracking\n                  via\nbacktrack points.\n\n\nWe say that a\ngoal\n𝐺\nmatches\n                  a\nhead\n𝐻,\niff\n                  we can make them\nequal\n                  by replacing\nvariables\n                  in\n𝐻\n                  with\nterms.\n\n\n▷We can force\nbacktracking\n                  to\ncompute\n                  more\nanswers\n                  by typing\n;.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "18228faf",
        "archive": "courses/FAU/AI/course",
        "filepath": "prolog/slides/DFS-back.en.xhtml"
    },
    {
        "slideContent": "\nBacktracking\n              by Example\n\n▷\n                  We extend\n??:\n\n\nhas_wheels(mytricycle,3).\nhas_wheels(myrollerblade,3).\nhas_wheels(mybmw,4).\nhas_motor(mybmw).\ncar(X):-has_wheels(X,3),has_motor(X). % cars sometimes have three wheels\ncar(X):-has_wheels(X,4),has_motor(X). % and sometimes four.\n?- car(Y).\n?- has_wheels(Y,3),has_motor(Y). % backtrack point 1\nY = mytricycle % backtrack point 2\n?- has_motor(mytricycle).\nFAIL % fails, backtrack to 2\nY = myrollerblade % backtrack point 2\n?- has_motor(myrollerblade).\nFAIL % fails, backtrack to 1\n?- has_wheels(Y,4),has_motor(Y).\nY = mybmw\n?- has_motor(mybmw).\nY=mybmw\ntrue\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-15\n",
        "sectionId": "18228faf",
        "archive": "courses/FAU/AI/course",
        "filepath": "prolog/slides/DFS-back-ex.en.xhtml"
    },
    {
        "slideContent": "\nMore Examples from elementary\nArithmetic\n\n▷\n                  We can also use the\nadd\n                  relation for subtraction without changing the\nimplementation. We just use\nvariables\n                  in the “input positions” and ground\nterms\n                  in the other two.\n(possibly very inefficient “generate and test\n                      approach”)\n\n\n?―add(s(zero),X,s(s(s(zero)))).\nX = s(s(zero))\ntrue\n\n▷Computing the\n𝑛\nth\n\nFibonacci number\n                  (0, 1, 1, 2, 3, 5, 8, 13,...; add the last two to get the next), using the\naddition\npredicate\n                  above.\n\n\nfib(zero,zero).\nfib(s(zero),s(zero)).\nfib(s(s(X)),Y):―fib(s(X),Z),fib(X,W),add(Z,W,Y).\n\n▷\n                  Using\nProlog’s internal\nfloating-point arithmetic: a\ngoal\n                  of the form\n?― D is 𝑒.\n                  ― where\n𝑒\n                  is a\nground\narithmetic\nexpression\n                  binds\n𝐷\n                  to the result of evaluating\n𝑒.\n\n\nfib(0,0).\nfib(1,1).\nfib(X,Y):― D is X ― 1, E is X ― 2,fib(D,Z),fib(E,W), Y is Z + W.\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "2cc7e59a",
        "archive": "courses/FAU/AI/course",
        "filepath": "prolog/slides/prolog-arithmetics.en.xhtml"
    },
    {
        "slideContent": "\nAdding Lists to\nProlog\n\n▷\n                  In\nProlog,\nlists\n                  are\nrepresented\n                  by\nlist terms\n                  of the form\n\n\n1.[a,b,c,...]\n                  for\nlist\nliterals, and\n\n\n2.a\nfirst/rest\nconstructor\n                  that\nrepresents\n                  a\nlist\n                  with\nhead\nF\n                  and\nrest list\nR\n                  as\n[F|R].\n\n\n▷Observation\n                  Just as in\nfunctional programming, we can define\nlist\n                  operations by\nrecursion, only that we\nprogram\n                  with\nrelations\n                  instead of with\nfunctions.\n\n\n▷\nPredicates\n                  for\nmember,\nappend\n                  and\nreverse\n                  of\nlists\n                  in default\nProlog\nrepresentation.\n\n\nmember(X,[X|_]).\nmember(X,[_|R]):―member(X,R).\n\nappend([],L,L).\nappend([X|R],L,[X|S]):―append(R,L,S).\n\nreverse([],[]).\nreverse([X|R],L):―reverse(R,S),append(S,[X],L).\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "2cc7e59a",
        "archive": "courses/FAU/AI/course",
        "filepath": "prolog/slides/prolog-lists.en.xhtml"
    },
    {
        "slideContent": "\nRelational Programming Techniques\n\n▷\n                  Parameters have no unique direction “in” or “out”\n\n\n?― rev(L,[1,2,3]).\n?― rev([1,2,3],L1).\n?― rev([1|X],[2|Y]).\n\n▷\n                  Symbolic programming by\nstructural induction:\n\n\nrev([],[]).\nrev([X|Xs],Ys) :― ...\n\n▷\nGenerate and test:\n\n\nsort(Xs,Ys) :― perm(Xs,Ys), ordered(Ys).\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "2cc7e59a",
        "archive": "courses/FAU/AI/course",
        "filepath": "prolog/slides/relational-programming.en.xhtml"
    },
    {
        "slideContent": "\nSpecifying Control in\nProlog\n\n▷\n                  The\nrunning time\n                  of the\nprogram\n                  from\n??\n                  is not\n𝒪(𝑛log2(𝑛))\n                  which is optimal for sorting\nalgorithms.\n\n\nsort(Xs,Ys) :― perm(Xs,Ys), ordered(Ys).\n\n▷Idea\n                  Gain\ncomputational\nefficiency\n                  by shaping the\nsearch!\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-15\n",
        "sectionId": "202fd840",
        "archive": "courses/FAU/AI/course",
        "filepath": "prolog/slides/prolog-control.en.xhtml"
    },
    {
        "slideContent": "\nFunctions and Predicates in\nProlog\n\n▷\nFunctions\n                  and\npredicates\n                  have radically different roles in\nProlog.\n\n\n▷Functions\n                  are used to\nrepresent\ndata.\n(e.g.\nfather(john)\n                      or\ns(s(zero)))\n\n\n▷Predicates\n                  are used for stating properties about and\ncomputing\n                  with\ndata.\n\n\n▷\n                  In\nfunctional programming,\nfunctions\n                  are used for both.(even more confusing than in\nProlog\n                      if you think about it)\n\n\n▷\n                  Consider again the\nreverse\n                  predicate for\nlists\n                  below:An input datum is e.g.\n[1,2,3], then the output datum is\n[3,2,1].\n\n\nreverse([],[]).\nreverse([X|R],L):―reverse(R,S),append(S,[X],L).\n\nWe “define” the computational behavior of the\npredicate\nrev, but the list constructors\n[...]\n                  are just used to construct lists from arguments.\n\n\n▷Trees and Leaf Counting\n                  We represent (unlabelled) trees via the function\nt\n                  from tree lists to trees. For instance, a\nbalanced binary tree\n                  of depth 2 is\nt([t([t([]),t([])]),t([t([]),t([])])]). We count leaves by\n\n\nleafcount(t([]),1).\nleafcount(t([V]),W) :― leafcount(V,W).\nleafcount(t([X|R]),Y) :― leafcount(X,Z), leafcount(t(R),W), Y is Z + W.\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "202fd840",
        "archive": "courses/FAU/AI/course",
        "filepath": "prolog/slides/functions-predicates.en.xhtml"
    },
    {
        "slideContent": "\nFor more information on\nProlog\n\n\nRTFM\n                    (=^\n                    “read the fine manuals”)\n\n\n▷RTFM Resources\n                  There are also lots of good tutorials on the web,\n\n\n▷I personally like [Fis;\nLPN],\n\n\n▷[Fla94] has a very thorough logic-based introduction,\n\n\n▷consult also the SWI Prolog Manual [SWI],\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-15\n",
        "sectionId": "202fd840",
        "archive": "courses/FAU/AI/course",
        "filepath": "prolog/slides/rtfm.en.xhtml"
    },
    {
        "slideContent": "\nPerformance and Scaling\n\n▷Suppose we have three\nalgorithms\n              to choose from.(which one to select)\n\n\n▷Systematic analysis reveals performance characteristics.\n\n\n▷\n                  For a\ncomputational problem\n                  of size\n𝑛\n                  we have\n\n\nperformancesize linear quadratic exponential𝑛 100𝑛𝜇s 7𝑛2𝜇s 2𝑛𝜇s1 100𝜇s 7𝜇s 2𝜇s5 .5ms 175𝜇s 32𝜇s10 1ms .7ms 1ms45 4.5ms 14ms 1.1𝑌 100 .........1000 .........10000 .........1000000 .........\n\n\n\n:\n12024-12-14\n",
        "sectionId": "3d002f21",
        "archive": "courses/Jacobs/GenCS/course",
        "filepath": "course/slides/CS-sample-performance.en.xhtml"
    },
    {
        "slideContent": "\nWhat?! One year?\n\n▷210=1024(1024𝜇s≃1ms)\n\n\n▷245=35184372088832(3.5×1013𝜇s≃3.5×107s≃1.1𝑌)\n\n\n▷\nWe denote all times that are longer than the age of the universe with\n−\n\n\nperformancesize linear quadratic exponential𝑛 100𝑛𝜇s 7𝑛2𝜇s 2𝑛𝜇s1 100𝜇s 7𝜇s 2𝜇s5 .5ms 175𝜇s 32𝜇s10 1ms .7ms 1ms45 4.5ms 14ms 1.1𝑌 < 100 100ms 7s 1016𝑌 1000 1s 12min − 10000 10s 20h − 1000000 1.6min 2.5mon − \n\n\n\n:\n22024-12-14\n",
        "sectionId": "3d002f21",
        "archive": "courses/Jacobs/GenCS/course",
        "filepath": "course/slides/CS-sample-performance.en.xhtml"
    },
    {
        "slideContent": "\nRecap: Time/Space Complexity of Algorithms\n\n▷We are mostly interested in\nworst-case\ncomplexity\n              in AI-1.\n\n\n▷\n                  We say that an\nalgorithm\n𝛼\n                  that\nterminates\n                  in time\n𝑡(𝑛)\n                  for all\ninputs\n                  of\nsize\n𝑛\n                  has\nrunning time\n𝑇(𝛼):=𝑡.\n\nLet\n𝑆⊆ℕ→ℕ\n                  be a set of\nnatural number\nfunctions, then we say that\n𝛼\n                  has\ntime complexity\n                  in\n𝑆\n                  (written\n𝑇(𝛼)∊𝑆\n                  or colloquially\n𝑇(𝛼)=𝑆), iff\n𝑡∊𝑆. We say\n𝛼\n                  has\nspace complexity\n                  in\n𝑆, iff\n𝛼\n                  uses only\nmemory\n                  of size\n𝑠(𝑛)\n                  on inputs of size\n𝑛\n                  and\n𝑠∊𝑆.\n\n\n▷\nTime/space complexity\n                  depends on size measures.(no canonical one)\n\n\n▷The following\nsets\n                  are often used for\n𝑆\n                  in\n𝑇(𝛼):\n\n\nLandau set class name rank Landau set class name rank𝒪(1) constant 1 𝒪(𝑛2) quadratic 4𝒪(log2(𝑛)) logarithmic 2 𝒪(𝑛𝑘) polynomial 5𝒪(𝑛) linear 3 𝒪(𝑘𝑛) exponential 6\n\n\nwhere\n𝒪(𝑔)={𝑓|∃𝑘>0.𝑓≤𝑎𝑘·𝑔}\n                  and\n𝑓≤𝑎𝑔\n                  (𝑓\n                  is\nasymptotically bounded\n                  by\n𝑔), iff there is an\n𝑛0∊ℕ, such that\n𝑓(𝑛)≤𝑔(𝑛)\n                  for all\n𝑛>𝑛0.\n\n\n▷Growth Ranking\n                  For\n𝑘'>2\n                  and\n𝑘>1\n                  we have\n𝒪(1)⊂𝒪(log2(𝑛))⊂𝒪(𝑛)⊂𝒪(𝑛2)⊂𝒪(𝑛𝑘')⊂𝒪(𝑘𝑛)\n\n▷For AI-1\n                  I expect that given an\nalgorithm, you can determine its\ncomplexity class.\n(next)\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-15\n",
        "sectionId": "3d002f21",
        "archive": "courses/FAU/AI/course",
        "filepath": "prereq/slides/complexity-recap.en.xhtml"
    },
    {
        "slideContent": "\nAdvantage: Big-Oh Arithmetics\n\n▷Practical Advantage\n                Computing with\nLandau sets\n                is quite simple.\n(good simplification)\n\n\n▷Computing with Landau Sets\n\n\n1.If\n𝒪(𝑐·𝑓)=𝒪(𝑓)\n                for any constant\n𝑐∊ℕ.(drop constant factors)\n\n\n2.If\n𝒪(𝑓)⊆𝒪(𝑔), then\n𝒪(𝑓+𝑔)=𝒪(𝑔).(drop low-complexity summands)\n\n\n3.If\n𝒪(𝑓·𝑔)=𝒪(𝑓)·𝒪(𝑔).(distribute over products)\n\n\n▷These are not all of “big-Oh calculation rules”, but they’re enough for most purposes\n\n\n▷Applications\n                Convince yourselves using the result above that\n\n\n▷𝒪(4𝑛3+3𝑛+71000𝑛)=𝒪(2𝑛)\n\n\n▷𝒪(𝑛)⊂𝒪(𝑛·log2(𝑛))⊂𝒪(𝑛2)\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-15\n",
        "sectionId": "3d002f21",
        "archive": "courses/FAU/AI/course",
        "filepath": "prereq/slides/bigO-arithmetics.en.xhtml"
    },
    {
        "slideContent": "\nDetermining the Time/Space Complexity of Algorithms\n\n▷\n                  Given a\nfunction\nΓ\n                  that\nassigns\nvariables\n𝑣\n                  to\nfunctions\nΓ(𝑣)\n                  and\n𝛼\n                  an\nimperative\nalgorithm, we compute the\n\n\n▷time complexity\n𝑇Γ(𝛼)\n                  of\nprogram\n𝛼\n                  and\n\n\n▷the\ncontext\n𝐶Γ(𝛼)\n                  introduced by\n𝛼\n\n\nby joint\ninduction on the structure\n                  of\n𝛼:\n\n\n▷constant: can be accessed in constant timeIf\n𝛼=𝛿\n                  for a data constant\n𝛿, then\n𝑇Γ(𝛼)∊𝒪(1).\n\n\n▷variable: need the complexity of the\nvalueIf\n𝛼=𝑣\n                  with\n𝑣∊𝐝𝐨𝐦(Γ), then\n𝑇Γ(𝛼)∊𝒪(Γ(𝑣)).\n\n\n▷application: compose the complexities of the\nfunction\n                  and the\nargumentIf\n𝛼=𝜑(𝜓)\n                  with\n𝑇Γ(𝜑)∊𝒪(𝑓)\n                  and\n𝑇Γ∪𝐶Γ(𝜑)(𝜓)∊𝒪(𝑔), then\n𝑇Γ(𝛼)∊𝒪(𝑓◦𝑔)\n                  and\n𝐶Γ(𝛼)=𝐶Γ∪𝐶Γ(𝜑)(𝜓).\n\n\n▷assignment: has to compute the\nvalue\n⤳\n                  has its complexityIf\n𝛼\n                  is\n𝑣:=𝜑\n                  with\n𝑇Γ(𝜑)∊𝑆, then\n𝑇Γ(𝛼)∊𝑆\n                  and\n𝐶Γ(𝛼)=Γ∪(𝑣,𝑆).\n\n\n▷composition: has the maximal complexity of the componentsIf\n𝛼\n                  is\n𝜑;𝜓, with\n𝑇Γ(𝜑)∊𝑃\n                  and\n𝑇Γ∪𝐶Γ(𝜓)(𝜓)∊𝑄, then\n𝑇Γ(𝛼)∊max{𝑃,𝑄}\n                  and\n𝐶Γ(𝛼)=𝐶Γ∪𝐶Γ(𝜓)(𝜓).\n\n\n▷branching: has the maximal complexity of the\ncondition\n                  and\nbranchesIf\n𝛼\n                  is\nif𝛾then𝜑else𝜓end, with\n𝑇Γ(𝛾)∊𝐶,\n𝑇Γ∪𝐶Γ(𝛾)(𝜑)∊𝑃,\n𝑇Γ∪𝐶Γ(𝛾)(𝜑)∊𝑄, and then\n𝑇Γ(𝛼)∊max{𝐶,𝑃,𝑄}\n                  and\n𝐶Γ(𝛼)=Γ∪𝐶Γ(𝛾)∪𝐶Γ∪𝐶Γ(𝛾)(𝜑)∪𝐶Γ∪𝐶Γ(𝛾)(𝜓).\n\n\n▷looping: multiplies complexitiesIf\n𝛼\n                  is\nwhile𝛾do𝜑end, with\n𝑇Γ(𝛾)∊𝒪(𝑓),\n𝑇Γ∪𝐶Γ(𝛾)(𝜑)∊𝒪(𝑔), then\n𝑇Γ(𝛼)∊𝒪(𝑓(𝑛)·𝑔(𝑛))\n                  and\n𝐶Γ(𝛼)=𝐶Γ∪𝐶Γ(𝛾)(𝜑).\n\n\n▷The\ntime complexity\n𝑇(𝛼)\n                  is just\n𝑇∅(𝛼), where\n∅\n                  is the\nempty\nfunction.\n\n\n▷Recursion\n              is much more difficult to analyze\n⤳\nrecurrences\n              and\nMaster’s theorem.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-15\n",
        "sectionId": "3d002f21",
        "archive": "courses/FAU/AI/course",
        "filepath": "prereq/slides/complexity-algorithm.en.xhtml"
    },
    {
        "slideContent": "\nWhy Complexity Analysis? (General)\n\n▷\n                Once upon a time I was trying to invent an\nefficient\nalgorithm.\n\n\n▷My first\nalgorithm\n                attempt didn’t work, so I had to try harder.\n\n\n\n\n▷But my 2nd attempt didn’t work either, which got me a bit agitated.\n\n\n\n\n▷The 3rd attempt didn’t work either...\n\n\n\n▷And neither the 4th. But then:\n\n\n\n\n▷Ta-da ...when, for once, I turned around and looked in the other direction— CAN one actually solve this\nefficiently? —\nNP hardness\n                was there to rescue me.\n\n\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-15\n",
        "sectionId": "3d002f21",
        "archive": "courses/FAU/AI/course",
        "filepath": "prereq/slides/why-complexity-analysis.en.xhtml"
    },
    {
        "slideContent": "\nWhy Complexity Analysis? (General)\n\n▷\n                Trying to find a sea route east to India (from Spain)(does not exist)\n\n\n\n\n▷Observation\nComplexity theory\n                saves you from spending lots of time trying to invent\nalgorithms\n                that do not exist.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 122024-12-15\n",
        "sectionId": "3d002f21",
        "archive": "courses/FAU/AI/course",
        "filepath": "prereq/slides/why-complexity-analysis.en.xhtml"
    },
    {
        "slideContent": "\nReminder (?):\n𝐍𝐏\n              and\n𝐏𝐒𝐏𝐀𝐂𝐄\n              (details\n⤳\n              e.g. [GJ79])\n\n▷Turing Machine\n                  Works on a\ntape\n                  consisting of\ncells, across which its Read/Write\nhead\n                  moves. The machine has internal\nstates. There is a\ntransition function\n                  that specifies — given the current cell content and internal state — what the subsequent internal state will be, how what the R/W head does (write a symbol and/or move). Some internal states are\naccepting.\n\n\n▷\nDecision problems\n                  are in\n𝐍𝐏\n                  if there is a\nnon deterministic Turing machine\n                  that halts with an answer after\ntime\npolynomial\n                  in the size of its input. Accepts if\nat least one\n                  of the possible runs accepts.\n\n\n▷\nDecision problems\n                  are in\n𝐍𝐏𝐒𝐏𝐀𝐂𝐄, if there is a\nnon deterministic Turing machine\n                  that runs in\nspace\n                  polynomial in the size of its input.\n\n\n▷NP vs. PSPACE\n                  Non-deterministic\npolynomial\n                  space can be simulated in deterministic\npolynomial\n                  space. Thus\n𝐏𝐒𝐏𝐀𝐂𝐄=𝐍𝐏𝐒𝐏𝐀𝐂𝐄, and hence (trivially)\n𝐍𝐏⊆𝐏𝐒𝐏𝐀𝐂𝐄.\n\nIt is commonly believed that\n𝐍𝐏⊉𝐏𝐒𝐏𝐀𝐂𝐄.\n(similar to\n𝐏⊆𝐍𝐏)\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-15\n",
        "sectionId": "3d002f21",
        "archive": "courses/FAU/AI/course",
        "filepath": "prereq/slides/np-recap.en.xhtml"
    },
    {
        "slideContent": "\nThe Utility of Complexity Knowledge (NP-Hardness)\n\n▷Assume\n                In 3 years from now, you have finished your studies and are working in your first industry job. Your boss Mr. X gives you a problem and says\nSolve It!. By which he means,\nwrite a program that solves it\nefficiently.\n\n\n▷Question\n                Assume further that, after trying in vain for 4 weeks, you got the next meeting with Mr. X.\nHow could knowing about\nNP hardness\n                  help?\n\n\n▷Answerreserved for the plenary sessions\n⤳\n                be there!\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-16\n",
        "sectionId": "3d002f21",
        "archive": "courses/FAU/AI/course",
        "filepath": "prereq/quest/solve-it.en.xhtml"
    },
    {
        "slideContent": "\nThe Mathematics of Strings\n\n▷\n                  An\nalphabet\n𝐴\n                  is a\nfinite\nset; we call each element\n𝑎∊𝐴\n                  a\ncharacter, and an\n𝑛\ntuple\n𝑠∊𝐴𝑛\n                  a\nstring\n                  (of\nlength\n𝑛\n                  over\n𝐴).\n\n\n▷\n                  Note that\n𝐴0={〈〉}, where\n〈〉\n                  is the (unique)\n0-tuple. With the definition above we consider\n〈〉\n                  as the\nstring\n                  of\nlength\n0\n                  and call it the\nempty string\n                  and denote it with\n𝜖.\n\n\n▷NoteSets\n≠\nstrings, e.g.\n{𝟷,𝟸,𝟹}={𝟹,𝟸,𝟷}, but\n〈𝟷,𝟸,𝟹〉≠〈𝟹,𝟸,𝟷〉.\n\n\n▷NotationWe will often write a string\n〈𝑐1,...,𝑐𝑛〉\n                  as\n”𝚌𝟷...𝚌𝚗”,\nfor instance\n”𝚊𝚋𝚌”\n                      for\n〈𝚊,𝚋,𝚌〉\n\n\n▷Take\n𝐴={𝚑,𝟷,/}\n                  as an\nalphabet. Each of the members\n𝚑,\n𝟷, and\n/\n                  is a\ncharacter. The\nvector\n〈/,/,𝟷,𝚑,𝟷〉\n                  is a\nstring\n                  of\nlength\n5\n                  over\n𝐴.\n\n\n▷String Length\n                  Given a\nstring\n𝑠\n                  we denote its\nlength\n                  with\n|𝑠|.\n\n\n▷The\nconcatenation\nconc(𝑠,𝑡)\n                  of two\nstrings\n𝑠=〈𝑠1,...,𝑠𝑛〉∊𝐴𝑛\n                  and\n𝑡=〈𝑡1,...,𝑡𝑚〉∊𝐴𝑚\n                  is defined as\n〈𝑠1,...,𝑠𝑛,𝑡1,...,𝑡𝑚〉∊𝐴𝑛+𝑚.\n\nWe will often write\nconc(𝑠,𝑡)\n                  as\n𝑠+𝑡\n                  or simply\n𝑠𝑡\n\n\n▷\nconc(”𝚝𝚎𝚡𝚝”,”𝚋𝚘𝚘𝚔”)=”𝚝𝚎𝚡𝚝”+”𝚋𝚘𝚘𝚔”=”𝚝𝚎𝚡𝚝𝚋𝚘𝚘𝚔”\n\n\n\n:\n12024-12-14\n",
        "sectionId": "f3fe1a79",
        "archive": "courses/Jacobs/GenCS/course",
        "filepath": "codes/slides/string-math.en.xhtml"
    },
    {
        "slideContent": "\nFormal Languages\n\n▷\n                  Let\n𝐴\n                  be an\nalphabet, then we define the\nsets\n𝐴+:=⋃𝑖∊ℕ+𝐴𝑖\n                  of\nnonempty string\n                  and\n𝐴*:=𝐴+∪{𝜖}\n                  of\nstrings.\n\n\n▷If\n𝐴={𝚊,𝚋,𝚌}, then\n𝐴*={𝜖,𝚊,𝚋,𝚌,𝚊𝚊,𝚊𝚋,𝚊𝚌,𝚋𝚊,...,𝚊𝚊𝚊,...}.\n\n\n▷\n                  A\nset\n𝐿⊆𝐴*\n                  is called a\nformal language\n                  over\n𝐴.\n\n\n▷We use\n𝚌[𝑛]\n                  for the\nstring\n                  that consists of the\ncharacter\n𝚌\nrepeated\n𝑛\n                  times.\n\n\n▷#[5]=〈#,#,#,#,#〉\n\n\n▷The\nset\n𝑀:={𝚋𝚊[𝑛]|𝑛∊ℕ}\n                  of\nstrings\n                  that start with\ncharacter\n𝚋\n                  followed by an arbitrary numbers of\n𝚊’s is a\nformal language\n                  over\n𝐴={𝚊,𝚋}.\n\n\n▷Formal&#160;Language&#160;Operations\n\n\n\n:\n12024-12-14\n",
        "sectionId": "f3fe1a79",
        "archive": "courses/Jacobs/GenCS/course",
        "filepath": "codes/slides/formal-language.en.xhtml"
    },
    {
        "slideContent": "\nPhrase Structure Grammars (Theory)\n\n▷Recap\n                  A\nformal language\n                  is an arbitrary\nset\n                  of\nsymbol\n                  sequences.\n\n\n▷ProblemThis may be\ninfinite\n                  and even\nundecidable\n                  even if\n𝐴\n                  is\nfinite.\n\n\n▷Idea\n                  Find a way of representing\nformal languages\n                  with structure\nfinitely.\n\n\n▷Grammar\n\n\n▷Intuition\nProduction rules\n                  map\nstrings\n                  with at least one\nnonterminal\n                  to arbitrary other\nstrings.\n\n\n▷NotationIf we have\n𝑛\n                  rules\nℎ→𝑏𝑖\n                  sharing a\nhead, we often write\nℎ→𝑏1|...|𝑏𝑛\n                  instead.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "f3fe1a79",
        "archive": "courses/FAU/AI/course",
        "filepath": "nlp/slides/grammar.en.xhtml"
    },
    {
        "slideContent": "\nPhrase Structure Grammars (cont.)\n\n▷\n                  A simple\nphrase structure grammar\n𝐺:\n𝑆→𝑁𝑃𝑉𝑖\n\n𝑁𝑃→𝐴𝑟𝑡𝑖𝑐𝑙𝑒𝑁\n\n𝐴𝑟𝑡𝑖𝑐𝑙𝑒→𝐭𝐡𝐞|𝐚|𝐚𝐧\n\n𝑁→𝐝𝐨𝐠|𝐭𝐞𝐚𝐜𝐡𝐞𝐫|...\n\n𝑉𝑖→𝐬𝐥𝐞𝐞𝐩𝐬|𝐬𝐦𝐞𝐥𝐥𝐬|...\n\nHere\n𝑆, is the\nstart symbol,\n𝑁𝑃,\n𝑉𝑃,\n𝐴𝑟𝑡𝑖𝑐𝑙𝑒,\n𝑁, and\n𝑉𝑖\n                  are\nnonterminals.\n\n\n▷Lexicon&#160;(Grammar)\n\n\n▷Structural&#160;Rules\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-15\n",
        "sectionId": "f3fe1a79",
        "archive": "courses/FAU/AI/course",
        "filepath": "nlp/slides/lexicon.en.xhtml"
    },
    {
        "slideContent": "\nPhrase Structure Grammars (Theory)\n\n▷Idea\n                  Each\nsymbol\n                  sequence in a\nformal language\n                  can be\nanalyzed/generated\n                  by the\ngrammar.\n\n\n▷Derivation&#160;in&#160;a&#160;Grammar\n\n\n▷Sentential&#160;Forms&#160;and&#160;Sentences\n\n\n▷Language&#160;over&#160;a&#160;Grammar\n\n\n▷\nParsing,\nsyntax analysis, or\nsyntactic analysis\n                  is the process of analyzing a\nstring\n                  of\nsymbols, either in a\nformal\n                  or a\nnatural language\n                  by means of a\ngrammar.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "f3fe1a79",
        "archive": "courses/FAU/AI/course",
        "filepath": "nlp/slides/grammar-sentence.en.xhtml"
    },
    {
        "slideContent": "\nPhrase Structure Grammars (Example)\n\n▷\n                In the\ngrammar\n𝐺\n                from\n??:\n\n\n\n1.𝐴𝑟𝑡𝑖𝑐𝑙𝑒𝐭𝐞𝐚𝐜𝐡𝐞𝐫𝑉𝑖\n                                  is a\nsentential form,\n𝑆→𝐺𝑁𝑃𝑉𝑖\n\n→𝐺𝐴𝑟𝑡𝑖𝑐𝑙𝑒𝑁𝑉𝑖\n\n→𝐺𝐴𝑟𝑡𝑖𝑐𝑙𝑒𝐭𝐞𝐚𝐜𝐡𝐞𝐫𝑉𝑖\n\n\n\n\n\n2.The teacher sleeps\n                                  is a\nsentence.\n𝑆→𝐺*𝐴𝑟𝑡𝑖𝑐𝑙𝑒𝐭𝐞𝐚𝐜𝐡𝐞𝐫𝑉𝑖\n\n→𝐺𝐭𝐡𝐞𝐭𝐞𝐚𝐜𝐡𝐞𝐫𝑉𝑖\n\n→𝐺𝐭𝐡𝐞𝐭𝐞𝐚𝐜𝐡𝐞𝐫𝐬𝐥𝐞𝐞𝐩𝐬\n\n\n\n\n\n𝑆→𝑁𝑃𝑉𝑖\n\n𝑁𝑃→𝐴𝑟𝑡𝑖𝑐𝑙𝑒𝑁\n\n𝐴𝑟𝑡𝑖𝑐𝑙𝑒→𝐭𝐡𝐞|𝐚|𝐚𝐧|...\n\n𝑁→𝐝𝐨𝐠|𝐭𝐞𝐚𝐜𝐡𝐞𝐫|...\n\n𝑉𝑖→𝐬𝐥𝐞𝐞𝐩𝐬|𝐬𝐦𝐞𝐥𝐥𝐬|...\n\n\n\n\n\n \n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-15\n",
        "sectionId": "f3fe1a79",
        "archive": "courses/FAU/AI/course",
        "filepath": "nlp/slides/grammar-sentence-ex.en.xhtml"
    },
    {
        "slideContent": "\nGrammar Types (Chomsky Hierarchy [Cho65])\n\n▷Observation\n                  The shape of the\ngrammar\n                  determines the “size” of its\nlanguage.\n\n\n▷Types&#160;of&#160;Grammars\n\n\n▷Context-sensitive\n                  The\nlanguage\n{𝑎[𝑛]𝑏[𝑛]𝑐[𝑛]}\nis accepted by\n𝑆→𝐚𝐛𝐜|𝐴\n\n𝐴→𝐚𝐴𝐵𝐜|𝐚𝐛𝐜\n\n𝐜𝐵→𝐵𝐜\n\n𝐛𝐵→𝐛𝐛\n\n\n\n\n▷Context-free\n                  The\nlanguage\n{𝑎[𝑛]𝑏[𝑛]}\nis accepted by\n𝑆→𝐚𝑆𝐛|𝜖.\n\n\n▷Regular\n                  The\nlanguage\n{𝑎[𝑛]}\nis accepted by\n𝑆→𝑆𝐚\n\n\n▷Observation\nNatural languages\n                  are probably\ncontext-sensitive\n                  but\nparsable\n                  in real time!(like languages low in the hierarchy)\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "f3fe1a79",
        "archive": "courses/FAU/AI/course",
        "filepath": "nlp/slides/grammar-types.en.xhtml"
    },
    {
        "slideContent": "\nUseful Extensions of Phrase Structure Grammars\n\n▷Bachus-Naur-Form\n\n\n▷Observation\n                All of these can be eliminated, .e.g\n(⤳\n                    many more\nrules)\n\n\n▷replace\n𝑋→𝑍(𝑠*)𝑊\n                with the\nproduction rules\n𝑋→𝑍𝑌𝑊,\n𝑌→𝜖, and\n𝑌→𝑌𝑠.\n\n\n▷replace\n𝑋→𝑍(𝑠+)𝑊\n                with the\nproduction rules\n𝑋→𝑍𝑌𝑊,\n𝑌→𝑠, and\n𝑌→𝑌𝑠.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-15\n",
        "sectionId": "f3fe1a79",
        "archive": "courses/FAU/AI/course",
        "filepath": "prereq/slides/bnf.en.xhtml"
    },
    {
        "slideContent": "\nAn Grammar Notation for AI-1\n\n▷Problem\n                In\ngrammars, notations for\nnonterminal symbols\n                should be\n\n\n▷short and mnemonic\n(for the use in the\nbody)\n\n\n▷close to the official name of the\nsyntactic category(for the use in the\nhead)\n\n\n▷In AI-1 we will only use\ncontext-free\ngrammars\n(simpler, but problem still applies)\n\n\n▷in AI-1\n                I will try to give “grammar overviews” that combine those, e.g. the grammar of first-order logic.\n\nvariables𝑋∊𝒱1\nfunction constants\n𝑓𝑘∊Σ𝑘𝑓\npredicate constants\n𝑝𝑘∊Σ𝑝𝑘terms𝑡::=𝑋variable|𝑓0constant|𝑓𝑘(𝑡1,...,𝑡𝑘)applicationformulae𝐀::=𝑝𝑘(𝑡1,...,𝑡𝑘)atomic|¬𝐀negation|𝐀1∧𝐀2conjunction|∀𝑋.𝐀quantifier\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-15\n",
        "sectionId": "f3fe1a79",
        "archive": "courses/FAU/AI/course",
        "filepath": "prereq/slides/aibnf.en.xhtml"
    },
    {
        "slideContent": "\nMathematical Structures\n\n▷Observation\nMathematicians\n                  often cast classes of complex objects as\nmathematical structures.\n\n\n▷We have just seen an example of a\nmathematical structure:(repeated here for convenience)\n\n\n▷Grammar\n\n\n▷Intuition\n                  All\ngrammars\n                  share structure: they have four\ncomponents, which again share struccture, which is further described in the definition above.\n\n\n▷Observation\n                  Even though we call\nproduction rules\n                  “pairs” above, they are also\nmathematical structures\n〈ℎ,𝑏〉\n                  with a funny notation\nℎ→𝑏.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "a65f93df",
        "archive": "courses/FAU/AI/course",
        "filepath": "prereq/slides/mathstruct-ai.en.xhtml"
    },
    {
        "slideContent": "\nMathematical Structures in Programming\n\n▷Observation\n                  Most\nprogramming languages\n                  have some way of creating “named structures”. Referencing\ncomponents\n                  is usually done via “dot notation”.\n\n\n▷Structs in\nC\nC\ndata structures\n                  for representing\ngrammars:\n\n\nstruct grule {\nchar[][] head;\nchar[][] body;\n}\nstruct grammar {\nchar[][] nterminals;\nchar[][] termininals;\ngrule[] grules;\nchar[] start;\n}\nint main() {\nstruct grule r1;\nr1.head = \"foo\";\nr1.body = \"bar\";\n}\n\n▷Classes\n                    in\nOOP\nClasses\n                  in\nobject-oriented\nprogramming languages\n                  are based on the same\nideas\n                  as\nmathematical structures, only that\nOOP\n                  adds powerful\ninheritance\n                  mechanisms.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "a65f93df",
        "archive": "courses/FAU/AI/course",
        "filepath": "prereq/slides/mathstruct-programming.en.xhtml"
    },
    {
        "slideContent": "\nIn AI-1 we use a mixture between\nMath\n              and Programming Styles\n\n▷In AI-1 we use\nmathematical\n              notation, ...\n\n▷\n                  A\nstructure signature\n                  combines the components, their “types”, and\naccessor\n                  names of a\nmathematical structure\n                  in a tabular overview.\n\n\n▷Example 0.1.\n\n\ngrammar = 〈𝑁𝐒𝐞𝐭\nnonterminal symbols\n,Σ𝐒𝐞𝐭\nterminal symbols\n,𝑃{ℎ→𝑏|...}\nproduction rules\n,𝑆𝑁\nstart symbol\n〉production rule ℎ→𝑏 = 〈ℎ(Σ∪𝑁)*,𝑁,(Σ∪𝑁)*head,𝑏(Σ∪𝑁)*body〉\n\nRead the first line “𝑁𝐒𝐞𝐭\nnonterminal symbols\n” in the structure above as “𝑁\n              is in an (unspecified) set and is a\nnonterminal symbol”.\n\nHere — and in the future —\nwe will use\n𝐒𝐞𝐭\n                  for the\nclass of sets\n⤳\n              “𝑁\n              is a\nset”.\n\n\n▷I will try to give\nstructure signatures\n              where necessary.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "a65f93df",
        "archive": "courses/FAU/AI/course",
        "filepath": "prereq/slides/mathstruct-overviews.en.xhtml"
    },
    {
        "slideContent": "\nSummary\n\n▷Agents\n              interact with\nenvironments\n              through\nactuators\n              and\nsensors.\n\n\n▷The\nagent function\n              describes what the\nagent\n              does in all circumstances.\n\n\n▷The\nperformance measure\n              evaluates the environment sequence.\n\n\n▷A perfectly\nrational\nagent\nmaximizes\n              expected\nperformance.\n\n\n▷Agent programs\nimplement\n              (some)\nagent functions.\n\n\n▷PEAS\n              descriptions define task environments.\n\n\n▷Environments are categorized along several dimensions:fully observable?\ndeterministic?\nepisodic?\nstatic?\ndiscrete?\nsingle-agent?\n\n\n▷Several basic\nagent\n              architectures exist:reflex,\nmodel-based,\ngoal-based,\nutility-based\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-15\n",
        "sectionId": "fcb54fa6",
        "archive": "courses/FAU/AI/course",
        "filepath": "rational-agents/slides/summary.en.xhtml"
    },
    {
        "slideContent": "\nWhat is AI? Going into Details\n\n▷Recap\nAI\n                studies how we can make the\ncomputer\n                do things that\nhumans\n                can still\ndo better\n                at the moment.(humans are proud to be rational)\n\n\n▷What is AI?\n                Four possible answers/facets: Systems that\n\n\nthink like humans think rationallyact like humans act rationally\n\n\nexpressed by four different definitions/quotes:\n\n\n\nHumanly\n\n\nRational\nThinking \n“The exciting new effort to make computers think ...machines with human-like minds”[Hau85]\n\n“The formalization of mental faculties in terms of computational models”[CM85]\n\nActing \n“The art of creating machines that perform actions requiring\nintelligence\n                                    when performed by people”[Kur90]\n\n\n“The branch of CS concerned with the automation of appropriate behavior in complex situations”[LS93]\n\n\n\n\n▷Idea\n                Rationality is performance-oriented rather than based on imitation.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-15\n",
        "sectionId": "f4b7a81e",
        "archive": "courses/FAU/AI/course",
        "filepath": "intro/slides/four-answers.en.xhtml"
    },
    {
        "slideContent": "\nSo, what does modern\nAI\n            do?\n\n▷Acting Humanly\n                Turing test, not much pursued outside Loebner prize\n\n\n▷=^\n                building pigeons that can fly so much like real pigeons that they can fool pigeons\n\n\n▷Not reproducible, not amenable to\nmathematical\n                analysis\n\n\n▷Thinking Humanly\n⤳\n                Cognitive Science.\n\n\n▷How do humans think? How does the (human) brain work?\n\n\n▷Neural networks are a (extremely simple so far) approximation\n\n\n▷Thinking Rationally\n                Logics, Formalization of knowledge and inference\n\n\n▷You know the basics, we do some more, fairly widespread in modern\nAI\n\n\n▷Acting Rationally\n                How to make good action choices?\n\n\n▷Contains logics\n(one possible way to make intelligent decisions)\n\n\n▷We are interested in making good choices in practice\n(e.g. in AlphaGo)\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "f4b7a81e",
        "archive": "courses/FAU/AI/course",
        "filepath": "intro/slides/four-elab.en.xhtml"
    },
    {
        "slideContent": "\nActing humanly: The Turing test\n\n▷Introduced by Alan Turing (1950) “Computing machinery and intelligence” [Tur50]:\n\n\n▷“Can machines think?”\n\n−\n→\n              “Can machines behave intelligently?”\n\n\n▷\n                  The\nTuring test\n                  is an operational test for intelligent behavior based on an\nimitation game\n                  over teletext\n(arbitrary topic)\n\n\n\n\n▷It was predicted that by 2000, a machine might have a\n30%\n              chance of fooling a lay person for 5 minutes.\n\n\n▷Note\n                  In [Tur50], Alan Turing\n\n\n▷anticipated all major arguments against\nAI\n                  in following 50 years and\n\n\n▷suggested major components of\nAI: knowledge, reasoning, language understanding, learning\n\n\n▷Problem\n                  Turing test is not\nreproducible,\nconstructive, or amenable to\nmathematical\n                  analysis!\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-15\n",
        "sectionId": "f4b7a81e",
        "archive": "courses/FAU/AI/course",
        "filepath": "intro/slides/turing-test.en.xhtml"
    },
    {
        "slideContent": "\nThinking humanly: Cognitive Science\n\n▷1960s\n“cognitive revolution”: information processing psychology replaced prevailing orthodoxy of\nbehaviorism.\n\n\n▷Requires scientific theories of internal activities of the brain\n\n\n▷What level of abstraction? “Knowledge” or “circuits”?\n\n\n▷How to validate?\n                  Requires\n\n\n1.Predicting and testing behavior of human subjects or(top-down)\n\n\n2.Direct identification from neurological data.(bottom-up)\n\n\n▷\nCognitive science\n                  is the interdisciplinary,\nscientific\nstudy\n                  of the\nmind\n                  and its processes. It examines the nature, the tasks, and the functions of\ncognition.\n\n\n▷\nCognitive neuroscience\n                  studies the biological processes and aspects that underlie\ncognition, with a specific focus on the neural connections in the brain which are involved in mental processes.\n\n\n▷Both approaches/disciplines are now distinct from\nAI.\n\n\n▷Both share with\nAI\n              the following characteristic:\nthe available theories do not explain (or engender) anything resembling human-level general\nintelligence\n\n\n▷Hence, all three fields share one principal direction!\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "f4b7a81e",
        "archive": "courses/FAU/AI/course",
        "filepath": "intro/slides/cognitive-science.en.xhtml"
    },
    {
        "slideContent": "\nThinking rationally: Laws of Thought\n\n▷\nNormative\n                      (or\nprescriptive) rather than\ndescriptive\n\n\n▷Aristotle: what are correct arguments/thought processes?\n\n\n▷\n                  Several Greek schools developed various forms of\nlogic:\nnotation\n                      and\nrules of derivation\n                      for thoughts; may or may not have proceeded to the idea of mechanization.\n\n\n▷Direct line through\nmathematics\n              and philosophy to modern\nAI\n\n\n▷Problems\n\n\n1.Not all intelligent behavior is mediated by logical deliberation\n\n\n2.What is the purpose of thinking? What thoughts\nshould\n                  I have out of all the thoughts (logical or otherwise) that I\ncould\n                  have?\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-15\n",
        "sectionId": "f4b7a81e",
        "archive": "courses/FAU/AI/course",
        "filepath": "intro/slides/thinking-rationally.en.xhtml"
    },
    {
        "slideContent": "\nActing\nRationally\n\n▷Idea\nRational behavior\n=^\n                  doing the right thing!\n\n\n▷\nRational behavior\n                  consists of always doing what is\nexpected\n                  to\nmaximize\ngoal\nachievement\n                  given the available\ninformation.\n\n\n▷Rational behavior\n              does not necessarily involve\nthinking\n              e.g., blinking reflex ― but\nthinking\n              should be in the service of\nrational\naction.\n\n\n▷Aristotle\nEvery art and every inquiry, and similarly every action and pursuit, is thought to aim at some good.(Nicomachean Ethics)\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "f4b7a81e",
        "archive": "courses/FAU/AI/course",
        "filepath": "intro/slides/acting-rationally.en.xhtml"
    },
    {
        "slideContent": "\nThe Rational Agents\n\n▷\n                  An\nagent\n                  is an entity that\nperceives\n                  and\nacts.\n\n\n▷Central IdeaThis\ncourse\n                  is about designing\nagent\n                  that exhibit\nrational behavior, i.e. for any given class of\nenvironments\n                  and tasks, we seek the\nagent\n                  (or class of\nagents) with the best performance.\n\n\n▷Caveat\nComputational limitations make perfect rationality unachievable⤳\n                  design best\nprogram\n                  for given machine resources.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "f4b7a81e",
        "archive": "courses/FAU/AI/course",
        "filepath": "intro/slides/rational-agents.en.xhtml"
    },
    {
        "slideContent": "\n[label=slide.agentenv]\nAgents\n              and\nEnvironments\n\n▷\n\n\n\n\n\nAgents\n                  include humans, robots, softbots, thermostats, etc.\n\n\n▷\n\n▷remark\n                  The notion of an\nagent\n                  and its\nenvironment\n                  is intentionally designed to be inclusive. We will classify and discuss subclasses of both later\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "419d6ee3",
        "archive": "courses/FAU/AI/course",
        "filepath": "rational-agents/slides/agentenv.en.xhtml"
    },
    {
        "slideContent": "\nModeling Agents\nMathematically\n              and\nComputationally\n\n▷\n\n\n▷\n\n\n▷\n                  The\nagent function\n𝑓𝑎\n                  of an\nagent\n𝑎\nmaps\n                  from\npercept\n                  histories to\nactions:\n𝑓𝑎:𝒫*→𝒜\n\n▷We assume that\nagents\n              can always\nperceive\n              their own\nactions.(but not necessarily their consequences)\n\n\n▷Problem\nAgent functions\n                  can become very big and may be\nuncomputable.(theoretical tool only)\n\n\n▷\n                  An\nagent function\n                  can be\nimplemented\n                  by an\nagent program\n                  that runs on a (physical or hypothetical)\nagent architecture.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "419d6ee3",
        "archive": "courses/FAU/AI/course",
        "filepath": "rational-agents/slides/agent-math.en.xhtml"
    },
    {
        "slideContent": "\nAgent Schema: Visualizing the Internal Agent Structure\n\n▷Agent Schema\n                  We will use the following kind of\nagent schema\n                      to visualize the internal structure of an\nagent:\n\n\n\n\nDifferent\nagents\n                  differ on the contents of the white box in the center.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "419d6ee3",
        "archive": "courses/FAU/AI/course",
        "filepath": "rational-agents/slides/agent-schema.en.xhtml"
    },
    {
        "slideContent": "\nExample: Vacuum-Cleaner World and Agent\n\n\n\n\n\n▷percepts: location and contents, e.g.,\n[𝐴,𝐷𝑖𝑟𝑡𝑦]\n\n\n▷actions:\n𝐿𝑒𝑓𝑡,\n𝑅𝑖𝑔ℎ𝑡,\n𝑆𝑢𝑐𝑘,\n𝑁𝑜𝑂𝑝\n\n\n\nPercept sequence Action [𝐴,𝐶𝑙𝑒𝑎𝑛] 𝑅𝑖𝑔ℎ𝑡 [𝐴,𝐷𝑖𝑟𝑡𝑦] 𝑆𝑢𝑐𝑘 [𝐵,𝐶𝑙𝑒𝑎𝑛] 𝐿𝑒𝑓𝑡 [𝐵,𝐷𝑖𝑟𝑡𝑦] 𝑆𝑢𝑐𝑘 [𝐴,𝐶𝑙𝑒𝑎𝑛], [𝐴,𝐶𝑙𝑒𝑎𝑛] 𝑅𝑖𝑔ℎ𝑡 [𝐴,𝐶𝑙𝑒𝑎𝑛], [𝐴,𝐷𝑖𝑟𝑡𝑦] 𝑆𝑢𝑐𝑘 [𝐴,𝐶𝑙𝑒𝑎𝑛], [𝐵,𝐶𝑙𝑒𝑎𝑛] 𝐿𝑒𝑓𝑡 [𝐴,𝐶𝑙𝑒𝑎𝑛], [𝐵,𝐷𝑖𝑟𝑡𝑦] 𝑆𝑢𝑐𝑘 [𝐴,𝐷𝑖𝑟𝑡𝑦], [𝐴,𝐶𝑙𝑒𝑎𝑛] 𝑅𝑖𝑔ℎ𝑡 [𝐴,𝐷𝑖𝑟𝑡𝑦], [𝐴,𝐷𝑖𝑟𝑡𝑦] 𝑆𝑢𝑐𝑘 ... ... [𝐴,𝐶𝑙𝑒𝑎𝑛], [𝐴,𝐶𝑙𝑒𝑎𝑛], [𝐴,𝐶𝑙𝑒𝑎𝑛] 𝑅𝑖𝑔ℎ𝑡 [𝐴,𝐶𝑙𝑒𝑎𝑛], [𝐴,𝐶𝑙𝑒𝑎𝑛], [𝐴,𝐷𝑖𝑟𝑡𝑦] 𝑆𝑢𝑐𝑘 ... ... \n\n\n\n\n \n\n▷Science Question\n                  What is the\nright\nagent function?\n\n\n▷AI Question\n                  Is there an\nagent architecture\n                  and\nagent program\n                  that\nimplements\n                  it.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "419d6ee3",
        "archive": "courses/FAU/AI/course",
        "filepath": "rational-agents/slides/vacuum-agent-ex.en.xhtml"
    },
    {
        "slideContent": "\nTable-Driven Agents\n\n▷Idea\n                  We can just\nimplement\n                  the\nagent function\n                  as a\nlookup table\n                  and\nlookup\nactions.\n\n\n▷We can directly\nimplement\n              this:\n\n\nfunction Table―Driven―Agent(𝑝𝑒𝑟𝑐𝑒𝑝𝑡) returns an action\npersistent 𝑡𝑎𝑏𝑙𝑒 /* a table of actions indexed by percept sequences */\nvar 𝑝𝑒𝑟𝑐𝑒𝑝𝑡𝑠 /* a sequence, initially empty */\nappend 𝑝𝑒𝑟𝑐𝑒𝑝𝑡 to the end of 𝑝𝑒𝑟𝑐𝑒𝑝𝑡𝑠\n𝑎𝑐𝑡𝑖𝑜𝑛 := lookup(𝑝𝑒𝑟𝑐𝑒𝑝𝑡𝑠, 𝑡𝑎𝑏𝑙𝑒)\nreturn 𝑎𝑐𝑡𝑖𝑜𝑛\n\nProblem\n                  Why is this not a good idea?\n\n\n▷▷The\ntable\n                  is much too large: even with\n𝑛\n                  binary\npercepts\n                  whose order of occurrence does not matter, we have\n2𝑛\n                  rows in the\ntable.\n\n\n▷Who is supposed to write this\ntable\n                  anyways, even if it “only” has a million entries?\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-15\n",
        "sectionId": "419d6ee3",
        "archive": "courses/FAU/AI/course",
        "filepath": "rational-agents/slides/table-agent.en.xhtml"
    },
    {
        "slideContent": "\nExample: Vacuum-Cleaner Agent Program\n\n▷A much better\nimplementation\n            idea is to trigger\nactions\n            from specific\npercepts.\n\n\n▷Agent Program\n\n\nprocedure Reflex―Vacuum―Agent [𝑙𝑜𝑐𝑎𝑡𝑖𝑜𝑛,𝑠𝑡𝑎𝑡𝑢𝑠] returns an action\nif 𝑠𝑡𝑎𝑡𝑢𝑠 = Dirty then return Suck\nelse if 𝑙𝑜𝑐𝑎𝑡𝑖𝑜𝑛 = A then return Right\nelse if 𝑙𝑜𝑐𝑎𝑡𝑖𝑜𝑛 = B then return Left\n\n▷This is the kind of\nagent programs\n            we will be looking for in AI-1.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "419d6ee3",
        "archive": "courses/FAU/AI/course",
        "filepath": "rational-agents/slides/vacuum-agent-program.en.xhtml"
    },
    {
        "slideContent": "\nRationality\n\n▷Idea\n                  Try to design\nagents\n                  that are successful!(aka. “do the right thing”)\n\n\n▷Problem\n                  What do we mean by “successful”, how do we measure “success”?\n\n\n▷\n                  A\nperformance measure\n                  is a\nfunction\n                  that evaluates a sequence of\nenvironments.\n\n\n▷\n                  A\nperformance measure\n                  for a vacuum cleaner could\n\n\n▷award one point per “square” cleaned up in time\n𝑇?\n\n\n▷award one point per clean “square” per time step, minus one per move?\n\n\n▷penalize for\n>𝑘\n                  dirty squares?\n\n\n▷\n                  An\nagent\n                  is called\nrational, if it chooses whichever\naction\nmaximizes\n                  the\nexpected value\n                  of the\nperformance measure\n                  given the\npercept\n                  sequence to date.\n\n\n▷Critical Observation\n                  We only need to\nmaximize\n                  the\nexpected value, not the actual\nvalue\n                  of the\nperformance measure!\n\n\n▷Question\n                  Why is\nrationality\n                  a good quality to aim for?\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "e5fb8314",
        "archive": "courses/FAU/AI/course",
        "filepath": "rational-agents/slides/rationality.en.xhtml"
    },
    {
        "slideContent": "\nConsequences of\nRationality:\nExploration,\nLearning,\nAutonomy\n\n▷Note\n                  A\nrational\nagent\n                  need not be perfect:\n\n\n▷It only needs to\nmaximize\nexpected value\n(rational\n≠\n                      omniscient)\n\n\n▷need not predict e.g. very unlikely but catastrophic events in the future\n\n\n▷Percepts\n                  may not supply all relevant information(rational\n≠\n                      clairvoyant)\n\n\n▷if we cannot perceive things we do not need to react to them.\n\n\n▷but we may need to try to find out about hidden dangers(exploration)\n\n\n▷Action\n                  outcomes may not be as expected(rational\n≠\n                      successful)\n\n\n▷but we may need to take\naction\n                  to ensure that they do (more often)(learning)\n\n\n▷Note\nRationality\n                  may entail\nexploration,\nlearning,\nautonomy\n(depending on the environment / task)\n\n\n▷\n                  An\nagent\n                  is called\nautonomous, if it does not rely on the prior knowledge about the\nenvironment\n                  of the designer.\n\n\n▷Autonomy\n              avoids fixed behaviors that can become unsuccessful in a changing\nenvironment.(anything else would be\nirrational)\n\n\n▷The\nagent\n              may have to\nlearn\n              all relevant traits, invariants, properties of the\nenvironment\n              and\nactions.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 122024-12-14\n",
        "sectionId": "e5fb8314",
        "archive": "courses/FAU/AI/course",
        "filepath": "rational-agents/slides/rationality.en.xhtml"
    },
    {
        "slideContent": "\nPEAS: Describing the Task Environment\n\n▷Observation\n                  To design a\nrational\nagent, we must specify the\ntask\nenvironment\n                      in terms of\nperformance measure,\nenvironment,\nactuators, and\nsensors, together called the\nPEAS\n                      components.\n\n\n▷\n                  When designing an automated taxi:\n\n\n▷Performance measure\n                      safety, destination, profits, legality, comfort,\n...\n\n\n▷Environment\n                      US streets/freeways, traffic, pedestrians, weather,\n...\n\n\n▷Actuators\n                      steering, accelerator, brake, horn, speaker/display,\n...\n\n\n▷Sensors\n                      video, accelerometers, gauges, engine sensors, keyboard, GPS,\n...\n\n\n▷Internet Shopping AgentThe task\nenvironment:\n\n\n▷Performance measure: price, quality, appropriateness,\nefficiency\n\n\n▷Environment: current and future WWW sites, vendors, shippers\n\n\n▷Actuators: display to user, follow\nURL, fill in form\n\n\n▷Sensors:\nHTML\n                  pages (text, graphics, scripts)\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "e5fb8314",
        "archive": "courses/FAU/AI/course",
        "filepath": "rational-agents/slides/peas.en.xhtml"
    },
    {
        "slideContent": "\nExamples of Agents: PEAS descriptions\n\n\nAgent Type\n\n\nPerformance measure\n\n\nEnvironment\n\n\nActuators\n\n\nSensors\n\nChess/Go\n                                player\n\n\nwin/loose/draw\n\n\ngame board\n\n\nmoves\n\n\nboard position\n\n\nMedical diagnosis system\n\n\naccuracy of diagnosis\n\n\npatient, staff\n\n\ndisplay questions, diagnoses\n\n\nkeyboard entry of symptoms\n\n\nPart-picking robot\n\n\npercentage of parts in correct bins\n\n\nconveyor belt with parts, bins\n\n\njointed arm and hand\n\n\ncamera, joint angle sensors\n\nRefinery controller\n\n\npurity, yield, safety\n\n\nrefinery, operators\n\n\nvalves, pumps, heaters, displays\n\n\ntemperature, pressure, chemical sensors\n\nInteractive English tutor\n\n\nstudent’s score on test\n\n\nset of students, testing accuracy\n\n\ndisplay exercises, suggestions, corrections\n\n\nkeyboard entry\n\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-16\n",
        "sectionId": "e5fb8314",
        "archive": "courses/FAU/AI/course",
        "filepath": "rational-agents/slides/peas-ex.en.xhtml"
    },
    {
        "slideContent": "\nAgents\n\n▷\n                Which are\nagents?\n\n\n(A)James Bond.\n\n\n(B)Your dog.\n\n\n(C)Vacuum cleaner.\n\n\n(D)Thermometer.\n\n\n▷Answerreserved for the plenary sessions\n⤳\n                be there!\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-15\n",
        "sectionId": "e5fb8314",
        "archive": "courses/FAU/AI/course",
        "filepath": "rational-agents/quest/rational-agents.en.xhtml"
    },
    {
        "slideContent": "\nEnvironment types\n\n▷\nAgent\n                  design is largely determined by the\ntype\n                  of\nenvironment\n                  it is intended for.\n\n\n▷ProblemThere is a vast number of possible kinds of\nenvironments\n                  in\nAI.\n\n\n▷Solution\n                  Classify along a few “dimensions”.\n(independent characteristics)\n\n\n▷\n                  For an\nagent\n𝑎\n                  we classify the\nenvironment\n𝑒\n                  of\n𝑎\n                  by its\ntype, which is one of the following. We call\n𝑒\n\n\n1.fully observable, iff the\n𝑎’s sensors give it access to the complete\nstate\n                  of the\nenvironment\n                  at any point in time, else\npartially observable.\n\n\n2.deterministic, iff the next\nstate\n                  of the\nenvironment\n                  is completely determined by the current\nstate\n                  and\n𝑎’s\naction, else\nstochastic.\n\n\n3.episodic, iff\n𝑎’s experience is divided into atomic\nepisodes, where it perceives and then performs a single\naction. Crucially, the next\nepisode\n                  does not depend on previous ones.\nNon-episodic\nenvironments\n                  are called\nsequential.\n\n\n4.dynamic, iff the\nenvironment\n                  can change without an\naction\n                  performed by\n𝑎, else\nstatic. If the\nenvironment\n                  does not change but\n𝑎’s performance measure does, we call\n𝑒\nsemidynamic.\n\n\n5.discrete, iff the sets of\n𝑒’s state and\n𝑎’s\nactions\n                  are\ncountable, else\ncontinuous.\n\n\n6.single-agent, iff only\n𝑎\n                  acts on\n𝑒; else\nmulti-agent(when must we count parts of\n𝑒\n                      as\nagents?)\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "e04b1d7e",
        "archive": "courses/FAU/AI/course",
        "filepath": "rational-agents/slides/envtypes.en.xhtml"
    },
    {
        "slideContent": "\nEnvironment Types (Examples)\n\n▷Some\nenvironments\n                  classified:\n\n\nSolitaire Backgammon Internet shopping Taxi fully observable No Yes No No deterministic Yes No Partly No episodic No Yes No No static Yes Semi Semi No discrete Yes Yes Yes No single-agent Yes No Yes (except auctions) No \n\n\n▷Note\n                  Take the example above with a grain of salt. There are often multiple interpretations that yield different classifications and different\nagents.(agent designer’s choice)\n\n\n▷Seen as a\nmulti-agent\ngame,\nchess\n                  is\ndeterministic, as a\nsingle-agent\ngame, it is\nstochastic.\n\n\n▷The real world is (of course) a\npartially observable,\nstochastic,\nsequential,\ndynamic,\ncontinuous, and\nmulti-agent\nenvironment.(worst case for\nAI)\n\n\n▷Preview\n                  We will concentrate on the “easy” environment types (fully observable,\ndeterministic,\nepisodic,\nstatic, and\nsingle-agent) in AI-1 and extend them to “realworld”-compatible ones in AI-2.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-15\n",
        "sectionId": "e04b1d7e",
        "archive": "courses/FAU/AI/course",
        "filepath": "rational-agents/slides/envtypes-ex.en.xhtml"
    },
    {
        "slideContent": "\nAgent\n              Types\n\n▷Observation\n                  So far we have described (and analyzed)\nagents\n                  only by their\nbehavior\n                  (cf.\nagent function\n𝑓:𝒫*→𝒜).\n\n\n▷ProblemThis does not help us to build\nagents.\n(the goal of\nAI)\n\n\n▷\n                  To build an\nagent, we need to fix an\nagent architecture\n                  and come up with an\nagent program\n                  that runs on it.\n\n\n▷Preview\n                  Four basic types of\nagent architectures\n                  in order of increasing generality:\n\n\n1.simple reflex agents\n\n\n2.model-based agents\n\n\n3.goal-based agents\n\n\n4.utility-based agents\n\n\nAll these can be turned into\nlearning agents.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "52fc40e3",
        "archive": "courses/FAU/AI/course",
        "filepath": "rational-agents/slides/agent-types.en.xhtml"
    },
    {
        "slideContent": "\nSimple reflex agents\n\n▷\n                  A\nsimple reflex agent\n                  is an\nagent\n𝑎\n                  that only bases its\nactions\n                  on the last\npercept: so the\nagent function\n                  simplifies to\n𝑓𝑎:𝒫→𝒜.\n\n\n▷Agent Schema\n\n\n\n\n▷Agent Program\n\n\nprocedure Reflex―Vacuum―Agent [location,status] returns an action\nif status = Dirty then ...\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "52fc40e3",
        "archive": "courses/FAU/AI/course",
        "filepath": "rational-agents/slides/simple-reflex-agent.en.xhtml"
    },
    {
        "slideContent": "\nSimple reflex agents (continued)\n\n▷General Agent Program\n\n\nfunction Simple―Reflex―Agent (𝑝𝑒𝑟𝑐𝑒𝑝𝑡) returns an action\npersistent: 𝑟𝑢𝑙𝑒𝑠 /* a set of condition―action rules*/\n\n𝑠𝑡𝑎𝑡𝑒 := Interpret―Input(𝑝𝑒𝑟𝑐𝑒𝑝𝑡)\n𝑟𝑢𝑙𝑒 := Rule―Match(𝑠𝑡𝑎𝑡𝑒,𝑟𝑢𝑙𝑒𝑠)\n𝑎𝑐𝑡𝑖𝑜𝑛 := Rule―action[𝑟𝑢𝑙𝑒]\nreturn 𝑎𝑐𝑡𝑖𝑜𝑛\n\n▷Problem\nSimple reflex agents\n                  can only react to the\nperceived\n                  state of the\nenvironment, not to changes.\n\n\n▷\n                  Automobile tail lights signal braking by brightening. A\nsimple reflex agent\n                  would have to compare subsequent\npercepts\n                  to realize.\n\n\n▷Problem\nPartially observable\nenvironments\n                  get\nsimple reflex agents\n                  into trouble.\n\n\n▷\n                  Vacuum cleaner robot with defective location sensor\n⤳\ninfinite loops.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-15\n",
        "sectionId": "52fc40e3",
        "archive": "courses/FAU/AI/course",
        "filepath": "rational-agents/slides/simple-reflex-agent-impl.en.xhtml"
    },
    {
        "slideContent": "\nModel-based Reflex Agents: Idea\n\n▷Idea\n                  Keep track of the state of the world we cannot see in an internal model.\n\n\n▷Agent Schema\n\n\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "52fc40e3",
        "archive": "courses/FAU/AI/course",
        "filepath": "rational-agents/slides/model-based-agent.en.xhtml"
    },
    {
        "slideContent": "\nModel-based Reflex Agents: Definition\n\n▷\n\n\n▷Note\n                  As different\npercept\n                  sequences lead to different\nstates, so the\nagent function\n𝑓𝑎:𝒫*→𝒜\n                  no longer depends only on the last\npercept.\n\n\n▷Tail Lights Again\nModel-based agents\n                  can do the\n??\n                  if the\nstates\n                  include a concept of tail light brightness.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 122024-12-14\n",
        "sectionId": "52fc40e3",
        "archive": "courses/FAU/AI/course",
        "filepath": "rational-agents/slides/model-based-agent.en.xhtml"
    },
    {
        "slideContent": "\nModel-Based Agents (continued)\n\n▷\n                  The\nagent program\n                  for a\nmodel-based agent\n                  is of the following form:\n\n\nfunction Model―Based―Agent (𝑝𝑒𝑟𝑐𝑒𝑝𝑡) returns an action\nvar 𝑠𝑡𝑎𝑡𝑒 /* a description of the current state of the world */\npersistent 𝑟𝑢𝑙𝑒𝑠 /* a set of condition―action rules */\nvar 𝑎𝑐𝑡𝑖𝑜𝑛 /* the most recent action, initially none */\n\n𝑠𝑡𝑎𝑡𝑒 := Update―State(𝑠𝑡𝑎𝑡𝑒,𝑎𝑐𝑡𝑖𝑜𝑛,𝑝𝑒𝑟𝑐𝑒𝑝𝑡)\n𝑟𝑢𝑙𝑒 := Rule―Match(𝑠𝑡𝑎𝑡𝑒,𝑟𝑢𝑙𝑒𝑠)\n𝑎𝑐𝑡𝑖𝑜𝑛 := Rule―action(𝑟𝑢𝑙𝑒)\nreturn 𝑎𝑐𝑡𝑖𝑜𝑛\n\n▷ProblemHaving a\nworld model\n                  does not always determine what to do (rationally).\n\n\n▷\n                  Coming to an intersection, where the\nagent\n                  has to decide between going left and right.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "52fc40e3",
        "archive": "courses/FAU/AI/course",
        "filepath": "rational-agents/slides/model-based-agent-impl.en.xhtml"
    },
    {
        "slideContent": "\nGoal-based Agents\n\n▷ProblemA\nworld model\n                  does not always determine what to do (rationally).\n\n\n▷Observation\n                  Having a goal in mind does!(determines future actions)\n\n\n▷Agent Schema\n\n\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "52fc40e3",
        "archive": "courses/FAU/AI/course",
        "filepath": "rational-agents/slides/goal-based-agent.en.xhtml"
    },
    {
        "slideContent": "\nGoal-based\nagents\n              (continued)\n\n▷\n                  A\ngoal-based agent\n                  is a\nmodel-based agent\n                  with\ntransition model\n𝑇\n                  that deliberates\nactions\n                  based on\ngoals\n                  and a\nworld model: It employs\n\n\n▷a set\n𝒢\n                  of\ngoals\n                  and a\ngoal function\n𝑓\n                  that given a (new)\nstate\n𝑠'\n                  selects an\naction\n𝑎\n                  to best reach\n𝒢.\n\n\nThe\naction function\n                  is then\n𝑠↦𝑓(𝑇(𝑠),𝒢).\n\n\n▷Observation\n                  A\ngoal-based agent\n                  is more flexible in the knowledge it can utilize.\n\n\n▷\n                  A\ngoal-based agent\n                  can easily be changed to go to a new destination, a\nmodel-based agent’s rules make it go to exactly one destination.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 122024-12-14\n",
        "sectionId": "52fc40e3",
        "archive": "courses/FAU/AI/course",
        "filepath": "rational-agents/slides/goal-based-agent.en.xhtml"
    },
    {
        "slideContent": "\nUtility-based Agents\n\n▷\n                  A\nutility-based agent\n                  uses a\nworld model\n                  along with a\nutility function\n                  that models its preferences among the\nstates\n                  of that world. It chooses the\naction\n                  that leads to the best\nexpected\nutility.\n\n\n▷Agent Schema\n\n\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "52fc40e3",
        "archive": "courses/FAU/AI/course",
        "filepath": "rational-agents/slides/utility-based-agent.en.xhtml"
    },
    {
        "slideContent": "\nUtility-based vs. Goal-based Agents\n\n▷Question\n                  What is the difference between\ngoal-based\n                  and\nutility-based agents?\n\n\n▷Utility-based Agents are a Generalization\n                  We can always force\ngoal-directedness by a\nutility function\n                  that only rewards\ngoal\nstates.\n\n\n▷Goal-based Agents can do less\n                  A\nutility function\n                  allows\nrational\n                  decisions where mere\ngoals\n                  are inadequate:\n\n\n▷conflicting\ngoals\n(utility\n                      gives tradeoff to make\nrational\n                      decisions)\n\n\n▷goals\n                  obtainable by\nuncertain\nactions(utility\n×\n                      likelihood helps)\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "52fc40e3",
        "archive": "courses/FAU/AI/course",
        "filepath": "rational-agents/slides/utility-vs-goal-based-agent.en.xhtml"
    },
    {
        "slideContent": "\nLearning Agents\n\n▷\n                  A\nlearning agent\n                  is an\nagent\n                  that augments the\nperformance element\n                  — which determines\nactions\n                  from\npercept\n                  sequences with\n\n\n▷a\nlearning element\n                  which makes improvements to the\nagent’s components,\n\n\n▷a\ncritic\n                  which gives feedback to the\nlearning element\n                  based on an external\nperformance standard,\n\n\n▷a\nproblem generator\n                  which suggests\nactions\n                  that lead to new and informative experiences.\n\n\n▷The\nperformance element\n              is what we took for the whole\nagent\n              above.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "52fc40e3",
        "archive": "courses/FAU/AI/course",
        "filepath": "rational-agents/slides/learning-agent.en.xhtml"
    },
    {
        "slideContent": "\nLearning Agents\n\n▷Agent Schema\n\n\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-15\n",
        "sectionId": "52fc40e3",
        "archive": "courses/FAU/AI/course",
        "filepath": "rational-agents/slides/learning-agent-schema.en.xhtml"
    },
    {
        "slideContent": "\nLearning Agents: Example\n\n▷Learning Taxi Agent\n                  It has the components\n\n\n▷Performance element: the knowledge and procedures for selecting driving actions.(this controls the actual driving)\n\n\n▷critic: observes the world and informs the\nlearning element\n(e.g. when passengers complain brutal braking)\n\n\n▷Learning element\n                  modifies the braking rules in the\nperformance element\n(e.g. earlier, softer)\n\n\n▷Problem generator\n                  might experiment with braking on different road surfaces\n\n\n▷The\nlearning element\n              can make changes to any “knowledge components” of the diagram, e.g. in the\n\n\n▷model from the\npercept\n              sequence\n(how the world evolves)\n\n\n▷success likelihoods by observing\naction\n              outcomes(what my actions do)\n\n\nObservation\n                  here, the passenger complaints serve as part of the “external performance standard” since they correlate to the overall outcome — e.g. in form of tips or blacklists.\n\n\n▷\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "52fc40e3",
        "archive": "courses/FAU/AI/course",
        "filepath": "rational-agents/slides/taxi-agent.en.xhtml"
    },
    {
        "slideContent": "\nDomain-Specific vs. General Agents\n\n▷\nDomain-Specific Agent\n\nvs. \nGeneral Agent\n\n\n\nvs. \n\n\nSolver specific to a particular problem (“domain”).\n\nvs. \nSolver based on\ndescription\n                              in a general problem-description language (e.g., the rules of any board game).\n\nMore\nefficient.\n\nvs. \nMuch less design/maintenance work.\n\n\n\n▷What kind of\nagent\n            are you?\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-16\n",
        "sectionId": "52fc40e3",
        "archive": "courses/FAU/AI/course",
        "filepath": "rational-agents/slides/domainspecific-vs-general-agents.en.xhtml"
    },
    {
        "slideContent": "\nRepresenting\n              the\nEnvironment\n              in\nAgents\n\n▷We have seen various\ncomponents\n              of\nagents\n              that\nanswer\nquestions\n              like\n\n\n▷What is the world like now?\n\n\n▷What\naction\n                should I do now?\n\n\n▷What do my\nactions\n                do?\n\n\nNext natural question\n                  How do these work?\n(see the rest of the\ncourse)\n\n\n▷\n\n▷Important Distinction\n                  How the\nagent\nimplements\n                  the\nwold model.\n\n\n▷\n                  We call a\nstate\nrepresentation\n\n\n▷atomic,\niff\n                  it has no internal structure(black box)\n\n\n▷factored,\niff\n                  each\nstate\n                  is characterized by\nattributes\n                  and their\nvalues.\n\n\n▷structured,\niff\n                  the\nstate\n                  includes\nrepresentations\n                  of\nobjects, their\nproperties\n                  and\nrelationships.\n\n\n▷Intuition\n                  From\natomic\n                  to\nstructured, the\nrepresentations\n                  agent designer more flexibility and the\nalgorithms\n                  more components to process.\n\n\n▷Also\n                  The additional internal structure will make the\nalgorithms\n                  more complex.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "48a50e88",
        "archive": "courses/FAU/AI/course",
        "filepath": "rational-agents/slides/agent-state.en.xhtml"
    },
    {
        "slideContent": "\nAtomic/Factored/Structured\nState\nRepresentations\n\n▷Schematically\n                  We can visualize the three kinds by\n\n\n\n\n▷\n                  Consider the problem of finding a driving route from one end of a country to the other via some sequence of cities.\n\n\n▷In an\natomic\nrepresentation\n                      the\nstate\n                      is\nrepresented\n                      by the name of a city.\n\n\n▷In a\nfactored\nrepresentation\n                      we may have\nattributes\n                      “gps-location”, “gas”,...(allows\ninformation\n                      sharing between\nstates\n                      and\nuncertainty)\n\n\n▷But how to\nrepresent\n                      a situation, where a large truck blocking the road, since it is trying to back into a driveway, but a loose cow is blocking its path.\n(attribute\n                      “TruckAheadBackingIntoDairyFarmDrivewayBlockedByLooseCow” is unlikely)\n\n\n▷In a\nstructured\nrepresentation, we can have\nobjects\n                  for trucks, cows, etc. and their relationships.(at “run-time”)\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-16\n",
        "sectionId": "48a50e88",
        "archive": "courses/FAU/AI/course",
        "filepath": "rational-agents/slides/agent-state-ex.en.xhtml"
    },
    {
        "slideContent": "\nProblem Solving: Introduction\n\n▷Recap\nAgents\nperceive\n                  the\nenvironment\n                  and compute an\naction.\n\n\n▷In other words\nAgents\n                  continually solve “the problem of what to do next”.\n\n\n▷AI Goal\n                  Find\nalgorithms\n                  that help solving problems in general.\n\n\n▷Idea\n                  If we can describe/represent problems in a standardized way, we may have a chance to find general\nalgorithms.\n\n\n▷Concretely\n                  We will use the following two concepts to describe problems\n\n\n▷States: A set of possible situations in our problem domain(=^\nenvironments)\n\n\n▷Actions: that get us from one\nstate\n                  to another.(=^\nagents)\n\n\nA sequence of\nactions\n                  is a\nsolution, if it brings us from an\ninitial state\n                  to a\ngoal state.\nProblem solving\n                  computes\nsolutions\n                  from\nproblem formulations.\n\n\n▷\n                  In\noffline\nproblem solving\n                  an\nagent\n                  computing an action sequence based complete knowledge of the\nenvironment.\n\n\n▷\nOffline\nproblem solving\n                  only works in\nfully observable,\ndeterministic,\nstatic, and\nepisodic\nenvironments.\n\n\n▷\n                  In\nonline\nproblem solving\n                  an\nagent\n                  computes one\naction\n                  at a time based on incoming\nperceptions.\n\n\n▷This Semester\n                  We largely restrict ourselves to\noffline\nproblem solving.(easier)\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "3be301e7",
        "archive": "courses/FAU/AI/course",
        "filepath": "search/slides/problem-solving.en.xhtml"
    },
    {
        "slideContent": "\nExample: Traveling in Romania\n\n▷Scenario\n                  An\nagent\n                  is on holiday in Romania; currently in Arad; flight home leaves tomorrow from Bucharest; how to get there? We have a map:\n\n\n\n\n▷Formulate the Problem\n\n\n▷States: various cities.\n\n\n▷Actions: drive between cities.\n\n\n▷Solution\n                  Appropriate sequence of cities, e.g.: Arad, Sibiu, Fagaras, Bucharest\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-16\n",
        "sectionId": "3be301e7",
        "archive": "courses/FAU/AI/course",
        "filepath": "search/slides/romania-ex.en.xhtml"
    },
    {
        "slideContent": "\nProblem Formulation\n\n▷\n                  A\nproblem formulation\n                  models a situation using\nstates\n                  and\nactions\n                  at an appropriate level of abstraction.(do not model things like “put on my left sock”, etc.)\n\n\n▷it describes the\ninitial state(we are in Arad)\n\n\n▷it also limits the objectives by specifying\ngoal states.\n(excludes, e.g. to stay another couple of weeks.)\n\n\nA\nsolution\n                  is a sequence of\nactions\n                  that leads from the\ninitial state\n                  to a\ngoal state.\n\nProblem solving\n                  computes\nsolutions\n                  from\nproblem formulations.\n\n\n▷Finding the right level of abstraction and the required (not more!) information is often the key to success.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "3be301e7",
        "archive": "courses/FAU/AI/course",
        "filepath": "search/slides/problem-formulation.en.xhtml"
    },
    {
        "slideContent": "\nThe Math of Problem Formulation: Search Problems\n\n▷\n                  A\nsearch problem\nΠ:=〈𝒮,𝒜,𝒯,ℐ,𝒢〉\n                  consists of a\nset\n𝒮\n                  of\nstates, a\nset\n𝒜\n                  of\nactions, and a\ntransition model\n𝒯:𝒜×𝒮→𝒫(𝒮)\n                  that\nassigns\n                  to any\naction\n𝑎∊𝒜\n                  and\nstate\n𝑠∊𝒮\n                  a\nset\n                  of\nsuccessor states.\n\nCertain\nstates\n                  in\n𝒮\n                  are designated as\ngoal states\n                  (also called\nterminal state) (𝒢⊆𝒮\n                  with\n𝒢≠∅) and\ninitial states\nℐ⊆𝒮.\n\n\n▷\n                  We say that an\naction\n𝑎∊𝒜\n                  is\napplicable\n                  in\nstate\n𝑠∊𝒮, iff\n𝒯(𝑎,𝑠)≠∅. We call\n𝒯𝑎:𝒮→𝒫(𝒮)\n                  with\n𝒯𝑎(𝑠):=𝒯(𝑎,𝑠)\n                  the\nresult relation\n                  for\n𝑎\n                  and\n𝒯𝒜:=⋃𝑎∊𝒜𝒯𝑎\n                  the\nresult relation\n                  of\nΠ.\n\n\n▷\n                  The\ngraph\n〈𝒮,𝒯𝒜〉\n                  is called the\nstate space\n                  induced by\nΠ.\n\n\n▷A\nsolution\n                  for\nΠ\n                  consists of a\nsequence\n𝑎1,...,𝑎𝑛\n                  of\nactions\n                  such that for all\n1≤𝑖<𝑛\n\n\n▷𝑎𝑖\n                  is\napplicable\n                  to\nstate\n𝑠𝑖−1, where\n𝑠0∊ℐ\n                  and\n\n\n▷𝑠𝑖∊𝒯𝑎𝑖(𝑠𝑖−1), and\n𝑠𝑛∊𝒢.\n\n\n▷Idea\n                  A\nsolution\n                  bring us from\nℐ\n                  to a\ngoal state\n                  via\napplicable\nactions.\n\n\n▷\n                  Often we add a\ncost function\n𝑐:𝒜→ℝ0+\n                  that associates a\nstep cost\n𝑐(𝑎)\n                  to an\naction\n𝑎∊𝒜. The\ncost\n                  of a\nsolution\n                  is the sum of the\nstep costs\n                  of its\nactions.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "3be301e7",
        "archive": "courses/FAU/AI/course",
        "filepath": "search/slides/search-problem.en.xhtml"
    },
    {
        "slideContent": "\nStructure Overview: Search Problem\n\n▷The structure overview for\nsearch problems:\n\n\nsearch problem = 〈𝒮𝐒𝐞𝐭states,𝒜𝐒𝐞𝐭actions,𝒯𝒜×𝒮→𝒫(𝒮)\ntransition model\n,ℐ𝒮\ninitial state\n,𝒢𝒫(𝒮)\ngoal states\n〉\n\n\nMichael Kohlhase:\nArtificial Intelligence 122024-12-14\n",
        "sectionId": "3be301e7",
        "archive": "courses/FAU/AI/course",
        "filepath": "search/slides/search-problem.en.xhtml"
    },
    {
        "slideContent": "\nSearch Problems\n              in\ndeterministic,\nfully observable\nEnvironments\n\n▷\n                  This\nsemester, we will restrict ourselves to\nsearch problems, where(extend in AI II)\n\n\n▷|𝒯(𝑎,𝑠)|≤1\n                  for the\ntransition models\n                  and\n(\n⇝\n\ndeterministic\nenvironment)\n\n\n▷ℐ={𝑠0}(\n⇝\n\nfully observable\nenvironment)\n\n\n▷\n\n\n▷\n\n\n▷\n                  The predicate that tests for\ngoal states\n                  is called a\ngoal test.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "3be301e7",
        "archive": "courses/FAU/AI/course",
        "filepath": "search/slides/search-problem-detenv.en.xhtml"
    },
    {
        "slideContent": "\nProblem types\n\n▷\n                  A\nsearch problem\n                  is called a\nsingle state problem, iff it is\n\n\n▷fully observable(at least the initial state)\n\n\n▷deterministic(unique\nsuccessor states)\n\n\n▷static(states do not change other than by our own actions)\n\n\n▷discrete(a countable number of states)\n\n\n▷\n                  A\nsearch problem\n                  is called a\nmulti state problem\n\n\n▷states\npartially observable(e.g. multiple\ninitial states)\n\n\n▷deterministic,\nstatic,\ndiscrete\n\n\n▷\n                  A\nsearch problem\n                  is called a\ncontingency problem, iff\n\n\n▷the\nenvironment\n                  is\nnon deterministic(solution can branch, depending on contingencies)\n\n\n▷the\nstate space\n                  is unknown(like a baby, agent has to learn about\nstates\n                      and\nactions)\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "e4a2e0f",
        "archive": "courses/FAU/AI/course",
        "filepath": "search/slides/problem-types.en.xhtml"
    },
    {
        "slideContent": "\nExample: vacuum-cleaner world\n\n▷Single-state Problem\n\n\n\n▷Start in\n5\n\n\n▷Solution:\n[𝑟𝑖𝑔ℎ𝑡,𝑠𝑢𝑐𝑘]\n\n\n\n\n\n\n\n\n \n\n▷Multiple-state Problem\n\n\n▷Start in\n{1,2,3,4,5,6,7,8}\n\n\n▷Solution:\n[𝑟𝑖𝑔ℎ𝑡,𝑠𝑢𝑐𝑘,𝑙𝑒𝑓𝑡,𝑠𝑢𝑐𝑘]\n𝑟𝑖𝑔ℎ𝑡→\n{2,4,6,8}\n𝑠𝑢𝑐𝑘→\n{4,8}\n𝑙𝑒𝑓𝑡→\n{3,7}\n𝑠𝑢𝑐𝑘→\n{7}\n\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-15\n",
        "sectionId": "e4a2e0f",
        "archive": "courses/FAU/AI/course",
        "filepath": "search/slides/vacuum-cleaner-example.en.xhtml"
    },
    {
        "slideContent": "\nExample: Vacuum-Cleaner World (continued)\n\n▷Contingency Problem\n\n\n\n▷Murphy’s Law:\n𝑠𝑢𝑐𝑘\n                                    can dirty a clean carpet\n\n\n▷Local sensing:\n𝑑𝑖𝑟𝑡𝑦/𝑛𝑜𝑡𝑑𝑖𝑟𝑡𝑦\n                                    at location only\n\n\n▷Start in:\n{1,3}\n\n\n▷Solution:\n[𝑠𝑢𝑐𝑘,𝑟𝑖𝑔ℎ𝑡,𝑠𝑢𝑐𝑘]\n𝑠𝑢𝑐𝑘→\n{5,7}\n𝑟𝑖𝑔ℎ𝑡→\n{6,8}\n𝑠𝑢𝑐𝑘→\n{6,8}\n\n\n\n\n\n\n\n\n\n \n\n▷better\n[𝑠𝑢𝑐𝑘,𝑟𝑖𝑔ℎ𝑡,𝐢𝐟𝑑𝑖𝑟𝑡𝐭𝐡𝐞𝐧𝑠𝑢𝑐𝑘]\n(decide whether in\n6\n                      or\n8\n                      using local sensing)\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 122024-12-15\n",
        "sectionId": "e4a2e0f",
        "archive": "courses/FAU/AI/course",
        "filepath": "search/slides/vacuum-cleaner-example.en.xhtml"
    },
    {
        "slideContent": "\nSingle-state problem formulation\n\n▷Defined by the following four items\n\n\n1.Initial state:(e.g.\n𝐴𝑟𝑎𝑑)\n\n\n2.Successor function\n𝑆𝑎(𝑠):(e.g.\n𝑆𝑔𝑜𝑍𝑒𝑟={(𝐴𝑟𝑎𝑑,𝑍𝑒𝑟𝑖𝑛𝑑),(𝑔𝑜𝑆𝑖𝑏,𝑆𝑖𝑏𝑖𝑢),...})\n\n\n3.Goal test:(e.g.\n𝑥=𝐵𝑢𝑐ℎ𝑎𝑟𝑒𝑠𝑡(explicit test) 𝑛𝑜𝐷𝑖𝑟𝑡(𝑥) (implicit test) )\n\n\n4.Path cost\n              (optional):(e.g. sum of distances, number of operators executed, etc.)\n\n\n▷Solution: A sequence of\nactions\n              leading from the\ninitial state\n              to a\ngoal state.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "e4a2e0f",
        "archive": "courses/FAU/AI/course",
        "filepath": "search/slides/single-state-problem.en.xhtml"
    },
    {
        "slideContent": "\nSelecting a\nstate space\n\n▷Abstraction\n                  Real world is absurdly complex!\nState space\n                  must be abstracted for problem solving.\n\n\n▷(Abstract) state\n                  Set of real states.\n\n\n▷(Abstract) operator\n                  Complex combination of real actions.\n\n\n▷Example\n𝐴𝑟𝑎𝑑→𝑍𝑒𝑟𝑖𝑛𝑑\n                  represents complex set of possible routes.\n\n\n▷(Abstract) solution\n                  Set of real paths that are solutions in the real world.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 122024-12-14\n",
        "sectionId": "e4a2e0f",
        "archive": "courses/FAU/AI/course",
        "filepath": "search/slides/single-state-problem.en.xhtml"
    },
    {
        "slideContent": "\nExample: The 8-puzzle\n\n\n\nStates?\nActions?...\nStates integer locations of tilesActions 𝑙𝑒𝑓𝑡,𝑟𝑖𝑔ℎ𝑡,𝑢𝑝,𝑑𝑜𝑤𝑛Goal test = goal state?Path cost 1 per move\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-15\n",
        "sectionId": "e4a2e0f",
        "archive": "courses/FAU/AI/course",
        "filepath": "search/slides/more-examples.en.xhtml"
    },
    {
        "slideContent": "\nExample: Vacuum-cleaner\n\n\n\nStates?\nActions?...\nStates integer dirt and robot locationsActions𝑙𝑒𝑓𝑡,𝑟𝑖𝑔ℎ𝑡,𝑠𝑢𝑐𝑘,𝑛𝑜𝑂𝑝Goal test𝑛𝑜𝑡𝑑𝑖𝑟𝑡𝑦?Path cost1 per operation(0 for 𝑛𝑜𝑂𝑝)\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 122024-12-15\n",
        "sectionId": "e4a2e0f",
        "archive": "courses/FAU/AI/course",
        "filepath": "search/slides/more-examples.en.xhtml"
    },
    {
        "slideContent": "\nExample: Robotic assembly\n\n\nStates?\nActions?...\nStates real-valued coordinates of robot joint angles and parts of the object to be assembledActionscontinuous motions of robot jointsGoal testassembly complete?Path costtime to execute\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 132024-12-15\n",
        "sectionId": "e4a2e0f",
        "archive": "courses/FAU/AI/course",
        "filepath": "search/slides/more-examples.en.xhtml"
    },
    {
        "slideContent": "\nGeneral Problems\n\n▷Question\n                Which are “Problems”?\n\n\n(A)You didn’t understand any of the\nlecture.\n\n\n(B)Your bus today will probably be late.\n\n\n(C)Your vacuum cleaner wants to clean your apartment.\n\n\n(D)You want to win a\nchess\n                game.\n\n\n▷Answerreserved for the plenary sessions\n⤳\n                be there!\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-16\n",
        "sectionId": "e4a2e0f",
        "archive": "courses/FAU/AI/course",
        "filepath": "search/quest/general-problems.en.xhtml"
    },
    {
        "slideContent": "\nTree Search Algorithms\n\n▷Note\n                  The\nstate space\n                  of a\nsearch problem\n〈𝒮,𝒜,𝒯,ℐ,𝒢〉\n                  is a\ngraph\n〈𝒮,𝒯𝒜〉.\n\n\n▷As\ngraphs\n              are difficult to compute with, we often compute a corresponding\ntree\n              and work on that.\n(standard trick in\ngraph\nalgorithms)\n\n\n▷\n                  Given a\nsearch problem\n𝒫:=〈𝒮,𝒜,𝒯,ℐ,𝒢〉, the\ntree search algorithm\n                  consists of the simulated exploration of\nstate space\n〈𝒮,𝒯𝒜〉\n                  in a\nsearch tree\n                  formed by successively\nexpanding\n                  already explored\nstates.(offline\nalgorithm)\n\n\nprocedure Tree―Search (problem, strategy) : <a solution or failure>\n<initialize the search tree using the initial state of problem>\nloop\nif <there are no candidates for expansion> <return failure> end if\n<choose a leaf node for expansion according to strategy>\nif <the node contains a goal state> return <the corresponding solution>\nelse <expand the node and add the resulting nodes to the search tree>\nend if\nend loop\nend procedure\n\nWe\nexpand\n                  a\nnode\n𝑛\n                  by generating all\nsuccessors\n                  of\n𝑛\n                  and inserting them as\nchildren\n                  of\n𝑛\n                  in the\nsearch tree.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "bcfcca62",
        "archive": "courses/FAU/AI/course",
        "filepath": "search/slides/ts-algo.en.xhtml"
    },
    {
        "slideContent": "\nTree Search: Example\n\n\n\n\n\n\n\n\n\n\n\n\n\nArad   \n\n\n                              ???\n\n\n\n\n\n\n\n\nSibiu   \n\n\n                              ???\n\n\n\n\n\n\n\n\n\n\n\n\n\nTimisoara   \n\n\n                              ???\n\n\n\n\n\n\n\n\n\n\n\n\n\nZerind   \n\n\n                              ???\n\n\n\n\n\n\n\n\n\n\n\n\n\nArad   \n\n\n                              ???\n\n\n\n\n\n\n\n\n\n\n\n\n\nFagaras   \n\n\n                              ???\n\n\n\n\n\n\n\n\n\n\n\n\n\nOradea   \n\n\n                              ???\n\n\n\n\n\n\n\n\n\n\n\n\n\nR. Vilcea   \n\n\n                              ???\n\n\n\n\n\n\n\n\n\n\n\n\n\nArad   \n\n\n                              ???\n\n\n\n\n\n\n\n\n\n\n\n\n\nLugoj   \n\n\n                              ???\n\n\n\n\n\n\n\n\n\n\n\n\n\nOradea   \n\n\n                              ???\n\n\n\n\n\n\n\n\n\n\n\n\n\nArad   \n\n\n                              ???\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArad  \n\n                              ???\n\n\n\n\n\n\n\n\nSibiu   \n\n\n                              ???\n\n\n\n\n\n\nTimisoara  \n\n                              ???\n\n\n\n\n\n\nZerind  \n\n                              ???\n\n\n\n\n\n\n\n\n\nArad   \n\n\n                              ???\n\n\n\n\n\n\n\n\n\n\n\n\n\nFagaras   \n\n\n                              ???\n\n\n\n\n\n\n\n\n\n\n\n\n\nOradea   \n\n\n                              ???\n\n\n\n\n\n\n\n\n\n\n\n\n\nR. Vilcea   \n\n\n                              ???\n\n\n\n\n\n\n\n\n\n\n\n\n\nArad   \n\n\n                              ???\n\n\n\n\n\n\n\n\n\n\n\n\n\nLugoj   \n\n\n                              ???\n\n\n\n\n\n\n\n\n\n\n\n\n\nOradea   \n\n\n                              ???\n\n\n\n\n\n\n\n\n\n\n\n\n\nArad   \n\n\n                              ???\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArad  \n\n                              ???\n\n\n\n\n\nSibiu  \n\n                              ???\n\n\n\n\n\n\nTimisoara  \n\n                              ???\n\n\n\n\n\n\n\n\n\nZerind   \n\n\n                              ???\n\n\n\n\n\n\nArad  \n\n                              ???\n\n\n\n\n\n\nFagaras  \n\n                              ???\n\n\n\n\n\n\nOradea  \n\n                              ???\n\n\n\n\n\n\nR. Vilcea  \n\n                              ???\n\n\n\n\n\n\n\n\n\nArad   \n\n\n                              ???\n\n\n\n\n\n\n\n\n\n\n\n\n\nLugoj   \n\n\n                              ???\n\n\n\n\n\n\n\n\n\n\n\n\n\nOradea   \n\n\n                              ???\n\n\n\n\n\n\n\n\n\n\n\n\n\nArad   \n\n\n                              ???\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArad  \n\n                              ???\n\n\n\n\n\nSibiu  \n\n                              ???\n\n\n\n\n\n\nTimisoara  \n\n                              ???\n\n\n\n\n\n\nZerind  \n\n                              ???\n\n\n\n\n\n\nArad  \n\n                              ???\n\n\n\n\n\n\nFagaras  \n\n                              ???\n\n\n\n\n\n\nOradea  \n\n                              ???\n\n\n\n\n\n\nR. Vilcea  \n\n                              ???\n\n\n\n\n\n\n\n\n\nArad   \n\n\n                              ???\n\n\n\n\n\n\n\n\n\n\n\n\n\nLugoj   \n\n\n                              ???\n\n\n\n\n\n\n\n\n\n\nOradea  \n\n                              ???\n\n\n\n\n\n\n\n\n\nArad   \n\n\n                              ???\n\n\n\n\n\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-15\n",
        "sectionId": "bcfcca62",
        "archive": "courses/FAU/AI/course",
        "filepath": "search/slides/ts-ex.en.xhtml"
    },
    {
        "slideContent": "\nImplementation: States vs. nodes\n\n▷Recap\n                  A\nstate\n                  is a (representation\n                  of) a physical configuration.\n\n\n▷Implementing a\nSearch Tree\n\n\n\nA\nsearch tree node\n                                    is a\ndata structure\n                                    that includes\naccessors\n                                    for\nparent,\nchildren,\ndepth,\npath cost, insertion order, etc.\n\nA\ngoal node\n                                    (initial node) is a\nsearch tree node\nlabeled\n                                    with a\ngoal state\n                                    (initial state).\n\n\n\n\n\n\n\n \n\n▷Observation\n                  A\nset\n                  of\nsearch tree nodes\n                  that can all (recursively) reach a single\ninitial node\n                  form a\nsearch tree.\n(they\nimplement\n                      it)\n\n\n▷Observation\nPaths\n                  in the\nsearch tree\n                  correspond to\npaths\n                  in the\nstate space.\n\n\n▷\n                  We define the\npath cost\n                  of a\nnode\n𝑛\n                  in a\nsearch tree\n𝑇\n                  to be the sum of the\nstep costs\n                  on the\npath\n                  from\n𝑛\n                  to the\nroot\n                  of\n𝑇.\n\n\n▷Observation\n                  As a\nsearch tree node\n                  has access to\nparents, we can read off the\nsolution\n                  from a\ngoal node.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "bcfcca62",
        "archive": "courses/FAU/AI/course",
        "filepath": "search/slides/ts-impl.en.xhtml"
    },
    {
        "slideContent": "\nImplementation\n              of Search Algorithms\n\n▷Implemented\nTree Search\nAlgorithm\n\n\nprocedure Tree_Search (problem,strategy)\nfringe := insert(make_node(initial_state(problem)))\nloop\nif empty(fringe) fail end if\nnode := first(fringe,strategy)\nif GoalNode(node) return node\nelse fringe := insert(expand(node,problem))\nend if\nend loop\nend procedure\n\nThe\nfringe\n                  is the\nset\n                  of\nsearch tree nodes\n                  not yet\nexpanded\n                  in\ntree search.\n\n\n▷Idea\n                  We treat the\nfringe\n                  as an\nabstract data type\n                  with three\naccessors: the\n\n\n▷binary\nfunction\nfirst\n                  retrieves an\nelement\n                  from the\nfringe\n                  according to a\nstrategy.\n\n\n▷binary\nfunction\ninsert\n                  adds a (set of)\nsearch tree node\n                  into a\nfringe.\n\n\n▷unary\npredicate\nempty\n                  to determine whether a\nfringe\n                  is the\nempty\nset.\n\n\n▷The\nstrategy\n              determines the behavior of the\nfringe\n              (data structure)(see below)\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 122024-12-14\n",
        "sectionId": "bcfcca62",
        "archive": "courses/FAU/AI/course",
        "filepath": "search/slides/ts-impl.en.xhtml"
    },
    {
        "slideContent": "\nSearch strategies\n\n▷\n                  A\nstrategy\n                  is a\nfunction\n                  that picks a\nnode\n                  from the\nfringe\n                  of a\nsearch tree.(equivalently, orders the\nfringe\n                      and picks the first.)\n\n\n▷Important Properties of Strategies\n\n\ncompleteness \ndoes it always find a\nsolution\n                                    if one exists?\n\ntime complexity \nnumber of\nnodes\n                                    generated/expanded\n\nspace complexity \nmaximum number of\nnodes\n                                    in memory\n\noptimality \ndoes it always find a least cost\nsolution?\n\n\n\n▷Time and space complexity measured in terms of\n\n\n𝑏 \nmaximum\nbranching factor\n                                    of the\nsearch tree\n\n𝑑 \nminimal\ngraph depth\n                                    of a\nsolution\n                                    in the\nsearch tree\n𝑚 \nmaximum\ngraph depth\n                                    of the\nsearch tree\n                                    (may be\n∞)\n\n\n\nComplexity\n                  means here always\nworst-case\ncomplexity!\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "bcfcca62",
        "archive": "courses/FAU/AI/course",
        "filepath": "search/slides/search-strategy.en.xhtml"
    },
    {
        "slideContent": "\nUninformed search strategies\n\n▷\n                  We speak of an\nuninformed\nsearch algorithm, if it only uses the\ninformation\n                  available in the\nproblem definition.\n\n\n▷NextFrequently used\nsearch algorithms\n\n\n▷Breadth first search\n\n\n▷Uniform cost search\n\n\n▷Depth first search\n\n\n▷Depth limited search\n\n\n▷Iterative deepening search\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "9217f80b",
        "archive": "courses/FAU/AI/course",
        "filepath": "search/slides/u-search-strategy.en.xhtml"
    },
    {
        "slideContent": "\nBreadth-First Search\n\n▷Idea\nExpand\n                  the shallowest\nunexpanded\nnode.\n\n\n▷\n                  The\nbreadth first search\n                  (BFS)\nstrategy\n                  treats the\nfringe\n                  as a\nFIFO\nqueue, i.e.\nsuccessors\n                  go in at the end of the\nfringe.\n\n\n▷Synthetic\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA   \n\n\n\n\n\n\n\n\n\n\nB   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nC   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nD   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nE   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nF   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nG   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nH   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nI   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nJ   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nK   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nL   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nM   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nN   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nO   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA  \n\n\n\n\n\n\n\n\n\nB   \n\n\n\n\n\n\n\n\nC  \n\n\n\n\n\n\n\n\n\n\nD   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nE   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nF   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nG   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nH   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nI   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nJ   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nK   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nL   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nM   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nN   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nO   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA  \n\n\n\n\n\n\nB  \n\n\n\n\n\n\n\n\n\n\nC   \n\n\n\n\n\n\n\n\nD  \n\n\n\n\n\n\n\nE  \n\n\n\n\n\n\n\n\n\n\nF   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nG   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nH   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nI   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nJ   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nK   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nL   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nM   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nN   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nO   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA  \n\n\n\n\n\n\nB  \n\n\n\n\n\n\n\nC  \n\n\n\n\n\n\n\n\n\n\nD   \n\n\n\n\n\n\n\n\nE  \n\n\n\n\n\n\n\nF  \n\n\n\n\n\n\n\nG  \n\n\n\n\n\n\n\n\n\n\nH   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nI   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nJ   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nK   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nL   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nM   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nN   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nO   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA  \n\n\n\n\n\n\nB  \n\n\n\n\n\n\n\nC  \n\n\n\n\n\n\n\nD  \n\n\n\n\n\n\n\n\n\n\nE   \n\n\n\n\n\n\n\n\nF  \n\n\n\n\n\n\n\nG  \n\n\n\n\n\n\n\nH  \n\n\n\n\n\n\n\nI  \n\n\n\n\n\n\n\n\n\n\nJ   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nK   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nL   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nM   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nN   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nO   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA  \n\n\n\n\n\n\nB  \n\n\n\n\n\n\n\nC  \n\n\n\n\n\n\n\nD  \n\n\n\n\n\n\n\nE  \n\n\n\n\n\n\n\n\n\n\nF   \n\n\n\n\n\n\n\n\nG  \n\n\n\n\n\n\n\nH  \n\n\n\n\n\n\n\nI  \n\n\n\n\n\n\n\nJ  \n\n\n\n\n\n\n\nK  \n\n\n\n\n\n\n\n\n\n\nL   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nM   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nN   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nO   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "6167f12",
        "archive": "courses/FAU/AI/course",
        "filepath": "search/slides/bf-search.en.xhtml"
    },
    {
        "slideContent": "\nBreadth-First Search: Romania\n\n▷\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArad   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArad  \n\n\n\n\n\n\n\n\n\nSibiu   \n\n\n\n\n\n\n\n\nTimisoara  \n\n\n\n\n\n\n\nZerind  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArad  \n\n\n\n\n\n\nSibiu  \n\n\n\n\n\n\n\n\n\n\nTimisoara   \n\n\n\n\n\n\n\n\nZerind  \n\n\n\n\n\n\n\nArad  \n\n\n\n\n\n\n\nFagaras  \n\n\n\n\n\n\n\nOradea  \n\n\n\n\n\n\n\nR. Vilcea  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArad  \n\n\n\n\n\n\nSibiu  \n\n\n\n\n\n\n\nTimisoara  \n\n\n\n\n\n\n\n\n\n\nZerind   \n\n\n\n\n\n\n\n\nArad  \n\n\n\n\n\n\n\nFagaras  \n\n\n\n\n\n\n\nOradea  \n\n\n\n\n\n\n\nR. Vilcea  \n\n\n\n\n\n\n\nArad  \n\n\n\n\n\n\n\nLugoj  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArad  \n\n\n\n\n\n\nSibiu  \n\n\n\n\n\n\n\nTimisoara  \n\n\n\n\n\n\n\nZerind  \n\n\n\n\n\n\n\n\n\n\nArad   \n\n\n\n\n\n\n\n\nFagaras  \n\n\n\n\n\n\n\nOradea  \n\n\n\n\n\n\n\nR. Vilcea  \n\n\n\n\n\n\n\nArad  \n\n\n\n\n\n\n\nLugoj  \n\n\n\n\n\n\n\nOradea  \n\n\n\n\n\n\n\nArad  \n\n\n\n\n\n\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 122024-12-14\n",
        "sectionId": "6167f12",
        "archive": "courses/FAU/AI/course",
        "filepath": "search/slides/bf-search.en.xhtml"
    },
    {
        "slideContent": "\nBreadth-first search: Properties\n\n▷\nCompleteness \nYes(if\n𝑏\n                                    is\nfinite)\n\nTime complexity \n1+𝑏+𝑏2+𝑏3+...+𝑏𝑑, so\n𝒪(𝑏𝑑), i.e. exponential in\n𝑑\n\nSpace complexity \n𝒪(𝑏𝑑)\n                                    (fringe\n                                    may be whole level)\n\nOptimality \nYes (if cost = 1 per step), not optimal in general\n\n\n\n▷Disadvantage\n                  Space is the big problem(can easily generate nodes at 500MB/sec\n=^\n                      1.8TB/h)\n\n\n▷Optimal?\n                  No! If cost varies for different steps, there might be better\nsolutions\n                  below the level of the first one.\n\n\n▷An alternative is to generate\nall\nsolutions\n              and then pick an\noptimal\n              one. This works only, if\n𝑚\n              is\nfinite.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 132024-12-14\n",
        "sectionId": "6167f12",
        "archive": "courses/FAU/AI/course",
        "filepath": "search/slides/bf-search.en.xhtml"
    },
    {
        "slideContent": "\nRomania with Step Costs as Distances\n\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "6167f12",
        "archive": "courses/FAU/AI/course",
        "filepath": "search/slides/uc-search.en.xhtml"
    },
    {
        "slideContent": "\nUniform-cost search\n\n▷Idea\nExpand\n                  least cost\nunexpanded\nnode.\n\n\n▷\nUniform-cost search\n                  (UCS) is the\nstrategy\n                  where the\nfringe\n                  is ordered by increasing\npath cost.\n\n\n▷NoteEquivalent to\nbreadth first search\n                  if all step costs are equal.\n\n\n▷Synthetic Example\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArad   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArad  \n\n\n\n\n\n\nSibiu  \n\n\n140  \n\n\n\n\n\nTimisoara  \n\n\n118  \n\n\n\n\n\n\n\n\nZerind   \n\n\n\n75  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArad  \n\n\n\n\n\n\nSibiu  \n\n\n140  \n\n\n\n\n\n\n\n\nTimisoara   \n\n\n\n118  \n\n\n\n\n\nZerind  \n\n\n75  \n\n\n\n\n\nOradea  \n\n\n71  \n\n\n\n\n\nArad  \n\n\n75  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArad  \n\n\n\n\n\n\n\n\n\nSibiu   \n\n\n\n140  \n\n\n\n\n\nTimisoara  \n\n\n118  \n\n\n\n\n\nZerind  \n\n\n75  \n\n\n\n\n\nArad  \n\n\n118  \n\n\n\n\n\nLugoj  \n\n\n111  \n\n\n\n\n\nOradea  \n\n\n71  \n\n\n\n\n\nArad  \n\n\n75  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArad  \n\n\n\n\n\n\nSibiu  \n\n\n140  \n\n\n\n\n\nTimisoara  \n\n\n118  \n\n\n\n\n\nZerind  \n\n\n75  \n\n\n\n\n\nArad  \n\n\n140  \n\n\n\n\n\nFagaras  \n\n\n99  \n\n\n\n\n\nOradea  \n\n\n151  \n\n\n\n\n\nR. Vilcea  \n\n\n80  \n\n\n\n\n\nArad  \n\n\n118  \n\n\n\n\n\nLugoj  \n\n\n111  \n\n\n\n\n\n\n\n\nOradea   \n\n\n\n71  \n\n\n\n\n\nArad  \n\n\n75  \n\n\n\n\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 122024-12-14\n",
        "sectionId": "6167f12",
        "archive": "courses/FAU/AI/course",
        "filepath": "search/slides/uc-search.en.xhtml"
    },
    {
        "slideContent": "\nUniform-cost search: Properties\n\nCompleteness \nYes(if step costs\n≥𝜖>0)\n\nTime complexity \nnumber of\nnodes\n                              with\npath cost\n                              less than that of optimal\nsolution\n\nSpace complexity \nditto\n\nOptimality \nYes\n\n\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 132024-12-14\n",
        "sectionId": "6167f12",
        "archive": "courses/FAU/AI/course",
        "filepath": "search/slides/uc-search.en.xhtml"
    },
    {
        "slideContent": "\nDepth-first Search\n\n▷Idea\nExpand\n                  deepest\nunexpanded\nnode.\n\n\n▷\nDepth-first search\n                  (DFS) is the\nstrategy\n                  where the\nfringe\n                  is organized as a (LIFO)\nstack\n                  i.e.\nsuccessors\n                  go in at front of the\nfringe.\n\n\n▷\n                  Every\nnode\n                  that is\npushed\n                  to the\nstack\n                  is called a\nbacktrack point. The action of\npopping\n                  a\nnon-goal node\n                  from the\nstack\n                  and continuing the\nsearch\n                  with the new top\nelement\n                  of the\nstack\n                  (a\nbacktrack point\n                  by construction) is called\nbacktracking, and correspondingly the\nDFS\nalgorithm\nbacktracking search.\n\n\n▷Note\nDepth first search\n                  can perform\ninfinite\ncyclic\n                  excursionsNeed a\nfinite, non cyclic\nstate space\n                  (or repeated state checking)\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "102de0f6",
        "archive": "courses/FAU/AI/course",
        "filepath": "search/slides/df-search.en.xhtml"
    },
    {
        "slideContent": "\nDepth-First Search\n\n▷Synthetic\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA   \n\n\n\n\n\n\n\n\n\n\nB   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nC   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nD   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nE   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nF   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nG   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nH   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nI   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nJ   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nK   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nL   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nM   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nN   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nO   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA  \n\n\n\n\n\n\n\n\n\nB   \n\n\n\n\n\n\n\n\nC  \n\n\n\n\n\n\n\n\n\n\nD   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nE   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nF   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nG   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nH   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nI   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nJ   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nK   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nL   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nM   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nN   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nO   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA  \n\n\n\n\n\n\nB  \n\n\n\n\n\n\n\nC  \n\n\n\n\n\n\n\n\n\n\nD   \n\n\n\n\n\n\n\n\nE  \n\n\n\n\n\n\n\n\n\n\nF   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nG   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nH   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nI   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nJ   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nK   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nL   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nM   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nN   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nO   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA  \n\n\n\n\n\n\nB  \n\n\n\n\n\n\n\nC  \n\n\n\n\n\n\n\nD  \n\n\n\n\n\n\n\nE  \n\n\n\n\n\n\n\n\n\n\nF   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nG   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nH   \n\n\n\n\n\n\n\n\nI  \n\n\n\n\n\n\n\n\n\n\nJ   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nK   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nL   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nM   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nN   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nO   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA  \n\n\n\n\n\n\nB  \n\n\n\n\n\n\n\nC  \n\n\n\n\n\n\n\nD  \n\n\n\n\n\n\n\nE  \n\n\n\n\n\n\n\n\n\n\nF   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nG   \n\n\n\n\n\n\n\n\n\n\n\n\nH  \n\n\n\n\n\n\n\n\n\n\nI   \n\n\n\n\n\n\n\n\n\n\n\nJ   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nK   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nL   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nM   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nN   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nO   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA  \n\n\n\n\n\n\nB  \n\n\n\n\n\n\n\nC  \n\n\n\n\n\n\n\nD  \n\n\n\n\n\n\n\n\n\n\nE   \n\n\n\n\n\n\n\n\n\n\n\nF   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nG   \n\n\n\n\n\n\n\n\n\n\n\n\nH  \n\n\n\n\n\n\n\nI  \n\n\n\n\n\n\n\n\n\n\nJ   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nK   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nL   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nM   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nN   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nO   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA  \n\n\n\n\n\n\nB  \n\n\n\n\n\n\n\nC  \n\n\n\n\n\n\n\nD  \n\n\n\n\n\n\n\nE  \n\n\n\n\n\n\n\n\n\n\nF   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nG   \n\n\n\n\n\n\n\n\n\n\n\n\nH  \n\n\n\n\n\n\n\nI  \n\n\n\n\n\n\n\n\n\n\nJ   \n\n\n\n\n\n\n\n\nK  \n\n\n\n\n\n\n\n\n\n\nL   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nM   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nN   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nO   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA  \n\n\n\n\n\n\nB  \n\n\n\n\n\n\n\nC  \n\n\n\n\n\n\n\nD  \n\n\n\n\n\n\n\nE  \n\n\n\n\n\n\n\n\n\n\nF   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nG   \n\n\n\n\n\n\n\n\n\n\n\n\nH  \n\n\n\n\n\n\n\nI  \n\n\n\n\n\n\n\nJ  \n\n\n\n\n\n\n\n\n\n\nK   \n\n\n\n\n\n\n\n\n\n\n\nL   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nM   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nN   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nO   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA  \n\n\n\n\n\n\nB  \n\n\n\n\n\n\n\n\n\n\nC   \n\n\n\n\n\n\n\n\nD  \n\n\n\n\n\n\n\nE  \n\n\n\n\n\n\n\n\n\n\nF   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nG   \n\n\n\n\n\n\n\n\n\n\n\n\nH  \n\n\n\n\n\n\n\nI  \n\n\n\n\n\n\n\nJ  \n\n\n\n\n\n\n\nK  \n\n\n\n\n\n\n\n\n\n\nL   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nM   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nN   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nO   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA  \n\n\n\n\n\n\nB  \n\n\n\n\n\n\n\nC  \n\n\n\n\n\n\n\nD  \n\n\n\n\n\n\n\nE  \n\n\n\n\n\n\n\n\n\n\nF   \n\n\n\n\n\n\n\n\nG  \n\n\n\n\n\n\n\nH  \n\n\n\n\n\n\n\nI  \n\n\n\n\n\n\n\nJ  \n\n\n\n\n\n\n\nK  \n\n\n\n\n\n\n\n\n\n\nL   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nM   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nN   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nO   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA  \n\n\n\n\n\n\nB  \n\n\n\n\n\n\n\nC  \n\n\n\n\n\n\n\nD  \n\n\n\n\n\n\n\nE  \n\n\n\n\n\n\n\nF  \n\n\n\n\n\n\n\nG  \n\n\n\n\n\n\n\nH  \n\n\n\n\n\n\n\nI  \n\n\n\n\n\n\n\nJ  \n\n\n\n\n\n\n\nK  \n\n\n\n\n\n\n\nL  \n\n\n\n\n\n\n\n\n\n\nM   \n\n\n\n\n\n\n\n\n\n\n\nN   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nO   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA  \n\n\n\n\n\n\nB  \n\n\n\n\n\n\n\nC  \n\n\n\n\n\n\n\nD  \n\n\n\n\n\n\n\nE  \n\n\n\n\n\n\n\nF  \n\n\n\n\n\n\n\n\n\n\nG   \n\n\n\n\n\n\n\n\nH  \n\n\n\n\n\n\n\nI  \n\n\n\n\n\n\n\nJ  \n\n\n\n\n\n\n\nK  \n\n\n\n\n\n\n\nL  \n\n\n\n\n\n\n\nM  \n\n\n\n\n\n\n\n\n\n\nN   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nO   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA  \n\n\n\n\n\n\nB  \n\n\n\n\n\n\n\nC  \n\n\n\n\n\n\n\nD  \n\n\n\n\n\n\n\nE  \n\n\n\n\n\n\n\nF  \n\n\n\n\n\n\n\nG  \n\n\n\n\n\n\n\nH  \n\n\n\n\n\n\n\nI  \n\n\n\n\n\n\n\nJ  \n\n\n\n\n\n\n\nK  \n\n\n\n\n\n\n\nL  \n\n\n\n\n\n\n\nM  \n\n\n\n\n\n\n\n\n\n\nN   \n\n\n\n\n\n\n\n\nO  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA  \n\n\n\n\n\n\nB  \n\n\n\n\n\n\n\nC  \n\n\n\n\n\n\n\nD  \n\n\n\n\n\n\n\nE  \n\n\n\n\n\n\n\nF  \n\n\n\n\n\n\n\nG  \n\n\n\n\n\n\n\nH  \n\n\n\n\n\n\n\nI  \n\n\n\n\n\n\n\nJ  \n\n\n\n\n\n\n\nK  \n\n\n\n\n\n\n\nL  \n\n\n\n\n\n\n\nM  \n\n\n\n\n\n\n\nN  \n\n\n\n\n\n\n\nO  \n\n\n\n\n\n\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 122024-12-14\n",
        "sectionId": "102de0f6",
        "archive": "courses/FAU/AI/course",
        "filepath": "search/slides/df-search.en.xhtml"
    },
    {
        "slideContent": "\nDepth-First Search: Romania\n\n▷Romania\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArad   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArad  \n\n\n\n\n\n\n\n\n\nSibiu   \n\n\n\n\n\n\n\n\nTimisoara  \n\n\n\n\n\n\n\nZerind  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArad  \n\n\n\n\n\n\nSibiu  \n\n\n\n\n\n\n\nTimisoara  \n\n\n\n\n\n\n\nZerind  \n\n\n\n\n\n\n\n\n\n\nArad   \n\n\n\n\n\n\n\n\nFagaras  \n\n\n\n\n\n\n\nOradea  \n\n\n\n\n\n\n\nR. Vilcea  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArad  \n\n\n\n\n\n\nSibiu  \n\n\n\n\n\n\n\nTimisoara  \n\n\n\n\n\n\n\nZerind  \n\n\n\n\n\n\n\nArad  \n\n\n\n\n\n\n\nFagaras  \n\n\n\n\n\n\n\nOradea  \n\n\n\n\n\n\n\nR. Vilcea  \n\n\n\n\n\n\n\n\n\n\nSibiu   \n\n\n\n\n\n\n\n\nTimisoara  \n\n\n\n\n\n\n\nZerind  \n\n\n\n\n\n\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 132024-12-14\n",
        "sectionId": "102de0f6",
        "archive": "courses/FAU/AI/course",
        "filepath": "search/slides/df-search.en.xhtml"
    },
    {
        "slideContent": "\nDepth-first search: Properties\n\n▷\nCompleteness \nYes:if\nsearch tree\nfinite\n\nNo:if search tree contains\ninfinite\n                                    paths or loops\n\nTime complexity \n𝒪(𝑏𝑚)\n\n\n(we need to explore until max depth\n𝑚\n                                    in any case!)\nSpace complexity \n𝒪(𝑏𝑚)(i.e. linear space)\n\n\n(need at most store\n𝑚\n                                    levels and at each level at most\n𝑏\n                                    nodes)\nOptimality \nNo(there can be many better solutions in the\n\nunexplored part of the search tree)\n\n\n\n▷Disadvantage\n                  Time terrible if\n𝑚\n                  much larger than\n𝑑.\n\n\n▷AdvantageTime may be much less than\nbreadth first search\n                  if solutions are dense.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 142024-12-14\n",
        "sectionId": "102de0f6",
        "archive": "courses/FAU/AI/course",
        "filepath": "search/slides/df-search.en.xhtml"
    },
    {
        "slideContent": "\nIterative deepening search\n\n▷\nDepth limited search\n                  is\ndepth first search\n                  with a\ndepth limit.\n\n\n▷\nIterative deepening search\n                  (IDS) is\ndepth limited search\n                  with ever increasing\ndepth limits. We call the difference between successive\ndepth limits\n                  the\nstep size.\n\n\n▷procedure Tree_Search (problem)\n<initialize the search tree using the initial state of problem>\nfor depth = 0 to ∞\nresult := Depth_Limited_search(problem,depth)\nif depth ≠ cutoff return result end if\nend for\nend procedure\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "102de0f6",
        "archive": "courses/FAU/AI/course",
        "filepath": "search/slides/id-search.en.xhtml"
    },
    {
        "slideContent": "\nIlustration: Iterative Deepening Search at various Limit Depths\n\n\n\n\n\n\n\n\n\n\n\n\n\nA   \n\n\n\n\n\n \n\n\n\n\n\n\n\n\nA  \n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA   \n\n\n\n\n\n\n\n\n\n\nB   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nC   \n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\nA  \n\n\n\n\n\n\n\n\n\nB   \n\n\n\n\n\n\n\n\nC  \n\n\n\n\n\n \n\n\n\n\n\n\n\n\nA  \n\n\n\n\n\n\nB  \n\n\n\n\n\n\n\n\n\n\nC   \n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\nA  \n\n\n\n\n\n\nB  \n\n\n\n\n\n\n\nC  \n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA   \n\n\n\n\n\n\n\n\n\n\nB   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nC   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nD   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nE   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nF   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nG   \n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\nA  \n\n\n\n\n\n\n\n\n\nB   \n\n\n\n\n\n\n\n\nC  \n\n\n\n\n\n\n\n\n\n\nD   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nE   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nF   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nG   \n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\nA  \n\n\n\n\n\n\nB  \n\n\n\n\n\n\n\nC  \n\n\n\n\n\n\n\n\n\n\nD   \n\n\n\n\n\n\n\n\nE  \n\n\n\n\n\n\n\n\n\n\nF   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nG   \n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\nA  \n\n\n\n\n\n\nB  \n\n\n\n\n\n\n\nC  \n\n\n\n\n\n\n\nD  \n\n\n\n\n\n\n\n\n\n\nE   \n\n\n\n\n\n\n\n\n\n\n\nF   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nG   \n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\nA  \n\n\n\n\n\n\nB  \n\n\n\n\n\n\n\n\n\n\nC   \n\n\n\n\n\n\n\n\nD  \n\n\n\n\n\n\n\nE  \n\n\n\n\n\n\n\n\n\n\nF   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nG   \n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\nA  \n\n\n\n\n\n\nB  \n\n\n\n\n\n\n\nC  \n\n\n\n\n\n\n\nD  \n\n\n\n\n\n\n\nE  \n\n\n\n\n\n\n\n\n\n\nF   \n\n\n\n\n\n\n\n\nG  \n\n\n\n\n\n \n\n\n\n\n\n\n\n\nA  \n\n\n\n\n\n\nB  \n\n\n\n\n\n\n\nC  \n\n\n\n\n\n\n\nD  \n\n\n\n\n\n\n\nE  \n\n\n\n\n\n\n\nF  \n\n\n\n\n\n\n\n\n\n\nG   \n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\nA  \n\n\n\n\n\n\nB  \n\n\n\n\n\n\n\nC  \n\n\n\n\n\n\n\nD  \n\n\n\n\n\n\n\nE  \n\n\n\n\n\n\n\nF  \n\n\n\n\n\n\n\nG  \n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n   \n\n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n   \n\n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n   \n\n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n   \n\n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n   \n\n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n   \n\n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n   \n\n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n   \n\n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n   \n\n\n\n\n\n\n\n\n  \n\n\n\n\n\n \n\n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n   \n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n  \n\n\n\n\n\n \n\n\n\nMichael Kohlhase:\nArtificial Intelligence 122024-12-14\n",
        "sectionId": "102de0f6",
        "archive": "courses/FAU/AI/course",
        "filepath": "search/slides/id-search.en.xhtml"
    },
    {
        "slideContent": "\nIterative deepening search: Properties\n\n▷\nCompleteness \nYes\n\nTime complexity \n(𝑑+1)·𝑏0+𝑑·𝑏1+(𝑑−1)·𝑏2+...+𝑏𝑑∊𝒪(𝑏𝑑+1)\n\nSpace complexity \n𝒪(𝑏·𝑑)\n\nOptimality \nYes(if step cost = 1)\n\n\n\n\n▷Consequence\nIDS\n                  used in practice for search spaces of large,\ninfinite, or unknown depth.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-15\n",
        "sectionId": "102de0f6",
        "archive": "courses/FAU/AI/course",
        "filepath": "search/slides/idsearch-props.en.xhtml"
    },
    {
        "slideContent": "\nComparison BFS (optimal) and IDS (not)\n\n▷\nIDS\n                may fail to be be optimal at step sizes\n>\n                1.\n\n\nBreadth first search Iterative deepening search  \n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-15\n",
        "sectionId": "102de0f6",
        "archive": "courses/FAU/AI/course",
        "filepath": "search/slides/idsearch-bfs.en.xhtml"
    },
    {
        "slideContent": "\nTree Search vs. Graph Search\n\n▷We have only covered\ntree search algorithms.\n\n\n▷States\n              duplicated in\nnodes\n              are a huge problem for\nefficiency.\n\n\n▷\n                  A\ngraph search\nalgorithm\n                  is a variant of a\ntree search algorithm\n                  that\nprunes\nnodes\n                  whose\nstate\n                  has already been considered (duplicate pruning), essentially using a\nDAG\ndata structure.\n\n\n▷\nTree search\n                  is memory intensive it has to store the\nfringe\n                  so keeping a list of “explored states” does not lose much.\n\n\n▷Graph versions\n              of all the\ntree search algorithms\n              considered here exist, but are more difficult to understand (and to prove properties about).\n\n\n▷The (time complexity) properties are largely stable under\nduplicate pruning.(no gain in the worst case)\n\n\n▷\n                  We speak of a\nsearch algorithm, when we do not want to distinguish whether it is a\ntree\n                  or\ngraph search\nalgorithm.\n(difference considered an\nimplementation\n                      detail)\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "c81ff904",
        "archive": "courses/FAU/AI/course",
        "filepath": "search/slides/graph-search.en.xhtml"
    },
    {
        "slideContent": "\nUninformed Search Summary\n\n▷Tree/Graph Search Algorithms\n                  Systematically explore the state tree/graph induced by a\nsearch problem\n                  in search of a goal state. Search strategies only differ by the treatment of the fringe.\n\n\n▷Search Strategies and their Properties\n                  We have discussed\n\n\nCriterion Breadth first Uniform cost Depth first Iterative deepening Completeness Yes\n1\n Yes\n2\n No Yes Time complexity 𝑏𝑑 ≈𝑏𝑑 𝑏𝑚 𝑏𝑑+1 Space complexity 𝑏𝑑 ≈𝑏𝑑 𝑏𝑚 𝑏𝑑 Optimality Yes* Yes No Yes* Conditions \n1\n 𝑏 finite\n2\n 0<𝜖≤cost\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-15\n",
        "sectionId": "c81ff904",
        "archive": "courses/FAU/AI/course",
        "filepath": "search/slides/usearch.en.xhtml"
    },
    {
        "slideContent": "\nSearch Strategies; the XKCD Take\n\n▷More Search Strategies?\n(from\nhttps://xkcd.com/2407/)\n\n\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-15\n",
        "sectionId": "c81ff904",
        "archive": "courses/FAU/AI/course",
        "filepath": "search/slides/usearch-xkcd.en.xhtml"
    },
    {
        "slideContent": "\nSummary: Uninformed Search/Informed Search\n\n▷Problem formulation usually requires abstracting away real-world details to define a\nstate space\n              that can feasibly be explored.\n\n\n▷Variety of\nuninformed\n              search strategies.\n\n\n▷Iterative deepening search\n              uses only\nlinear\nspace\n              and not much more\ntime\n              than other\nuninformed\nalgorithms.\n\n\n▷Next StepIntroduce additional knowledge about the problem(heuristic search)\n\n\n▷Best-first-,\n𝐴*-strategies\n(guide the search by\nheuristics)\n\n\n▷Iterative improvement\nalgorithms.\n\n\n▷\n                  A\nsearch algorithm\n                  is called\ninformed, iff it uses some form of external information — that is not part of the\nsearch problem\n                  — to guide the search.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "988605ca",
        "archive": "courses/FAU/AI/course",
        "filepath": "search/slides/i-search-strategy.en.xhtml"
    },
    {
        "slideContent": "\nEmpirical Performance:\n𝐴*\n            in Path Planning\n\n▷Live Demo vs. Breadth-First Search\n\n\n\n\nSee\nhttp://qiao.github.io/PathFinding.js/visual/\n\n\n▷Difference to Breadth-first Search?\n                That would explore all grid cells in a\ncircle\n                around the initial state!\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "988605ca",
        "archive": "courses/FAU/AI/course",
        "filepath": "search/slides/astar-vs-bfs.en.xhtml"
    },
    {
        "slideContent": "\nBest-first search\n\n▷Idea\n                  Order the\nfringe\n                  by estimated “desirability”\n(Expand\n                      most desirable\nunexpanded\nnode)\n\n\n▷\n                  An\nevaluation function\n                  assigns a\ndesirability\n                  value to each\nnode\n                  of the\nsearch tree.\n\n\n▷Note\n                  A\nevaluation function\n                  is not part of the\nsearch problem, but must be added externally.\n\n\n▷\n                  In\nbest first search, the\nfringe\n                  is a\nqueue\n                  sorted in decreasing order of\ndesirability.\n\n\n▷Special casesGreedy search,\n𝐴*\n                  search\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "1c9f442",
        "archive": "courses/FAU/AI/course",
        "filepath": "search/slides/bestfirst-search.en.xhtml"
    },
    {
        "slideContent": "\nGreedy search\n\n▷Idea\nExpand\n                  the\nnode\n                  that\nappears\n                  to be closest to the\ngoal.\n\n\n▷\n                  A\nheuristic\n                  is an\nevaluation function\nℎ\n                  on\nstates\n                  that estimates the\ncost\n                  from\n𝑛\n                  to the nearest\ngoal state. We speak of\nheuristic search\n                  if the\nsearch algorithm\n                  uses a\nheuristic\n                  in some way.\n\n\n▷Note\n                  All\nnodes\n                  for the same\nstate\n                  must have the same\nℎ-value!\n\n\n▷\n                  Given a\nheuristic\nℎ,\ngreedy search\n                  is the\nstrategy\n                  where the\nfringe\n                  is organized as a\nqueue\n                  sorted by increasing\nℎ\nvalue.\n\n\n▷\n                  Straight-line distance from/to Bucharest.\n\n\n▷NoteUnlike\nuniform cost search\n                  the\nnode\nevaluation function\n                  has nothing to do with the\nnodes\nexpanded\n                  so far\n\n\ninternal search control\n⤳\n                  external search control\n\npartial solution cost\n⤳\n                  goal cost estimation\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "1c9f442",
        "archive": "courses/FAU/AI/course",
        "filepath": "search/slides/greedy-search.en.xhtml"
    },
    {
        "slideContent": "\nRomania with Straight-Line Distances\n\n▷Informed Travel\nℎSLD(𝑛)=𝑠𝑡𝑟𝑎𝑖𝑔ℎ𝑡−𝑙𝑖𝑛𝑒𝑑𝑖𝑠𝑡𝑎𝑛𝑐𝑒𝑡𝑜𝐵𝑢𝑐ℎ𝑎𝑟𝑒𝑠𝑡\n\n\nArad 366 Mehadia 241 Bucharest 0 Neamt 234Craiova 160 Oradea 380 Drobeta 242 Pitesti 100 Eforie 161 Rimnicu Vilcea 193 Fragaras 176 Sibiu 253Giurgiu 77 Timisoara 329 Hirsova 151 Urziceni 80Iasi 226 Vaslui 199 Lugoj 244 Zerind 374\n\n\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "1c9f442",
        "archive": "courses/FAU/AI/course",
        "filepath": "search/slides/gsearch-sldex.en.xhtml"
    },
    {
        "slideContent": "\nGreedy Search: Romania\n\n\n\n\n\n\n\n\n\n\n\n\n\nArad   \n\n\n\n366  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArad  \n\n\n366  \n\n\n\n\n\n\n\n\nSibiu   \n\n\n\n\n253  \n\n\n\n\n\nTimisoara  \n\n\n\n329  \n\n\n\n\n\nZerind  \n\n\n\n374  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArad  \n\n\n366  \n\n\n\n\n\nSibiu  \n\n\n\n253  \n\n\n\n\n\nTimisoara  \n\n\n\n329  \n\n\n\n\n\nZerind  \n\n\n\n374  \n\n\n\n\n\nArad  \n\n\n\n366  \n\n\n\n\n\n\n\n\nFagaras   \n\n\n\n\n176  \n\n\n\n\n\nOradea  \n\n\n\n380  \n\n\n\n\n\nR. Vilcea  \n\n\n\n193  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArad  \n\n\n366  \n\n\n\n\n\nSibiu  \n\n\n\n253  \n\n\n\n\n\nTimisoara  \n\n\n\n329  \n\n\n\n\n\nZerind  \n\n\n\n374  \n\n\n\n\n\nArad  \n\n\n\n366  \n\n\n\n\n\nFagaras  \n\n\n\n176  \n\n\n\n\n\nOradea  \n\n\n\n380  \n\n\n\n\n\nR. Vilcea  \n\n\n\n193  \n\n\n\n\n\nSibiu  \n\n\n\n253  \n\n\n\n\n\nBucharest  \n\n\n\n0  \n\n\n\n\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 122024-12-14\n",
        "sectionId": "1c9f442",
        "archive": "courses/FAU/AI/course",
        "filepath": "search/slides/gsearch-sldex.en.xhtml"
    },
    {
        "slideContent": "\nHeuristic Functions in Path Planning\n\n▷The maze solved\n                We indicate\nℎ*\n                by giving the\ngoal distance:\n\n\n\n\n▷Maze Heuristic: The good case\n                We use the\nManhattan distance\n                to the goal as a\nheuristic:\n\n\n\n\n▷Maze Heuristic: The bad case\n                We use the\nManhattan distance\n                to the goal as a\nheuristic\n                again:\n\n\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-16\n",
        "sectionId": "1c9f442",
        "archive": "courses/FAU/AI/course",
        "filepath": "search/slides/gsearch-pathplanning.en.xhtml"
    },
    {
        "slideContent": "\nGreedy search: Properties\n\n▷Completeness \nNo: Can get stuck in\ninfinite loops.\n\n\nComplete in\nfinite\nstate spaces\n                                with repeated state checking\n\nTime complexity \n𝒪(𝑏𝑚)\n\nSpace complexity \n𝒪(𝑏𝑚)\n\nOptimality \nNo\n\n\n\n▷\nGreedy search\n                  can get stuck going from Iasi to Oradea:Iasi\n→\n                  Neamt\n→\n                  Iasi\n→\n                  Neamt\n→···\n\n\n\n\n▷Worst-case Time\n                  Same as\ndepth first search.\n\n\n▷Worst-case Space\n                  Same as\nbreadth first search.(\n⇝\n\n                      repeated state checking)\n\n\n▷But\n                  A good\nheuristic\n                  can give dramatic improvements.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-15\n",
        "sectionId": "1c9f442",
        "archive": "courses/FAU/AI/course",
        "filepath": "search/slides/gsearch-props.en.xhtml"
    },
    {
        "slideContent": "\nHeuristic Functions\n\n▷\n                  Let\nΠ\n                  be a\nsearch problem\n                  with\nstates\n𝒮. A\nheuristic function\n                  (or short\nheuristic) for\nΠ\n                  is a\nfunction\nℎ:𝒮→ℝ0+∪{∞}\n                  so that\nℎ(𝑠)=0\n                  whenever\n𝑠\n                  is a\ngoal state.\n\n\n▷\nℎ(𝑠)\n                  is intended as an estimate the distance between\nstate\n𝑠\n                  and the nearest\ngoal state.\n\n\n▷\n                  Let\nΠ\n                  be a\nsearch problem\n                  with\nstates\n𝒮, then the\nfunction\nℎ*:𝑆→ℝ0+∪{∞}, where\nℎ*(𝑠)\n                  is the\ncost\n                  of a cheapest\npath\n                  from\n𝑠\n                  to a\ngoal state, or\n∞\n                  if no such\npath\n                  exists, is called the\ngoal distance function\n                  for\nΠ.\n\n\n▷Notes\n\n\n▷ℎ(𝑠)=0\n                  on\ngoal states: If your estimator returns “I think it’s still a long way” on a\ngoal state, then its\nintelligence\n                  is, um ...\n\n▷Return\nvalue\n∞: To indicate dead ends, from which the\ngoal state\n                  can’t be reached anymore.\n\n\n▷The distance estimate depends only on the\nstate\n𝑠, not on the\nnode\n                  (i.e., the\npath\n                  we took to reach\n𝑠).\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "c187a627",
        "archive": "courses/FAU/AI/course",
        "filepath": "search/slides/heuristics.en.xhtml"
    },
    {
        "slideContent": "\nWhere does the word “Heuristic” come from?\n\n▷Ancient Greek word\n𝜖𝜐𝜌𝜄𝜎𝜅𝜖𝜄𝜈\n              (=^\n              “I find”)(aka.\n𝜖𝜐𝜌𝜖𝜅𝛼!)\n\n\n▷Popularized in modern science by George Polya: “How to solve it” [Pól73]\n\n\n▷Same word often used for “rule of thumb” or “imprecise solution method”.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 122024-12-14\n",
        "sectionId": "c187a627",
        "archive": "courses/FAU/AI/course",
        "filepath": "search/slides/heuristics.en.xhtml"
    },
    {
        "slideContent": "\nHeuristic Functions: The Eternal Trade-Off\n\n▷\n                  “Distance Estimate”?(ℎ\n                      is an arbitrary\nfunction\n                      in principle)\n\n\n▷In practice, we want it to be\naccurate\n                  (aka:\ninformative), i.e., close to the actual\ngoal distance.\n\n\n▷We also want it to be fast, i.e., a small overhead for computing\nℎ.\n\n\n▷These two wishes are in\ncontradiction!\n\n\n▷Extreme cases\n\n\n▷ℎ=0: no overhead at all, completely un-informative.\n\n\n▷ℎ=ℎ*: perfectly accurate, overhead\n=^\n                  solving the problem in the first place.\n\n\n▷\n                  We need to trade off the accuracy of\nℎ\n                  against the overhead for computing it.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "c187a627",
        "archive": "courses/FAU/AI/course",
        "filepath": "search/slides/heuristics-tradeoff.en.xhtml"
    },
    {
        "slideContent": "\nProperties of Heuristic Functions\n\n▷\n                  Let\nΠ\n                  be a\nsearch problem\n                  with\nstates\n𝑆\n                  and\nactions\n𝐴. We say that a\nheuristic\nℎ\n                  for\nΠ\n                  is\nadmissible\n                  if\nℎ(𝑠)≤ℎ*(𝑠)\n                  for all\n𝑠∊𝑆.\n\nWe say that\nℎ\n                  is\nconsistent\n                  if\nℎ(𝑠)−ℎ(𝑠')≤𝑐(𝑎)\n                  for all\n𝑠∊𝑆,\n𝑎∊𝐴, and\n𝑠'∊𝒯(𝑠,𝑎).\n\n\n▷In other words ...\n\n\n▷ℎ\n                  is\nadmissible\n                  if it is a\nlower bound\n                  on goal distance.\n\n\n▷ℎ\n                  is\nconsistent\n                  if, when applying an\naction\n𝑎, the\nheuristic\nvalue\n                  cannot decrease by more than the cost of\n𝑎.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "c187a627",
        "archive": "courses/FAU/AI/course",
        "filepath": "search/slides/admissible-consistent.en.xhtml"
    },
    {
        "slideContent": "\nProperties of Heuristic Functions, ctd.\n\n▷Consistency implies Admissibility\n                  Let\nΠ\n                  be a problem, and let\nℎ\n                  be a\nheuristic\n                  for\nΠ. If\nℎ\n                  is\nconsistent, then\nℎ\n                  is\nadmissible.\n\n\n▷Proof:\nwe prove\nℎ(𝑠)≤ℎ*(𝑠)\n                  for all\n𝑠∊𝑆\n                  by\ninduction\n                  over the\nlength\n                  of the cheapest\npath\n                  to a\ngoal node.\n\n1.base case\n\n\n\n1.1.ℎ(𝑠)=0\n                        by definition of\nheuristic, so\nℎ(𝑠)≤ℎ*(𝑠)\n                        as desired.\n\n\n2.step case\n\n\n\n2.1.We assume that\nℎ(𝑠')≤ℎ*(𝑠)\n                        for all\nstates\n𝑠'\n                        with a cheapest\ngoal node\npath\n                        of\nlength\n𝑛.\n\n\n\n\n2.2.Let\n𝑠\n                        be a state whose cheapest\ngoal\npath\n                        has\nlength\n𝑛+1\n                        and the first transition is\n𝑜=(𝑠,𝑠').\n\n\n\n\n2.3.By\nconsistency, we have\nℎ(𝑠)−ℎ(𝑠')≤𝑐(𝑜)\n                        and thus\nℎ(𝑠)≤ℎ(𝑠')+𝑐(𝑜).\n\n\n\n\n2.4.By construction,\nℎ*(𝑠)\n                        has a cheapest goal path of\nlength\n𝑛\n                        and thus, by\ninduction hypothesis\nℎ(𝑠')≤ℎ*(𝑠').\n\n\n\n\n2.5.By construction,\nℎ*(𝑠)=ℎ*(𝑠')+𝑐(𝑜).\n\n\n\n\n2.6.Together this gives us\nℎ(𝑠)≤ℎ*(𝑠)\n                        as desired.\n\n\n▷Consistency\n              is a sufficient condition for\nadmissibility(easier to check)\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 122024-12-14\n",
        "sectionId": "c187a627",
        "archive": "courses/FAU/AI/course",
        "filepath": "search/slides/admissible-consistent.en.xhtml"
    },
    {
        "slideContent": "\nProperties of Heuristic Functions: Examples\n\n▷\n                  Straight line distance is\nadmissible\n                  and\nconsistent\n                  by the\ntriangle inequality.If you drive 100km, then the straight line distance to Rome can’t decrease by more than 100km.\n\n\n▷Observation\n                  In practice,\nadmissible\nheuristics\n                  are typically\nconsistent.\n\n\n▷An admissible, but inconsistent heuristic\n                  When traveling to Rome, let\nℎ(𝑀𝑢𝑛𝑖𝑐ℎ)=300\n                  and\nℎ(𝐼𝑛𝑛𝑠𝑏𝑟𝑢𝑐𝑘)=100.\n\n\n▷Inadmissible heuristics\n                  typically arise as approximations of\nadmissible\nheuristics\n                  that are too costly to compute.\n(see later)\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 132024-12-14\n",
        "sectionId": "c187a627",
        "archive": "courses/FAU/AI/course",
        "filepath": "search/slides/admissible-consistent.en.xhtml"
    },
    {
        "slideContent": "\n𝐴*\n              Search: Evaluation Function\n\n▷Idea\n                  Avoid\nexpanding\npaths\n                  that are already expensive(make use of actual cost)\n\nThe simplest way to combine\nheuristic\n                  and\npath cost\n                  is to simply add them.\n\n\n▷\n                  The\nevaluation function\n                  for\n𝐴*\n                  search is given by\n𝑓(𝑛)=𝑔(𝑛)+ℎ(𝑛), where\n𝑔(𝑛)\n                  is the\npath cost\n                  for\n𝑛\n                  and\nℎ(𝑛)\n                  is the estimated\ncost\n                  to the nearest\ngoal\n                  from\n𝑛.\n\n\n▷Thus\n𝑓(𝑛)\n              is the estimated total\ncost\n              of the\npath\n              through\n𝑛\n              to a\ngoal.\n\n\n▷\nBest first search\n                  with\nevaluation function\n𝑔+ℎ\n                  is called\n𝐴*\n                      search.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "c241d997",
        "archive": "courses/FAU/AI/course",
        "filepath": "search/slides/a-star.en.xhtml"
    },
    {
        "slideContent": "\n𝐴*\n              Search: Optimality\n\n▷\n𝐴*\n                  search with\nadmissible\nheuristic\n                  is\noptimal.\n\n\n▷Proof:\nWe show that sub-optimal\nnodes\n                  are never\nexpanded\n                  by\n𝐴*\n\n\n\n1.Suppose a\nsuboptimal\ngoal node\n𝐺\n                    has been generated then we are in the following situation:\n\n\n\n\n\n\n\n\n\n\nstart  \n\n\n\n\n\n\nn  \n\n\n\n\n\n\n\n\n\nO  \n\n\n\n\n\n\n\n\n\n\n\nG  \n\n\n\n\n\n\n\n \n\n\n\n2.Let\n𝑛\n                    be an\nunexpanded\nnode\n                    on a\npath\n                    to an\noptimality\ngoal node\n𝑂, then\n\n𝑓(𝐺)=𝑔(𝐺) since ℎ(𝐺)=0 𝑔(𝐺)>𝑔(𝑂) since 𝐺 suboptimal 𝑔(𝑂)=𝑔(𝑛)+ℎ*(𝑛) 𝑛 on optimal path𝑔(𝑛)+ℎ*(𝑛)≥𝑔(𝑛)+ℎ(𝑛) since ℎ is admissible 𝑔(𝑛)+ℎ(𝑛)=𝑓(𝑛) \n\n\n\n\n3.Thus,\n𝑓(𝐺)>𝑓(𝑛)\n                    and\n𝐴*\n                    never\nexpands\n𝐺.\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "c241d997",
        "archive": "courses/FAU/AI/course",
        "filepath": "search/slides/astar-optimal.en.xhtml"
    },
    {
        "slideContent": "\n𝐴*\n              Search Example\n\n\n\n\n\n\n\n\n\n\n\n\n\nArad   \n\n\n\n366=0+366  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArad  \n\n\n\n\n\n\n\n\n\nSibiu   \n\n\n\n\n393=140+253  \n\n\n\n\n\nTimisoara  \n\n\n\n447=118+329  \n\n\n\n\n\nZerind  \n\n\n\n449=75+374  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArad  \n\n\n\n\n\n\nSibiu  \n\n\n\n\n\n\n\nTimisoara  \n\n\n\n447=118+329  \n\n\n\n\n\nZerind  \n\n\n\n449=75+374  \n\n\n\n\n\nArad  \n\n\n\n646=280+366  \n\n\n\n\n\nFagaras  \n\n\n\n415=239+176  \n\n\n\n\n\nOradea  \n\n\n\n671=291+380  \n\n\n\n\n\n\n\n\nR. Vilcea   \n\n\n\n\n413=220+193  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArad  \n\n\n\n\n\n\nSibiu  \n\n\n\n\n\n\n\nTimisoara  \n\n\n\n447=118+329  \n\n\n\n\n\nZerind  \n\n\n\n449=75+374  \n\n\n\n\n\nArad  \n\n\n\n646=280+366  \n\n\n\n\n\n\n\n\nFagaras   \n\n\n\n\n415=239+176  \n\n\n\n\n\nOradea  \n\n\n\n671=291+380  \n\n\n\n\n\nR. Vilcea  \n\n\n\n\n\n\n\nCraiova  \n\n\n\n526=366+160  \n\n\n\n\n\nPitesti  \n\n\n\n417=317+100  \n\n\n\n\n\nSibiu  \n\n\n\n553=300+253  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArad  \n\n\n\n\n\n\nSibiu  \n\n\n\n\n\n\n\nTimisoara  \n\n\n\n447=118+329  \n\n\n\n\n\nZerind  \n\n\n\n449=75+374  \n\n\n\n\n\nArad  \n\n\n\n646=280+366  \n\n\n\n\n\nFagaras  \n\n\n\n\n\n\n\nOradea  \n\n\n\n671=291+380  \n\n\n\n\n\nR. Vilcea  \n\n\n\n\n\n\n\nCraiova  \n\n\n\n526=366+160  \n\n\n\n\n\n\n\n\nPitesti   \n\n\n\n\n417=317+100  \n\n\n\n\n\nSibiu  \n\n\n\n553=300+253  \n\n\n\n\n\nSibiu  \n\n\n\n591=338+253  \n\n\n\n\n\nBucharest  \n\n\n\n450=450+0  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArad  \n\n\n\n\n\n\nSibiu  \n\n\n\n\n\n\n\nTimisoara  \n\n\n\n447=118+329  \n\n\n\n\n\nZerind  \n\n\n\n449=75+374  \n\n\n\n\n\nArad  \n\n\n\n646=280+366  \n\n\n\n\n\nFagaras  \n\n\n\n\n\n\n\nOradea  \n\n\n\n671=291+380  \n\n\n\n\n\nR. Vilcea  \n\n\n\n\n\n\n\nCraiova  \n\n\n\n526=366+160  \n\n\n\n\n\nPitesti  \n\n\n\n\n\n\n\nSibiu  \n\n\n\n553=300+253  \n\n\n\n\n\nSibiu  \n\n\n\n591=338+253  \n\n\n\n\n\nBucharest  \n\n\n\n450=450+0  \n\n\n\n\n\nBucharest  \n\n\n\n418=418+0  \n\n\n\n\n\nCraiova  \n\n\n\n615=455+160  \n\n\n\n\n\nSibiu  \n\n\n\n607=414+193  \n\n\n\n\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-15\n",
        "sectionId": "c241d997",
        "archive": "courses/FAU/AI/course",
        "filepath": "search/slides/astar-ex.en.xhtml"
    },
    {
        "slideContent": "\nAdditional Observations (Not Limited to Path Planning)\n\n▷Greedy best-first search, “good case”\n\n\n\n\nWe will find a\nsolution\n                with little\nsearch.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-15\n",
        "sectionId": "c241d997",
        "archive": "courses/FAU/AI/course",
        "filepath": "search/slides/astar-pathplanning.en.xhtml"
    },
    {
        "slideContent": "\nAdditional Observations (Not Limited to Path Planning)\n\n▷𝐴*\n                  (𝑔+ℎ), “good case”\n\n\n\n\n▷In\n𝐴*\n                with a\nconsistent\nheuristic,\n𝑔+ℎ\n                always\nincreases monotonically\n(ℎ\n                    cannot decrease more than\n𝑔\n                    increases)\n\n\n▷We need more search, in the “right upper half”. This is typical: Greedy\nbest first search\n                tends to be faster than\n𝐴*.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 122024-12-15\n",
        "sectionId": "c241d997",
        "archive": "courses/FAU/AI/course",
        "filepath": "search/slides/astar-pathplanning.en.xhtml"
    },
    {
        "slideContent": "\nAdditional Observations (Not Limited to Path Planning)\n\n▷Greedy best-first search, “bad case”\n\n\n\n\nSearch\n                will be mis-guided into the “dead-end street”.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 132024-12-15\n",
        "sectionId": "c241d997",
        "archive": "courses/FAU/AI/course",
        "filepath": "search/slides/astar-pathplanning.en.xhtml"
    },
    {
        "slideContent": "\nAdditional Observations (Not Limited to Path Planning)\n\n▷𝐴*\n                  (𝑔+ℎ), “bad case”\n\n\n\n\nWe will search less of the “dead-end street”. Sometimes\n𝑔+ℎ\n                gives better search guidance than\nℎ.(⤳\n𝐴*\n                    is faster there)\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 142024-12-15\n",
        "sectionId": "c241d997",
        "archive": "courses/FAU/AI/course",
        "filepath": "search/slides/astar-pathplanning.en.xhtml"
    },
    {
        "slideContent": "\nAdditional Observations (Not Limited to Path Planning)\n\n▷𝐴*\n                  (𝑔+ℎ) using\nℎ*\n\n\n\n\nIn\n𝐴*, node values always increase monotonically (with any\nheuristic). If the\nheuristic\n                is perfect, they remain constant on optimal paths.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 152024-12-15\n",
        "sectionId": "c241d997",
        "archive": "courses/FAU/AI/course",
        "filepath": "search/slides/astar-pathplanning.en.xhtml"
    },
    {
        "slideContent": "\n𝐴*\n              search:\n𝑓-contours\n\n▷Intuition\n𝐴*-search\n                  gradually adds “𝑓-contours” (areas of the same\n𝑓-value) to the\nsearch.\n\n\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-15\n",
        "sectionId": "c241d997",
        "archive": "courses/FAU/AI/course",
        "filepath": "search/slides/astar-props.en.xhtml"
    },
    {
        "slideContent": "\n𝐴*\n              search: Properties\n\n▷\n                  Properties or\n𝐴*-search:\n\n\nCompleteness \nYes (unless there are\ninfinitely\n                                    many nodes\n𝑛\n                                    with\n𝑓(𝑛)≤𝑓(0))\n\nTime complexity \nExponential in [relative error in\nℎ\n×\n                                    length of solution]\n\nSpace complexity \nSame as time (variant of\nBFS)\nOptimality \nYes\nn\n\n\n▷𝐴*-search\nexpands\n              all (some/no)\nnodes\n              with\n𝑓(𝑛)<ℎ*(𝑛)\n\n\n▷The run-time depends on how well we approximated the\nreal cost\nℎ*\n              with\nℎ.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 122024-12-15\n",
        "sectionId": "c241d997",
        "archive": "courses/FAU/AI/course",
        "filepath": "search/slides/astar-props.en.xhtml"
    },
    {
        "slideContent": "\nAdmissible heuristics: Example 8-puzzle\n\n\n\n▷\n                  Let\nℎ1(𝑛)\n                      be the number of misplaced tiles in node\n𝑛.(ℎ1(𝑆)=9)\n\n\n▷\n                  Let\nℎ2(𝑛)\n                      be the total\nManhattan distance\n                      from desired location of each tile.(ℎ2(𝑆)=3+1+2+2+2+3+2+2+3=20)\n\n\n▷Typical search costs\n(IDS\n=^\niterative deepening search)\n\n\nnodes explored IDS 𝐴*(ℎ1) 𝐴*(ℎ2) 𝑑=14 3,473,941 539 113 𝑑=24 too many 39,135 1,641\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "504a8937",
        "archive": "courses/FAU/AI/course",
        "filepath": "search/slides/admissible-heuristics.en.xhtml"
    },
    {
        "slideContent": "\nDominance\n\n▷\n                  Let\nℎ1\n                  and\nℎ2\n                  be two\nadmissible\nheuristics\n                  we say that\nℎ2\ndominates\nℎ1\n                  if\nℎ2(𝑛)≥ℎ1(𝑛)\n                  for all\n𝑛.\n\n\n▷\n                  If\nℎ2\ndominates\nℎ1, then\nℎ2\n                  is better for\nsearch\n                  than\nℎ1.\n\n\n▷Proof sketch:\n                If\nℎ2\ndominates\nℎ1, then\nℎ2\n                is “closer to\nℎ*” than\nℎ1, which means better\nsearch\nperformance.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "504a8937",
        "archive": "courses/FAU/AI/course",
        "filepath": "search/slides/heuristics-dominance.en.xhtml"
    },
    {
        "slideContent": "\nRelaxed problems\n\n▷Observation\n                  Finding good\nadmissible\nheuristics\n                  is an art!\n\n\n▷Idea\nAdmissible\nheuristics\n                  can be derived from the\nexact\n                  solution cost of a\nrelaxed\n                  version of the problem.\n\n\n▷\n                  If the rules of the 8-puzzle are\nrelaxed\n                  so that a tile can move\nanywhere, then we get\nheuristic\nℎ1.\n\n\n▷\n                  If the rules are\nrelaxed\n                  so that a tile can move to\nany adjacent square, then we get\nheuristic\nℎ2.(Manhattan distance)\n\n\n▷Let\nΠ:=〈𝒮,𝒜,𝒯,ℐ,𝒢〉\n                  be a\nsearch problem, then we call a\nsearch problem\n𝒫𝑟:=〈𝒮,𝒜𝑟,𝒯𝑟,ℐ𝑟,𝒢𝑟〉\n                  a\nrelaxed problem\n                  (wrt.\nΠ; or simply\nrelaxation\n                  of\nΠ), iff\n𝒜⊆𝒜𝑟,\n𝒯⊆𝒯𝑟,\nℐ⊆ℐ𝑟, and\n𝒢⊆𝒢𝑟.\n\n\n▷If\n𝒫𝑟\nrelaxes\nΠ, then every\nsolution\n                  for\nΠ\n                  is one for\n𝒫𝑟.\n\n\n▷Key point\n                  The\noptimal\n                  solution cost of a\nrelaxed\n                  problem is not greater than the optimal solution cost of the real problem.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "504a8937",
        "archive": "courses/FAU/AI/course",
        "filepath": "search/slides/relaxed-problems.en.xhtml"
    },
    {
        "slideContent": "\nSystematic Search vs. Local Search\n\n▷\n                  We call a\nsearch algorithm\nsystematic, if it considers all\nstates\n                  at some point.\n\n\n▷\n                  All\ntree search algorithms\n                  (except pure\ndepth first search) are\nsystematic.\n(given reasonable assumptions e.g. about costs.)\n\n\n▷\nSystematic\nsearch algorithms\n                  are\ncomplete.\n\n\n▷\n                  In\nsystematic\nsearch algorithms\n                  there is no limit of the number of\nnodes\n                  that are kept in\nmemory\n                  at any time.\n\n\n▷Alternative\n                  Keep only one (or a few)\nnodes\n                  at a time\n\n\n▷⤳\n                  no\nsystematic\n                  exploration of all options,\n⤳\nincomplete.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "59328df2",
        "archive": "courses/FAU/AI/course",
        "filepath": "search/slides/systematic-search.en.xhtml"
    },
    {
        "slideContent": "\nLocal Search Problems\n\n▷Idea\n                  Sometimes the\npath\n                  to the\nsolution\n                  is irrelevant.\n\n\n\n\n▷8 Queens Problem\n                                  Place 8\nqueens\n                                  on a\nchess\n                                  board, so that no two\nqueens\n                                  threaten each other.\n\n\n▷\n                                  This problem has various solutions\n(the one of the right isn’t one of them)\n\n\n▷\n                                  A\nlocal search algorithm\n                                  is a\nsearch algorithm\n                                  that operates on a single\nstate, the\ncurrent state\n                                  (rather than multiple\npaths).(advantage:\nconstant\nspace)\n\n\n\n\n\n\n\n \n\n▷\n                  Typically\nlocal search algorithms\n                  only move to\nsuccessor\n                  of the\ncurrent state, and do not retain search\npaths.\n\n\n▷Applications include: integrated circuit design, factory-floor layout, job-shop scheduling, portfolio management, fleet deployment,...\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "59328df2",
        "archive": "courses/FAU/AI/course",
        "filepath": "search/slides/local-search-intro.en.xhtml"
    },
    {
        "slideContent": "\nLocal Search: Iterative improvement algorithms\n\n▷\n\n\n▷Idea\n                  Start with any complete tour, perform pairwise exchanges\n\n\n\n\n\n▷\n                  The\n𝑛-queens problem\n                  is to put\n𝑛\nqueens\n                  on\n𝑛×𝑛\n                  board such that no two\nqueen\n                  in the same row, columns, or diagonal.\n\n\n▷Idea\n                  Move a\nqueen\n                  to reduce number of conflicts\n\n\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 122024-12-14\n",
        "sectionId": "59328df2",
        "archive": "courses/FAU/AI/course",
        "filepath": "search/slides/local-search-intro.en.xhtml"
    },
    {
        "slideContent": "\nHill-climbing (gradient ascent/descent)\n\n▷Idea\n                  Start anywhere and go in the direction of the steepest ascent.\n\n\n▷\nHill climbing\n                  (also\ngradient ascent) is a\nlocal search algorithm\n                  that iteratively selects the best\nsuccessor:\n\n\nprocedure Hill―Climbing (problem) /* a state that is a local minimum */\nlocal current, neighbor /* nodes */\ncurrent := Make―Node(Initial―State[problem])\nloop\nneighbor := <a highest―valued successor of current>\nif Value[neighbor] < Value[current] return [current] end if\ncurrent := neighbor\nend loop\nend procedure\n\n▷IntuitionLike\nbest first search\n                  without memory.\n\n\n▷Works, if solutions are dense and\nlocal maxima\n              can be escaped.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "59328df2",
        "archive": "courses/FAU/AI/course",
        "filepath": "search/slides/hill-climbing.en.xhtml"
    },
    {
        "slideContent": "\nExample\nHill Climbing\n              with\n8 Queens\n\n\n\n▷Idea\n                                  Consider\nℎ\n=^\n                                  number of\nqueens\n                                  that\nthreaten\n                                  each other.\n\n\n▷\n                                  An\n8-queens\nstate\n                                  with\nheuristic\n                                  cost estimate\nℎ=17\n                                  showing\nℎ-values for moving a\nqueen\n                                  within its column:\n\n\n\n\n\n\n\n \n\n\n▷Problem\n                                  The\nstate space\n                                  has\nlocal minima. e.g. the board on the right has\nℎ=1\n                                  but every\nsuccessor\n                                  has\nℎ>1.\n\n\n\n\n\n\n\n\n \n\n\nMichael Kohlhase:\nArtificial Intelligence 122024-12-14\n",
        "sectionId": "59328df2",
        "archive": "courses/FAU/AI/course",
        "filepath": "search/slides/hill-climbing.en.xhtml"
    },
    {
        "slideContent": "\nHill-climbing\n\n\n\n▷Problem\n                                  Depending on\ninitial state, can get stuck on\nlocal maxima/minima\n                                  and plateaux.\n\n\n▷\n                                  “Hill-climbing search is like climbing Everest in thick fog with amnesia”.\n\n\n\n\n\n\n\n\n \n\n▷Idea\n                  Escape\nlocal maxima\n                  by allowing some “bad” or random moves.\n\n\n▷local search,\nsimulated annealing, ...\n\n▷Properties\n                  All are\nincomplete,\nnonoptimal.\n\n\n▷Sometimes performs well in practice(if (optimal) solutions are dense)\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 132024-12-14\n",
        "sectionId": "59328df2",
        "archive": "courses/FAU/AI/course",
        "filepath": "search/slides/hill-climbing.en.xhtml"
    },
    {
        "slideContent": "\nSimulated annealing (Idea)\n\n\n\n▷\nRidges\n                                  are ascending successions of\nlocal maxima.\n\n\n▷Problem\n                                  They are extremely difficult to bv navigate for\nlocal search algorithms.\n\n\n▷Idea\n                                  Escape\nlocal maxima\n                                  by allowing some “bad” moves, but gradually decrease their size and frequency.\n\n\n\n\n\n\n\n \n\n▷Annealing is the process of heating steel and let it cool gradually to give it time to grow an optimal cristal structure.\n\n\n▷Simulated annealing\n              is like shaking a ping pong ball occasionally on a bumpy surface to free it.(so it does not get stuck)\n\n\n▷Devised by Metropolis et al for physical process modelling [Met+53]\n\n\n▷Widely used in VLSI layout, airline scheduling, etc.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "59328df2",
        "archive": "courses/FAU/AI/course",
        "filepath": "search/slides/simulated-annealing.en.xhtml"
    },
    {
        "slideContent": "\nSimulated annealing (Implementation)\n\n▷\n                  The following\nalgorithm\n                  is called\nsimulated annealing:\n\n\nprocedure Simulated―Annealing (problem,schedule) /* a solution state */\nlocal node, next /* nodes */\nlocal T /* a ‘‘temperature’’ controlling prob.~of downward steps */\ncurrent := Make―Node(Initial―State[problem])\nfor t :=1 to ∞\nT := schedule[t]\nif T = 0 return current end if\nnext := <a randomly selected successor of current>\n∆(E) := Value[next]―Value[current]\nif ∆(E) > 0 current := next\nelse\ncurrent := next <only with probability> 𝑒∆(𝐸)/𝑇\nend if\nend for\nend procedure\n\nA\nschedule\n                  is a mapping from time to “temperature”.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 122024-12-14\n",
        "sectionId": "59328df2",
        "archive": "courses/FAU/AI/course",
        "filepath": "search/slides/simulated-annealing.en.xhtml"
    },
    {
        "slideContent": "\nProperties of simulated annealing\n\n▷At fixed “temperature”\n𝑇, state occupation probability reaches Boltzman distribution\n𝑝(𝑥)=𝛼𝑒𝐸(𝑥)𝑘𝑇𝑇\n              decreased slowly enough\n⤳\n              always reach best state\n𝑥*\n              because\n𝑒𝐸(𝑥*)𝑘𝑇𝑒𝐸(𝑥)𝑘𝑇=𝑒𝐸(𝑥*)−𝐸(𝑥)𝑘𝑇≫1for small\n𝑇.\n\n\n▷Question\n                  Is this necessarily an interesting guarantee?\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 132024-12-14\n",
        "sectionId": "59328df2",
        "archive": "courses/FAU/AI/course",
        "filepath": "search/slides/simulated-annealing.en.xhtml"
    },
    {
        "slideContent": "\nLocal beam search\n\n▷\nLocal beam search\n                  is a\nsearch algorithm\n                  that keep\n𝑘\nstates\n                  instead of 1 and chooses the top\n𝑘\n                  of all their\nsuccessors.\n\n\n▷Observation\nLocal beam search\n                  is not the same as\n𝑘\n                  searches run in parallel!(Searches that find good\nstates\n                      recruit other searches to join them)\n\n\n▷Problem\n                  Quite often, all\n𝑘\n                  searches end up on the same local hill!\n\n\n▷Idea\n                  Choose\n𝑘\nsuccessors\n                  randomly, biased towards good ones.(Observe the close analogy to natural selection!)\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-15\n",
        "sectionId": "59328df2",
        "archive": "courses/FAU/AI/course",
        "filepath": "search/slides/local-beam-search.en.xhtml"
    },
    {
        "slideContent": "\nGenetic algorithms (very briefly)\n\n▷\n                  A\ngenetic algorithm\n                  is a variant of\nlocal beam search\n                  that generates\nsuccessors\n                  by\n\n\n▷randomly modifying\nstates\n                  (mutation)\n\n\n▷mixing\npairs\n                  of\nstates\n                  (sexual reproduction\n                  or\ncrossover)\n\n\nto optimize a fitness function.(survival of the fittest)\n\n\n▷\n                  Generating\nsuccessors\n                  for\n8 queens\n\n\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-15\n",
        "sectionId": "59328df2",
        "archive": "courses/FAU/AI/course",
        "filepath": "search/slides/genetic-algorithms.en.xhtml"
    },
    {
        "slideContent": "\nGenetic algorithms (continued)\n\n▷Problem\nGenetic algorithms\n                  require\nstates\n                  encoded as\nstrings.\n\n\n▷Crossover\n              only helps iff\nsubstrings\n              are meaningful components.\n\n\n▷Evolving 8 QueensFirst\ncrossover\n\n\n\n\n▷Note\nGenetic algorithms\n≠\n                  evolution: e.g., real genes also encode replication machinery!\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 122024-12-15\n",
        "sectionId": "59328df2",
        "archive": "courses/FAU/AI/course",
        "filepath": "search/slides/genetic-algorithms.en.xhtml"
    },
    {
        "slideContent": "\nThe Problem\n\n▷The Problem of Game-Play\n                  cf.\n??\n\n\n▷Example 0.1.\n\n\n\n\n▷\nAdversarial search\n=^\n                  Game playing against an opponent.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "974f1ed1",
        "archive": "courses/FAU/AI/course",
        "filepath": "game-play/slides/gameplay-problem.en.xhtml"
    },
    {
        "slideContent": "\nWhy Game Playing?\n\n▷What do\nyou\n              think?\n\n\n▷Playing a game well clearly requires a form of “intelligence”.\n\n\n▷Games capture a pure form of competition between opponents.\n\n\n▷Games are abstract and precisely defined, thus very easy to formalize.\n\n\n▷Game playing is one of the oldest sub-areas of\nAI\n            (ca. 1950).\n\n\n▷The dream of a machine that plays\nchess\n            is, indeed,\nmuch\n            older than\nAI!\n\n\n  “Schachtürke” (1769) “El Ajedrecista” (1912) \n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "974f1ed1",
        "archive": "courses/FAU/AI/course",
        "filepath": "game-play/slides/gameplay-why.en.xhtml"
    },
    {
        "slideContent": "\n“Game” Playing?\nWhich\n              Games?\n\n▷...sorry, we’re not gonna do soccer here.\n\n\n▷Restrictions\n                  A\ngame in the sense of AI-1\n                  is one where\n\n\n▷Game state\ndiscrete, number of\ngame state\nfinite.\n\n\n▷Finite\n                  number of possible moves.\n\n\n▷The\ngame state\n                  is\nfully observable.\n\n\n▷The outcome of each move is\ndeterministic.\n\n\n▷Two players:\nMax\n                  and\nMin.\n\n\n▷Turn-taking: It’s each player’s turn alternatingly.\nMax\n                  begins.\n\n\n▷Terminal game states\n                  have a\nutility\n𝑢.\nMax\n                  tries to\nmaximize\n𝑢,\nMin\n                  tries to\nminimize\n𝑢.\n\n\n▷In that sense, the\nutility\n                  for\nMin\n                  is the exact opposite of the\nutility\n                  for\nMax\n                  (“zero sum”).\n\n\n▷There are no\ninfinite\n                  runs of the game (no matter what\nmoves\n                  are chosen, a\nterminal state\n                  is reached after a\nfinite\n                  number of\nmoves).\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "974f1ed1",
        "archive": "courses/FAU/AI/course",
        "filepath": "game-play/slides/gameplay-which.en.xhtml"
    },
    {
        "slideContent": "\nAn Example Game\n\n\n\n\n\n\n\n▷Game states: Positions of figures.\n\n\n▷Moves: Given by rules.\n\n\n▷Players: White (Max), Black (Min).\n\n\n▷Terminal states: Checkmate.\n\n\n▷Utility of terminal states, e.g.:\n\n\n▷+100\n                            if Black is checkmated.\n\n\n▷0\n                            if stalemate.\n\n\n▷−100\n                            if White is checkmated.\n\n\n\n\n \n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-15\n",
        "sectionId": "974f1ed1",
        "archive": "courses/FAU/AI/course",
        "filepath": "game-play/slides/gameplay-ex.en.xhtml"
    },
    {
        "slideContent": "\n“Game” Playing? Which Games\nNot?\n\n▷Soccer\n(sorry guys; not even RoboCup)\n\n\n▷Important types of games that we\ndon’t\n            tackle here:\n\n\n▷Chance. (E.g.,\nbackgammon)\n\n\n▷More than two players. (E.g., Halma)\n\n\n▷Hidden information. (E.g., most card games)\n\n\n▷Simultaneous moves. (E.g., Diplomacy)\n\n\n▷Not zero-sum, i.e., outcomes may be beneficial (or detrimental) for both players.\n(cf. Game theory: Auctions, elections, economy, politics, ...)\n\n\n▷Many of these more general game types can be handled by similar/extended\nalgorithms.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-15\n",
        "sectionId": "974f1ed1",
        "archive": "courses/FAU/AI/course",
        "filepath": "game-play/slides/gameplay-whichnot.en.xhtml"
    },
    {
        "slideContent": "\n(A Brief Note On) Formalization\n\n▷\n                  An\nadversarial search problem\n                  is a\nsearch problem\n〈𝒮,𝒜,𝒯,ℐ,𝒢〉, where\n\n\n1.𝒮=𝒮Max⊎𝒮Min⊎𝒢\n                  and\n𝒜=𝒜Max⊎𝒜Min\n\n\n2.For\n𝑎∊𝒜Max, if\n𝑠\n\n−\n\n\n−\n\n→\n𝑎𝑠'\n                  then\n𝑠∊𝒮Max\n                  and\n𝑠'∊(𝒮Min∪𝒢).\n\n\n3.For\n𝑎∊𝒜Min, if\n𝑠\n\n−\n\n\n−\n\n→\n𝑎𝑠'\n                  then\n𝑠∊𝒮Min\n                  and\n𝑠'∊(𝒮Max∪𝒢).\n\n\ntogether with a\ngame utility function\n𝑢:𝒢→ℝ.\n(the “score” of the game)\n\n\n▷Commonly used terminologyposition\n=^\nstate,\nmove\n=^\naction,\nend state\n=^\nterminal state\n=^\ngoal state.\n\n\n▷Remark\n                  A round of the game — one move\nMax, one move\nMin\n                  — is often referred to as a “move”, and individual\nactions\n                  as “half-moves”(we\ndon’t\n                      in AI-1)\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "974f1ed1",
        "archive": "courses/FAU/AI/course",
        "filepath": "game-play/slides/game-formalization.en.xhtml"
    },
    {
        "slideContent": "\nWhy Games are Hard to Solve: I\n\n▷What is a “solution” here?\n\n\n▷\n                  Let\nΘ\n                  be an\nadversarial search problem, and let\n𝑋∊{Max,Min}. A\nstrategy\n                  for\n𝑋\n                  is a\nfunction\n𝜎𝑋:𝒮𝑋→𝒜𝑋\n                  so that\n𝑎\n                  is\napplicable\n                  to\n𝑠\n                  whenever\n𝜎𝑋(𝑠)=𝑎.\n\n\n▷We don’t know how the opponent will react, and need to prepare for all possibilities.\n\n\n▷\n                  A\nstrategy\n                  is called\noptimal\n                  if it yields the best possible\nutility\n                  for\n𝑋\n                  assuming perfect opponent play (not formalized here).\n\n\n▷Problem\n                  In (almost) all games, computing an\noptimal\nstrategy\n                  is infeasible.(state/search tree\n                      too huge)\n\n\n▷Solution\n                  Compute the next\nmove\n                  “on demand”, given the current\nstate\n                  instead.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "974f1ed1",
        "archive": "courses/FAU/AI/course",
        "filepath": "game-play/slides/strategy.en.xhtml"
    },
    {
        "slideContent": "\nWhy Games are hard to solve II\n\n▷\n                Number of\nreachable\nstates\n                in\nchess:\n1040.\n\n\n▷\n                Number of\nreachable\nstates\n                in\ngo:\n10100.\n\n\n▷It’s even worse\n                Our\nalgorithms\n                here look at\nsearch trees\n                (game trees), no\nduplicate pruning.\n\n\n▷\n\n\n▷Chess\n                without\nduplicate pruning:\n35100≃10154.\n\n\n▷Go without\nduplicate pruning:\n200300≃10690.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-16\n",
        "sectionId": "974f1ed1",
        "archive": "courses/FAU/AI/course",
        "filepath": "game-play/slides/reachable-ex.en.xhtml"
    },
    {
        "slideContent": "\nHow To Describe a Game State Space?\n\n▷Like for classical\nsearch problems, there are three possible ways to describe a game:\nblackbox/API description,\ndeclarative\n              description,\nexplicit\n              game\nstate space.\n\n\n▷Question\n                  Which ones do humans use?\n\n\n▷Explicit\n≈\n                      Hand over a book with all\n1040\nmoves\n                      in\nchess.\n\n\n▷Blackbox\n≈\n                      Give possible\nchess\n                      moves on demand but don’t say how they are generated.\n\n\n▷Answer\nDeclarative!With “game description language”\n=^\nnatural language.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "974f1ed1",
        "archive": "courses/FAU/AI/course",
        "filepath": "game-play/slides/state-space.en.xhtml"
    },
    {
        "slideContent": "\nSpecialized vs. General Game Playing\n\n▷And which game descriptions do\ncomputers\n              use?\n\n\n▷Explicit: Only in illustrations.\n\n\n▷Blackbox/API: Assumed description in\n(This Chapter)\n\n\n▷Method of choice for all those game players out there in the market (Chess\n              computers, video game opponents, you name it).\n\n\n▷Programs\n              designed for, and specialized to, a particular game.\n\n\n▷Human knowledge is key:\nevaluation functions\n              (see later), opening databases (chess!!), end game databases.\n\n\n▷Declarative:\nGeneral game playing, active area of research in\nAI.\n\n\n▷Generic\ngame description language\n                  (GDL), based on\nlogic.\n\n\n▷Solvers\n                      are given only “the rules of the game”, no other knowledge/input whatsoever\n                  (cf.\n??).\n\n\n▷Regular academic competitions since 2005.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-15\n",
        "sectionId": "974f1ed1",
        "archive": "courses/FAU/AI/course",
        "filepath": "game-play/slides/gameplay-special-general.en.xhtml"
    },
    {
        "slideContent": "\nOur Agenda for This Chapter\n\n▷Minimax\n                  Search\n                How to compute an optimal strategy?\n\n\n▷Minimax\n                is the canonical (and easiest to understand)\nalgorithm\n                for\nsolving\n                games, i.e., computing an\noptimal\nstrategy.\n\n\n▷Evaluation functions\n                But what if we don’t have the time/memory to solve the entire game?\n\n\n▷Given limited time, the best we can do is look ahead as far as we can.\nEvaluation functions\n                tell us how to evaluate the\nleaf\nstates\n                at the cut off.\n\n\n▷Alphabeta search\n                How to\nprune\n                unnecessary parts of the tree?\n\n\n▷Often, we can detect early on that a particular action choice cannot be part of the optimal strategy. We can then stop considering this part of the game tree.\n\n\n▷State of the art\n                What is the state of affairs, for prominent games, of computer game playing vs.,human experts?\n\n\n▷Just FYI (not part of the technical content of this\ncourse).\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-15\n",
        "sectionId": "974f1ed1",
        "archive": "courses/FAU/AI/course",
        "filepath": "game-play/slides/agenda.en.xhtml"
    },
    {
        "slideContent": "\nExample Tic-Tac-Toe\n\n▷\n                A full\ngame tree\n                for\ntic-tac-toe\n\n\n\n\n▷current player and\naction\n                marked on the left.\n\n\n▷Last row:\nterminal positions\n                with their\nutility.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "21e7ed74",
        "archive": "courses/FAU/AI/course",
        "filepath": "game-play/slides/minimax-tictactoe.en.xhtml"
    },
    {
        "slideContent": "\nMinimax: Outline\n\n▷We max, we min, we max, we min ...\n\n\n1.Depth first search\n            in\ngame tree, with\nMax\n            in the\nroot.\n\n\n2.Apply\ngame utility function\n            to\nterminal positions.\n\n\n3.Bottom-up for each\ninner node\n𝑛\n            in the\nsearch tree, compute the\nutility\n𝑢^(𝑛)\n            of\n𝑛\n            as follows:\n\n\n▷If it’s\nMax’s turn: Set\n𝑢^(𝑛)\n            to the\nmaximum\n            of the\nutilities\n            of\n𝑛’s\nsuccessor\nnodes.\n\n\n▷If it’s\nMin’s turn: Set\n𝑢^(𝑛)\n            to the\nminimum\n            of the\nutilities\n            of\n𝑛’s\nsuccessor\nnodes.\n\n\n4.Selecting a\nmove\n            for\nMax\n            at the\nroot: Choose one\nmove\n            that leads to a\nsuccessor\nnode\n            with\nmaximal\nutility.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-15\n",
        "sectionId": "21e7ed74",
        "archive": "courses/FAU/AI/course",
        "filepath": "game-play/slides/minimax-outline.en.xhtml"
    },
    {
        "slideContent": "\nMinimax: Example\n\n\n\n\n\n\n\n\n\n  \nMax  \n3  \n\n\n\n\n  \n\nMin  \n3  \n\n\n\n\n\n\n  \n\n3  \n\n\n\n\n\n\n  \n\n12  \n\n\n\n\n\n\n  \n\n8  \n\n\n\n\n\n\n  \n\nMin  \n2  \n\n\n\n\n\n\n  \n\n2  \n\n\n\n\n\n\n  \n\n4  \n\n\n\n\n\n\n  \n\n6  \n\n\n\n\n\n\n  \n\nMin  \n2  \n\n\n\n\n\n\n  \n\n14  \n\n\n\n\n\n\n  \n\n5  \n\n\n\n\n\n\n  \n\n2  \n\n\n\n\n\n\n\n\n▷Blue numbers\nUtility function\n𝑢\n                applied to\nterminal positions.\n\n\n▷Red numbers\nUtilities\n                of\ninner nodes, as computed by the\nminimax algorithm.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-15\n",
        "sectionId": "21e7ed74",
        "archive": "courses/FAU/AI/course",
        "filepath": "game-play/slides/minimax-tree.en.xhtml"
    },
    {
        "slideContent": "\nThe Minimax Algorithm: Pseudo-Code\n\n▷\n                  The\nminimax algorithm\n                  (often just called\nminimax) is given by the following\nfunctions\n                  whose\ninput\n                  is a\nstate\n𝑠∊𝒮Max, in which\nMax\n                  is to move.\n\n\nfunction Minimax―Decision(𝑠) returns an action\n𝑣 := Max―Value(𝑠)\nreturn an action yielding value 𝑣 in the previous function call\n\nfunction Max―Value(𝑠) returns a utility value\nif Terminal―Test(𝑠) then return 𝑢(𝑠)\n𝑣 := −∞\nfor each 𝑎∊ Actions(𝑠) do\n𝑣 := max(𝑣,Min―Value(ChildState(𝑠,𝑎)))\nreturn 𝑣\n\nfunction Min―Value(𝑠) returns a utility value\nif Terminal―Test(𝑠) then return 𝑢(𝑠)\n𝑣 := +∞\nfor each 𝑎∊ Actions(𝑠) do\n𝑣 := min(𝑣,Max―Value(ChildState(𝑠,𝑎)))\nreturn 𝑣\n\nWe call\nnodes, where\nMax/Min\n                  acts\nMax-nodes/Min-nodes.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "21e7ed74",
        "archive": "courses/FAU/AI/course",
        "filepath": "game-play/slides/minimax-algo.en.xhtml"
    },
    {
        "slideContent": "\nMinimax: Example, Now in Detail\n\n\n\n\n\n\n\n\n\n  \nMax  \n−∞  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \nMax  \n−∞  \n\n\n\n\n  \n\nMin  \n∞  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \nMax  \n−∞  \n\n\n\n\n  \n\nMin  \n∞  \n\n\n\n\n\n\n  \n\n3  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \nMax  \n−∞  \n\n\n\n\n  \n\nMin  \n3  \n\n\n\n\n\n\n  \n\n3  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \nMax  \n−∞  \n\n\n\n\n  \n\nMin  \n3  \n\n\n\n\n\n\n  \n\n3  \n\n\n\n\n\n\n  \n\n12  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \nMax  \n−∞  \n\n\n\n\n  \n\nMin  \n3  \n\n\n\n\n\n\n  \n\n3  \n\n\n\n\n\n\n  \n\n12  \n\n\n\n\n\n\n  \n\n8  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \nMax  \n3  \n\n\n\n\n  \n\nMin  \n3  \n\n\n\n\n\n\n  \n\n3  \n\n\n\n\n\n\n  \n\n12  \n\n\n\n\n\n\n  \n\n8  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \nMax  \n3  \n\n\n\n\n  \n\nMin  \n3  \n\n\n\n\n\n\n  \n\n3  \n\n\n\n\n\n\n  \n\n12  \n\n\n\n\n\n\n  \n\n8  \n\n\n\n\n\n\n  \n\nMin  \n∞  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \nMax  \n3  \n\n\n\n\n  \n\nMin  \n3  \n\n\n\n\n\n\n  \n\n3  \n\n\n\n\n\n\n  \n\n12  \n\n\n\n\n\n\n  \n\n8  \n\n\n\n\n\n\n  \n\nMin  \n∞  \n\n\n\n\n\n\n  \n\n2  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \nMax  \n3  \n\n\n\n\n  \n\nMin  \n3  \n\n\n\n\n\n\n  \n\n3  \n\n\n\n\n\n\n  \n\n12  \n\n\n\n\n\n\n  \n\n8  \n\n\n\n\n\n\n  \n\nMin  \n∞  \n\n\n\n\n\n\n  \n\n2  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \nMax  \n3  \n\n\n\n\n  \n\nMin  \n3  \n\n\n\n\n\n\n  \n\n3  \n\n\n\n\n\n\n  \n\n12  \n\n\n\n\n\n\n  \n\n8  \n\n\n\n\n\n\n  \n\nMin  \n2  \n\n\n\n\n\n\n  \n\n2  \n\n\n\n\n\n\n  \n\n4  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \nMax  \n3  \n\n\n\n\n  \n\nMin  \n3  \n\n\n\n\n\n\n  \n\n3  \n\n\n\n\n\n\n  \n\n12  \n\n\n\n\n\n\n  \n\n8  \n\n\n\n\n\n\n  \n\nMin  \n2  \n\n\n\n\n\n\n  \n\n2  \n\n\n\n\n\n\n  \n\n4  \n\n\n\n\n\n\n  \n\n6  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \nMax  \n3  \n\n\n\n\n  \n\nMin  \n3  \n\n\n\n\n\n\n  \n\n3  \n\n\n\n\n\n\n  \n\n12  \n\n\n\n\n\n\n  \n\n8  \n\n\n\n\n\n\n  \n\nMin  \n2  \n\n\n\n\n\n\n  \n\n2  \n\n\n\n\n\n\n  \n\n4  \n\n\n\n\n\n\n  \n\n6  \n\n\n\n\n\n\n  \n\nMin  \n∞  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \nMax  \n3  \n\n\n\n\n  \n\nMin  \n3  \n\n\n\n\n\n\n  \n\n3  \n\n\n\n\n\n\n  \n\n12  \n\n\n\n\n\n\n  \n\n8  \n\n\n\n\n\n\n  \n\nMin  \n2  \n\n\n\n\n\n\n  \n\n2  \n\n\n\n\n\n\n  \n\n4  \n\n\n\n\n\n\n  \n\n6  \n\n\n\n\n\n\n  \n\nMin  \n∞  \n\n\n\n\n\n\n  \n\n14  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \nMax  \n3  \n\n\n\n\n  \n\nMin  \n3  \n\n\n\n\n\n\n  \n\n3  \n\n\n\n\n\n\n  \n\n12  \n\n\n\n\n\n\n  \n\n8  \n\n\n\n\n\n\n  \n\nMin  \n2  \n\n\n\n\n\n\n  \n\n2  \n\n\n\n\n\n\n  \n\n4  \n\n\n\n\n\n\n  \n\n6  \n\n\n\n\n\n\n  \n\nMin  \n14  \n\n\n\n\n\n\n  \n\n14  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \nMax  \n3  \n\n\n\n\n  \n\nMin  \n3  \n\n\n\n\n\n\n  \n\n3  \n\n\n\n\n\n\n  \n\n12  \n\n\n\n\n\n\n  \n\n8  \n\n\n\n\n\n\n  \n\nMin  \n2  \n\n\n\n\n\n\n  \n\n2  \n\n\n\n\n\n\n  \n\n4  \n\n\n\n\n\n\n  \n\n6  \n\n\n\n\n\n\n  \n\nMin  \n5  \n\n\n\n\n\n\n  \n\n14  \n\n\n\n\n\n\n  \n\n5  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \nMax  \n3  \n\n\n\n\n  \n\nMin  \n3  \n\n\n\n\n\n\n  \n\n3  \n\n\n\n\n\n\n  \n\n12  \n\n\n\n\n\n\n  \n\n8  \n\n\n\n\n\n\n  \n\nMin  \n2  \n\n\n\n\n\n\n  \n\n2  \n\n\n\n\n\n\n  \n\n4  \n\n\n\n\n\n\n  \n\n6  \n\n\n\n\n\n\n  \n\nMin  \n2  \n\n\n\n\n\n\n  \n\n14  \n\n\n\n\n\n\n  \n\n5  \n\n\n\n\n\n\n  \n\n2  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \nMax  \n3  \n\n\n\n\n  \n\nMin  \n3  \n\n\n\n\n\n\n  \n\n3  \n\n\n\n\n\n\n  \n\n12  \n\n\n\n\n\n\n  \n\n8  \n\n\n\n\n\n\n  \n\nMin  \n2  \n\n\n\n\n\n\n  \n\n2  \n\n\n\n\n\n\n  \n\n4  \n\n\n\n\n\n\n  \n\n6  \n\n\n\n\n\n\n  \n\nMin  \n2  \n\n\n\n\n\n\n  \n\n14  \n\n\n\n\n\n\n  \n\n5  \n\n\n\n\n\n\n  \n\n2  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \nMax  \n3  \n\n\n\n\n  \n\nMin  \n3  \n\n\n\n\n\n\n  \n\n3  \n\n\n\n\n\n\n  \n\n12  \n\n\n\n\n\n\n  \n\n8  \n\n\n\n\n\n\n  \n\nMin  \n2  \n\n\n\n\n\n\n  \n\n2  \n\n\n\n\n\n\n  \n\n4  \n\n\n\n\n\n\n  \n\n6  \n\n\n\n\n\n\n  \n\nMin  \n2  \n\n\n\n\n\n\n  \n\n14  \n\n\n\n\n\n\n  \n\n5  \n\n\n\n\n\n\n  \n\n2  \n\n\n\n\n\n\n\n\n▷So which action for\nMax\n            is returned?\n\n\n▷Leftmost branch.\n\n\n▷Note\n                The maximal possible pay-off is higher for the rightmost branch, but assuming perfect play of\nMin, it’s better to go left. (Going right would be “relying on your opponent to do something stupid”.)\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-16\n",
        "sectionId": "21e7ed74",
        "archive": "courses/FAU/AI/course",
        "filepath": "game-play/slides/minimax-tree-detail.en.xhtml"
    },
    {
        "slideContent": "\nMinimax, Pro and Contra\n\n▷Minimax advantages\n\n\n▷Minimax\n                is the simplest possible (reasonable)\nsearch algorithm\n                for games.\n\n(If any of you sat down, prior to this\nlecture, to\nimplement\n                a Tic-Tac-Toe player, chances are you either looked this up on Wikipedia, or invented it in the process.)\n\n\n▷Returns an\noptimal\naction, assuming perfect opponent play.\n\n\n▷No matter how the opponent plays, the\nutility\n                of the\nterminal state\n                reached will be at least the value computed for the\nroot.\n\n\n▷If the opponent plays perfectly, exactly that value will be reached.\n\n\n▷There’s no need to re-run\nminimax\n                for every\ngame state: Run it once,\noffline\n                before the game starts. During the actual game, just follow the branches taken in the\ntree. Whenever it’s your turn, choose an\naction\nmaximizing\n                the value of the\nsuccessor\nstates.\n\n\n▷Minimax\n                  disadvantages\nIt’s completely infeasible in practice.\n\n\n▷When the\nsearch tree\n                is too large, we need to limit the search depth and apply an\nevaluation function\n                to the cut off\nstates.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-15\n",
        "sectionId": "21e7ed74",
        "archive": "courses/FAU/AI/course",
        "filepath": "game-play/slides/minimax-eval.en.xhtml"
    },
    {
        "slideContent": "\nEvaluation Functions for Minimax\n\n▷Problem\nSearch tree\n                  are too big to search through in\nminimax.\n\n\n▷Solution\n                  We impose a\nsearch depth limit\n                      (also called\nhorizon)\n𝑑, and apply an\nevaluation function\n                  to the\ncut-off states, i.e.\nstates\n𝑠\n                      with\ndp(𝑠)=𝑑.\n\n\n▷\n                  An\nevaluation function\n𝑓\n                  maps\ngame states\n                  to numbers:\n\n\n▷𝑓(𝑠)\n                  is an estimate of the actual value of\n𝑠\n                  (as would be computed by unlimited-depth\nminimax\n                  for\n𝑠).\n\n\n▷If\ncut-off state\n                  is\nterminal: Just use\n𝑢^\n                  instead of\n𝑓.\n\n\n▷Analogy to\nheuristic functions\n              (cf.\n??): We want\n𝑓\n              to be both (a) accurate and (b) fast.\n\n\n▷Another analogy: (a) and (b) are in\ncontradiction\n⤳\n              need to trade-off accuracy against overhead.\n\n\n▷In typical game playing\nalgorithms\n              today,\n𝑓\n              is inaccurate but very fast.\n(usually no good methods known for computing accurate\n𝑓)\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "ebfeb85a",
        "archive": "courses/FAU/AI/course",
        "filepath": "game-play/slides/evaluation-function.en.xhtml"
    },
    {
        "slideContent": "\nExample Revisited: Minimax With Depth Limit\n𝑑=2\n\n\n\n\n\n\n\n\n\n  \nMax  \n3  \n\n\n\n\n  \n\nMin  \n3  \n\n\n\n\n\n\n  \n\n3  \n\n\n\n\n\n\n  \n\n12  \n\n\n\n\n\n\n  \n\n8  \n\n\n\n\n\n\n  \n\nMin  \n2  \n\n\n\n\n\n\n  \n\n2  \n\n\n\n\n\n\n  \n\n4  \n\n\n\n\n\n\n  \n\n6  \n\n\n\n\n\n\n  \n\nMin  \n2  \n\n\n\n\n\n\n  \n\n14  \n\n\n\n\n\n\n  \n\n5  \n\n\n\n\n\n\n  \n\n2  \n\n\n\n\n\n\n\n\n▷Blue numbers\nevaluation function\n𝑓, applied to the\ncut-off states\n                at\n𝑑=2.\n\n\n▷Red numbers\nutilities\n                of\ninner node, as computed by\nminimax\n                using\n𝑓.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-15\n",
        "sectionId": "ebfeb85a",
        "archive": "courses/FAU/AI/course",
        "filepath": "game-play/slides/minimax-depth2.en.xhtml"
    },
    {
        "slideContent": "\nExample\nChess\n\n\n\n\n\n\n\n▷Evaluation function\n                            in\nchess:\n\n\n▷Material: Pawn 1, Knight 3, Bishop 3, Rook 5, Queen 9.\n\n\n▷3 points advantage\n⤳\n                            safe win.\n\n\n▷Mobility: How many fields do you control?\n\n\n▷King safety, Pawn structure, ...\n\n▷Note how simple this is!(probably is not how Kasparov evaluates his positions)\n\n\n\n\n \n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-15\n",
        "sectionId": "ebfeb85a",
        "archive": "courses/FAU/AI/course",
        "filepath": "game-play/slides/chess-evaluation.en.xhtml"
    },
    {
        "slideContent": "\nLinear Evaluation Functions\n\n▷Problem\n                  How to come up with\nevaluation functions?\n\n\n▷\n                  A common approach is to use a\nweighted linear function\n                  for\n𝑓, i.e. given a\nsequence\n                  of\nfeatures\n𝑓𝑖:𝑆→ℝ\n                  and a corresponding\nsequence\n                  of\nweights\n𝑤𝑖∊ℝ,\n𝑓\n                  is of the form\n𝑓(𝑠):=𝑤1·𝑓1(𝑠)+𝑤2·𝑓2(𝑠)+···+𝑤𝑛·𝑓𝑛(𝑠)\n\n\n▷ProblemHow to obtain these\nweighted linear functions?\n\n\n▷Weights\n𝑤𝑖\n                  can be learned automatically.(learning agent)\n\n\n▷The\nfeatures\n𝑓𝑖, however, have to be designed by human experts.\n\n\n▷Note\n                  Very fast, very simplistic.\n\n\n▷Observation\n                  Can be computed\nincrementally: In transition\n𝑠\n\n−\n\n\n−\n\n→\n𝑎𝑠', adapt\n𝑓(𝑠)\n                  to\n𝑓(𝑠')\n                  by considering only those\nfeatures\n                  whose\nvalues\n                  have changed.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-16\n",
        "sectionId": "ebfeb85a",
        "archive": "courses/FAU/AI/course",
        "filepath": "game-play/slides/linear-evaluation.en.xhtml"
    },
    {
        "slideContent": "\nThe Horizon Problem\n\n▷Problem\n                  Critical aspects of the game can be cut off by the\nhorizon.We call this the\nhorizon problem.\n\n\n▷\n\n\n\n\n\n\n\n▷Who’s gonna win here?\n\n\n▷White\n                                    wins (pawn\n                                    cannot be prevented from becoming a\nqueen.)\n\n\n▷Black\n                                    has a\n+4\n                                    advantage in material, so if we cut-off here then our\nevaluation function\n                                    will say “100%,\nblack\n                                    wins”.\n\n\n▷The loss for\nblack\n                                    is “beyond our\nhorizon” unless we\nsearch\n                                    extremely deeply:\nblack\n                                    can hold off the end by repeatedly giving\ncheckmate\n                                    to\nwhite’s\nking.\n\n\n\n\n \n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-15\n",
        "sectionId": "ebfeb85a",
        "archive": "courses/FAU/AI/course",
        "filepath": "game-play/slides/horizon-problem.en.xhtml"
    },
    {
        "slideContent": "\nSo, How Deeply to Search?\n\n▷Goal\n                  In given time, search as deeply as possible.\n\n\n▷Problem\n                  Very difficult to predict search\nrunning time.(need an\nanytime algorithm)\n\n\n▷Solution\nIterative deepening search.\n\n\n▷Search with\ndepth limit\n𝑑=1,2,3,...\n\n\n▷When time is up: return result of deepest completed search.\n\n\n▷Better Solution\n                  The\nquiescent search\nalgorithm\n                  uses a dynamically adapted search depth\n𝑑: It searches more deeply in\nunquiet\n                  positions, where value of\nevaluation function\n                  changes a lot in neighboring\nstates.\n\n\n▷\n                  In\nquiescent search\n                  for\nchess:\n\n\n▷piece exchange situations (“you take mine, I take yours”) are very\nunquiet\n\n\n▷⤳\n                  Keep searching until the end of the piece exchange is reached.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-15\n",
        "sectionId": "ebfeb85a",
        "archive": "courses/FAU/AI/course",
        "filepath": "game-play/slides/quiescent-search.en.xhtml"
    },
    {
        "slideContent": "\nWhen We Already Know We Can Do Better Than This\n\n\n\n\n\n\n\n▷Say\n𝑛>𝑚.\n\n\n▷By choosing to go to the left in search\nnode\n                              (A),\nMax\n                              already can get\nutility\n                              of at least\n𝑛\n                              in this part of the game.\n\n\n▷So, if “later on” (further down in the same\nsubtree), in search\nnode\n                              (B) we already know that\nMin\n                              can force\nMax\n                              to get\nvalue\n𝑚<𝑛.\n\n\n▷Then\nMax\n                              will play differently in (A) so we will never actually get to (B).\n\n\n\n\n \n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-16\n",
        "sectionId": "17ab9467",
        "archive": "courses/FAU/AI/course",
        "filepath": "game-play/slides/alpha-idea.en.xhtml"
    },
    {
        "slideContent": "\nAlpha Pruning: Basic Idea\n\n▷Question\nCan we save some work here?\n\n\n\n\n\n\n\n\n\n\n  \nMax  \n3  \n\n\n\n\n  \n\nMin  \n3  \n\n\n\n\n\n\n  \n\n3  \n\n\n\n\n\n\n  \n\n12  \n\n\n\n\n\n\n  \n\n8  \n\n\n\n\n\n\n  \n\nMin  \n2  \n\n\n\n\n\n\n  \n\n2  \n\n\n\n\n\n\n  \n\n4  \n\n\n\n\n\n\n  \n\n6  \n\n\n\n\n\n\n  \n\nMin  \n2  \n\n\n\n\n\n\n  \n\n14  \n\n\n\n\n\n\n  \n\n5  \n\n\n\n\n\n\n  \n\n2  \n\n\n\n\n\n\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 122024-12-16\n",
        "sectionId": "17ab9467",
        "archive": "courses/FAU/AI/course",
        "filepath": "game-play/slides/alpha-idea.en.xhtml"
    },
    {
        "slideContent": "\nAlpha Pruning: Basic Idea (Continued)\n\n▷Answer\n                  Yes! We already know at this point that the middle action won’t be taken by\nMax.\n\n\n\n\n\n\n\n\n\n\n  \nMax  \n≥3  \n\n\n\n\n  \n\nMin  \n3  \n\n\n\n\n\n\n  \n\n3  \n\n\n\n\n\n\n  \n\n12  \n\n\n\n\n\n\n  \n\n8  \n\n\n\n\n\n\n  \n\nMin  \n≤2  \n\n\n\n\n\n\n  \n\n2  \n\n\n\n\n\n\n  \n\nMin  \n\n\n\n\n\n\n  \n\n\n\n\n\n  \n\n\n\n\n\n  \n\n\n\n\n\n\n\n▷Idea\n                  We can use this to\nprune\n                  the\nsearch tree\n⤳\n                  better\nalgorithm\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 132024-12-16\n",
        "sectionId": "17ab9467",
        "archive": "courses/FAU/AI/course",
        "filepath": "game-play/slides/alpha-idea.en.xhtml"
    },
    {
        "slideContent": "\nAlpha\nPruning\n\n▷\n                  For each\nnode\n𝑛\n                  in a\nminimax\nsearch tree, the\nalpha value\n𝛼(𝑛)\n                  is the highest\nMax-node\nutility\n                  that search has encountered on its\npath\n                  from the\nroot\n                  to\n𝑛.\n\n\n▷Computing\nalpha values\n\n\n\n\n\n\n\n\n\n\n  \nMax  \n−∞;𝛼=−∞  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \nMax  \n−∞;𝛼=−∞  \n\n\n\n\n  \n\nMin  \n∞;𝛼=−∞  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \nMax  \n−∞;𝛼=−∞  \n\n\n\n\n  \n\nMin  \n∞;𝛼=−∞  \n\n\n\n\n\n\n  \n\n3  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \nMax  \n−∞;𝛼=−∞  \n\n\n\n\n  \n\nMin  \n3;𝛼=−∞  \n\n\n\n\n\n\n  \n\n3  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \nMax  \n−∞;𝛼=−∞  \n\n\n\n\n  \n\nMin  \n3;𝛼=−∞  \n\n\n\n\n\n\n  \n\n3  \n\n\n\n\n\n\n  \n\n12  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \nMax  \n−∞;𝛼=−∞  \n\n\n\n\n  \n\nMin  \n3;𝛼=−∞  \n\n\n\n\n\n\n  \n\n3  \n\n\n\n\n\n\n  \n\n12  \n\n\n\n\n\n\n  \n\n8  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \nMax  \n3;𝛼=3  \n\n\n\n\n  \n\nMin  \n3;𝛼=−∞  \n\n\n\n\n\n\n  \n\n3  \n\n\n\n\n\n\n  \n\n12  \n\n\n\n\n\n\n  \n\n8  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \nMax  \n3;𝛼=3  \n\n\n\n\n  \n\nMin  \n3;𝛼=−∞  \n\n\n\n\n\n\n  \n\n3  \n\n\n\n\n\n\n  \n\n12  \n\n\n\n\n\n\n  \n\n8  \n\n\n\n\n\n\n  \n\nMin  \n∞;𝛼=3  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \nMax  \n3;𝛼=3  \n\n\n\n\n  \n\nMin  \n3;𝛼=−∞  \n\n\n\n\n\n\n  \n\n3  \n\n\n\n\n\n\n  \n\n12  \n\n\n\n\n\n\n  \n\n8  \n\n\n\n\n\n\n  \n\nMin  \n∞;𝛼=3  \n\n\n\n\n\n\n  \n\n2  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \nMax  \n3;𝛼=3  \n\n\n\n\n  \n\nMin  \n3;𝛼=−∞  \n\n\n\n\n\n\n  \n\n3  \n\n\n\n\n\n\n  \n\n12  \n\n\n\n\n\n\n  \n\n8  \n\n\n\n\n\n\n  \n\nMin  \n2;𝛼=3  \n\n\n\n\n\n\n  \n\n2  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \nMax  \n3;𝛼=3  \n\n\n\n\n  \n\nMin  \n3;𝛼=−∞  \n\n\n\n\n\n\n  \n\n3  \n\n\n\n\n\n\n  \n\n12  \n\n\n\n\n\n\n  \n\n8  \n\n\n\n\n\n\n  \n\nMin  \n2;𝛼=3  \n\n\n\n\n\n\n  \n\n2  \n\n\n\n\n\n\n  \n\nMin  \n\n\n\n\n\n\n  \n\n\n\n\n\n  \n\n\n\n\n\n  \n\n\n\n\n\n\n\n▷How to use\n𝛼?\n                  In a\nMin-node\n𝑛, if\n𝑢^(𝑛')≤𝛼(𝑛)\n                  for one of the\nsuccessors, then stop considering\n𝑛.\n(pruning\n                      out its remaining\nsuccessors)\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "17ab9467",
        "archive": "courses/FAU/AI/course",
        "filepath": "game-play/slides/alpha-pruning.en.xhtml"
    },
    {
        "slideContent": "\nAlpha-Beta\nPruning\n\n▷Recall\n\n\n▷What is\n𝛼:\n                  For each search\nnode\n𝑛, the highest\nMax-node\nutility\n                  that search has encountered on its\npath\n                  from the\nroot\n                  to\n𝑛.\n\n\n▷How to use\n𝛼:\n                  In a\nMin-node\n𝑛, if one of the\nsuccessors\n                  already has\nutility\n≤𝛼(𝑛), then stop considering\n𝑛.\n(Pruning\n                      out its remaining\nsuccessors)\n\n\n▷Idea\n                  We can use a dual method for\nMin!\n\n\n▷\n                  For each\nnode\n𝑛\n                  in a\nminimax\nsearch tree, the\nbeta value\n𝛽(𝑛)\n                  is the highest\nMin-node\nutility\n                  that search has encountered on its\npath\n                  from the\nroot\n                  to\n𝑛.\n\n\n▷How to use\n𝛽\n                  In a\nMax-node\n𝑛, if one of the\nsuccessors\n                  already has\nutility\n≥𝛽(𝑛), then stop considering\n𝑛.(pruning\n                      out its remaining\nsuccessors)\n\n\n▷...and of course we can\nuse\n𝛼\n                  and\n𝛽\n                  together!\n⤳\nalphabeta-pruning\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "17ab9467",
        "archive": "courses/FAU/AI/course",
        "filepath": "game-play/slides/alphabeta.en.xhtml"
    },
    {
        "slideContent": "\nAlpha-Beta Search: Pseudocode\n\n▷\n                  The\nalphabeta search\nalgorithm\n                  is given by the following\npseudocode\n\n\nfunction Alpha―Beta―Search (𝑠) returns an action\n𝑣 := Max―Value(𝑠, −∞, +∞)\nreturn an action yielding value 𝑣 in the previous function call\n\nfunction Max―Value(𝑠, 𝛼, 𝛽) returns a utility value\nif Terminal―Test(𝑠) then return 𝑢(𝑠)\n𝑣:= −∞\nfor each 𝑎∊ Actions(𝑠) do\n𝑣 := max(𝑣,Min―Value(ChildState(𝑠,𝑎), 𝛼, 𝛽))\n𝛼 := max(𝛼, 𝑣)\nif 𝑣≥𝛽 then return 𝑣 /* Here: 𝑣≥𝛽⇔𝛼≥𝛽 */\nreturn 𝑣\n\nfunction Min―Value(𝑠, 𝛼, 𝛽) returns a utility value\nif Terminal―Test(𝑠) then return 𝑢(𝑠)\n𝑣 := +∞\nfor each 𝑎∊ Actions(𝑠) do\n𝑣 := min(𝑣,Max―Value(ChildState(𝑠,𝑎), 𝛼, 𝛽))\n𝛽 := min(𝛽, 𝑣)\nif 𝑣≤𝛼 then return 𝑣 /* Here: 𝑣≤𝛼⇔𝛼≥𝛽 */\nreturn 𝑣\n\n=^\nMinimax\n                  (slide\n??) +\n𝛼/𝛽\n                  book-keeping and\npruning.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "17ab9467",
        "archive": "courses/FAU/AI/course",
        "filepath": "game-play/slides/alphabeta-algo.en.xhtml"
    },
    {
        "slideContent": "\nAlpha-Beta Search: Example\n\n▷Notation\n𝑣;[𝛼,𝛽]\n\n\n\n\n\n\n\n\n\n\n  \nMax  \n−∞;[−∞,∞]  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \nMax  \n−∞;[−∞,∞]  \n\n\n\n\n  \n\nMin  \n∞;[−∞,∞]  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \nMax  \n−∞;[−∞,∞]  \n\n\n\n\n  \n\nMin  \n∞;[−∞,∞]  \n\n\n\n\n\n\n  \n\n3  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \nMax  \n−∞;[−∞,∞]  \n\n\n\n\n  \n\nMin  \n3;[−∞,3]  \n\n\n\n\n\n\n  \n\n3  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \nMax  \n−∞;[−∞,∞]  \n\n\n\n\n  \n\nMin  \n3;[−∞,3]  \n\n\n\n\n\n\n  \n\n3  \n\n\n\n\n\n\n  \n\n12  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \nMax  \n−∞;[−∞,∞]  \n\n\n\n\n  \n\nMin  \n3;[−∞,3]  \n\n\n\n\n\n\n  \n\n3  \n\n\n\n\n\n\n  \n\n12  \n\n\n\n\n\n\n  \n\n8  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \nMax  \n3;[3,∞]  \n\n\n\n\n  \n\nMin  \n3;[−∞,3]  \n\n\n\n\n\n\n  \n\n3  \n\n\n\n\n\n\n  \n\n12  \n\n\n\n\n\n\n  \n\n8  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \nMax  \n3;[3,∞]  \n\n\n\n\n  \n\nMin  \n3;[−∞,3]  \n\n\n\n\n\n\n  \n\n3  \n\n\n\n\n\n\n  \n\n12  \n\n\n\n\n\n\n  \n\n8  \n\n\n\n\n\n\n  \n\nMin  \n∞;[3,∞]  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \nMax  \n3;[3,∞]  \n\n\n\n\n  \n\nMin  \n3;[−∞,3]  \n\n\n\n\n\n\n  \n\n3  \n\n\n\n\n\n\n  \n\n12  \n\n\n\n\n\n\n  \n\n8  \n\n\n\n\n\n\n  \n\nMin  \n∞;[3,∞]  \n\n\n\n\n\n\n  \n\n2  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \nMax  \n3;[3,∞]  \n\n\n\n\n  \n\nMin  \n3;[−∞,3]  \n\n\n\n\n\n\n  \n\n3  \n\n\n\n\n\n\n  \n\n12  \n\n\n\n\n\n\n  \n\n8  \n\n\n\n\n\n\n  \n\nMin  \n2;[3,2]  \n\n\n\n\n\n\n  \n\n2  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \nMax  \n3;[3,∞]  \n\n\n\n\n  \n\nMin  \n3;[−∞,3]  \n\n\n\n\n\n\n  \n\n3  \n\n\n\n\n\n\n  \n\n12  \n\n\n\n\n\n\n  \n\n8  \n\n\n\n\n\n\n  \n\nMin  \n2;[3,2]  \n\n\n\n\n\n\n  \n\n2  \n\n\n\n\n\n\n  \n\nMin  \n∞;[3,∞]  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \nMax  \n3;[3,∞]  \n\n\n\n\n  \n\nMin  \n3;[−∞,3]  \n\n\n\n\n\n\n  \n\n3  \n\n\n\n\n\n\n  \n\n12  \n\n\n\n\n\n\n  \n\n8  \n\n\n\n\n\n\n  \n\nMin  \n2;[3,2]  \n\n\n\n\n\n\n  \n\n2  \n\n\n\n\n\n\n  \n\nMin  \n∞;[3,∞]  \n\n\n\n\n\n\n  \n\n14  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \nMax  \n3;[3,∞]  \n\n\n\n\n  \n\nMin  \n3;[−∞,3]  \n\n\n\n\n\n\n  \n\n3  \n\n\n\n\n\n\n  \n\n12  \n\n\n\n\n\n\n  \n\n8  \n\n\n\n\n\n\n  \n\nMin  \n2;[3,2]  \n\n\n\n\n\n\n  \n\n2  \n\n\n\n\n\n\n  \n\nMin  \n14;[3,14]  \n\n\n\n\n\n\n  \n\n14  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \nMax  \n3;[3,∞]  \n\n\n\n\n  \n\nMin  \n3;[−∞,3]  \n\n\n\n\n\n\n  \n\n3  \n\n\n\n\n\n\n  \n\n12  \n\n\n\n\n\n\n  \n\n8  \n\n\n\n\n\n\n  \n\nMin  \n2;[3,2]  \n\n\n\n\n\n\n  \n\n2  \n\n\n\n\n\n\n  \n\nMin  \n14;[3,14]  \n\n\n\n\n\n\n  \n\n14  \n\n\n\n\n\n\n  \n\n5  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \nMax  \n3;[3,∞]  \n\n\n\n\n  \n\nMin  \n3;[−∞,3]  \n\n\n\n\n\n\n  \n\n3  \n\n\n\n\n\n\n  \n\n12  \n\n\n\n\n\n\n  \n\n8  \n\n\n\n\n\n\n  \n\nMin  \n2;[3,2]  \n\n\n\n\n\n\n  \n\n2  \n\n\n\n\n\n\n  \n\nMin  \n5;[3,5]  \n\n\n\n\n\n\n  \n\n14  \n\n\n\n\n\n\n  \n\n5  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \nMax  \n3;[3,∞]  \n\n\n\n\n  \n\nMin  \n3;[−∞,3]  \n\n\n\n\n\n\n  \n\n3  \n\n\n\n\n\n\n  \n\n12  \n\n\n\n\n\n\n  \n\n8  \n\n\n\n\n\n\n  \n\nMin  \n2;[3,2]  \n\n\n\n\n\n\n  \n\n2  \n\n\n\n\n\n\n  \n\nMin  \n5;[3,5]  \n\n\n\n\n\n\n  \n\n14  \n\n\n\n\n\n\n  \n\n5  \n\n\n\n\n\n\n  \n\n2  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \nMax  \n3;[3,∞]  \n\n\n\n\n  \n\nMin  \n3;[−∞,3]  \n\n\n\n\n\n\n  \n\n3  \n\n\n\n\n\n\n  \n\n12  \n\n\n\n\n\n\n  \n\n8  \n\n\n\n\n\n\n  \n\nMin  \n2;[3,2]  \n\n\n\n\n\n\n  \n\n2  \n\n\n\n\n\n\n  \n\nMin  \n2;[3,2]  \n\n\n\n\n\n\n  \n\n14  \n\n\n\n\n\n\n  \n\n5  \n\n\n\n\n\n\n  \n\n2  \n\n\n\n\n\n\n\n\n▷Note\n                We could have saved work by choosing the opposite order for the successors of the rightmost\nMin-node.Choosing the best moves (for each of\nMax\n                and\nMin) first yields more\npruning!\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "17ab9467",
        "archive": "courses/FAU/AI/course",
        "filepath": "game-play/slides/alphabeta-ex.en.xhtml"
    },
    {
        "slideContent": "\nAlpha-Beta Search: Modified Example\n\n▷Showing off some actual\n𝛽\npruning:\n\n\n\n\n\n\n\n\n\n\n  \nMax  \n3;[3,∞]  \n\n\n\n\n  \n\nMin  \n3;[−∞,3]  \n\n\n\n\n\n\n  \n\n3  \n\n\n\n\n\n\n  \n\n12  \n\n\n\n\n\n\n  \n\n8  \n\n\n\n\n\n\n  \n\nMin  \n2;[3,2]  \n\n\n\n\n\n\n  \n\n2  \n\n\n\n\n\n\n  \n\nMin  \n∞;[3,∞]  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \nMax  \n3;[3,∞]  \n\n\n\n\n  \n\nMin  \n3;[−∞,3]  \n\n\n\n\n\n\n  \n\n3  \n\n\n\n\n\n\n  \n\n12  \n\n\n\n\n\n\n  \n\n8  \n\n\n\n\n\n\n  \n\nMin  \n2;[3,2]  \n\n\n\n\n\n\n  \n\n2  \n\n\n\n\n\n\n  \n\nMin  \n∞;[3,∞]  \n\n\n\n\n\n\n  \n\n5  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \nMax  \n3;[3,∞]  \n\n\n\n\n  \n\nMin  \n3;[−∞,3]  \n\n\n\n\n\n\n  \n\n3  \n\n\n\n\n\n\n  \n\n12  \n\n\n\n\n\n\n  \n\n8  \n\n\n\n\n\n\n  \n\nMin  \n2;[3,2]  \n\n\n\n\n\n\n  \n\n2  \n\n\n\n\n\n\n  \n\nMin  \n5;[3,5]  \n\n\n\n\n\n\n  \n\n5  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \nMax  \n3;[3,∞]  \n\n\n\n\n  \n\nMin  \n3;[−∞,3]  \n\n\n\n\n\n\n  \n\n3  \n\n\n\n\n\n\n  \n\n12  \n\n\n\n\n\n\n  \n\n8  \n\n\n\n\n\n\n  \n\nMin  \n2;[3,2]  \n\n\n\n\n\n\n  \n\n2  \n\n\n\n\n\n\n  \n\nMin  \n5;[3,5]  \n\n\n\n\n\n\n  \n\n5  \n\n\n\n\n\n\n  \n\nMax  \n−∞;[3,5]  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \nMax  \n3;[3,∞]  \n\n\n\n\n  \n\nMin  \n3;[−∞,3]  \n\n\n\n\n\n\n  \n\n3  \n\n\n\n\n\n\n  \n\n12  \n\n\n\n\n\n\n  \n\n8  \n\n\n\n\n\n\n  \n\nMin  \n2;[3,2]  \n\n\n\n\n\n\n  \n\n2  \n\n\n\n\n\n\n  \n\nMin  \n5;[3,5]  \n\n\n\n\n\n\n  \n\n5  \n\n\n\n\n\n\n  \n\nMax  \n−∞;[3,5]  \n\n\n\n\n\n\n  \n\n14  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \nMax  \n3;[3,∞]  \n\n\n\n\n  \n\nMin  \n3;[−∞,3]  \n\n\n\n\n\n\n  \n\n3  \n\n\n\n\n\n\n  \n\n12  \n\n\n\n\n\n\n  \n\n8  \n\n\n\n\n\n\n  \n\nMin  \n2;[3,2]  \n\n\n\n\n\n\n  \n\n2  \n\n\n\n\n\n\n  \n\nMin  \n5;[3,5]  \n\n\n\n\n\n\n  \n\n5  \n\n\n\n\n\n\n  \n\nMax  \n14;[14,5]  \n\n\n\n\n\n\n  \n\n14  \n\n\n\n\n\n\n  \n\n\n\n\n\n  \n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \nMax  \n3;[3,∞]  \n\n\n\n\n  \n\nMin  \n3;[−∞,3]  \n\n\n\n\n\n\n  \n\n3  \n\n\n\n\n\n\n  \n\n12  \n\n\n\n\n\n\n  \n\n8  \n\n\n\n\n\n\n  \n\nMin  \n2;[3,2]  \n\n\n\n\n\n\n  \n\n2  \n\n\n\n\n\n\n  \n\nMin  \n5;[3,5]  \n\n\n\n\n\n\n  \n\n5  \n\n\n\n\n\n\n  \n\nMax  \n14;[14,5]  \n\n\n\n\n\n\n  \n\n14  \n\n\n\n\n\n\n  \n\n\n\n\n\n  \n\n\n\n\n\n  \n\n\n\n\n\n  \n\n2  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \nMax  \n3;[3,∞]  \n\n\n\n\n  \n\nMin  \n3;[−∞,3]  \n\n\n\n\n\n\n  \n\n3  \n\n\n\n\n\n\n  \n\n12  \n\n\n\n\n\n\n  \n\n8  \n\n\n\n\n\n\n  \n\nMin  \n2;[3,2]  \n\n\n\n\n\n\n  \n\n2  \n\n\n\n\n\n\n  \n\nMin  \n2;[3,2]  \n\n\n\n\n\n\n  \n\n5  \n\n\n\n\n\n\n  \n\nMax  \n14;[14,5]  \n\n\n\n\n\n\n  \n\n14  \n\n\n\n\n\n\n  \n\n\n\n\n\n  \n\n\n\n\n\n  \n\n\n\n\n\n  \n\n2  \n\n\n\n\n\n\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-15\n",
        "sectionId": "17ab9467",
        "archive": "courses/FAU/AI/course",
        "filepath": "game-play/slides/alphabeta-ex2.en.xhtml"
    },
    {
        "slideContent": "\nHow Much\nPruning\n              Do We Get?\n\n▷Choosing the best moves first yields most\npruning\n              in\nalphabeta search.\n\n\n▷The\nmaximizing\n              moves for\nMax, the\nminimizing\n              moves for\nMin.\n\n\nObservation\n                  Assuming game tree with branching factor\n𝑏\n                  and depth limit\n𝑑:\n\n\n▷▷Minimax\n                  would have to search\n𝑏𝑑\n                  nodes.\n\n\n▷Best case:\n                  If we always choose the best moves first, then the search tree is reduced to\n𝑏𝑑2\n                  nodes!\n\n\n▷Practice:\n                  It is often possible to get very close to the best case by simple move-ordering methods.\n\n\nChess\n\n\n▷▷Move ordering: Try captures first, then threats, then forward moves, then backward moves.\n\n\n▷From\n35𝑑\n                  to\n35𝑑2. E.g., if we have the time to search a billion (109)\nnodes, then\nminimax\n                  looks ahead\n𝑑=6\n                  moves, i.e.,\n3\n                  rounds (white-black) of the game. Alpha-beta search looks ahead\n6\n                  rounds.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "17ab9467",
        "archive": "courses/FAU/AI/course",
        "filepath": "game-play/slides/alphabeta-eval.en.xhtml"
    },
    {
        "slideContent": "\nAnd now ...\n\n▷AlphaGo\n              =\nMonte Carlo tree search\n              (AI-1) +\nneural networks\n              (AI-2)\n\n\n\n\nCC-BY-SA: Buster Benson@\nhttps://www.flickr.com/photos/erikbenson/25717574115\n\n\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-15\n",
        "sectionId": "3b10b157",
        "archive": "courses/FAU/AI/course",
        "filepath": "game-play/slides/alphago-now.en.xhtml"
    },
    {
        "slideContent": "\nMonte-Carlo Tree Search: Basic Ideas\n\n▷Observation\n                  We do not always have good\nevaluation functions.\n\n\n▷\n                  For\nMonte Carlo sampling\n                  we evaluate actions through\nsampling.\n\n\n▷When deciding which\naction\n                  to take on\ngame state\n𝑠:\n\n\nwhile time not up do\nselect action 𝑎 applicable to 𝑠\nrun a random sample from 𝑎 until terminal state 𝑡\nreturn an 𝑎 for 𝑠 with maximal average 𝑢(𝑡)\n\n▷\n                  For the\nMonte Carlo tree search\nalgorithm\n                  (MCTS) we maintain a\nsearch tree\n𝑇, the\nMCTS tree.\n\n\nwhile time not up do\napply actions within 𝑇 to select a leaf state 𝑠'\nselect action 𝑎' applicable to 𝑠', run random sample from 𝑎'\nadd 𝑠' to 𝑇, update averages etc.\nreturn an 𝑎 for 𝑠 with maximal average 𝑢(𝑡)\nWhen executing 𝑎, keep the part of 𝑇 below 𝑎.\n\n▷Compared to\nalphabeta search: no exhaustive\nenumeration.\n\n\n▷Pro:\nrunning time\n                  &\nmemory.\n\n\n▷Contra: need good guidance how to select and\nsample.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-15\n",
        "sectionId": "3b10b157",
        "archive": "courses/FAU/AI/course",
        "filepath": "game-play/slides/mcts-idea.en.xhtml"
    },
    {
        "slideContent": "\nMonte-Carlo Sampling: Illustration of Sampling\n\n▷Idea\n                Sample the search tree keeping track of the average utilities.\n\n\n▷Single-player, for simplicity\n(with adversary, distinguish max/min nodes)\n\n\n\n\n\n\n\n  \n\n  \n\n  \n\n  \n\n  \n  \n\n  \n\n  \n  \n\n  \n\n  \n\n  \n\n40  \n\n  \n\n70  \n\n50  \n  \n\n  \n  \n\n30  \n\n100  \n\n10  \n\n\nExpansions: 0, 0, 0avg. reward: 0, 0, 0 Expansions: 0, 1, 0avg. reward: 0, 10, 0 Expansions: 1, 1, 0avg. reward: 70, 10, 0 Expansions: 1, 1, 1avg. reward: 70, 10, 40 Expansions: 1, 1, 2avg. reward: 70, 10, 35 Expansions: 2, 1, 2avg. reward: 60, 10, 35 Expansions: 2, 2, 2avg. reward: 60, 55, 35 Expansions: 2, 2, 2avg. reward:\n60, 55, 35\n\n   \n\n\nExpansions: 0, 0avg. reward: 0, 0\n\n   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-16\n",
        "sectionId": "3b10b157",
        "archive": "courses/FAU/AI/course",
        "filepath": "game-play/slides/mcts-illustration.en.xhtml"
    },
    {
        "slideContent": "\nMonte-Carlo Tree Search: Building the Tree\n\n▷Idea\n                We can save work by building the\ntree\n                as we go along.\n\n\n▷Redoing the previous example\n\n\n\n\n\n\n\n  \n\n  \n\n  \n\n  \n\n  \n  \n\n  \n\n  \n  \n\n  \n\n  \n  \n\n  \n\n40  \n\n  \n\n70  \n\n50  \n  \n\n  \n  \n\n30  \n\n100  \n\n10  \n\n\nExpansions: 0, 0, 0avg. reward: 0, 0, 0 Expansions: 0, 1, 0avg. reward: 0, 10, 0 Expansions: 1, 1, 0avg. reward: 70, 10, 0 Expansions: 1, 1, 1avg. reward: 70, 10, 40 Expansions: 1, 1, 2avg. reward: 70, 10, 35 Expansions: 2, 1, 2avg. reward: 60, 10, 35 Expansions: 2, 2, 2avg. reward: 60, 55, 35 Expansions: 2, 2, 2avg. reward:\n60, 55, 35\n\n   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExpansions: 1, 0avg. reward: 70, 0 Expansions: 2, 0avg. reward: 60, 0\n\n   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExpansions: 1avg. reward: 10 Expansions: 2avg. reward: 55\n\n   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExpansions: 1, 0avg. reward: 40, 0 Expansions: 2, 0avg. reward: 35, 0\n\n   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExpansions: 0, 1avg. reward: 0, 50\n\n   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExpansions: 1avg. reward: 100\n\n   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExpansions: 0, 1avg. reward: 0, 30\n\n   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-15\n",
        "sectionId": "3b10b157",
        "archive": "courses/FAU/AI/course",
        "filepath": "game-play/slides/mcts-illustration2.en.xhtml"
    },
    {
        "slideContent": "\nHow to Guide the Search in\nMCTS?\n\n▷How to\nsample?\n                  What exactly is “random”?\n\n\n▷Classical formulation\n                  balance exploitation vs. exploration.\n\n\n▷Exploitation: Prefer moves that have high average already\n(interesting regions of state space)\n\n\n▷Exploration: Prefer moves that have not been tried a lot yet\n(don’t overlook other, possibly better, options)\n\n\n▷UCT: “Upper Confidence bounds applied to Trees” [KS06].\n\n\n▷Inspired by Multi-Armed Bandit (as in: Casino) problems.\n\n\n▷Basically a formula defining the balance. Very popular (buzzword).\n\n\n▷Recent critics (e.g. [FD14]):\nExploitation\n              in search is very different from the Casino, as the “accumulated rewards” are fictitious (we’re only thinking about the game, not actually playing and winning/losing all the time).\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-15\n",
        "sectionId": "3b10b157",
        "archive": "courses/FAU/AI/course",
        "filepath": "game-play/slides/mcts-guidance.en.xhtml"
    },
    {
        "slideContent": "\nAlphaGo: Overview\n\n▷Neural Networks in AlphaGo\n\n\n▷Policy networks: Given a state\n𝑠, output a probability distribution over the actions applicable in\n𝑠.\n\n\n▷Value networks: Given a state\n𝑠, output a number estimating the game value of\n𝑠.\n\n\n▷Combination with MCTS\n\n\n▷Policy networks bias the action choices within the\nMCTS tree\n                  (and hence the\nleaf\nstate\n                  selection), and bias the random\nsamples.\n\n\n▷Value networks are an additional source of state values in the\nMCTS tree, along with the random\nsamples.\n\n\n▷And now in a little more detail\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-15\n",
        "sectionId": "3b10b157",
        "archive": "courses/FAU/AI/course",
        "filepath": "game-play/slides/alphago-overview.en.xhtml"
    },
    {
        "slideContent": "\nNeural Networks in\nAlphaGo\n\n▷Neural network training pipeline and architecture\n\n\n\n\nIllustration taken from [Sil+16] .\n\n\n▷Rollout policy\n𝑝𝜋: Simple but fast,\n≈\n                      prior work on Go.\n\n\n▷SL policy network\n𝑝𝜎: Supervised learning, human-expert data\n                  (“learn to choose an expert action”).\n\n\n▷RL policy network\n𝑝𝜌: Reinforcement learning, self-play\n                  (“learn to win”).\n\n\n▷Value network\n𝑣𝜃: Use self-play games with\n𝑝𝜌\n                      as training data for game-position evaluation\n𝑣𝜃\n                  (“predict which player will win in this state”).\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-15\n",
        "sectionId": "3b10b157",
        "archive": "courses/FAU/AI/course",
        "filepath": "game-play/slides/alphago-nn.en.xhtml"
    },
    {
        "slideContent": "\nNeural Networks +\nMCTS\n              in\nAlphaGo\n\n▷Monte Carlo tree search in AlphaGo\n\n\n\n\nIllustration taken from [Sil+16]\n\n\n▷Rollout policy\n𝑝𝜋:\n                  Action choice in random\nsamples.\n\n\n▷SL policy network\n𝑝𝜎:\n                  Action choice bias within the UCTS tree (stored as “𝑃”, gets smaller to “𝑢(𝑃)” with number of visits); along with quality\n𝑄.\n\n\n▷RL policy network\n𝑝𝜌:\n                  Not used here (used only to learn\n𝑣𝜃).\n\n\n▷Value network\n𝑣𝜃:\n                  Used to evaluate\nleaf\nstates\n𝑠, in linear sum with the value returned by a random\nsample\n                  on\n𝑠.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-15\n",
        "sectionId": "3b10b157",
        "archive": "courses/FAU/AI/course",
        "filepath": "game-play/slides/alphago-nn-mcts.en.xhtml"
    },
    {
        "slideContent": "\nState of the Art\n\n▷Some well-known board games:\n\n\n▷Chess: Up next.\n\n\n▷Othello (Reversi): In 1997, “Logistello” beat the human world champion. Best\ncomputer\n            players now are clearly better than best human players.\n\n\n▷Checkers (Dame): Since 1994, “Chinook” is the offical world champion. In 2007, it was shown to be\nunbeatable: Checkers is\nsolved. (We know the exact value of, and optimal strategy for, the initial state.)\n\n\n▷Go: In 2016,\nAlphaGo\n            beat the Grandmaster Lee Sedol, cracking the “holy grail” of board games. In 2017, “AlphaZero” — a variant of\nAlphaGo\n            with zero prior knowledge beat all reigning champion systems in all board games (including\nAlphaGo) 100/0 after 24h of self-play.\n\n\n▷Intuition\n                Board Games are considered a “solved problem” from the\nAI\n                perspective.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-16\n",
        "sectionId": "52a6c82",
        "archive": "courses/FAU/AI/course",
        "filepath": "game-play/slides/soa.en.xhtml"
    },
    {
        "slideContent": "\nComputer Chess: “Deep Blue” beat Garry Kasparov in 1997\n\n\n\n\n\n\n▷6 games, final score 3.5 : 2.5.\n\n\n▷Specialized\nchess\n                            hardware, 30 nodes with 16 processors each.\n\n\n▷Alphabeta search\n                            plus human knowledge.\n(more details in a moment)\n\n\n▷Nowadays, standard PC hardware plays at world champion level.\n\n\n\n\n \n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-16\n",
        "sectionId": "52a6c82",
        "archive": "courses/FAU/AI/course",
        "filepath": "game-play/slides/computer-chess.en.xhtml"
    },
    {
        "slideContent": "\nComputer Chess: Famous Quotes\n\n▷The\nchess\n            machine is an ideal one to start with, since(Claude Shannon (1949))\n\n\n1.the problem is sharply defined both in allowed operations (the moves) and in the ultimate goal (checkmate),\n\n\n2.it is neither so simple as to be trivial nor too difficult for satisfactory solution,\n\n\n3.chess is generally considered to require “thinking” for skilful play, [...]\n\n\n4.the discrete structure of chess fits well into the digital nature of modern\ncomputers.\n\n\n▷Chess is the drosophila of\nArtificial Intelligence.(Alexander Kronrod (1965))\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-15\n",
        "sectionId": "52a6c82",
        "archive": "courses/FAU/AI/course",
        "filepath": "game-play/slides/chess-quotes.en.xhtml"
    },
    {
        "slideContent": "\nComputer\nChess: Another Famous Quote\n\n▷In 1965, the Russian\nmathematician\n            Alexander Kronrod said, “Chess\n            is the Drosophila of artificial intelligence.”\n\nHowever, computer\nchess\n            has developed much as genetics might have if the geneticists had concentrated their efforts starting in 1910 on breeding racing Drosophilae. We would have some science, but mainly we would have very fast fruit flies.(John McCarthy (1997))\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 122024-12-15\n",
        "sectionId": "52a6c82",
        "archive": "courses/FAU/AI/course",
        "filepath": "game-play/slides/chess-quotes.en.xhtml"
    },
    {
        "slideContent": "\nSummary\n\n▷Games (2-player turn-taking zero-sum discrete and finite games) can be understood as a simple extension of classical\nsearch problems.\n\n\n▷Each player tries to reach a terminal state with the best possible\nutility\n            (maximal vs. minimal).\n\n\n▷Minimax\n            searches the game depth-first, max’ing and min’ing at the respective turns of each player. It yields perfect play, but takes time\n𝒪(𝑏𝑑)\n            where\n𝑏\n            is the branching factor and\n𝑑\n            the search depth.\n\n\n▷Except in trivial games (Tic-Tac-Toe),\nminimax\n            needs a depth limit and apply an\nevaluation function\n            to estimate the value of the cut-off states.\n\n\n▷Alpha-beta search remembers the best values achieved for each player elsewhere in the tree already, and\nprunes\n            out sub-trees that won’t be reached in the game.\n\n\n▷Monte Carlo tree search\n            (MCTS)\nsamples\n            game branches, and averages the findings.\nAlphaGo\n            controls this using\nneural networks:\nevaluation function\n            (“value network”), and action filter (“policy network”).\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-15\n",
        "sectionId": "b592c3c7",
        "archive": "courses/FAU/AI/course",
        "filepath": "game-play/slides/game-play-summary.en.xhtml"
    },
    {
        "slideContent": "\nA (Constraint Satisfaction) Problem\n\n▷Tournament Schedule\n                  Who’s going to play against who, when and where?\n\n\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "ed56a51",
        "archive": "courses/FAU/AI/course",
        "filepath": "csp/slides/bundesliga-ex.en.xhtml"
    },
    {
        "slideContent": "\nConstraint Satisfaction Problems (CSPs)\n\n▷Standard\nsearch problem:\nstate\n              is a “black box” any old\ndata structure\n              that supports\ngoal test, eval,\nsuccessor state, ...\n\n▷Constraint&#160;Satisfaction&#160;Problem\n\n\n▷\n                  A\nCSP\n𝛾\n                  is called\nsatisfiable,\niff\n                  it has a\nsolution: a\ntotal\nvariable assignment\n𝜑\n                  that satisfies all\nconstraints.\n\n\n▷Constraint&#160;Solving\n\n\n▷We are using\nfactored\n                  representation for world states now!\n\n\n▷\n                  Allows useful\ngeneral-purpose\nalgorithms\n                  with more power than standard\ntree search algorithm.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "ed56a51",
        "archive": "courses/FAU/AI/course",
        "filepath": "csp/slides/csp-intro.en.xhtml"
    },
    {
        "slideContent": "\nAnother Constraint Satisfaction Problem\n\n▷SuDoKu\n                  Fill the cells with row/column/block-unique digits\n\n\n⤳\n\n\n\n▷Variables: The 81 cells.\n\n\n▷Domains: Numbers\n1,...,9.\n\n\n▷Constraints: Each number only once in each row, column, block.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-15\n",
        "sectionId": "ed56a51",
        "archive": "courses/FAU/AI/course",
        "filepath": "csp/slides/sudoku-ex.en.xhtml"
    },
    {
        "slideContent": "\nCSP Example: Map-Coloring\n\n▷\n                  Given a map\n𝑀, the\nmap coloring\n                  problem is to assign colors to regions in a map so that no adjoining regions have the same color.\n\n\n▷Map coloring in Australia\n\n\n\n\n\n\n\n\n\n\n▷Variables:\nWA,\nNT,\nQ,\nNSW,\nV,\nSA,\nT\n\n\n▷Domains:\n𝐷𝑖={red,green,blue}\n\n\n▷Constraints: adjacent regions must have different colors e.g.,\nWA≠NT\n                                          (if the language allows this), or\n〈WA,NT〉∊{〈red,green〉,〈red,blue〉,〈green,red〉,...}\n\n\n\n\n \n\n\n\n\n\n\n▷Intuition:\nsolutions\n                                    map\nvariables\n                                    to\ndomain\nvalues\n                                    satisfying all\nconstraints,\n\n\n▷e.g.,\n{WA=red,NT=green,...}\n\n\n\n\n \n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "ed56a51",
        "archive": "courses/FAU/AI/course",
        "filepath": "csp/slides/map-coloring-ex.en.xhtml"
    },
    {
        "slideContent": "\nBundesliga Constraints\n\n▷Variables:\n𝑣𝐴vs.𝐵\n              where\n𝐴\n              and\n𝐵\n              are teams, with\ndomains\n{1,...,34}: For each match, the index of the weekend where it is scheduled.\n\n\n▷(Some)\nconstraints:\n\n\n\n\n\n\n▷If\n{𝐴,𝐵}∩{𝐶,𝐷}≠∅:\n𝑣𝐴vs.𝐵≠𝑣𝐶vs.𝐷\n                                (each team only one match per day).\n\n\n▷If\n{𝐴,𝐵}={𝐶,𝐷}:\n𝑣𝐴vs.𝐵≤17<𝑣𝐶vs.𝐷\n                                or\n𝑣𝐶vs.𝐷≤17<𝑣𝐴vs.𝐵\n                                (each pairing exactly once in each half-season).\n\n\n▷If\n𝐴=𝐶:\n𝑣𝐴vs.𝐵+1≠𝑣𝐶vs.𝐷\n                                (each team alternates between home matches and away matches).\n\n\n▷Leading teams of last season meet near the end of each half-season.\n\n\n▷...\n\n\n\n \n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "ed56a51",
        "archive": "courses/FAU/AI/course",
        "filepath": "csp/slides/bundesliga-constraints.en.xhtml"
    },
    {
        "slideContent": "\nHow to Solve the Bundesliga Constraints?\n\n▷306\n              nested for-loops (for each of the\n306\n              matches), each ranging from\n1\n              to\n306. Within the innermost loop, test whether the current values are (a) a permutation and, if so, (b) a legal Bundesliga schedule.\n\n\n▷Estimated\nrunning time: End of this universe, and the next couple billion ones after it ...\n\n▷Directly enumerate all\npermutations\n              of the numbers\n1,...,306, test for each whether it’s a legal Bundesliga schedule.\n\n\n▷Estimated\nrunning time: Maybe only the time span of a few thousand universes.\n\n\n▷View this as\nvariables/constraints\n              and use\nbacktracking(this chapter)\n\n\n▷Executed\nrunning time: About 1 minute.\n\n\nHow do they actually do it?\n                  Modern\ncomputers\n                  and\nCSP\n                  methods: fractions of a second. 19th (20th/21st?) century: Combinatorics and manual work.\n\n\n▷\n\n▷Try it yourself\n                  with an off-the shelf\nCSP\n                  solver, e.g. Minion [Min]\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-16\n",
        "sectionId": "ed56a51",
        "archive": "courses/FAU/AI/course",
        "filepath": "csp/slides/bundesliga-solving.en.xhtml"
    },
    {
        "slideContent": "\nMore Constraint Satisfaction Problems\n\n\nTraveling Tournament Problem\n\n\n\nScheduling\n\n\n\nTimetabling\n\n\n\nRadio Frequency Assignment\n\n\n\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "ed56a51",
        "archive": "courses/FAU/AI/course",
        "filepath": "csp/slides/csp-applications.en.xhtml"
    },
    {
        "slideContent": "\nOur Agenda for This Topic\n\n▷Our treatment of the topic “Constraint Satisfaction Problems” consists of Chapters 7 and 8. in [RN03]\n\n\n▷This Chapter: Basic definitions and concepts; naïve\nbacktracking search.\n\n\n▷Sets up the framework.\nBacktracking\n            underlies many successful\nalgorithms\n            for solving\nconstraint satisfaction problems\n            (and, naturally, we start with the simplest version thereof).\n\n\n▷Next Chapter:\nConstraint propagation\n            and\ndecomposition\n            methods.\n\n\n▷Constraint propagation\n            reduces the\nsearch space\n            of\nbacktracking.\nDecomposition\n            methods break the problem into smaller pieces. Both are crucial for\nefficiency\n            in practice.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-15\n",
        "sectionId": "ed56a51",
        "archive": "courses/FAU/AI/course",
        "filepath": "csp/slides/csp-agenda.en.xhtml"
    },
    {
        "slideContent": "\nOur Agenda for This Chapter\n\n▷How are\nconstraint networks, and\nassignments,\nconsistency,\nsolutions: How are\nconstraint satisfaction problems\n            defined? What is a\nsolution?\n\n\n▷Get ourselves on firm ground.\n\n\n▷Naïve Backtracking: How does backtracking work? What are its main weaknesses?\n\n\n▷Serves to understand the basic workings of this wide-spread\nalgorithm, and to motivate its enhancements.\n\n\n▷Variable- and Value Ordering: How should we guide\nbacktracking searchs?\n\n\n▷Simple methods for making\nbacktracking\n            aware of the structure of the problem, and thereby reduce search.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 122024-12-15\n",
        "sectionId": "ed56a51",
        "archive": "courses/FAU/AI/course",
        "filepath": "csp/slides/csp-agenda.en.xhtml"
    },
    {
        "slideContent": "\nThe Waltz Algorithm\n\n▷Remark\n                  One of the earliest examples of applied\nCSPs.\n\n\n▷Motivation\n                  Interpret line drawings of\npolyhedra.\n\n\n\n\n▷Problem\n                  Are intersections\nconvex\n                  or concave?\n(interpret\n=^\n                      label as such)\n\n\n▷Idea\n                  Adjacent intersections impose\nconstraints\n                  on each other. Use\nCSP\n                  to find a unique set of labelings.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "51ec80b",
        "archive": "courses/FAU/AI/course",
        "filepath": "csp/slides/waltz-problem.en.xhtml"
    },
    {
        "slideContent": "\nWaltz Algorithm on Simple Scenes\n\n▷Assumptions\n                  All objects\n\n\n▷have no shadows or cracks,\n\n\n▷have only three-faced vertices,\n\n\n▷are in “general position”, i.e. no junctions change with small movements of the eye.\n\n\n▷\n                  Then each line on the\nimages\n                  is one of the following:\n\n\n▷a boundary line (edge of an object) (<) with right hand of arrow denoting “solid” and left hand denoting “space”\n\n\n▷an interior convex edge\n(label with “+”)\n\n\n▷an interior concave edge\n(label with “-”)\n\n\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "51ec80b",
        "archive": "courses/FAU/AI/course",
        "filepath": "csp/slides/waltz-csp.en.xhtml"
    },
    {
        "slideContent": "\n18 Legal Kinds of Junctions\n\n▷\n                  There are only 18 “legal” kinds of junctions:\n\n\n\n\n▷Idea\n                  given a representation of a diagram\n\n\n▷label each junction in one of these manners(lots of possible ways)\n\n\n▷junctions must be labeled, so that lines are labeled consistently\n\n\n▷Fun Fact\nCSP\n                  always works perfectly!(early success story for\nCSP\n                      [Wal75])\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 122024-12-14\n",
        "sectionId": "51ec80b",
        "archive": "courses/FAU/AI/course",
        "filepath": "csp/slides/waltz-csp.en.xhtml"
    },
    {
        "slideContent": "\nWaltz’s Examples\n\n▷In his dissertation 1972 [Wal75] David Waltz used the following examples\n\n\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "51ec80b",
        "archive": "courses/FAU/AI/course",
        "filepath": "csp/slides/waltz-ex.en.xhtml"
    },
    {
        "slideContent": "\nWaltz Algorithm (More Examples):\nAmbiguous\n            Figures\n\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-15\n",
        "sectionId": "51ec80b",
        "archive": "courses/FAU/AI/course",
        "filepath": "csp/slides/waltz-ex-ambiguous.en.xhtml"
    },
    {
        "slideContent": "\nWaltz Algorithm (More Examples): Impossible Figures\n\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "51ec80b",
        "archive": "courses/FAU/AI/course",
        "filepath": "csp/slides/waltz-ex-impossible.en.xhtml"
    },
    {
        "slideContent": "\nTypes of\nCSPs\n\n▷\n                  We call a\nCSP\ndiscrete, iff all of the\nvariables\n                  have\ncountable\ndomains; we have two kinds:\n\n\n▷finite\ndomains\n(size\n𝑑\n⤳\n𝒪(𝑑𝑛)\nsolutions)\n\n\n▷e.g., Boolean\nCSPs\n(solvability\n=^\n                      Boolean satisfiability\n⤳\nNP complete)\n\n\n▷infinite\ndomains\n                  (e.g. integers, strings, etc.)\n\n\n▷e.g., job scheduling,\nvariables\n                  are start/end days for each job\n\n\n▷need a “constraint language”, e.g.,\n𝑆𝑡𝑎𝑟𝑡𝐽𝑜𝑏1+5≤𝑆𝑡𝑎𝑟𝑡𝐽𝑜𝑏3\n\n\n▷linear\nconstraints\ndecidable, nonlinear ones\nundecidable\n\n\n▷\n                  We call a\nCSP\ncontinuous, iff one\ndomain\n                  is\nuncountable.\n\n\n▷\n                  Start/end times for Hubble Telescope observations form a\ncontinuous\nCSP.\n\n\n▷Linear\nconstraints\n                  solvable in poly time by\nlinear programming\n                  methods.\n\n\n▷\n                  There cannot be optimal\nalgorithms\n                  for nonlinear constraint systems.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "ca4e7a64",
        "archive": "courses/FAU/AI/course",
        "filepath": "csp/slides/csp-types.en.xhtml"
    },
    {
        "slideContent": "\nTypes of Constraints\n\n▷We classify the\nconstraints\n              by the number of\nvariables\n              they involve.\n\n\n▷\nUnary\nconstraints\n                  involve a single\nvariable,\ne.g.,\nSA≠𝑔𝑟𝑒𝑒𝑛.\n\n\n▷\nBinary\nconstraints\n                  involve pairs of\nvariables,\ne.g.,\nSA≠WA.\n\n\n▷\nHigher-order\nconstraints\n                  involve\n𝑛=3\n                  or more\nvariables,\ne.g., cryptarithmetic column\nconstraints.\n\nThe number\n𝑛\n                  of\nvariables\n                  is called the\norder\n                  of the\nconstraint.\n\n\n▷\nPreferences\n                  (soft constraint)(e.g.,\nred\n                        is better than\ngreen)are often representable by a cost for each\nvariable assignment\n⤳\nconstrained optimization problems.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "ca4e7a64",
        "archive": "courses/FAU/AI/course",
        "filepath": "csp/slides/constraints-types.en.xhtml"
    },
    {
        "slideContent": "\nNon-Binary Constraints, e.g. “Send More Money”\n\n▷Send More MoneyA student writes home:\n\n\n\n𝑆𝐸𝑁𝐷+𝑀𝑂𝑅𝐸𝑀𝑂𝑁𝐸𝑌\n\n\nPuzzle: letters stand for digits, addition should work out(parents send MONEY€)\n\n\n\n\n \n\n▷Variables:\n𝑆,𝐸,𝑁,𝐷,𝑀,𝑂,𝑅,𝑌, each with\ndomain\n{0,...,9}.\n\n\n▷Constraints:\n\n\n1.all\nvariables\n                  should have different values:\n𝑆≠𝐸,\n𝑆≠𝑁, ...\n\n2.first digits are non-zero:\n𝑆≠0,\n𝑀≠0.\n\n\n3.the addition scheme should work out: i.e.1000·𝑆+100·𝐸+10·𝑁+𝐷+1000·𝑀+100·𝑂+10·𝑅+𝐸=10000·𝑀+1000·0+100·𝑁+10·𝐸+𝑌.\n\n\nBTW: The solution is\n𝑆↦9,𝐸↦5,𝑁↦6,𝐷↦7,𝑀↦1,𝑂↦0,𝑅↦8,𝑌↦2\n⤳\n                  parents send\n10652\n€\n\n\n\n▷\n                  Problems like the one in\n??\n                  are called\ncrypto-arithmetic puzzles.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "ca4e7a64",
        "archive": "courses/FAU/AI/course",
        "filepath": "csp/slides/encode-hypergraph.en.xhtml"
    },
    {
        "slideContent": "\nEncoding Higher-Order Constraints as Binary ones\n\n▷Problem\n                  The last\nconstraint\n                  is of\norder\n                  8.(𝑛=8\nvariables\n                      involved)\n\n\n▷\n                  We can write the addition scheme\nconstraint\n                  column wise using\nauxiliary variables, i.e.\nvariables\n                      that do not “occur” in the original problem.\n\n\n\n𝐷+𝐸=𝑌+10·𝑋1\n\n𝑋1+𝑁+𝑅=𝐸+10·𝑋2\n\n𝑋2+𝐸+𝑂=𝑁+10·𝑋3\n\n𝑋3+𝑆+𝑀=𝑂+10·𝑀\n\n\n\n\n\n𝑆𝐸𝑁𝐷+𝑀𝑂𝑅𝐸𝑀𝑂𝑁𝐸𝑌\n\n\n\n\nThese\nconstraints\n                  are of\norder\n≤5.\n\n\n▷General RecipeFor\n𝑛≥3, encode\n𝐶(𝑣1,...,𝑣𝑛−1,𝑣𝑛)\n                  as\n𝐶(𝑝1(𝑥),...,𝑝𝑛−1(𝑥),𝑣𝑛)∧𝑣1=𝑝1(𝑥)∧...∧𝑣𝑛−1=𝑝𝑛−1(𝑥)\n\n▷Problem\n                  The problem structure gets hidden.(search\nalgorithms\n                      can get confused)\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 122024-12-14\n",
        "sectionId": "ca4e7a64",
        "archive": "courses/FAU/AI/course",
        "filepath": "csp/slides/encode-hypergraph.en.xhtml"
    },
    {
        "slideContent": "\nConstraint Graph\n\n▷\n                  A\nbinary CSP\n                  is a\nCSP\n                  where each\nconstraint\n                  is\nunary\n                  or\nbinary.\n\n\n▷\n                  A\nbinary CSP\n                  forms\na\ngraph\n                      called the\nconstraint graph\n                  whose\nnodes\n                  are\nvariables, and whose\nedges\n                  represent the\nconstraints.\n\n\n▷\n                  Australia as a\nbinary CSP\n\n\n\n\n\n▷Intuition\n                  General-purpose\nCSP\nalgorithms\n                  use the\ngraph\n                  structure to speed up search.(E.g., Tasmania is an independent subproblem!)\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "ca4e7a64",
        "archive": "courses/FAU/AI/course",
        "filepath": "csp/slides/constraint-graph.en.xhtml"
    },
    {
        "slideContent": "\nReal-world\nCSPs\n\n▷Assignment problems\n                  e.g., who teaches what class\n\n\n▷Timetabling problems\n                  e.g., which class is offered when and where?\n\n\n▷Hardware configuration\n\n\n▷Spreadsheets\n\n\n▷Transportation scheduling\n\n\n▷Factory scheduling\n\n\n▷Floorplanning\n\n\n▷Note\n                  many real-world problems involve real-valued\nvariables\n⤳\ncontinuous\nCSPs.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-16\n",
        "sectionId": "ca4e7a64",
        "archive": "courses/FAU/AI/course",
        "filepath": "csp/slides/real-world-csps.en.xhtml"
    },
    {
        "slideContent": "\nConstraint Networks (Formalizing binary CSPs)\n\n▷\n\n\n▷We will talk of\nCSPs\n                  and mean\nconstraint networks.\n\n\n▷RemarksThe\nmathematical\n                  formulation gives us a lot of leverage:\n\n\n▷𝐶𝑢𝑣⊆𝐷𝑢×𝐷𝑣\n=^\n                  possible assignments to\nvariables\n𝑢\n                  and\n𝑣\n\n\n▷Relations\n                  are the most general formalization, generally we use\nsymbolic\n                  formulations,\ne.g. “𝑢=𝑣” for the\nrelation\n𝐶𝑢𝑣={(𝑎,𝑏)|𝑎=𝑏}\n                      or “𝑢≠𝑣”.\n\n\n▷We can express\nunary constraints\n𝐶𝑢\n                  by restricting the\ndomain\n                  of\n𝑣:\n𝐷𝑣:=𝐶𝑣.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "96cced6b",
        "archive": "courses/FAU/AI/course",
        "filepath": "csp/slides/csnet-formal.en.xhtml"
    },
    {
        "slideContent": "\nExample: SuDoKu as a Constraint Network\n\n▷Formalize SuDoKu\n                  We use the added formality to encode SuDoKu as a\nconstraint network, not just as a\nCSP\n                  as\n??.\n\n\n\n\n▷Variables:\n𝑉={𝑣𝑖𝑗|1≤𝑖,𝑗≤9}:\n𝑣𝑖𝑗=cell in row\n𝑖\n                  column\n𝑗.\n\n\n▷Domains\n                  For all\n𝑣∊𝑉:\n𝐷𝑣=𝐷={1,...,9}.\n\n\n▷Unary constraint:\n𝐶𝑣𝑖𝑗={𝑑}\n                  if cell\n𝑖,𝑗\n                  is pre-filled with\n𝑑.\n\n\n▷(Binary)\nconstraint:\n𝐶𝑣𝑖𝑗𝑣𝑖'𝑗'\n=^\n                  “𝑣𝑖𝑗≠𝑣𝑖'𝑗'”, i.e.𝐶𝑣𝑖𝑗𝑣𝑖'𝑗'={(𝑑,𝑑')∊𝐷×𝐷|𝑑≠𝑑'}, for:\n𝑖=𝑖'\n                  (same row), or\n𝑗=𝑗'\n                  (same column), or\n(⌈𝑖3⌉,⌈𝑗3⌉)=(⌈𝑖'3⌉,⌈𝑗'3⌉)\n                  (same block).\n\n\nNote that the ideas are still the same as\n??, but in\nconstraint networks\n                  we have a language to formulate things precisely.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "96cced6b",
        "archive": "courses/FAU/AI/course",
        "filepath": "csp/slides/csnet-sudoku.en.xhtml"
    },
    {
        "slideContent": "\nConstraint Networks (Solutions)\n\n▷Let\n𝛾:=〈𝑉,𝐷,𝐶〉\n              be a\nconstraint network.\n\n\n▷\n                  We call a\npartial function\n𝑎:𝑉⇀⋃𝑢∊𝑉𝐷𝑢\n                  a\nvariable assignment\n                  if\n𝑎(𝑢)∊𝐷𝑢\n                  for all\n𝑢∊𝐝𝐨𝐦(𝑎).\n\n\n▷\n\n\n▷\n                  The\nempty assignment\n𝜖\n                  is (trivially)\nconsistent\n                  in any\nconstraint network.\n\n\n▷\n                  Let\n𝑓\n                  and\n𝑔\n                  be\nvariable assignments, then we say that\n𝑓\nextends\n                  (or is an\nextension of)\n𝑔, iff\n𝐝𝐨𝐦(𝑔)⊂𝐝𝐨𝐦(𝑓)\n                  and\n𝑓|𝐝𝐨𝐦(𝑔)=𝑔.\n\n\n▷\n                  We call a\nconsistent\n                  (total)\nassignment\n                  a\nsolution\n                  for\n𝛾\n                  and\n𝛾\n                  itself\nsolvable\n                  or\nsatisfiable.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "96cced6b",
        "archive": "courses/FAU/AI/course",
        "filepath": "csp/slides/csnet-solutions.en.xhtml"
    },
    {
        "slideContent": "\nHow it all fits together\n\n▷\nHigher-order\nconstraints\n                  can be transformed into equi-satisfiable\nbinary\nconstraints\n                  using auxiliary\nvariables.\n\n\n▷\n                  Any\nCSP\n                  can be represented by a\nconstraint network.\n\n\n▷In other words\n                  The notion of a\nconstraint network\n                  is a refinement of a\nCSP.\n\n\n▷So we will stick to\nconstraint networks\n              in this\ncourse.\n\n\n▷\n                  We can view a\nconstraint network\n                  as a\nsearch problem, if we take the\nstates\n                  as the\nvariable assignments, the\nactions\n                  as\nassignment extensions, and the\ngoal states\n                  as\nconsistent\nassignments.\n\n\n▷Idea\n                  We will explore that idea for\nalgorithms\n                  that\nsolve\nconstraint networks.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "96cced6b",
        "archive": "courses/FAU/AI/course",
        "filepath": "csp/slides/csp-views.en.xhtml"
    },
    {
        "slideContent": "\nStandard search formulation (incremental)\n\n▷Idea\n                  Every\nconstraint network\n                  induces a\nsingle state problem.\n\n\n▷Let’s do the math\n                  Given a\nconstraint network\n𝛾:=〈𝑉,𝐷,𝐶〉, then\nΠ𝛾:=〈𝒮𝛾,𝒜𝛾,𝒯𝛾,ℐ𝛾,𝒢𝛾〉\n                  is called the\nsearch problem induced\n                  by\n𝛾, iff\n\n\n▷States\nΠ𝛾.𝒮𝛾\n                  are\nvariable assignments\n\n\n▷Actions\nΠ𝛾.𝒜𝛾:\nextend\n𝜑∊Π𝛾.𝒮𝛾\n                  by a\npair\n𝑥↦𝑣\n                  not\nconflicted\n                  with\n𝜑.\n\n\n▷Transition model\nΠ𝛾.𝒯𝛾(𝑎,𝜑)=𝜑,𝑥↦𝑣(extended\nassignment)\n\n\n▷Initial state\nΠ𝛾.ℐ𝛾: the\nempty assignment\n𝜖.\n\n\n▷Goal states\nΠ𝛾.𝒢𝛾: the\ntotal\nassignments\n\n\n▷What has just happened?\n                  We interpret a\nconstraint network\n𝛾\n                  as a\nsearch problem\nΠ𝛾. A\nsolution\n                  to\nΠ𝛾\n                  induces a\nsolution\n                  to\n𝛾.\n\n\n▷Idea\n                  We have\nalgorithms\n                  for that: e.g.\ntree search.\n\n\n▷Remark\n                  This is the same for all\nCSPs!\n🙂⤳\n                  fail if no\nconsistent\nassignments\n                  exist\n(not fixable!)\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "ad6ad297",
        "archive": "courses/FAU/AI/course",
        "filepath": "csp/slides/csnet-search.en.xhtml"
    },
    {
        "slideContent": "\nStandard search formulation (incremental)\n\n▷\n                  A\nsearch tree\n                  for\nΠ𝐴𝑢𝑠𝑡𝑟𝑎𝑙𝑖𝑎:\n\n\n\n\n\n\n\n  \n\n𝑊𝐴=𝑟𝑒𝑑  \n\n𝑊𝐴=𝑔𝑟𝑒𝑒𝑛  \n\n𝑊𝐴=𝑏𝑙𝑢𝑒  \n\n\n\n\n𝑊𝐴=𝑟𝑒𝑑𝑁𝑇=𝑔𝑟𝑒𝑒𝑛  \n\n𝑊𝐴=𝑟𝑒𝑑𝑁𝑇=𝑏𝑙𝑢𝑒  \n\n\n\n𝑊𝐴=𝑟𝑒𝑑𝑁𝑇=𝑔𝑟𝑒𝑒𝑛𝑄=𝑟𝑒𝑑  \n\n𝑊𝐴=𝑟𝑒𝑑𝑁𝑇=𝑔𝑟𝑒𝑒𝑛𝑄=𝑏𝑙𝑢𝑒  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n▷Observation\n                  Every\nsolution\n                  appears at\ndepth\n𝑛\n                  with\n𝑛\nvariables.\n\n\n▷Idea\n                  Use\ndepth first search!\n\n\n▷Observation\nPath\n                  is irrelevant\n⤳\n                  can use\nlocal search algorithms.\n\n\n▷Branching factor\n𝑏=(𝑛−ℓ)𝑑\n              at\ndepth\nℓ, hence\n𝑛!𝑑𝑛\nleaves!!!!\n🙁\n\n\nMichael Kohlhase:\nArtificial Intelligence 122024-12-14\n",
        "sectionId": "ad6ad297",
        "archive": "courses/FAU/AI/course",
        "filepath": "csp/slides/csnet-search.en.xhtml"
    },
    {
        "slideContent": "\nBacktracking Search\n\n▷\nAssignments\n                  for different\nvariables\n                  are independent!\n\n\n▷e.g. first\nWA=red\n                      then\nNT=greenvs.\nfirst\nNT=green\n                      then\nWA=red\n\n\n▷⤳\n                  we only need to consider\nassignments\n                  to a single\nvariable\n                  at each\nnode\n\n\n▷⤳\n𝑏=𝑑\n                  and there are\n𝑑𝑛\nleaves.\n\n\n▷\nDepth first search\n                  for\nCSPs\n                  with single-variable\nassignment\nextensions\nactions\n                  is called\nbacktracking search.\n\n\n▷\nBacktracking search\n                  is the basic\nuninformed\nalgorithm\n                  for\nCSPs.\n\n\n▷\n                  It can solve the\n𝑛-queens problem\n                  for\n≊𝑛,25.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "ad6ad297",
        "archive": "courses/FAU/AI/course",
        "filepath": "csp/slides/backtracking-search.en.xhtml"
    },
    {
        "slideContent": "\nBacktracking Search (Implementation)\n\n▷\n                  The generic\nbacktracking search\nalgorithm:\n\n\nprocedure Backtracking―Search(csp ) returns solution/failure\nreturn Recursive―Backtracking (∅, csp)\n\nprocedure Recursive―Backtracking (assignment) returns soln/failure\nif assignment is complete then return assignment\nvar := Select―Unassigned―Variable(Variables[csp], assignment, csp)\nforeach value in Order―Domain―Values(var, assignment, csp) do\nif value is consistent with assignment given Constraints[csp] then\nadd {var = value} to assignment\nresult := Recursive―Backtracking(assignment,csp)\nif result ≠ failure then return result\nremove {var= value} from assignment\nreturn failure\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-15\n",
        "sectionId": "ad6ad297",
        "archive": "courses/FAU/AI/course",
        "filepath": "csp/slides/backtracking-search-algo.en.xhtml"
    },
    {
        "slideContent": "\nBacktracking in Australia\n\n▷\n                  We apply\nbacktracking search\n                  for a\nmap coloring\n                  problem:\n\nStep 1:\n\n\nStep 2:\n\n\nStep 3:\n\n\nStep 4:\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "ad6ad297",
        "archive": "courses/FAU/AI/course",
        "filepath": "csp/slides/backtracking-australia.en.xhtml"
    },
    {
        "slideContent": "\nImproving Backtracking Efficiency\n\n▷General-purpose methods can give huge gains in speed for\nbacktracking search.\n\n\n▷Answering the following questions well helps find powerful\nheuristics:\n\n\n1.Which\nvariable\n                  should be\nassigned\n                  next?\n(i.e. a\nvariable ordering\nheuristic)\n\n\n2.In what order should its\nvalues\n                  be tried?(i.e. a\nvalue ordering\nheuristic)\n\n\n3.Can we detect inevitable failure early?\n(for\npruning\n                  strategies)\n\n\n4.Can we take advantage of problem structure?\n(⤳\ninference)\n\n\nObservation\n                  Questions 1/2 correspond to the missing subroutinesSelect―Unassigned―Variable\n                  and\nOrder―Domain―Values\n                  from\n??.\n\n\n▷\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "ad6ad297",
        "archive": "courses/FAU/AI/course",
        "filepath": "csp/slides/backtracking-efficiency.en.xhtml"
    },
    {
        "slideContent": "\nHeuristic: Minimum Remaining Values (Which Variable)\n\n▷\n                  The\nminimum remaining values\n                  (MRV)\nheuristic\n                  for\nbacktracking search\n                  always chooses the\nvariable\n                  with the fewest\nlegal\n                  values, i.e. a\nvariable\n𝑣\n                  that given an initial\nassignment\n𝑎\nminimizes\n#({𝑑∊𝐷𝑣|\n𝑎∪{𝑣↦𝑑} is consistent\n}).\n\n\n▷Intuition\n                  By choosing a most constrained\nvariable\n𝑣\n                  first, we reduce the\nbranching factor\n                  (number of sub trees generated for\n𝑣) and thus reduce the\nsize\n                  of our search tree.\n\n\n▷Extreme case\n                  If\n#({𝑑∊𝐷𝑣|\n𝑎∪{𝑣↦𝑑} is consistent\n})=1, then the value assignment to\n𝑣\n                  is forced by our previous choices.\n\n\n▷In step 3 of\n??, there is only one remaining value for\nSA!\n\n\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "ad6ad297",
        "archive": "courses/FAU/AI/course",
        "filepath": "csp/slides/mrv.en.xhtml"
    },
    {
        "slideContent": "\nDegree Heuristic (Variable Order Tie Breaker)\n\n▷Problem\n                  Need a tie-breaker among\nMRV\nvariables!(there was no preference in step 1,2)\n\n\n▷\n                  The\ndegree heuristic\n                  in\nbacktracking search\n                  always chooses a\nmost constraining\nvariable, i.e. given an initial assignment\n𝑎\n                  always pick a variable\n𝑣\n                  with\n#({𝑣∊(𝑉\\𝐝𝐨𝐦(𝑎))|𝐶𝑢𝑣∊𝐶})\nmaximal.\n\n\n▷By choosing a\nmost constraining\nvariable\n              first, we detect\ninconsistencies\n              earlier on and thus reduce the\nsize\n              of our\nsearch tree.\n\n\n▷Commonly used strategy combination\n                  From the set of\nmost constrained variable, pick a\nmost constraining\nvariable.\n\n\n▷\n\n\n\nDegree heuristic:\nSA=5,\nT=0, all others 2 or 3.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-15\n",
        "sectionId": "ad6ad297",
        "archive": "courses/FAU/AI/course",
        "filepath": "csp/slides/degree-heuristic.en.xhtml"
    },
    {
        "slideContent": "\nLeast Constraining Value Heuristic (Value Ordering)\n\n▷\n                  Given a\nvariable\n𝑣, the\nleast constraining value heuristic\n                  chooses the\nleast constraining value\n                  for\n𝑣: the one that rules out the fewest\nvalues\n                  in the remaining\nvariables, i.e. for a given initial\nassignment\n𝑎\n                  and a chosen\nvariable\n𝑣\n                  pick a value\n𝑑∊𝐷𝑣\n                  that\nminimizes\n#({𝑒∊𝐷𝑢|\n𝑢∉𝐷𝑣, 𝐶𝑢𝑣∊𝐶, and (𝑒,𝑑)∉𝐶𝑢𝑣\n})\n\n\n▷By choosing the\nleast constraining value\n              first, we increase the chances to not rule out the\nsolutions\n              below the current node.\n\n\n▷\n\n\n\n\n▷\n                  Combining these\nheuristics\n                  makes\n1000 queens\n                  feasible.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "ad6ad297",
        "archive": "courses/FAU/AI/course",
        "filepath": "csp/slides/least-constraining-variable.en.xhtml"
    },
    {
        "slideContent": "\nSummary & Preview\n\n▷Summary of “CSP\n            as Search”:\n\n\n▷Constraint networks\n𝛾\n            consist of\nvariables, associated with\nfinite\ndomains, and\nconstraints\n            which are binary\nrelations\n            specifying permissible\nvalue\npairs.\n\n\n▷A\nvariable assignment\n𝑎\n            maps some\nvariables\n            to\nvalues.\n𝑎\n            is\nconsistent\n            if it complies with all\nconstraints. A\nconsistent\ntotal\nassignment\n            is a\nsolution.\n\n\n▷The\nconstraint satisfaction problem\n            (CSP) consists in finding a\nsolution\n            for a\nconstraint network. This has numerous applications including, e.g., scheduling and timetabling.\n\n\n▷Backtracking search\nassigns\nvariable\n            one by one,\npruning\ninconsistent\nvariable assignments.\n\n\n▷Variable orderings\n            in\nbacktracking\n            can dramatically reduce the\nsize\n            of the\nsearch tree.\nValue orderings\n            have this potential (only) in\nsolvable\n            sub trees.\n\n\nUp nextInference\n                and\ndecomposition, for improved\nefficiency.\n\n\n▷\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-15\n",
        "sectionId": "18bc2164",
        "archive": "courses/FAU/AI/course",
        "filepath": "csp/slides/csp-summary.en.xhtml"
    },
    {
        "slideContent": "\nIllustration: Constraint Propagation\n\n▷\n                  A\nconstraint network\n𝛾:\n\n\n\n\n▷Question\n                  Can we add a\nconstraint\n                  without losing any\nsolutions?\n\n\n▷\n𝐶WAQ:=\n                  “=”. If\nWA\n                  and\nQ\n                  are\nassigned\n                  different colors, then\nNT\n                  must be\nassigned\n                  the 3rd color, leaving no color for\nSA.\n\n\n▷Intuition\n                  Adding\nconstraints\n                  without losing\nsolutions=^\n                  obtaining an\nequivalent\nnetwork\n                  with a “tighter\n                  description”⤳\n                  a smaller number of\nconsistent\n                  (partial)\nvariable assignments⤳\n                  more\nefficient\n                  search!\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "ebdf6354",
        "archive": "courses/FAU/AI/course",
        "filepath": "csp/slides/csnet-inference-intro.en.xhtml"
    },
    {
        "slideContent": "\nIllustration: Decomposition\n\n▷\nConstraint network\n𝛾:\n\n\n\n\n▷We can separate this into two independent\nconstraint networks.\n\n\n▷Tasmania is not adjacent to any other state. Thus we can color Australia first, and assign an arbitrary color to Tasmania afterwards.\n\n\n▷Decomposition methods exploit the structure of the\nconstraint network. They identify separate parts (sub-networks) whose inter-dependencies are “simple” and can be handled\nefficiently.\n\n\n▷Extreme case\n                  No inter-dependencies at all, as for Tasmania above.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 122024-12-14\n",
        "sectionId": "ebdf6354",
        "archive": "courses/FAU/AI/course",
        "filepath": "csp/slides/csnet-inference-intro.en.xhtml"
    },
    {
        "slideContent": "\nOur Agenda for This Chapter\n\n▷Constraint propagation: How does\ninference\n            work in principle? What are relevant practical aspects?\n\n\n▷Fundamental concepts underlying\ninference, basic facts about its use.\n\n\n▷Forward checking: What is the simplest instance of\ninference?\n\n\n▷Gets us started on this subject.\n\n\n▷Arc consistency: How to make\ninferences\n            between\nvariables\n            whose value is not fixed yet?\n\n\n▷Details a\nstate of the art\ninference\n            method.\n\n\n▷Decomposition:\nConstraint graphs, and two simple cases\n\n\n▷How to capture dependencies in a constraint network? What are “simple cases”?\n\n\n▷Basic results on this subject.\n\n\n▷Cutset conditioning: What if we’re not in a simple case?\n\n\n▷Outlines the most easily understandable technique for\ndecomposition\n            in the general case.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-15\n",
        "sectionId": "ebdf6354",
        "archive": "courses/FAU/AI/course",
        "filepath": "csp/slides/csprop-agenda.en.xhtml"
    },
    {
        "slideContent": "\nConstraint Propagation/Inference: Basic Facts\n\n▷\nConstraint propagation\n                  (i.e\ninference\n                  in\nconstraint networks) consists in deducing additional\nconstraints, that\nfollow\n                  from the already known\nconstraints, i.e. that are\nsatisfied\n                  in all\nsolutions.\n\n\n▷\n                  It’s what you do all the time when playing SuDoKu:\n\n\n\n\n▷Formally\n                  Replace\n𝛾\n                  by an\nequivalent\n                  and\nstrictly tighter\nconstraint network\n𝛾'.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "15962b21",
        "archive": "courses/FAU/AI/course",
        "filepath": "csp/slides/csnet-inference.en.xhtml"
    },
    {
        "slideContent": "\nEquivalent Constraint Networks\n\n▷\n                  We say that two\nconstraint networks\n𝛾:=〈𝑉,𝐷,𝐶〉\n                  and\n𝛾':=〈𝑉,𝐷',𝐶'〉\n                  sharing the same set of\nvariables\n                  are\nequivalent, (write\n𝛾'≡𝛾), if they have the same\nsolutions.\n\n\n▷\n\n\n  \n\n\n\n𝛾  \n\n\n\n\n   \n\n\n\n\n\n\n\n\n\nred\n\nblue\n\n  \n\n\n𝑣1  \n\n\n\n\n   \n\n\n\n\n\n\n\n\n\nred\n\nblue\n\n  \n\n\n𝑣2  \n\n\n\n\n   \n\n\n\n\n\n\n\n\n\nred\n\nblue\n\n  \n\n\n𝑣3  \n\n≠  \n\n≠  \n\n\n\n   \n\n\n\n𝛾'  \n\n\n\n\n   \n\n\n\n\n\n\n\n\n\nred\n\nblue\n\n  \n\n\n𝑣1  \n\n\n\n\n   \n\n\n\n\n\n\n\n\n\nred\n\nblue\n\n  \n\n\n𝑣2  \n\n\n\n\n   \n\n\n\n\n\n\n\n\n\nred\n\nblue\n\n  \n\n\n𝑣3  \n\n≠  \n\n≠  \n\n≠  \n\n\n\n  \n\n\nAre these\nconstraint networks\nequivalent? No.\n\n\n  \n\n\n\n𝛾  \n\n\n\n\n   \n\n\n\n\n\n\n\n\n\nred\n\nblue\n\n  \n\n\n𝑣1  \n\n\n\n\n   \n\n\n\n\n\n\n\n\n\nred\n\nblue\n\n  \n\n\n𝑣2  \n\n\n\n\n   \n\n\n\n\n\n\n\n\n\nred\n\nblue\n\n  \n\n\n𝑣3  \n\n≠  \n\n≠  \n\n\n\n   \n\n\n\n𝛾'  \n\n\n\n\n   \n\n\n\n\n\n\n\n\n\nred\n\nblue\n\n  \n\n\n𝑣1  \n\n\n\n\n   \n\n\n\n\n\n\n\n\n\nred\n\nblue\n\n  \n\n\n𝑣2  \n\n\n\n\n   \n\n\n\n\n\n\n\n\n\nred\n\nblue\n\n  \n\n\n𝑣3  \n\n≠  \n\n≠  \n\n=  \n\n\n\n  \n\n\nAre these\nconstraint networks\nequivalent? Yes.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "15962b21",
        "archive": "courses/FAU/AI/course",
        "filepath": "csp/slides/csnet-equivalent.en.xhtml"
    },
    {
        "slideContent": "\nTightness\n\n▷Tightness\n                  Let\n𝛾:=〈𝑉,𝐷,𝐶〉\n                  and\n𝛾'=〈𝑉,𝐷',𝐶'〉\n                  be\nconstraint networks\n                  sharing the same set of\nvariables, then\n𝛾'\n                  is\ntighter\n                  than\n𝛾, (write\n𝛾'⊑𝛾), if:\n\n\n(i)For all\n𝑣∊𝑉:\n𝐷'𝑣⊆𝐷𝑣.\n\n\n(ii)For all\n𝑢≠𝑣∊𝑉\n                  and\n𝐶'𝑢𝑣∊𝐶': either\n𝐶'𝑢𝑣∉𝐶\n                  or\n𝐶'𝑢𝑣⊆𝐶𝑢𝑣.\n\n\n𝛾'\n                  is\nstrictly tighter\n                  than\n𝛾, (written\n𝛾'⊏𝛾), if at least one of these\ninclusions\n                  is\nproper.\n\n\n▷\n\n\n  \n\n\n\n𝛾  \n\n\n\n\n   \n\n\n\n\n\n\n\n\n\nred\n\nblue\n\n  \n\n\n𝑣1  \n\n\n\n\n   \n\n\n\n\n\n\n\n\n\nred\n\nblue\n\n  \n\n\n𝑣2  \n\n\n\n\n   \n\n\n\n\n\n\n\n\n\nred\n\nblue\n\n  \n\n\n𝑣3  \n\n≠  \n\n≠  \n\n\n\n   \n\n\n\n𝛾'  \n\n\n\n\n   \n\n\n\n\n\n\n\n\n\nred\n\nblue\n\n  \n\n\n𝑣1  \n\n\n\n\n   \n\n\n\n\n\n\n\n\n\nred\n\nblue\n\n  \n\n\n𝑣2  \n\n\n\n\n   \n\n\n\n\n\n\n\n\n\nred\n\nblue\n\n  \n\n\n𝑣3  \n\n≠  \n\n≠  \n\n≠  \n\n\n\n  \n\nHere, we do have\n𝛾'⊑𝛾.\n\n\n  \n\n\n\n𝛾  \n\n\n\n\n   \n\n\n\n\n\n\n\n\n\nred\n\nblue\n\n  \n\n\n𝑣1  \n\n\n\n\n   \n\n\n\n\n\n\n\n\n\nred\n\nblue\n\n  \n\n\n𝑣2  \n\n\n\n\n   \n\n\n\n\n\n\n\n\n\nred\n\nblue\n\n  \n\n\n𝑣3  \n\n≠  \n\n≠  \n\n\n\n   \n\n\n\n𝛾'  \n\n\n\n\n   \n\n\n\n\n\n\n\n\n\nred\n\nblue\n\n  \n\n\n𝑣1  \n\n\n\n\n   \n\n\n\n\n\n\n\n\n\nred\n\nblue\n\n  \n\n\n𝑣2  \n\n\n\n\n   \n\n\n\n\n\n\n\n\n\nred\n\nblue\n\n  \n\n\n𝑣3  \n\n≠  \n\n≠  \n\n=  \n\n\n\n  \n\nHere, we do have\n𝛾'⊑𝛾.\n\n\n  \n\n\n\n𝛾  \n\n\n\n\n   \n\n\n\n\n\n\n\n\n\nred\n\nblue\n\n  \n\n\n𝑣1  \n\n\n\n\n   \n\n\n\n\n\n\n\n\n\nred\n\nblue\n\n  \n\n\n𝑣2  \n\n\n\n\n   \n\n\n\n\n\n\n\n\n\nred\n\nblue\n\n  \n\n\n𝑣3  \n\n≠  \n\n≠  \n\n\n\n   \n\n\n\n𝛾'  \n\n\n\n\n   \n\n\n\n\n\n\n\n\n\nred\n\nblue\n\n  \n\n\n𝑣1  \n\n\n\n\n   \n\n\n\n\n\n\n\n\n\nred\n\nblue\n\n  \n\n\n𝑣2  \n\n\n\n\n   \n\n\n\n\n\n\n\n\n\nred\n\nblue\n\n  \n\n\n𝑣3  \n\n≠  \n\n=  \n\n\n\n  \n\nHere, we do not have\n𝛾'⊑𝛾!.\n\n\n▷Intuition\nStrict tightness\n=^\n𝛾'\n                    has the same\nconstraints\n                    as\n𝛾, plus some.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "15962b21",
        "archive": "courses/FAU/AI/course",
        "filepath": "csp/slides/csnet-tightness.en.xhtml"
    },
    {
        "slideContent": "\nEquivalence + Tightness = Inference\n\n▷\n                Let\n𝛾\n                and\n𝛾'\n                be\nconstraint networks\n                such that\n𝛾'≡𝛾\n                and\n𝛾'⊑𝛾. Then\n𝛾'\n                has the same\nsolutions\n                as, but fewer\nconsistent\nassignments\n                than,\n𝛾.\n\n\n▷⤳\n𝛾'\n            is a better encoding of the underlying problem.\n\n\n▷\n                Two\nequivalent\nconstraint networks(one obviously unsolvable)\n\n\n  \n\n\n\n𝛾  \n\n\n\n\n   \n\n\n\n\n\n\n\n\n\nred\n\nblue\n\n  \n\n\n𝑣1  \n\n\n\n\n   \n\n\n\n\n\n\n\n\n\nred\n\n  \n\n\n𝑣2  \n\n\n\n\n   \n\n\n\n\n\n\n\n\n\nblue\n\n  \n\n\n𝑣3  \n\n≠  \n\n≠  \n\n\n\n   \n\n\n\n𝛾'  \n\n\n\n\n   \n\n\n\n\n\n\n\n\n\nred\n\nblue\n\n  \n\n\n𝑣1  \n\n\n\n\n   \n\n\n\n\n\n\n\n\n\nred\n\n  \n\n\n𝑣2  \n\n\n\n\n   \n\n\n\n\n\n\n\n\n\nblue\n\n  \n\n\n𝑣3  \n\n≠  \n\n≠  \n\n=  \n\n\n\n  \n\n\n𝜖\n                cannot be\nextended\n                to a\nsolution\n                (neither in\n𝛾\n                nor in\n𝛾'\n                because they’re\nequivalent); this is obvious (red\n≠\n                blue) in\n𝛾', but not in\n𝛾.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-15\n",
        "sectionId": "15962b21",
        "archive": "courses/FAU/AI/course",
        "filepath": "csp/slides/csnet-equiv-tight-inference.en.xhtml"
    },
    {
        "slideContent": "\nHow to Use Constraint Propagation in CSP Solvers?\n\n▷Simple\nConstraint propagation\n                as a pre-process:\n\n\n▷When: Just once before\nsearch\n                starts.\n\n\n▷Effect: Little\nrunning time\n                overhead, little\npruning\n                power.\n(not considered here)\n\n\n▷More Advanced\nConstraint propagation\n                during search:\n\n\n▷When: At every\nrecursive call\n                of\nbacktracking.\n\n\n▷Effect: Strong\npruning\n                power, may have large\nrunning time\n                overhead.\n\n\n▷Search vs. Inference\n                The more complex the\ninference, the\nsmaller\n                the number of\nsearch\nnodes, but the\nlarger\n                the\nrunning time\n                needed at each\nnode.\n\n\n▷Idea\n                Encode\nvariable assignments\n                as\nunary constraints\n                (i.e., for\n𝑎(𝑣)=𝑑, set the\nunary constraint\n𝐷𝑣={𝑑}), so that\ninference\n                reasons about\nthe network restricted to the commitments already made in the\nsearch.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-16\n",
        "sectionId": "15962b21",
        "archive": "courses/FAU/AI/course",
        "filepath": "csp/slides/csnet-inference-howto.en.xhtml"
    },
    {
        "slideContent": "\nBacktracking With\nInference\n\n▷\n                  The general\nalgorithm\n                  for\nbacktracking with inference\n                  is\n\n\n1function BacktrackingWithInference(𝛾,𝑎) returns a solution, or ‘‘inconsistent’’\n2if 𝑎 is inconsistent then return ‘‘inconsistent’’\n3if 𝑎 is a total assignment then return 𝑎\n4𝛾' := a copy of 𝛾 /* 𝛾'=(𝛾'.𝑉𝛾',𝛾'.𝐷𝛾',𝛾'.𝐶𝛾') */\n5𝛾' := Inference(𝛾')\n6if exists 𝑣 with 𝛾'.𝐷𝛾'𝑣=∅ then return ‘‘inconsistent’’\n7select some variable 𝑣 for which 𝑎 is not defined\n8for each 𝑑∊ copy of 𝛾'.𝐷𝛾'𝑣 in some order do\n9𝑎':=𝑎∪{𝑣=𝑑}; 𝛾'.𝐷𝛾'𝑣:={𝑑} /* makes 𝑎 explicit as a constraint */\n10𝑎'' := BacktrackingWithInference(𝛾',𝑎')\n11if 𝑎''≠\n“inconsistent”\n then return 𝑎''\n12return ‘‘inconsistent’’\n\n▷Exactly the same as\n??, only line 5 new!\n\n\n▷Inference(): Any procedure delivering a (tighter)\nequivalent\nnetwork.\n\n\n▷Inference()\n                  typically\nprunes\ndomains; indicate\nunsolvability\n                  by\n𝛾'.𝐷𝛾'𝑣=∅.\n\n\n▷When\nbacktracking\n                  out of a\nsearch\nbranch, retract the\ninferred\nconstraints: these were dependent on\n𝑎, the search commitments so far.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-16\n",
        "sectionId": "15962b21",
        "archive": "courses/FAU/AI/course",
        "filepath": "csp/slides/csnet-backtracking-inference.en.xhtml"
    },
    {
        "slideContent": "\nForward Checking\n\n▷\nForward checking\n                  propagates information about\nillegal\n                  values:Whenever a\nvariable\n𝑢\n                  is\nassigned\n                  by\n𝑎, delete all\nvalues\ninconsistent\n                  with\n𝑎(𝑢)\n                  from every\n𝐷𝑣\n                  for all\nvariables\n𝑣\n                  connected with\n𝑢\n                  by a\nconstraint.\n\n\n▷\nForward checking\n                  in Australia\n\n\n\n\n\n\n\n\n\n\n▷Inference, Version 1\nForward checking\nimplemented\n\nfunction ForwardChecking(𝛾,𝑎) returns modified 𝛾\nfor each 𝑣 where 𝑎(𝑣)=𝑑' is defined do\nfor each 𝑢 where 𝑎(𝑢) is undefined and 𝐶𝑢𝑣∊𝐶 do\n𝐷𝑢 := {𝑑∊𝐷𝑢|(𝑑,𝑑')∊𝐶𝑢𝑣}\nreturn 𝛾\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "355b0bbd",
        "archive": "courses/FAU/AI/course",
        "filepath": "csp/slides/forward-checking.en.xhtml"
    },
    {
        "slideContent": "\nForward Checking: Discussion\n\n▷\n                  An\ninference\nprocedure\n                  is called\nsound, iff for any\ninput\n𝛾\n                  the\noutput\n𝛾'\n                  have the same\nsolutions.\n\n\n▷\nForward checking\n                  is\nsound.\n\n\nProof sketch:\n                Recall here that the\nassignment\n𝑎\n                is represented as\nunary constraints\n                inside\n𝛾.\n\n\n▷\n𝛾\n                  and\n𝛾'\n                  are\nequivalent.\n\n\n▷Incremental\n              computation: Instead of the first\nfor-loop\n              in\n??, use only the inner one every time a new\nassignment\n𝑎(𝑣)=𝑑'\n              is added.\n\n\n▷Practical Properties\n\n\n▷Cheap but useful\ninference\n                  method.\n\n\n▷Rarely a good idea to not use\nforward checking\n                  (or a stronger\ninference\n                  method subsuming it).\n\n\n▷Up next\n                  A stronger\ninference\n                  method (subsuming\nforward checking).\n\n\n▷\n                  Let\n𝑝\n                  and\n𝑞\n                  be\ninference\nprocedures, then\n𝑝\nsubsumes\n𝑞, if\n𝑝(𝛾)⊑𝑞(𝛾)\n                  for any\ninput\n𝛾.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-15\n",
        "sectionId": "355b0bbd",
        "archive": "courses/FAU/AI/course",
        "filepath": "csp/slides/forward-checking-props.en.xhtml"
    },
    {
        "slideContent": "\nWhen Forward Checking is Not Good Enough\n\n▷Problem\nForward checking\n                makes\ninferences\n                only from\nassigned\n                to\nunassigned\nvariables.\n\n\n▷\n\n\n  \n\n\n\n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n\n1\n_\n\n  \n\n\n𝑣1  \n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n1\n2\n3\n\n  \n\n\n𝑣2  \n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n1\n2\n3\n\n  \n\n\n𝑣3  \n\n𝑣1<𝑣2  \n\n𝑣2<𝑣3  \n\n\n\n   \n\n\n\n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n\n1\n_\n\n  \n\n\n𝑣1  \n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n2\n3\n\n  \n\n\n𝑣2  \n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n1\n2\n3\n\n  \n\n\n𝑣3  \n\n𝑣1<𝑣2  \n\n𝑣2<𝑣3  \n\n\n\n   \n\n\n\n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n\n1\n_\n\n  \n\n\n𝑣1  \n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n2\n3\n\n  \n\n\n𝑣2  \n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n3\n\n  \n\n\n𝑣3  \n\n𝑣1<𝑣2  \n\n𝑣2<𝑣3  \n\n\n\n  \n\n\nWe could do better here:\nvalue\n                3 for\n𝑣2\n                is not\nconsistent\n                with any remaining value for\n𝑣3\n⤳\n                it can be removed!\n\nBut\nforward checking\n                does not catch this.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "44fa5e7f",
        "archive": "courses/FAU/AI/course",
        "filepath": "csp/slides/ac-motivation.en.xhtml"
    },
    {
        "slideContent": "\nArc Consistency: Definition\n\n▷\n\n\n▷Intuition\nArc consistency\n=^\n                  for every\ndomain\n                  value and\nconstraint, at least one value on the other side of the\nconstraint\n                  “works”.\n\n\n▷Note\n                  the asymmetry between\n𝑢\n                  and\n𝑣:\narc consistency\n                  is directed.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "44fa5e7f",
        "archive": "courses/FAU/AI/course",
        "filepath": "csp/slides/arc-consistency.en.xhtml"
    },
    {
        "slideContent": "\nArc Consistency: Example\n\n▷\n\n\n▷Arc Consistency\n\n  \n\n\n\n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n\n1\n_\n\n  \n\n\n𝑣1  \n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n1\n2\n3\n\n  \n\n\n𝑣2  \n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n1\n2\n3\n\n  \n\n\n𝑣3  \n\n𝑣1<𝑣2  \n\n𝑣2<𝑣3  \n\n\n\n   \n\n\n\n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n\n1\n_\n\n  \n\n\n𝑣1  \n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n2\n3\n\n  \n\n\n𝑣2  \n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n1\n2\n3\n\n  \n\n\n𝑣3  \n\n𝑣1<𝑣2  \n\n𝑣2<𝑣3  \n\n\n\n   \n\n\n\n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n\n1\n_\n\n  \n\n\n𝑣1  \n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n2\n3\n\n  \n\n\n𝑣2  \n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n3\n\n  \n\n\n𝑣3  \n\n𝑣1<𝑣2  \n\n𝑣2<𝑣3  \n\n\n\n  \n\n\n▷Question: On top, middle, is\n𝑣3\narc consistent\n                  relative to\n𝑣2?\n\n\n▷Answer: No. For values\n1\n                  and\n2,\n𝐷𝑣2\n                  does not have a\nvalue\n                  that works.\n\n\n▷Note: Enforcing\narc consistency\n                  for one variable may lead to further reductions on another\nvariable!\n\n\n▷Question: And on the right?\n\n▷Answer: Yes.\n(But\n𝑣2\n                      is not\narc consistent\n                      relative to\n𝑣3)\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 122024-12-14\n",
        "sectionId": "44fa5e7f",
        "archive": "courses/FAU/AI/course",
        "filepath": "csp/slides/arc-consistency.en.xhtml"
    },
    {
        "slideContent": "\nArc Consistency: Example\n\n▷\n\n\n▷\n\n\n\n\n⤳?\n\n\n\n\n▷Note:\nSA\n                  is not\narc consistent\n                  relative to\nNT\n                  in 3rd row.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 132024-12-14\n",
        "sectionId": "44fa5e7f",
        "archive": "courses/FAU/AI/course",
        "filepath": "csp/slides/arc-consistency.en.xhtml"
    },
    {
        "slideContent": "\nEnforcing Arc Consistency: General Remarks\n\n▷Inference, version 2\n                  “Enforcing Arc Consistency” = removing\ndomain\nvalues\n                  until\n𝛾\n                  is\narc consistent.\n(Up next)\n\n\n▷Note\n                  Assuming such an\ninference\n                  method\nAC(𝛾).\n\n\n▷\nAC(𝛾)\n                  is\nsound: guarantees to deliver an\nequivalent\nnetwork.\n\n\n▷Proof sketch:\n                If, for\n𝑑∊𝐷𝑢, there does not exist a value\n𝑑'∊𝐷𝑣\n                such that\n(𝑑,𝑑')∊𝐶𝑢𝑣, then\n𝑢=𝑑\n                cannot be part of any\nsolution.\n\n\n▷\nAC(𝛾)\nsubsumes\nforward checking:\nAC(𝛾)⊑ForwardChecking(𝛾).\n\n\n▷Proof:\nRecall from slide\n??\n                  that\n𝛾'⊑𝛾\n                  means\n𝛾'\n                  is\ntighter\n                  than\n𝛾.\n\n\n\n\n1.Forward checking\n                    removes\n𝑑\n                    from\n𝐷𝑢\n                    only if there is a\nconstraint\n𝐶𝑢𝑣\n                    such that\n𝐷𝑣={𝑑'}\n                    (i.e. when\n𝑣\n                    was\nassigned\n                    the value\n𝑑'), and\n(𝑑,𝑑')∉𝐶𝑢𝑣.\n\n\n\n\n2.Clearly, enforcing\narc consistency\n                    of\n𝑢\n                    relative to\n𝑣\n                    removes\n𝑑\n                    from\n𝐷𝑢\n                    as well.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-16\n",
        "sectionId": "44fa5e7f",
        "archive": "courses/FAU/AI/course",
        "filepath": "csp/slides/ac-enforcing.en.xhtml"
    },
    {
        "slideContent": "\nEnforcing Arc Consistency for\nOne\n              Pair of Variables\n\n▷Revise\nRevise\n                  is an\nalgorithm\n                  enforcing\narc consistency\n                  of\n𝑢\n                  relative to\n𝑣\n\n\nfunction Revise(𝛾,𝑢,𝑣) returns modified 𝛾\nfor each 𝑑∊𝐷𝑢 do\nif there is no 𝑑'∊𝐷𝑣 with (𝑑,𝑑')∊𝐶𝑢𝑣 then 𝐷𝑢 := 𝐷𝑢\\{𝑑}\nreturn 𝛾\n\n▷\n                  If\n𝑑\n                  is maximal\ndomain\nsize\n                  in\n𝛾\n                  and the test “(𝑑,𝑑')∊𝐶𝑢𝑣?” has\ntime complexity\n𝒪(1), then the\nrunning time\n                  of\nRevise(𝛾,𝑢,𝑣)\n                  is\n𝒪(𝑑2).\n\n\n▷\nRevise(𝛾,𝑣3,𝑣2)\n\n\n  \n\n\n\n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n\n1\n_\n\n  \n\n\n𝑣1  \n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n2\n3\n\n  \n\n\n𝑣2  \n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n1\n2\n3\n\n  \n\n\n𝑣3  \n\n𝑣1<𝑣2  \n\n𝑣2<𝑣3  \n\n\n\n \n\n  \n\n\n\n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n\n1\n_\n\n  \n\n\n𝑣1  \n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n2\n3\n\n  \n\n\n𝑣2  \n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n1\n2\n3\n\n  \n\n\n𝑣3  \n\n𝑣1<𝑣2  \n\n𝑣2<𝑣3  \n\n\n\n \n\n  \n\n\n\n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n\n1\n_\n\n  \n\n\n𝑣1  \n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n2\n3\n\n  \n\n\n𝑣2  \n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n1\n2\n3\n\n  \n\n\n𝑣3  \n\n𝑣1<𝑣2  \n\n𝑣2<𝑣3  \n\n\n\n \n\n  \n\n\n\n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n\n1\n_\n\n  \n\n\n𝑣1  \n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n2\n3\n\n  \n\n\n𝑣2  \n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n2\n3\n\n  \n\n\n𝑣3  \n\n𝑣1<𝑣2  \n\n𝑣2<𝑣3  \n\n\n\n \n\n  \n\n\n\n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n\n1\n_\n\n  \n\n\n𝑣1  \n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n2\n3\n\n  \n\n\n𝑣2  \n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n2\n3\n\n  \n\n\n𝑣3  \n\n𝑣1<𝑣2  \n\n𝑣2<𝑣3  \n\n\n\n \n\n  \n\n\n\n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n\n1\n_\n\n  \n\n\n𝑣1  \n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n2\n3\n\n  \n\n\n𝑣2  \n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n3\n\n  \n\n\n𝑣3  \n\n𝑣1<𝑣2  \n\n𝑣2<𝑣3  \n\n\n\n \n\n  \n\n\n\n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n\n1\n_\n\n  \n\n\n𝑣1  \n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n2\n3\n\n  \n\n\n𝑣2  \n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n3\n\n  \n\n\n𝑣3  \n\n𝑣1<𝑣2  \n\n𝑣2<𝑣3  \n\n\n\n \n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "44fa5e7f",
        "archive": "courses/FAU/AI/course",
        "filepath": "csp/slides/AC1-revise.en.xhtml"
    },
    {
        "slideContent": "\nAC-1: Enforcing Arc Consistency (Version 1)\n\n▷Idea\n                  Apply\nRevise\n                  pairwise up to a\nfixed point.\n\n\n▷\nAC-1\n                  enforces\narc consistency\n                  in\nconstraint networks:\n\n\nfunction AC―1(𝛾) returns modified 𝛾\nrepeat\nchangesMade := False\nfor each constraint 𝐶𝑢0𝑣 do\nRevise(𝛾,𝑢,𝑣) /* if 𝐷𝑢 reduces, set changesMade := True */\nRevise(𝛾,𝑣,𝑢) /* if 𝐷𝑣 reduces, set changesMade := True */\nuntil changesMade = False\nreturn 𝛾\n\n▷Observation\n                  Obviously, this does indeed enforce\narc consistency\n                  for\n𝛾.\n\n\n▷\n                  If\n𝛾\n                  has\n𝑛\nvariables,\n𝑚\nconstraints, and maximal\ndomain\nsize\n𝑑, then the\ntime complexity\n                  of\nAC1(𝛾)\n                  is\n𝒪(𝑚𝑑2𝑛𝑑).\n\n\n▷Proof sketch:\n𝒪(𝑚𝑑2)\n                for each inner\nloop,\nfixed point\n                reached at the latest once all\n𝑛𝑑\nvariable\nvalues\n                have been removed.\n\n\n▷Problem\n                  There are redundant\ncomputations.\n\n\n▷Question\n                  Do you see what these redundant\ncomputations\n                  are?\n\n\n▷Redundant computations\n𝑢\n                  and\n𝑣\n                  are revised even if theirdomains\n                  haven’t changed since the last time.\n\n\n▷Better\nalgorithm\n              avoiding this: AC 3\n(coming up)\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "44fa5e7f",
        "archive": "courses/FAU/AI/course",
        "filepath": "csp/slides/AC1-algo.en.xhtml"
    },
    {
        "slideContent": "\nAC-3: Enforcing Arc Consistency (Version 3)\n\n▷Idea\n                  Remember the potentially\ninconsistent\nvariable\n                  pairs.\n\n\n▷\nAC-3\n                  optimizes\nAC-1\n                  for enforcing\narc consistency.\n\n\nfunction AC―3(𝛾) returns modified 𝛾\n𝑀 := ∅\nfor each constraint 𝐶𝑢𝑣∊𝐶 do\n𝑀 := 𝑀∪{(𝑢,𝑣),(𝑣,𝑢)}\nwhile 𝑀≠∅ do\nremove any element (𝑢,𝑣) from 𝑀\nRevise(𝛾,𝑢,𝑣)\nif 𝐷𝑢 has changed in the call to Revise then\nfor each constraint 𝐶𝑤𝑢∊𝐶 where 𝑤≠𝑣 do\n𝑀 := 𝑀∪{(𝑤,𝑢)}\nreturn 𝛾\n\n▷Question\nAC−3(𝛾)\n                  enforces\narc consistency\n                  because?\n\n\n▷Answer\n                  At any time during the while-loop, if\n(𝑢,𝑣)∉𝑀\n                  then\n𝑢\n                  is\narc consistent\n                  relative to\n𝑣.\n\n\n▷Question\n                  Why only “where\n𝑤≠𝑣”?\n\n\n▷Answer\n                  If\n𝑤=𝑣\n                  is the reason why\n𝐷𝑢\n                  changed, then\n𝑤\n                  is still\narc consistent\n                  relative to\n𝑢: the\nvalues\n                  just removed from\n𝐷𝑢\n                  did not match any\nvalues\n                  from\n𝐷𝑤\n                  anyway.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "44fa5e7f",
        "archive": "courses/FAU/AI/course",
        "filepath": "csp/slides/AC3-algo.en.xhtml"
    },
    {
        "slideContent": "\nAC-3: Example\n\n▷\n𝑦div𝑥=0:\n𝑦\n                modulo\n𝑥\n                is\n0, i.e.,\n𝑦\n                is divisible by\n𝑥\n\n\n\n\n\n\n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n2\n5\n\n  \n\n\n𝑣1  \n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n2\n4\n\n  \n\n\n𝑣2  \n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n2\n5\n\n  \n\n\n𝑣3  \n\n𝑣2div𝑣1=0  \n\n𝑣3div𝑣1=0  \n\n\n\n\n𝑀(𝑣2,𝑣1)(𝑣1,𝑣2)(𝑣3,𝑣1)(𝑣1,𝑣3)\n\n \n\n\n\n\n\n\n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n\n\n\n2\n5\n\n  \n\n\n\n𝑣1  \n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n2\n4\n\n  \n\n\n𝑣2  \n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n\n\n\n2\n5\n\n  \n\n\n\n𝑣3  \n\n𝑣2div𝑣1=0  \n\n𝑣3div𝑣1=0  \n\n\n\n\n𝑀(𝑣2,𝑣1)(𝑣1,𝑣2)(𝑣3,𝑣1)(𝑣1,𝑣3)\n\n \n\n\n\n\n\n\n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n\n\n\n2\n5\n\n  \n\n\n\n𝑣1  \n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n2\n4\n\n  \n\n\n𝑣2  \n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n\n\n\n2\n5\n\n  \n\n\n\n𝑣3  \n\n𝑣2div𝑣1=0  \n\n𝑣3div𝑣1=0  \n\n\n\n\n𝑀(𝑣2,𝑣1)(𝑣1,𝑣2)(𝑣3,𝑣1)\n\n \n\n\n\n\n\n\n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n\n\n\n2\n5\n\n  \n\n\n\n𝑣1  \n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n\n\n\n2\n4\n\n  \n\n\n\n𝑣2  \n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n2\n5\n\n  \n\n\n𝑣3  \n\n𝑣2div𝑣1=0  \n\n𝑣3div𝑣1=0  \n\n\n\n\n𝑀(𝑣2,𝑣1)(𝑣1,𝑣2)\n\n \n\n\n\n\n\n\n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n2\n\n  \n\n\n𝑣1  \n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n2\n4\n\n  \n\n\n𝑣2  \n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n2\n5\n\n  \n\n\n𝑣3  \n\n𝑣2div𝑣1=0  \n\n𝑣3div𝑣1=0  \n\n\n\n\n𝑀(𝑣2,𝑣1)\n\n \n\n\n\n\n\n\n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n2\n\n  \n\n\n𝑣1  \n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n2\n4\n\n  \n\n\n𝑣2  \n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n2\n5\n\n  \n\n\n𝑣3  \n\n𝑣2div𝑣1=0  \n\n𝑣3div𝑣1=0  \n\n\n\n\n𝑀(𝑣2,𝑣1)(𝑣3,𝑣1)\n\n \n\n\n\n\n\n\n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n\n\n\n2\n\n  \n\n\n\n𝑣1  \n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n2\n4\n\n  \n\n\n𝑣2  \n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n\n\n\n2\n5\n\n  \n\n\n\n𝑣3  \n\n𝑣2div𝑣1=0  \n\n𝑣3div𝑣1=0  \n\n\n\n\n𝑀(𝑣2,𝑣1)(𝑣3,𝑣1)\n\n \n\n\n\n\n\n\n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n\n\n\n2\n\n  \n\n\n\n𝑣1  \n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n\n\n\n2\n4\n\n  \n\n\n\n𝑣2  \n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n2\n\n  \n\n\n𝑣3  \n\n𝑣2div𝑣1=0  \n\n𝑣3div𝑣1=0  \n\n\n\n\n𝑀(𝑣2,𝑣1)\n\n \n\n\n\n\n\n\n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n2\n\n  \n\n\n𝑣1  \n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n2\n4\n\n  \n\n\n𝑣2  \n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n2\n\n  \n\n\n𝑣3  \n\n𝑣2div𝑣1=0  \n\n𝑣3div𝑣1=0  \n\n\n\n\n𝑀\n\n \n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-15\n",
        "sectionId": "44fa5e7f",
        "archive": "courses/FAU/AI/course",
        "filepath": "csp/slides/AC3-ex.en.xhtml"
    },
    {
        "slideContent": "\nAC-3: Runtime\n\n▷Runtime of\nAC-3\n                  Let\n𝛾:=〈𝑉,𝐷,𝐶〉\n                  be a\nconstraint network\n                  with\n𝑚\nconstraints, and maximal\ndomain\nsize\n𝑑. Then\nAC−3(𝛾)\n                  runs in time\n𝒪(𝑚𝑑3).\n\n\n▷Proof:\nby counting how often\nRevise\n                  is called.\n\n\n\n1.Each call to\nRevise(𝛾,𝑢,𝑣)\n                    takes time\n𝒪(𝑑2)\n                    so it suffices to prove that at most\n𝒪(𝑚𝑑)\n                    of these calls are made.\n\n\n\n\n2.The number of calls to\nRevise(𝛾,𝑢,𝑣)\n                    is the number of iterations of the while-loop, which is at most the number of insertions into\n𝑀.\n\n\n\n\n3.Consider any\nconstraint\n𝐶𝑢𝑣.\n\n\n\n\n4.Two\nvariable\npairs\n                    corresponding to\n𝐶𝑢𝑣\n                    are inserted in the for-loop. In the while loop, if a pair corresponding to\n𝐶𝑢𝑣\n                    is inserted into\n𝑀, then\n\n\n\n\n5.beforehand the\ndomain\n                    of either\n𝑢\n                    or\n𝑣\n                    was reduced, which happens at most\n2𝑑\n                    times.\n\n\n\n\n6.Thus we have\n𝒪(𝑑)\n                    insertions per\nconstraint, and\n𝒪(𝑚𝑑)\n                    insertions overall, as desired.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-15\n",
        "sectionId": "44fa5e7f",
        "archive": "courses/FAU/AI/course",
        "filepath": "csp/slides/AC3-props.en.xhtml"
    },
    {
        "slideContent": "\nReminder: The Big Picture\n\n▷Say\n𝛾\n            is a\nconstraint network\n            with\n𝑛\nvariables\n            and maximal\ndomain\nsize\n𝑑.\n\n\n▷𝑑𝑛\ntotal\nassignments\n            must be tested in the worst case to\nsolve\n𝛾.\n\n\nInference\n                One method to try to avoid/ameliorate this\ncombinatorial explosion\n                in practice.\n\n\n▷▷Often, from an\nassignment\n                to some\nvariables, we can easily make\ninferences\n                regarding other\nvariables.\n\n\nDecomposition\n                Another method to avoid/ameliorate this\ncombinatorial explosion\n                in practice.\n\n\n▷▷Often, we can exploit the\nstructure\n                of a network to\ndecompose\n                it into smaller parts that are easier to solve.\n\n\n▷Question: What is “structure”, and how to “decompose”?\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-16\n",
        "sectionId": "2db0400a",
        "archive": "courses/FAU/AI/course",
        "filepath": "csp/slides/cg-intro.en.xhtml"
    },
    {
        "slideContent": "\nProblem Structure\n\n\n\n▷Idea\n                                  Tasmania and mainland are “independent subproblems”\n\n\n▷\nIndependent subproblems\n                                  are identified as\nconnected\ncomponents\n                                  of\nconstraint graphs.\n\n\n▷Suppose each\nindependent subproblem\n                              has\n𝑐\nvariables\n                              out of\n𝑛\n                              total.(𝑑\n                                  is max\ndomain\nsize)\n\n\n▷Worst-case solution cost is\n𝑛div𝑐·𝑑𝑐(linear in\n𝑛)\n\n\n▷E.g.,\n𝑛=80,\n𝑑=2,\n𝑐=20\n\n\n▷280\n=^\n                              4 billion years at 10 million nodes/sec\n\n\n▷4·220\n=^\n                              0.4 seconds at 10 million nodes/sec\n\n\n\n\n\n\n\n\n \n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "2db0400a",
        "archive": "courses/FAU/AI/course",
        "filepath": "csp/slides/csnet-structure.en.xhtml"
    },
    {
        "slideContent": "\n“Decomposition” 1.0: Disconnected Constraint Graphs\n\n▷Disconnected Constraint GraphsLet\n𝛾:=〈𝑉,𝐷,𝐶〉\n                  be a\nconstraint network. Let\n𝑎𝑖\n                  be a\nsolution\n                  to each\nconnected\ncomponent\n𝛾𝑖\n                  of the\nconstraint graph\n                  of\n𝛾. Then\n𝑎:=⋃𝑖𝑎𝑖\n                  is a\nsolution\n                  to\n𝛾.\n\n\n▷Proof:\n\n\n\n\n1.𝑎\n                    satisfies all\n𝐶𝑢𝑣\n                    where\n𝑢\n                    and\n𝑣\n                    are inside the same\nconnected\ncomponent.\n\n\n\n\n2.The latter is the case for all\n𝐶𝑢𝑣.\n\n\n\n\n3.If two parts of\n𝛾\n                    are not\nconnected, then they are independent.\n\n\n▷\n                  Color Tasmania separately in Australia\n\n\n\n\n▷Doing the Numbers\n\n\n▷𝛾\n                  with\n𝑛=40\nvariables, each\ndomain\nsize\n𝑘=2. Four separate\nconnected\ncomponents\n                  each of\nsize\n10.\n\n\n▷Reduction of worst-case when using\ndecomposition:\n\n\n▷No\ndecomposition:\n240. With:\n4·210. Gain:\n228≊280.000.000.\n\n\n▷\n                  The process of decomposing a\nconstraint network\n                  into\ncomponents\n                  is called\ndecomposition. There are various\ndecomposition\nalgorithms.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-16\n",
        "sectionId": "2db0400a",
        "archive": "courses/FAU/AI/course",
        "filepath": "csp/slides/cg-disconnected.en.xhtml"
    },
    {
        "slideContent": "\nTree-structured CSPs\n\n\n\n▷\n                  We call a\nCSP\ntree-structured, iff its\nconstraint graph\n                  is\nacyclic\n\n\n▷\nTree-structured\nCSP\n                  can be solved in\n𝒪(𝑛𝑑2)\ntime.\n\n\n▷Compare to general\nCSPs, where worst case time is\n𝒪(𝑑𝑛).\n\n\n▷This property also applies to\nlogical\n              and\nprobabilistic reasoning: an important example of the relation between syntactic restrictions and the complexity of\nreasoning.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "2db0400a",
        "archive": "courses/FAU/AI/course",
        "filepath": "csp/slides/csnet-tree-structured.en.xhtml"
    },
    {
        "slideContent": "\nAlgorithm for tree-structured CSPs\n\n1.Choose a\nvariable\n              as root, order\nvariables\n              from root to leaves such that every node’s parent precedes it in the ordering\n\n\n\n\n2.For\n𝑗\n              from\n𝑛\n              down to\n2, apply\n\n\nRemoveInconsistent(Parent(𝑋𝑗,𝑋𝑗)\n\n3.For\n𝑗\n              from\n1\n              to\n𝑛, assign\n𝑋𝑗\n              consistently with\n𝑃𝑎𝑟𝑒𝑛𝑡(𝑋𝑗)\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-15\n",
        "sectionId": "2db0400a",
        "archive": "courses/FAU/AI/course",
        "filepath": "csp/slides/csnet-tree-structured-algo.en.xhtml"
    },
    {
        "slideContent": "\nNearly tree-structured CSPs\n\n▷\nConditioning: instantiate a variable,\nprune\n                  its neighbors’\ndomains.\n\n\n▷\n\n\n\n\n▷\nCutset conditioning: instantiate (in all ways) a set of\nvariables\n                  such that the remaining\nconstraint graph\n                  is a\ntree.\n\n\n▷Cutset\nsize\n𝑐\n⤳\nrunning time\n𝒪(𝑑𝑐(𝑛−𝑐)𝑑2), very fast for small\n𝑐.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-16\n",
        "sectionId": "2db0400a",
        "archive": "courses/FAU/AI/course",
        "filepath": "csp/slides/csnet-nearly-tree-structured.en.xhtml"
    },
    {
        "slideContent": "\n“Decomposition” 2.0: Acyclic Constraint Graphs\n\n▷Acyclic Constraint Graphs\n                  Let\n𝛾:=〈𝑉,𝐷,𝐶〉\n                  be a\nconstraint network\n                  with\n𝑛\nvariables\n                  and maximal\ndomain\nsize\n𝑘, whose\nconstraint graph\n                  is\nacyclic. Then we can find a\nsolution\n                  for\n𝛾, or prove\n𝛾\n                  to be\nunsatisfiable, in time\n𝒪(𝑛𝑘2).\n\n\n▷Proof sketch:\n                See the\nalgorithm\n                on the next slide\n\n\n▷Constraint networks\n              with\nacyclic\nconstraint graphs\n              can be solved in (low order)\npolynomial time.\n\n\n▷\n                  Australia is not\nacyclic.\n(But see next section)\n\n\n\n▷Doing the Numbers\n\n\n▷𝛾\n                  with\n𝑛=40\nvariables, each\ndomain\nsize\n𝑘=2.\nAcyclic\nconstraint graph.\n\n\n▷Reduction of worst-case when using\ndecomposition:\n\n\n▷No\ndecomposition:\n240.\n\n\n▷With\ndecomposition:\n40·22. Gain:\n232.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "2db0400a",
        "archive": "courses/FAU/AI/course",
        "filepath": "csp/slides/cg-acyclic.en.xhtml"
    },
    {
        "slideContent": "\nAcyclic Constraint Graphs: How To\n\n▷Algorithm\nAcyclicCG(𝛾):\n\n\n1.Obtain a (directed)\ntree\n                  from\n𝛾’s\nconstraint graph, picking an arbitrary\nvariable\n𝑣\n                  as the\nroot, and directing\nedges\n                  outwards.\n1\n\n\n\n2.Order the\nvariables\ntopologically, i.e., such that each\nnode\n                  is ordered before its\nchildren; denote that order by\n𝑣1,...,𝑣𝑛.\n\n3.for\n𝑖:=𝑛,𝑛−1,...,2\ndo:\n\n\n(a)Revise(𝛾,𝑣𝑝𝑎𝑟𝑒𝑛𝑡(𝑖),𝑣𝑖).\n\n\n(b)if\n𝐷𝑣𝑝𝑎𝑟𝑒𝑛𝑡(𝑖)=∅\nthen return\n                  “inconsistent”\n\n\nNow, every\nvariable\n                  is\narc consistent\n                  relative to its\nchildren.\n\n\n4.Run\nBacktrackingWithInference\n                  with\nforward checking, using the\nvariable\n                  order\n𝑣1,...,𝑣𝑛.\n\n\n▷\n                  This\nalgorithm\n                  will find a\nsolution\n                  without ever having to backtrack!\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "2db0400a",
        "archive": "courses/FAU/AI/course",
        "filepath": "csp/slides/cg-acyclic-algo.en.xhtml"
    },
    {
        "slideContent": "\nAcyclicCG(𝛾): Example\n\n▷AcyclicCG() execution\n\n\n\n\n\n\n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n1\n2\n3\n\n  \n\n\n𝑣1  \n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n1\n2\n3\n\n  \n\n\n𝑣2  \n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n1\n2\n3\n\n  \n\n\n𝑣3  \n\n𝑣1<𝑣2  \n\n𝑣2<𝑣3  \n\n\n\n\n\nInput network\n𝛾.\n\n\n\n\n\n\n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n1\n2\n3\n\n  \n\n\n𝑣1  \n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n1\n2\n3\n\n  \n\n\n𝑣2  \n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n1\n2\n3\n\n  \n\n\n𝑣3  \n\n\n\n\n\n\n\n\n\n\n\n𝑣1<𝑣2   \n\n\n\n\n\n\n\n\n\n\n\n\n𝑣2<𝑣3   \n\n\n\n\n\n\nStep 1: Directed tree for root\n𝑣1.\n\nStep 2: Order\n𝑣1,𝑣2,𝑣3.\n\n\n\n\n\n\n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n1\n2\n3\n\n  \n\n\n𝑣1  \n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n1\n2\n\n  \n\n\n𝑣2  \n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n1\n2\n3\n\n  \n\n\n𝑣3  \n\n\n\n\n\n\n\n\n\n\n𝑣1<𝑣2  \n\n\n\n\n\n\n\n\n\n\n𝑣2<𝑣3  \n\n\n\n\n\nStep 3: After\nRevise(𝛾,𝑣2,𝑣3).\n\n\n\n\n\n\n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n1\n\n  \n\n\n𝑣1  \n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n1\n2\n\n  \n\n\n𝑣2  \n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n1\n2\n3\n\n  \n\n\n𝑣3  \n\n\n\n\n\n\n\n\n\n\n𝑣1<𝑣2  \n\n\n\n\n\n\n\n\n\n\n𝑣2<𝑣3  \n\n\n\n\n\nStep 3: After\nRevise(𝛾,𝑣1,𝑣2).\n\n\n\n\n\n\n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n\n1\n_\n\n  \n\n\n𝑣1  \n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n2\n\n  \n\n\n𝑣2  \n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n1\n2\n3\n\n  \n\n\n𝑣3  \n\n\n\n\n\n\n\n\n\n\n𝑣1<𝑣2  \n\n\n\n\n\n\n\n\n\n\n𝑣2<𝑣3  \n\n\n\n\n\nStep 4: After\n𝑎(𝑣1):=1\n                    and\nforward checking.\n\n\n\n\n\n\n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n\n1\n_\n\n  \n\n\n𝑣1  \n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n\n2\n_\n\n  \n\n\n𝑣2  \n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n3\n\n  \n\n\n𝑣3  \n\n\n\n\n\n\n\n\n\n\n𝑣1<𝑣2  \n\n\n\n\n\n\n\n\n\n\n𝑣2<𝑣3  \n\n\n\n\n\nStep 4: After\n𝑎(𝑣2):=2\n                    and\nforward checking.\n\n\n\n\n\n\n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n\n1\n_\n\n  \n\n\n𝑣1  \n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n\n2\n_\n\n  \n\n\n𝑣2  \n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n\n3\n_\n\n  \n\n\n𝑣3  \n\n\n\n\n\n\n\n\n\n\n𝑣1<𝑣2  \n\n\n\n\n\n\n\n\n\n\n𝑣2<𝑣3  \n\n\n\n\n\nStep 4: After\n𝑎(𝑣3):=3\n                    (and\nforward checking).\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "2db0400a",
        "archive": "courses/FAU/AI/course",
        "filepath": "csp/slides/cg-acyclic-ex.en.xhtml"
    },
    {
        "slideContent": "\n“Almost” Acyclic Constraint Graphs\n\n▷Coloring Australia\n\n\n\n\n▷Cutset Conditioning: Idea\n\n\n1.Recursive call\n                  of\nbacktracking search\n                  on\n𝑎\n                  s.t. the\nsubgraph\n                  of the\nconstraint graph\n                  induced by\n{𝑣∊𝑉|\n𝑎(𝑣) is undefined\n}\n                  is\nacyclic.\n\n\n▷Then we can solve the remaining sub-problem with\nAcyclicCG().\n\n\n2.Choose the\nvariable ordering\n                  so that removing the first\n𝑑\nvariables\n                  renders the\nconstraint graph\nacyclic.\n\n\n▷Then with (1) we won’t have to search deeper than\n𝑑\n                  ...!\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "ce44197a",
        "archive": "courses/FAU/AI/course",
        "filepath": "csp/slides/cutset-conditioning-idea.en.xhtml"
    },
    {
        "slideContent": "\n“Decomposition” 3.0: Cutset Conditioning\n\n▷Cutset\n                  Let\n𝛾:=〈𝑉,𝐷,𝐶〉\n                  be a\nconstraint network, and\n𝑉0⊆𝑉. Then\n𝑉0\n                  is a\ncutset\n                  for\n𝛾\n                  if the\nsubgraph\n                  of\n𝛾’s\nconstraint graph\n                  induced by\n𝑉\\𝑉0\n                  is\nacyclic.\n𝑉0\n                  is called\noptimal\n                  if its\nsize\n                  is\nminimal\n                  among all\ncutsets\n                  for\n𝛾.\n\n\n▷The\ncutset conditioning\nalgorithm, computes an\noptimal\ncutset, from\n𝛾\n                  and an existing\ncutset\n𝑉0.\n\n\nfunction CutsetConditioning(𝛾,𝑉0,𝑎) returns a solution, or ‘‘inconsistent’’\n𝛾' := a copy of 𝛾; 𝛾' := ForwardChecking(𝛾',𝑎)\nif ex. 𝑣 with 𝛾'.𝐷𝛾'𝑣=∅ then return ‘‘inconsistent’’\nif ex. 𝑣∊𝑉0 s.t. 𝑎(𝑣) is undefined then select such 𝑣\nelse 𝑎' := AcyclicCG(𝛾');\nif 𝑎'≠\n“inconsistent”\n then return 𝑎∪𝑎' else return ‘‘inconsistent’’\nfor each 𝑑∊\ncopy of \n𝛾'.𝐷𝛾'𝑣 in some order do\n𝑎' := 𝑎∪{𝑣=𝑑}; 𝛾'.𝐷𝛾'𝑣 := {𝑑};\n𝑎'' := CutsetConditioning(𝛾',𝑉0,𝑎')\nif 𝑎''≠\n“inconsistent”\n then return 𝑎'' else return ‘‘inconsistent’’\n\n▷Forward checking\n              is required so that “𝑎∪AcyclicCG(𝛾')” is\nconsistent\n              in\n𝛾.\n\n\n▷\nRunning time\n                  is\nexponential\n                  only in\n#(𝑉0), not in\n#(𝑉)!\n\n\n▷\n                  Finding\noptimal\ncutsets\n                  is\n𝐍𝐏\n                  hard, but good approximations exist.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "ce44197a",
        "archive": "courses/FAU/AI/course",
        "filepath": "csp/slides/cutset-conditioning-algo.en.xhtml"
    },
    {
        "slideContent": "\nIterative algorithms for\nCSPs\n\n▷Local search algorithms\n              like\nhill climbing\n              and\nsimulated annealing\n              typically work with “complete”\nstates, i.e., all\nvariables\n              are\nassigned\n\n\n▷To apply to\nCSPs: allow\nstates\n              with\nunsatisfied\nconstraints,\nactions\nreassign\nvariable\nvalues.\n\n\n▷Variable selection\n                  Randomly select any\nconflicted\nvariable.\n\n\n▷Value selection\n                  by\nmin conflicts\nheuristic: choose\nvalue\n                      that\nviolates\n                      the fewest\nconstraints\n                  i.e.,\nhill climb\n                  with\nℎ(𝑛):=\ntotal number of violated constraints\n.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "4d2b51e2",
        "archive": "courses/FAU/AI/course",
        "filepath": "csp/slides/csnet-iterative.en.xhtml"
    },
    {
        "slideContent": "\nExample:\n4-Queens\n\n▷States: 4\nqueens\n              in 4 columns (44=256\n              states)\n\n\n▷Actions: Move\nqueen\n              in column\n\n\n▷Goal state: No conflicts\n\n\n▷Heuristic:\nℎ(𝑛)\n=^\n              number of conflict\n\n\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-15\n",
        "sectionId": "4d2b51e2",
        "archive": "courses/FAU/AI/course",
        "filepath": "csp/slides/fourqueens-ex.en.xhtml"
    },
    {
        "slideContent": "\nPerformance of min-conflicts\n\n▷\n                  Given a random initial state, can solve\n𝑛-queens\n                  in almost\nconstant\ntime\n                  for arbitrary\n𝑛\n                  with high probability (e.g.,\n𝑛\n                  = 10,000,000)\n\n\n▷\n                  The same appears to be true for any randomly-generated\nCSP\nexcept\n                  in a narrow range of the ratio\n𝑅=\nnumber of constraints\n\nnumber of variables\n\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "4d2b51e2",
        "archive": "courses/FAU/AI/course",
        "filepath": "csp/slides/min-conflicts-performance.en.xhtml"
    },
    {
        "slideContent": "\nConclusion & Summary\n\n▷𝛾\n            and\n𝛾'\n            are\nequivalent\n            if they have the same\nsolutions.\n𝛾'\n            is\ntighter\n            than\n𝛾\n            if it is more constrained.\n\n\n▷Inference\n            tightens\n𝛾\n            without losing\nequivalence, during\nbacktracking search. This reduces the amount of search needed; that benefit must be traded off against the\nrunning time\n            overhead for making the\ninferences.\n\n\n▷Forward checking\n            removes values\nconflicting\n            with an assignment already made.\n\n\n▷Arc consistency\n            removes values that do not comply with any value still available at the other end of a\nconstraint. This\nsubsumes\nforward checking.\n\n\n▷The\nconstraint graph\n            captures the dependencies between\nvariables. Separate\nconnected\ncomponents\n            can be solved independently. Networks with\nacyclic\nconstraint graphs\n            can be solved in low order\npolynomial time.\n\n\n▷A\ncutset\n            is a subset of\nvariables\n            removing which renders the\nconstraint graph\nacyclic.\nCutset conditioning\nbacktracks\n            only on such a\ncutset, and solves a sub-problem with\nacyclic\nconstraint graph\n            at each search\nleaf.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-16\n",
        "sectionId": "c41fbcb4",
        "archive": "courses/FAU/AI/course",
        "filepath": "csp/slides/csprop-concl.en.xhtml"
    },
    {
        "slideContent": "\nTopics We Didn’t Cover Here\n\n▷Path consistency,\n𝑘-consistency\n                Generalizes\narc consistency\n                to\nsize\n𝑘\n                subsets of\nvariables. Path consistency\n=^\n                3-consistency.\n\n\n▷Tree decomposition\n                Instead of instantiating\nvariables\n                until the\nleaf\nnodes\n                are\ntrees, distribute the\nvariables\n                and\nconstraints\n                over\nsub-CSPs\n                whose connections form a\ntree.\n\n\n▷Backjumping\n                Like\nbacktracking search, but with ability to back up\nacross several levels\n                (to a previous\nvariable assignment\n                identified to be responsible for failure).\n\n\n▷No-Good Learning\n                Inferring additional\nconstraints\n                based on information gathered during\nbacktracking search.\n\n\n▷Local search\n                In space of\ntotal\n                (but not necessarily\nconsistent)\nassignments.\n(E.g.,\n8 queens\n                    in\n??)\n\n\n▷Tractable\n                  CSP\n                Classes of\nCSPs\n                that can be solved in\n𝐏.\n\n\n▷Global Constraints\nConstraints\n                over many/all\nvariables, with associated specialized\ninference\n                methods.\n\n\n▷Constraint Optimization Problems (COP)\n                Utility function over\nsolutions, need an optimal one.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 122024-12-16\n",
        "sectionId": "c41fbcb4",
        "archive": "courses/FAU/AI/course",
        "filepath": "csp/slides/csprop-concl.en.xhtml"
    },
    {
        "slideContent": "\nState\nRepresentations\n            in\nAgents\n            and\nAlgorithms\n\n▷Recall\n                We call a\nstate\nrepresentation\n\n\n▷atomic,\niff\n                it has no internal structure(black box)\n\n\n▷factored,\niff\n                each\nstate\n                is characterized by\nattribute\n                and their\nvalues.\n\n\n▷structured,\niff\n                the\nstate\n                includes\nrepresentations\n                of\nobjects, their\nproperties\n                and\nrelationships.\n\n\n▷Recall\n                We have used\natomic\nrepresentations\n                in\nsearch problems\n                and\ntree search algorithms.\n\n\n▷But\n                We already allowed peeking into\nstates\n                in\n\n\n▷informed search\n                to\ncompute\nheuristics\n\n\n▷adversarial search\n\n⇝\n\n                too many\nstates!\n\n\n▷Recall\n                We have used\nfactored\nrepresentations\n                in\n\n\n▷backtracking search\n                for\nCSPs\n⤳\n                universally useful\nheuristics\n\n\n▷constraint propagation:\ninference\n⤳\n                lifting\nsearch\n                to the\nCSP\n                description level.\n\n\n▷Up Next\nInference\n                for\nstructured\nstate\nrepresentations.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-15\n",
        "sectionId": "4327585e",
        "archive": "courses/FAU/AI/course",
        "filepath": "logic/slides/structured-representations.en.xhtml"
    },
    {
        "slideContent": "\nReasoning\n              in the\nWumpus\n              World\n\n▷Reasoning in the Wumpus WorldAs humans we mark\ncells\n                  with the\nknowledge\ninferred\n                  so far:\nA:\nagent,\nV: visited,\nOK: safe,\nP:\npit,\nW:\nWumpus,\nB:\nbreeze,\nS:\nstench,\nG:\ngold.\n\n\n\n(1) Initial state\n\n\n\n(2) One step to right\n\n\n\n(3) Back, and up to [1,2]\n\n\n\n\n \n\n▷The\nWumpus\n                    is in [1,3]! How do we\nknow?\n\n\n▷No\nstench\n                  in [2,1], so the\nstench\n                  in [1,2] can only come from [1,3].\n\n\n▷There’s a pit in [3,1]! How do we\nknow?\n\n\n▷No\nbreeze\n                  in [1,2], so the\nbreeze\n                  in [2,1] can only come from [3,1].\n\n\n▷Note\n                  The\nagent\n                  has more\nknowledge\n                  than just the\npercepts\n\n⇝\n\ninference!\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-16\n",
        "sectionId": "6ab91bb1",
        "archive": "courses/FAU/AI/course",
        "filepath": "logic/slides/wumpus-reasoning.en.xhtml"
    },
    {
        "slideContent": "\nGeneral Problem Solving using\nLogic\n\n▷Idea\n                Any problem that can be formulated as\nreasoning\n                about\nlogic.\n⤳\n                use off-the-shelf\nreasoning\n                tool.\n\n\n▷Very\n            successful using\npropositional logic\n            and modern\nSAT solvers!\n(Propositional satisfiability testing;\n??)\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-16\n",
        "sectionId": "6c8ce760",
        "archive": "courses/FAU/AI/course",
        "filepath": "logic/slides/proplog-gps.en.xhtml"
    },
    {
        "slideContent": "\nPropositional Logic\n            and Its\nApplications\n\n▷Propositional logic\n            =\ncanonical form\n            of\nknowledge\n            +\nreasoning.\n\n\n▷Syntax:\nAtomic\npropositions\n            that can be either\ntrue\n            or\nfalse, connected by “and, or, and not”.\n\n\n▷Semantics:\nAssign\nvalue\n            to every\nproposition,\nevaluate\nconnectives.\n\n\nApplications\n                Despite its simplicity, widely\napplied!\n\n\n▷▷Product configuration\n                (e.g., Mercedes). Check consistency of customized combinations of components.\n\n\n▷Hardware\nverification\n                (e.g., Intel, AMD, IBM, Infineon). Check whether a circuit has a desired\nproperty\n𝑝.\n\n\n▷Software\nverification: Similar.\n\n\n▷CSP\napplications:\nPropositional logic\n                can be (successfully!) used to formulate and solve\nconstraint satisfaction problems.(see\n??)\n\n\n▷??\n            gives an\nexample\n            for\nverification.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-16\n",
        "sectionId": "6c8ce760",
        "archive": "courses/FAU/AI/course",
        "filepath": "logic/slides/proplog-appl.en.xhtml"
    },
    {
        "slideContent": "\nOur Agenda for This Topic\n\n▷This\ndocument: Basic\ndefinitions\n            and\nconcepts;\ntableaux,\nresolution.\n\n\n▷Sets up the framework.\nResolution\n            is the quintessential\nreasoning\nprocedure\n            underlying most successful\nSAT solvers.\n\n\n▷Next Section (??): The\nDavis Putnam\nprocedure\n            and\nclause learning; practical problem structure.\n\n\n▷State-of-the-art\nalgorithms\n            for\nreasoning\n            about\npropositional logic, and an important\nobservation\n            about how they behave.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-15\n",
        "sectionId": "dc2672c7",
        "archive": "courses/FAU/AI/course",
        "filepath": "logic/slides/proplog-agenda.en.xhtml",
        "video_name": "AI1_25thDec.m4v",
        "start_time": 2241.41,
        "end_time": 2303.01
    },
    {
        "slideContent": "\nOur Agenda for This Chapter\n\n▷Propositional logic: What’s the\nsyntax\n            and\nsemantics? How can we capture\ndeduction?\n\n\n▷We\nstudy\n            this\nlogic\nformally.\n\n\n▷Tableaux,\nResolution: How can we make\ndeduction\n            mechanizable? What are its\nproperties?\n\n\n▷Formally introduces the most basic\nmachine-oriented\nreasoning\nalgorithm.\n\n\n▷Killing a\nWumpus: How can we use all this to figure out where the\nWumpus\n            is?\n\n\n▷Coming back to our introductory\nexample.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 122024-12-15\n",
        "sectionId": "dc2672c7",
        "archive": "courses/FAU/AI/course",
        "filepath": "logic/slides/proplog-agenda.en.xhtml"
    },
    {
        "slideContent": "\nPropositional Logic\n              (Syntax)\n\n▷Syntax\n                  The\nformulae\n                  of\npropositional logic\n                  (write\nPL0) are made up from\n\n\n▷propositional variables:\n𝒱0:={𝑃,𝑄,𝑅,𝑃1,𝑃2,...}\n(countably infinite)\n\n\n▷A\npropositional signature:\nconstants/constructors called\nconnectives:\nΣ0:={𝑇,𝐹,¬,∨,∧,⇒,⇔,...}\n\n\nWe define the\nset\n𝑤𝑓𝑓0(𝒱0)\n                  of\nwell-formed propositional formula\n                  (wffs) as\n\n\n▷propositional variables,\n\n\n▷the\nlogical constants\n𝑇\n                  and\n𝐹,\n\n\n▷negations\n¬𝐀,\n\n\n▷conjunctions\n𝐀∧𝐁(𝐀\n                  and\n𝐁\n                  are called\nconjuncts),\n\n\n▷disjunctions\n𝐀∨𝐁\n                  (𝐀\n                  and\n𝐁\n                  are called\ndisjuncts),\n\n\n▷implications\n𝐀⇒𝐁, and\n\n\n▷equivalences\n                  (or\nbiimplication).\n𝐀⇔𝐁,\n\n\nwhere\n𝐀,𝐁∊𝑤𝑓𝑓0(𝒱0)\n                  themselves.\n\n\n▷\n𝑃∧𝑄,𝑃∨𝑄,¬𝑃∨𝑄⇔𝑃⇒𝑄∊𝑤𝑓𝑓0(𝒱0)\n\n\n▷\nPropositional formulae\n                  without\nconnectives\n                  are called\natomic\n                  (or an\natom) and\ncomplex\n                  otherwise.\n\n\n\n:\n12024-12-14\n",
        "sectionId": "69703b1f",
        "archive": "courses/Jacobs/GenCS/course",
        "filepath": "pl0/slides/pl0-syntax.en.xhtml"
    },
    {
        "slideContent": "\nPropositional Logic\nGrammar\n            Overview\n\n▷Grammar\n                  for\nPropositional Logic\npropositional variables\n𝑋::=𝒱0={𝑃,𝑄,𝑅,...,...}variables\npropositional formulae\n𝐀::=𝑋variable|¬𝐀negation|𝐀1∧𝐀2conjunction|𝐀1∨𝐀2disjunction|𝐀1⇒𝐀2implication|𝐀1⇔𝐀2equivalence\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-16\n",
        "sectionId": "69703b1f",
        "archive": "courses/FAU/AI/course",
        "filepath": "logic/slides/pl0-grammar-overview.en.xhtml"
    },
    {
        "slideContent": "\nAlternative Notations for\nConnectives\n\nHere Elsewhere¬𝐀 ∼𝐀 𝐀―𝐀∧𝐁 𝐀&𝐁 𝐀•𝐁 𝐀,𝐁𝐀∨𝐁 𝐀+𝐁 𝐀|𝐁 𝐀;𝐁𝐀⇒𝐁 𝐀→𝐁𝐀⊃𝐁𝐀⇔𝐁 𝐀↔𝐁𝐀≡𝐁𝐹 ⊥0𝑇 ⊤1\n\n\n\n:\n12024-12-15\n",
        "sectionId": "69703b1f",
        "archive": "courses/Jacobs/GenCS/course",
        "filepath": "pl0/slides/pl0-notations.en.xhtml",
        "video_name": "AI1_25thDec.m4v",
        "start_time": 3195.51,
        "end_time": 3244.8
    },
    {
        "slideContent": "\nComputing\nSemantics\n\n▷Let\n𝜑:=[𝖳/𝑃1],[𝖥/𝑃2],[𝖳/𝑃3],[𝖥/𝑃4],...\n                    then\nℐ𝜑(𝑃1∨𝑃2∨¬(¬𝑃1∧𝑃2)∨𝑃3∧𝑃4)\n\n=ℐ(∨)(ℐ𝜑(𝑃1∨𝑃2),ℐ𝜑(¬(¬𝑃1∧𝑃2)∨𝑃3∧𝑃4))\n\n=ℐ(∨)(ℐ(∨)(ℐ𝜑(𝑃1),ℐ𝜑(𝑃2)),ℐ(∨)(ℐ𝜑(¬(¬𝑃1∧𝑃2)),ℐ𝜑(𝑃3∧𝑃4)))\n\n=ℐ(∨)(ℐ(∨)(𝜑(𝑃1),𝜑(𝑃2)),ℐ(∨)(ℐ(¬)(ℐ𝜑(¬𝑃1∧𝑃2)),ℐ(∧)(ℐ𝜑(𝑃3),ℐ𝜑(𝑃4))))\n\n=ℐ(∨)(ℐ(∨)(𝖳,𝖥),ℐ(∨)(ℐ(¬)(ℐ(∧)(ℐ𝜑(¬𝑃1),ℐ𝜑(𝑃2))),ℐ(∧)(𝜑(𝑃3),𝜑(𝑃4))))\n\n=ℐ(∨)(𝖳,ℐ(∨)(ℐ(¬)(ℐ(∧)(ℐ(¬)(ℐ𝜑(𝑃1)),𝜑(𝑃2))),ℐ(∧)(𝖳,𝖥)))\n\n=ℐ(∨)(𝖳,ℐ(∨)(ℐ(¬)(ℐ(∧)(ℐ(¬)(𝜑(𝑃1)),𝖥)),𝖥))\n\n=ℐ(∨)(𝖳,ℐ(∨)(ℐ(¬)(ℐ(∧)(ℐ(¬)(𝖳),𝖥)),𝖥))\n\n=ℐ(∨)(𝖳,ℐ(∨)(ℐ(¬)(ℐ(∧)(𝖥,𝖥)),𝖥))\n\n=ℐ(∨)(𝖳,ℐ(∨)(ℐ(¬)(𝖥),𝖥))\n\n=ℐ(∨)(𝖳,ℐ(∨)(𝖳,𝖥))\n\n=ℐ(∨)(𝖳,𝖳)\n\n=𝖳\n\n\n\n\n\n▷What a mess!\n\n\n\n:\n12024-12-16\n",
        "sectionId": "69703b1f",
        "archive": "courses/Jacobs/GenCS/course",
        "filepath": "pl0/slides/pl0-semantics-ex.en.xhtml"
    },
    {
        "slideContent": "\nA better mouse-trap:\nTruth Tables\n\n▷Truth tables\nvisualize\ntruth functions:\n\n¬⊤𝖥⊥𝖳\n\n∧⊤⊥⊤𝖳𝖥⊥𝖥𝖥\n\n∨⊤⊥⊤𝖳𝖳⊥𝖳𝖥\n\n\n▷If we are interested in\nvalues\n              for all\nassignments(e.g\n𝑧∧𝑥∨¬(𝑧∧𝑦))\n\n\nassignmentsintermediate resultsfull𝑥 𝑦 𝑧 𝑒1:=𝑧∧𝑦 𝑒2:=¬𝑒1 𝑒3:=𝑧∧𝑥 𝑒3∨𝑒2𝖥 𝖥 𝖥 𝖥𝖳𝖥𝖳𝖥 𝖥 𝖳 𝖥𝖳𝖥𝖳𝖥 𝖳 𝖥 𝖥𝖳𝖥𝖳𝖥 𝖳 𝖳 𝖳𝖥𝖥𝖥𝖳 𝖥 𝖥 𝖥𝖳𝖥𝖳𝖳 𝖥 𝖳 𝖥𝖳𝖳𝖳𝖳 𝖳 𝖥 𝖥𝖳𝖥𝖳𝖳 𝖳 𝖳 𝖳𝖥𝖳𝖳\n\n\n\n:\n12024-12-14\n",
        "sectionId": "69703b1f",
        "archive": "courses/Jacobs/GenCS/course",
        "filepath": "pl0/slides/truth-tables.en.xhtml"
    },
    {
        "slideContent": "\nHair Color in\nPropositional Logic\n\n▷There are three persons, Stefan, Nicole, and Jochen.\n\n\n1.Their hair colors are black, red, or green.\n\n\n2.Their study subjects are AI, Physics, or Chinese at least one studies AI.\n\n\n(a)Persons with red or green hair do not study AI.\n\n\n(b)Neither the Physics nor the Chinese students have black hair.\n\n\n(c)Of the two male persons, one studies Physics, and the other studies Chinese.\n\n\nQuestion\n                Who studies AI?(A) Stefan(B) Nicole\n(C) Jochen\n(D) Nobody\n\n\n▷\n\n▷AnswerYou can solve this using\nPL0, if we accept\n𝑏𝑙𝑎(𝑆), etc. as\npropositional variables.\n\n\nWe first\nexpress\n                  what we\nknow: For every\n𝑥∊{𝑆,𝑁,𝐽}\n                  (Stefan, Nicole, Jochen) we have\n\n\n1.𝑏𝑙𝑎(𝑥)∨𝑟𝑒𝑑(𝑥)∨𝑔𝑟𝑒(𝑥);(note: three\nformulae)\n\n\n2.𝑎𝑖(𝑥)∨𝑝ℎ𝑦(𝑥)∨𝑐ℎ𝑖(𝑥)\n                  and\n𝑎𝑖(𝑆)∨𝑎𝑖(𝑁)∨𝑎𝑖(𝐽)\n\n\n(a)𝑎𝑖(𝑥)⇒¬𝑟𝑒𝑑(𝑥)∧¬𝑔𝑟𝑒(𝑥).\n\n\n(b)𝑝ℎ𝑦(𝑥)⇒¬𝑏𝑙𝑎(𝑥)\n                  and\n𝑐ℎ𝑖(𝑥)⇒¬𝑏𝑙𝑎(𝑥).\n\n\n(c)𝑝ℎ𝑦(𝑆)∧𝑐ℎ𝑖(𝐽)∨𝑝ℎ𝑦(𝐽)∧𝑐ℎ𝑖(𝑆).\n\n\nNow, we obtain new\nknowledge\n                  via\nentailment\n                  steps:\n\n\n3.1. together with 2.1\nentails\n                  that\n𝑎𝑖(𝑥)⇒𝑏𝑙𝑎(𝑥)\n                  for every\n𝑥∊{𝑆,𝑁,𝐽},\n\n\n4.thus\n¬𝑏𝑙𝑎(𝑆)∧¬𝑏𝑙𝑎(𝐽)\n                  by 3. and 2.2 and\n\n\n5.so\n¬𝑎𝑖(𝑆)∧¬𝑎𝑖(𝐽)\n                  by 3. and 4.\n\n\n6.With 2.3 the latter\nentails\n𝑎𝑖(𝑁).\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "69703b1f",
        "archive": "courses/FAU/AI/course",
        "filepath": "logic/quest/hair-color.en.xhtml"
    },
    {
        "slideContent": "\nA Simple Formal System: Prop. Logic with Hilbert-Calculus\n\n▷Formulae\n                  Built from\npropositional variables:\n𝑃,𝑄,𝑅...\n                  and\nimplication:\n⇒\n\n\n▷Semantics\nℐ𝜑(𝑃)=𝜑(𝑃)\n                  and\nℐ𝜑(𝐀⇒𝐁)=𝖳, iff\nℐ𝜑(𝐀)=𝖥\n                  or\nℐ𝜑(𝐁)=𝖳.\n\n\n▷\n                  The\nHilbert calculus\nℋ0\n                  consists of the\ninference rules:\n𝑃⇒𝑄⇒𝑃K(𝑃⇒𝑄⇒𝑅)⇒(𝑃⇒𝑄)⇒𝑃⇒𝑅S𝐀⇒𝐁𝐀𝐁MP𝐀[𝐁/𝑋](𝐀)Subst\n\n▷A\nℋ0\ntheorem\n𝐂⇒𝐂\n                  and its\nproof\n\n\nProof:\nWe show that\n∅⊢ℋ0𝐂⇒𝐂\n\n\n\n1.(𝐂⇒(𝐂⇒𝐂)⇒𝐂)⇒(𝐂⇒𝐂⇒𝐂)⇒𝐂⇒𝐂\n(S\n                            with\n[𝐂/𝑃],[𝐂⇒𝐂/𝑄],[𝐂/𝑅])\n\n\n\n\n2.𝐂⇒(𝐂⇒𝐂)⇒𝐂(K\n                            with\n[𝐂/𝑃],[𝐂⇒𝐂/𝑄])\n\n\n\n\n3.(𝐂⇒𝐂⇒𝐂)⇒𝐂⇒𝐂\n(MP\n                            on P.1 and P.2)\n\n\n\n\n4.𝐂⇒𝐂⇒𝐂(K\n                            with\n[𝐂/𝑃],[𝐂/𝑄])\n\n\n\n\n5.𝐂⇒𝐂(MP\n                            on P.3 and P.4)\n\n\n\n:\n12024-12-14\n",
        "sectionId": "941d6763",
        "archive": "courses/Jacobs/GenCS/course",
        "filepath": "pl0/slides/HilbertCalc.en.xhtml"
    },
    {
        "slideContent": "\nSoundness and Completeness\n\n▷Soundness&#160;and&#160;Completeness&#160;of&#160;Logical&#160;Calculi\n\n\n▷Goal\n                  Find\ncalculi\n𝐶, such that\n⊢𝐶𝐀\n                  iff\n⊨𝐀(provability and validity coincide)\n\n\n▷To TRUTH through PROOF(CALCULEMUS [Leibniz\n∼1680])\n\n\n▷\n\n\n:\n12024-12-14\n",
        "sectionId": "941d6763",
        "archive": "courses/Jacobs/GenCS/course",
        "filepath": "logic/slides/calculi-properties.en.xhtml"
    },
    {
        "slideContent": "\nThe Miracle of Logic\n\n▷\nPurely formal derivations are true in the real world!\n\n\n\n\n\n:\n12024-12-15\n",
        "sectionId": "941d6763",
        "archive": "courses/Jacobs/GenCS/course",
        "filepath": "logic/slides/miracle-of-logics.en.xhtml"
    },
    {
        "slideContent": "\nCalculi: Natural Deduction (𝒩𝒟0; Gentzen [Gen34])\n\n▷Idea\n𝒩𝒟0\n                  tries to mimic human argumentation for\ntheorem proving.\n\n\n▷\n                  The\npropositional natural deduction calculus\n𝒩𝒟0\n                  has\ninference rules\n                  for the\nintroduction\n                  and\nelimination\n                  of\nconnectives:\n\n\nIntroduction Elimination Axiom𝐀𝐁𝐀∧𝐁𝒩𝒟0∧𝐼 𝐀∧𝐁𝐀𝒩𝒟0∧𝐸𝑙𝐀∧𝐁𝐁𝒩𝒟0∧𝐸𝑟 𝐀∨¬𝐀𝒩𝒟0TND\n[𝐀]1\n\n\n𝐁\n\n𝐀⇒𝐁𝒩𝒟0⇒𝐼1 𝐀⇒𝐁𝐀𝐁𝒩𝒟0⇒𝐸 \n\n\n𝒩𝒟0⇒𝐼𝑎\n                  proves\n𝐀⇒𝐁\n                  by exhibiting a\n𝒩𝒟0\nderivation\n𝒟\n                  (depicted by the double horizontal lines) of\n𝐁\n                  from the\nlocal hypothesis\n𝐀;\n𝒩𝒟0⇒𝐼𝑎\n                  then\ndischarges\n                  (get rid of\n𝐀, which can only be used in\n𝒟) the\nhypothesis\n                  and\nconcludes\n𝐀⇒𝐁. This mode of reasoning is called\nhypothetical reasoning.\n\n\n▷Given a set\nℋ⊆𝑤𝑓𝑓0(𝒱0)\n                  of\nassumptions\n                  and a\nconclusion\n𝐂, we write\nℋ⊢𝒩𝒟0𝐂, iff there is a\n𝒩𝒟0\nderivation\ntree\n                  whose\nleaves\n                  are in\nℋ.\n\n\n▷Note𝒩𝒟0TND\n                  is used only in\nclassical logic.\n(otherwise\nconstructive/intuitionistic)\n\n\n\n:\n12024-12-14\n",
        "sectionId": "79375f62",
        "archive": "courses/Jacobs/GenCS/course",
        "filepath": "pl0/slides/nd.en.xhtml"
    },
    {
        "slideContent": "\nNatural Deduction: Examples\n\n▷Inference with Local Hypotheses\n\n\n\n\n\n[𝐀∧𝐁]1\n𝒩𝒟0∧𝐸𝑟\n\n𝐁\n\n\n[𝐀∧𝐁]1\n𝒩𝒟0∧𝐸𝑙\n\n𝐀\n\n\n𝒩𝒟0∧𝐼\n\n𝐁∧𝐀\n\n\n𝒩𝒟0⇒𝐼1\n\n𝐀∧𝐁⇒𝐁∧𝐀\n\n\n\n[𝐴]1[𝐵]2\n\n𝐴\n𝒩𝒟0⇒𝐼2\n\n𝐵⇒𝐴\n\n\n𝒩𝒟0⇒𝐼1\n\n𝐴⇒𝐵⇒𝐴\n\n\n\n\n\n\n:\n12024-12-15\n",
        "sectionId": "79375f62",
        "archive": "courses/Jacobs/GenCS/course",
        "filepath": "pl0/slides/nd-ex.en.xhtml"
    },
    {
        "slideContent": "\nA Deduction Theorem for\n𝒩𝒟0\n\n▷\nℋ,𝐀⊢𝒩𝒟0𝐁, iff\nℋ⊢𝒩𝒟0𝐀⇒𝐁.\n\n\n▷Proof:\nWe show the two directions separately\n\n\n\n1.If\nℋ,𝐀⊢𝒩𝒟0𝐁, then\nℋ⊢𝒩𝒟0𝐀⇒𝐁\n                    by\n𝒩𝒟0⇒𝐼, and\n\n\n\n\n2.If\nℋ⊢𝒩𝒟0𝐀⇒𝐁, then\nℋ,𝐀⊢𝒩𝒟0𝐀⇒𝐁\n                    by weakening and\nℋ,𝐀⊢𝒩𝒟0𝐁\n                    by\n𝒩𝒟0⇒𝐸.\n\n\n\n:\n12024-12-15\n",
        "sectionId": "79375f62",
        "archive": "courses/Jacobs/GenCS/course",
        "filepath": "pl0/slides/nd-deduction-thm.en.xhtml"
    },
    {
        "slideContent": "\nMore Rules for Natural Deduction\n\n▷Note\n𝒩𝒟0\n                  does not try to be minimal, but comfortable to work in!\n\n\n▷\n𝒩𝒟0\n                  has the following additional\ninference rules\n                  for the remaining\nconnectives.\n𝐀𝐀∨𝐁𝒩𝒟0∨𝐼𝑙𝐁𝐀∨𝐁𝒩𝒟0∨𝐼𝑟𝐀∨𝐁[𝐀]1\n...\n𝐂[𝐁]1\n...\n𝐂𝐂𝒩𝒟0∨𝐸1[𝐀]1\n...\n𝐂[𝐀]1\n...\n¬𝐂¬𝐀𝒩𝒟0¬ℐ1¬¬𝐀𝐀𝒩𝒟0¬ℰ¬𝐀𝐀𝐹𝒩𝒟0𝐹𝐼𝐹𝐀𝒩𝒟0𝐹𝐸\n\n▷Again𝒩𝒟0¬ℰ\n                  is used only in\nclassical logic\n(otherwise\nconstructive/intuitionistic)\n\n\n\n:\n12024-12-14\n",
        "sectionId": "79375f62",
        "archive": "courses/Jacobs/GenCS/course",
        "filepath": "pl0/slides/more-ndrules.en.xhtml"
    },
    {
        "slideContent": "\nNatural Deduction in Sequent Calculus Formulation\n\n▷Idea\n                  Represent\nhypotheses\n                  explicitly.(lift calculus to judgments)\n\n\n▷\n                  A\njudgment\n                  is a meta statement about the provability of\npropositions.\n\n\n▷\n                  A\nsequent\n                  is a\njudgment\n                  of the form\nℋ⊢𝐀\n                  about the provability of the\nformula\n𝐀\n                  from the set\nℋ\n                  of\nhypotheses. We write\n⊢𝐀\n                  for\n∅⊢𝐀.\n\n\n▷Idea\n                  Reformulate\n𝒩𝒟0\ninference rules\n                  so that they act on\nsequents.\n\n\n▷We give the\nsequent\n                  style version of\n??:\n\n\n\n\n\n\n\n𝒩𝒟⊢0Ax\n\n𝐀∧𝐁⊢𝐀∧𝐁\n\n\n𝒩𝒟⊢0∧𝐸𝑟\n\n𝐀∧𝐁⊢𝐁\n\n\n\n\n𝒩𝒟⊢0Ax\n\n𝐀∧𝐁⊢𝐀∧𝐁\n\n\n𝒩𝒟⊢0∧𝐸𝑙\n\n𝐀∧𝐁⊢𝐀\n\n\n𝒩𝒟⊢0∧𝐼\n\n𝐀∧𝐁⊢𝐁∧𝐀\n\n\n𝒩𝒟⊢0⇒𝐼\n\n⊢𝐀∧𝐁⇒𝐁∧𝐀\n\n\n\n\n\n\n\n𝒩𝒟⊢0Ax\n\n𝐀,𝐁⊢𝐀\n\n\n𝒩𝒟⊢0⇒𝐼\n\n𝐀⊢𝐁⇒𝐀\n\n\n𝒩𝒟⊢0⇒𝐼\n\n⊢𝐀⇒𝐁⇒𝐀\n\n\n\n\n\n▷NoteEven though the antecedent of a\nsequent\n                  is written like a\nsequences, it is actually a\nset. In particular, we can\npermute\n                  and duplicate\nmembers\n                  at will.\n\n\n\n:\n12024-12-14\n",
        "sectionId": "79375f62",
        "archive": "courses/Jacobs/GenCS/course",
        "filepath": "pl0/slides/nd-sequents.en.xhtml"
    },
    {
        "slideContent": "\nSequent-Style Rules for Natural Deduction\n\n▷\n                  The following\ninference rules\n                  make up the\npropositional sequent style natural deduction calculus\n𝒩𝒟⊢0:\nΓ,𝐀⊢𝐀𝒩𝒟⊢0AxΓ⊢𝐁Γ,𝐀⊢𝐁𝒩𝒟⊢0weakenΓ⊢𝐀∨¬𝐀𝒩𝒟⊢0TNDΓ⊢𝐀Γ⊢𝐁Γ⊢𝐀∧𝐁𝒩𝒟⊢0∧𝐼Γ⊢𝐀∧𝐁Γ⊢𝐀𝒩𝒟⊢0∧𝐸𝑙Γ⊢𝐀∧𝐁Γ⊢𝐁𝒩𝒟⊢0∧𝐸𝑟Γ⊢𝐀Γ⊢𝐀∨𝐁𝒩𝒟⊢0∨𝐼𝑙Γ⊢𝐁Γ⊢𝐀∨𝐁𝒩𝒟⊢0∨𝐼𝑟Γ⊢𝐀∨𝐁Γ,𝐀⊢𝐂Γ,𝐁⊢𝐂Γ⊢𝐂𝒩𝒟⊢0∨𝐸Γ,𝐀⊢𝐁Γ⊢𝐀⇒𝐁𝒩𝒟⊢0⇒𝐼Γ⊢𝐀⇒𝐁Γ⊢𝐀Γ⊢𝐁𝒩𝒟⊢0⇒𝐸Γ,𝐀⊢𝐹Γ⊢¬𝐀𝒩𝒟⊢0¬ℐΓ⊢¬¬𝐀Γ⊢𝐀𝒩𝒟⊢0¬ℰ𝒩𝒟⊢0𝐹𝐼Γ⊢¬𝐀Γ⊢𝐀Γ⊢𝐹𝒩𝒟⊢0𝐹𝐸Γ⊢𝐹Γ⊢𝐀\n\n\n\n:\n22024-12-14\n",
        "sectionId": "79375f62",
        "archive": "courses/Jacobs/GenCS/course",
        "filepath": "pl0/slides/nd-sequents.en.xhtml"
    },
    {
        "slideContent": "\nLinearized Notation for (Sequent-Style) ND Proofs\n\n▷Linearized notation for sequent-style ND proofs1.ℋ1⊢𝐀1(𝒥1)2.ℋ2⊢𝐀2(𝒥2)3.ℋ3⊢𝐀3(𝒥31,2)\ncorresponds to\nℋ1⊢𝐀1ℋ2⊢𝐀2ℋ3⊢𝐀3ℛ\n\n\n▷\n                  We show a linearized version of the\n𝒩𝒟0\n                  examples\n??\n\n\n\n\n\n\n\n𝒩𝒟⊢0Ax\n\n𝐀∧𝐁⊢𝐀∧𝐁\n\n\n𝒩𝒟⊢0∧𝐸𝑟\n\n𝐀∧𝐁⊢𝐁\n\n\n\n\n𝒩𝒟⊢0Ax\n\n𝐀∧𝐁⊢𝐀∧𝐁\n\n\n𝒩𝒟⊢0∧𝐸𝑙\n\n𝐀∧𝐁⊢𝐀\n\n\n𝒩𝒟⊢0∧𝐼\n\n𝐀∧𝐁⊢𝐁∧𝐀\n\n\n𝒩𝒟⊢0⇒𝐼\n\n⊢𝐀∧𝐁⇒𝐁∧𝐀\n\n\n\n\n\n\n\n𝒩𝒟⊢0Ax\n\n𝐀,𝐁⊢𝐀\n\n\n𝒩𝒟⊢0⇒𝐼\n\n𝐀⊢𝐁⇒𝐀\n\n\n𝒩𝒟⊢0⇒𝐼\n\n⊢𝐀⇒𝐁⇒𝐀\n\n#ℎ𝑦𝑝⊢𝑓𝑜𝑟𝑚𝑢𝑙𝑎𝑁𝐷𝑗𝑢𝑠𝑡1.1⊢𝐀∧𝐁𝒩𝒟⊢0Ax2.1⊢𝐁𝒩𝒟⊢0∧𝐸𝑟13.1⊢𝐀𝒩𝒟⊢0∧𝐸𝑙14.1⊢𝐁∧𝐀𝒩𝒟⊢0∧𝐼2,35.⊢𝐀∧𝐁⇒𝐁∧𝐀𝒩𝒟⊢0⇒𝐼4\n#ℎ𝑦𝑝⊢𝑓𝑜𝑟𝑚𝑢𝑙𝑎𝑁𝐷𝑗𝑢𝑠𝑡1.1⊢𝐀𝒩𝒟⊢0Ax2.2⊢𝐁𝒩𝒟⊢0Ax3.1,2⊢𝐀𝒩𝒟⊢0weaken1,24.1⊢𝐁⇒𝐀𝒩𝒟⊢0⇒𝐼35.⊢𝐀⇒𝐁⇒𝐀𝒩𝒟⊢0⇒𝐼4\n\n\n\n\n:\n12024-12-14\n",
        "sectionId": "79375f62",
        "archive": "courses/Jacobs/GenCS/course",
        "filepath": "logic/slides/sequent-calc-linearized.en.xhtml"
    },
    {
        "slideContent": "\nIssues with Propositional Logic\n\n▷Awkward to write for humansE.g., to model the\nWumpus\n                world we had to make a copy of the rules for every cell ...\n𝑅1:=¬𝑆1,1⇒¬𝑊1,1∧¬𝑊1,2∧¬𝑊2,1\n𝑅2:=¬𝑆2,1⇒¬𝑊1,1∧¬𝑊2,1∧¬𝑊2,2∧¬𝑊3,1\n𝑅3:=¬𝑆1,2⇒¬𝑊1,1∧¬𝑊1,2∧¬𝑊2,2∧¬𝑊1,3\n\nCompared to\n\n\nCell adjacent to\nWumpus: Stench (else: None)\n\n\nthat is not a very nice description language ...\n\n▷Can we design a more human-like logic?\n                Yep!\n\n\n▷Idea\n                Introduce explict representations for\n\n\n▷individuals, e.g. the wumpus, the gold, numbers, ...\n\n▷functions on individuals, e.g. the cell at\n𝑖,𝑗, ...\n\n▷relations between them, e.g. being in a cell, being adjacent, ...\n\nThis is essentially the same as\nPL0, so we can reuse the\ncalculi.\n(up next)\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-16\n",
        "sectionId": "ddb2b2cd",
        "archive": "courses/FAU/AI/course",
        "filepath": "logic/slides/proplog-issues.en.xhtml"
    },
    {
        "slideContent": "\nIndividuals and their Properties/Relations\n\n▷Observation\n                  We want to talk about\nindividuals\n                  like Stefan, Nicole, and Jochenand their properties, e.g. being blond, or studying AIand relationships, e.g. that\nStefan loves Nicole.\n\n\n▷Idea\n                  Re-use\nPL0, but replace\npropositional variables\n                  with something more expressive!\n(instead of fancy variable name trick)\n\n\n▷\n\n\n\n:\nComputational Logic12024-12-14\n",
        "sectionId": "ddb2b2cd",
        "archive": "courses/Jacobs/CompLog",
        "filepath": "pl1/slides/plnq.en.xhtml"
    },
    {
        "slideContent": "\nA\nGrammar\n              for\nPLnq\n\n▷The\nformulae\n                  of\nPLnq\n                  are given by the following\ngrammar\n\nfunction constants\n𝑓𝑘∊Σ𝑘𝑓\npredicate constants\n𝑝𝑘∊Σ𝑝𝑘terms𝑡::=𝑓0constant|𝑓𝑘(𝑡1,...,𝑡𝑘)applicationformulae𝐀::=𝑝𝑘(𝑡1,...,𝑡𝑘)atomic|¬𝐀negation|𝐀1∧𝐀2conjunction\n\n\n:\nComputational Logic22024-12-14\n",
        "sectionId": "ddb2b2cd",
        "archive": "courses/Jacobs/CompLog",
        "filepath": "pl1/slides/plnq.en.xhtml"
    },
    {
        "slideContent": "\nPLnq\n              Semantics\n\n▷\nDomains\n𝒟0={𝖳,𝖥}\n                  of\ntruth values\n                  and\n𝒟𝜄≠∅\n                  of\nindividuals.\n\n\n▷\nInterpretation\nℐ\nassigns\nvalues\n                  to\nconstants, e.g.\n\n\n▷ℐ(¬):𝒟0→𝒟0;𝖳↦𝖥;𝖥↦𝖳\n                  and\nℐ(∧)=...(as in\nPL0)\n\n\n▷ℐ:Σ0𝑓→𝒟𝜄(interpret individual\nconstants\n                      as\nindividuals)\n\n\n▷ℐ:Σ𝑘𝑓→𝒟𝜄𝑘→𝒟𝜄(interpret\nfunction constants\n                      as\nfunctions)\n\n\n▷ℐ:Σ𝑝𝑘→𝒫(𝒟𝜄𝑘)(interpret\npredicate constants\n                      as\nrelations)\n\n\n▷The\nvalue function\nℐ\nassigns\nvalues\n                  to\nformulae:(recursively)\n\n\n▷ℐ(𝑓(𝐀1,...,𝐀𝑘)):=ℐ(𝑓)(ℐ(𝐀1),...,ℐ(𝐀𝑘))\n\n\n▷ℐ(𝑝(𝐀1,...,𝐀𝑘)):=𝖳, iff\n〈ℐ(𝐀1),...,ℐ(𝐀𝑘)〉∊ℐ(𝑝)\n\n\n▷ℐ(¬𝐀)=ℐ(¬)(ℐ(𝐀))\n                  and\nℐ(𝐀∧𝐁)=ℐ(∧)(ℐ(𝐀),ℐ(𝐆))(just as in\nPL0)\n\n\n▷\nModel:\nℳ=〈𝒟𝜄,ℐ〉\n                  varies in\n𝒟𝜄\n                  and\nℐ.\n\n\n▷\nPLnq\n                  is isomorphic to\nPL0(interpret\natoms\n                      as\nprop. variables)\n\n\n\n:\nComputational Logic12024-12-14\n",
        "sectionId": "ddb2b2cd",
        "archive": "courses/Jacobs/CompLog",
        "filepath": "pl1/slides/plnq-semantics.en.xhtml"
    },
    {
        "slideContent": "\nA Model for\nPLnq\n\n▷\n                  Let\n𝐿:={𝑎,𝑏,𝑐,𝑑,𝑒,𝑃,𝑄,𝑅,𝑆}, we set the\nuniverse\n𝒟:={♣,♠,♡,♢}, and specify the\ninterpretation\nfunction\nℐ\n                  by setting\n\n\n▷𝑎↦♣,\n𝑏↦♠,\n𝑐↦♡,\n𝑑↦♢, and\n𝑒↦♢\n                  for\nconstants,\n\n\n▷𝑃↦{♣,♠}\n                  and\n𝑄↦{♠,♢}, for unary\npredicate constants.\n\n\n▷𝑅↦{〈♡,♢〉,〈♢,♡〉}, and\n𝑆↦{〈♢,♠〉,〈♠,♣〉}\n                  for binary\npredicate constants.\n\n\n▷Computing\nMeaning\n                    in this Model\n\n\n▷ℐ(𝑅(𝑎,𝑏)∧𝑃(𝑐))=𝖳, iff\n\n\n▷ℐ(𝑅(𝑎,𝑏))=𝖳\n                  and\nℐ(𝑃(𝑐))=𝖳, iff\n\n\n▷〈ℐ(𝑎),ℐ(𝑏)〉∊ℐ(𝑅)\n                  and\nℐ(𝑐)∊ℐ(𝑃), iff\n\n\n▷〈♣,♠〉∊{〈♡,♢〉,〈♢,♡〉}\n                  and\n♡∊{♣,♠}\n\n\nSo,\nℐ(𝑅(𝑎,𝑏)∧𝑃(𝑐))=𝖥.\n\n\n\n:\nComputational Logic12024-12-15\n",
        "sectionId": "ddb2b2cd",
        "archive": "courses/Jacobs/CompLog",
        "filepath": "pl1/slides/plnq-model-example.en.xhtml"
    },
    {
        "slideContent": "\nPLnq\n              and\nPL0\n              are Isomorphic\n\n▷Observation\n                  For every choice of\nΣ\n                  of\nsignature, the set\n𝒜Σ\n                  of\natomic\nPLnq\nformulae\n                  is\ncountable, so there is a\n𝒱Σ⊆𝒱0\n                  and a\nbijection\n𝜃Σ:𝒜Σ→𝒱Σ.\n\n𝜃Σ\n                  can be extended to\nformulae\n                  as\nPLnq\n                  and\nPL0\n                  share\nconnectives.\n\n\n▷\n                  For every\nmodel\nℳ=〈𝒟𝜄,ℐ〉, there is a\nvariable assignment\n𝜑ℳ, such that\nℐ𝜑ℳ(𝐀)=ℐ(𝐀).\n\n\n▷Proof sketch:\n                We just define\n𝜑ℳ(𝑋):=ℐ(𝜃Σ−1(𝑋))\n\n\n▷\n                  For every\nvariable assignment\n𝜓:𝒱Σ→{𝖳,𝖥}\n                  there is a\nmodel\nℳ𝜓=〈𝒟𝜓,ℐ𝜓〉, such that\nℐ𝜓(𝐀)=ℐ𝜓(𝐀).\n\n\n▷Proof sketch:\n                see next slide\n\n\n▷\nPLnq\n                  is isomorphic to\nPL0, i.e. the following\ndiagram\ncommutes:\n\n\n\n\n\n\nPLnq(Σ)  \nPL0(𝒜Σ)  \n\n\n\n\n\n\n\n\n\n\n𝜃Σ  \n〈𝒟𝜓,ℐ𝜓〉  \n𝒱Σ→{𝖳,𝖥}  \n\n\n\n\n\n\n\n\n\n\n𝜓↦ℳ𝜓  \n\n\n\n\n\n\n\n\n\n\nℐ𝜓()  \n\n\n\n\n\n\n\n\n\n\nℐ𝜑ℳ()  \n\n\n\n\n\n\n▷Note\n                  This constellation with a language isomorphism and a corresponding model isomorphism (in converse direction) is typical for a logic isomorphism.\n\n\n\n:\nComputational Logic12024-12-14\n",
        "sectionId": "ddb2b2cd",
        "archive": "courses/Jacobs/CompLog",
        "filepath": "pl1/slides/plnq-pl0-isomorphic.en.xhtml"
    },
    {
        "slideContent": "\nValuation and Satisfiability\n\n▷\n                  For every\nvariable assignment\n𝜓:𝒱Σ→{𝖳,𝖥}\n                  there is a\nmodel\nℳ𝜓=〈𝒟𝜓,ℐ𝜓〉, such that\nℐ𝜓(𝐀)=ℐ𝜓(𝐀).\n\n\n▷Proof:\nWe construct\nℳ𝜓=〈𝒟𝜓,ℐ𝜓〉\n                  and show that it works as desired.\n\n\n\n1.Let\n𝒟𝜓\n                    be the set of\nPLnq\n                    terms over\nΣ, and\n\n▷ℐ𝜓(𝑓):𝒟𝜄𝑘→𝒟𝜓𝑘;〈𝐀1,...,𝐀𝑘〉↦𝑓(𝐀1,...,𝐀𝑘)\n                    for\n𝑓∊Σ𝑘𝑓\n\n\n▷ℐ𝜓(𝑝):={〈𝐀1,...,𝐀𝑘〉|𝜓(𝜃𝜓−1𝑝(𝐀1,...,𝐀𝑘))=𝖳}\n                    for\n𝑝∊Σ𝑝.\n\n\n2.We show\nℐ𝜓(𝐀)=𝐀\n                      for terms\n𝐀\n                      by\ninduction\n                      on\n𝐀\n\n\n\n2.1.If\n𝐀=𝑐, then\nℐ𝜓(𝐀)=ℐ𝜓(𝑐)=𝑐=𝐀\n\n\n\n2.2.If\n𝐀=𝑓(𝐀1,...,𝐀𝑛)\n                        thenℐ𝜓(𝐀)=ℐ𝜓(𝑓)(ℐ(𝐀1),...,ℐ(𝐀𝑛))=ℐ𝜓(𝑓)(𝐀1,...,𝐀𝑘)=𝐀.\n\n3.For a\nPLnq\nformula\n𝐀\n                      we show that\nℐ𝜓(𝐀)=ℐ𝜓(𝐀)\n                      by\ninduction\n                      on\n𝐀.\n\n\n\n3.1.If\n𝐀=𝑝(𝐀1,...,𝐀𝑘), then\nℐ𝜓(𝐀)=ℐ𝜓(𝑝)(ℐ(𝐀1),...,ℐ(𝐀𝑛))=𝖳, iff\n〈𝐀1,...,𝐀𝑘〉∊ℐ𝜓(𝑝), iff\n𝜓(𝜃𝜓−1𝐀)=𝖳, so\nℐ𝜓(𝐀)=ℐ𝜓(𝐀)\n                        as desired.\n\n\n\n3.2.If\n𝐀=¬𝐁, then\nℐ𝜓(𝐀)=𝖳, iff\nℐ𝜓(𝐁)=𝖥, iff\nℐ𝜓(𝐁)=ℐ𝜓(𝐁), iff\nℐ𝜓(𝐀)=ℐ𝜓(𝐀).\n\n\n\n3.3.If\n𝐀=𝐁∧𝐂\n                        then we argue similarly\n\n\n\n4.Hence\nℐ𝜓(𝐀)=ℐ𝜓(𝐀)\n                    for all\nPLnq\nformulae\n                    and we have concluded the proof.\n\n\n:\nComputational Logic22024-12-14\n",
        "sectionId": "ddb2b2cd",
        "archive": "courses/Jacobs/CompLog",
        "filepath": "pl1/slides/plnq-pl0-isomorphic.en.xhtml"
    },
    {
        "slideContent": "\nSummary\n\n▷Sometimes, it pays off to think before acting.\n\n\n▷In\nAI, “thinking” is\nimplemented\n            in terms of\nreasoning\n            to\ndeduce\n            new\nknowledge\n            from a\nknowledge base\n            represented in a suitable\nlogic.\n\n\n▷Logic prescribes a\nsyntax\n            for formulas, as well as a\nsemantics\n            prescribing which\ninterpretations\n            satisfy them.\n𝐀\nentails\n𝐁\n            if all\ninterpretations\n            that\nsatisfy\n𝐀\n            also\nsatisfy\n𝐁.\nDeduction\n            is the process of deriving new\nentailed\nformulae.\n\n\n▷Propositional logic\n            formulas are built from\natomic\npropositions, with the\nconnectives\nand,\nor,\nnot.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-16\n",
        "sectionId": "ff0c1079",
        "archive": "courses/FAU/AI/course",
        "filepath": "logic/slides/proplog-concl.en.xhtml"
    },
    {
        "slideContent": "\nIssues with Propositional Logic\n\n▷Time\n                For things that change (e.g.,\nWumpus\n                moving according to certain rules), we need time-indexed propositions (like,\n𝑆2,1𝑡=7) to represent validity over time\n⤳\n                further expansion of the rules.\n\n\n▷Can we design a more human-like logic?Yep\n\n\n▷Predicate logic:\nquantification\n                of\nvariables\n                ranging over\nindividuals.\n(cf.\n??\n                    and\n??)\n\n\n▷...and a whole zoo of logics much more powerful still.\n\n\n▷Note: In applications, propositional\nCNF\n                encodings are generated by\ncomputer\nprograms. This mitigates (but does not remove!) the inconveniences of propositional modeling.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-16\n",
        "sectionId": "ff0c1079",
        "archive": "courses/FAU/AI/course",
        "filepath": "logic/slides/proplog-time.en.xhtml"
    },
    {
        "slideContent": "\nRecap: General Aspects of Propositional Logic\n\n▷There are many ways to define Propositional Logic\n\n\n▷We chose\n∧\n                  and\n¬\n                  as primitive, and many others as defined.\n\n\n▷We could have used\n∨\n                  and\n¬\n                  just as well.\n\n\n▷We could even have used only one\nconnective\n                  e.g. negated conjunction\n↑\n                  or disjunction\n↓\n                  and defined\n∧,\n∨, and\n¬\n                  via\n↑\n                  and\n↓\n                  respectively.\n\n\n\n↑⊤⊥⊤𝖥𝖳⊥𝖳𝖳\n\n↓⊤⊥⊤𝖥𝖥⊥𝖥𝖳\n¬𝑎 𝑎↑𝑎 𝑎↓𝑎𝑎𝑏 𝑎↑𝑏↑𝑎↑𝑏 𝑎↓𝑎𝑏↓𝑏𝑎𝑏 𝑎↑𝑎↑𝑏↑𝑏 𝑎↓𝑏↓𝑎↓𝑏\n\n\n▷Observation\n                  The set\n𝑤𝑓𝑓0(𝒱0)\n                  of\nwell-formed propositional formulae\n                  is a\nformal language\n                  over the\nalphabet\n                  given by\n𝒱0, the connectives, and brackets.\n\n\n▷Recall\n                  We are mostly interested in\n\n\n▷satisfiability\n                  i.e. whether\nℳ⊨𝐀, and\n\n\n▷entailment\n                  i.e whether\n𝐀⊨𝐁.\n\n\n▷ObservationIn particular, the\ninductive/compositional\n                  nature of\n𝑤𝑓𝑓0(𝒱0)\n                  and\nℐ𝜑:𝑤𝑓𝑓0(𝒱0)→𝒟0\n                  are secondary.\n\n\n▷Idea\n                  Concentrate on language, models (ℳ,𝜑), and satisfiability.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "94a94813",
        "archive": "courses/FAU/AI/course",
        "filepath": "logic/slides/pl0-recap.en.xhtml"
    },
    {
        "slideContent": "\nLogical Systems\n\n▷\n\n\n▷Propositional Logic〈𝑤𝑓𝑓(𝑃𝐿0.Σ𝑃𝐿0,𝑃𝐿0.𝒱𝑃𝐿0),𝒦𝑜,|=〉\n                is a\nlogical system, if we define\n𝒦𝑜:=𝒱0⇀𝒟0\n                (the\nset\n                of\nvariable assignments) and\n𝜑|=𝐀\n                iff\nℐ𝜑(𝐀)=𝖳.\n\n\n▷Satisfaction&#160;Relation\n\n\n\n:\n12024-12-16\n",
        "sectionId": "94a94813",
        "archive": "courses/Jacobs/GenCS/course",
        "filepath": "logic/slides/logical-system.en.xhtml"
    },
    {
        "slideContent": "\nDerivation Relations and Inference Rules\n\n▷\n\n\n▷\n\n\n▷Axiom\n\n\n▷Calculus&#160;(Logic)\n\n\n\n:\n12024-12-16\n",
        "sectionId": "94a94813",
        "archive": "courses/Jacobs/GenCS/course",
        "filepath": "logic/slides/calculus-infrules.en.xhtml"
    },
    {
        "slideContent": "\nDerivations\n\n▷Let\nℒ:=〈ℒ,𝒦,⊨〉\n                  be a\nlogical system\n                  and\n𝒞\n                  a\ncalculus\n                  for\nℒ, then a\n𝒞-derivation\n                  of a\nformula\n𝐂∊ℒ\n                  from a set\nℋ⊆ℒ\n                  of\nhypotheses\n                  (write\nℋ⊢𝒞𝐂) is a sequence\n𝐀1,...,𝐀𝑚\n                  of\nℒ-formulae, such that\n\n\n▷𝐀𝑚=𝐂,(derivation culminates in\n𝐂)\n\n\n▷for all\n1≤𝑖≤𝑚, either\n𝐀𝑖∊ℋ, or\n(hypothesis)\n\n\n▷there is an\ninference rule\n𝐀𝑙1...𝐀𝑙𝑘𝐀𝑖\n                  in\n𝒞\n                  with,𝑙𝑗<𝑖\n                  for all\n𝑗≤𝑘.(rule application)\n\n\nWe can also see a\nderivation\n                  as a\nderivation tree, where the\n𝐀𝑙𝑗\n                  are the\nchildren\n                  of the\nnode\n𝐀𝑘.\n\n\n▷\n\n\nIn the propositional Hilbert calculus\nℋ0\n                                    we have the\nderivation\n𝑃⊢ℋ0𝑄⇒𝑃: the sequence is\n𝑃⇒𝑄⇒𝑃,𝑃,𝑄⇒𝑃\n                                    and the corresponding tree on the right.\n\n\n\n\n𝐾\n\n𝑃⇒𝑄⇒𝑃\n𝑃\n𝑀𝑃\n\n𝑄⇒𝑃\n\n\n\n\n\n \n\n\n:\n12024-12-14\n",
        "sectionId": "94a94813",
        "archive": "courses/Jacobs/GenCS/course",
        "filepath": "logic/slides/calculi-proofs.en.xhtml"
    },
    {
        "slideContent": "\nFormal Systems\n\n▷Let\n〈ℒ,𝒦,⊨〉\n                  be a\nlogical system\n                  and\n𝒞\n                  a\ncalculus, then\n⊢𝒞\n                  is a\nderivation relation\n                  and thus\n〈ℒ,𝒦,⊨,⊢𝒞〉\n                  a\nderivation system.\n\n\n▷Therefore we will sometimes also\ncall\n〈ℒ,𝒞,𝒦,⊨〉\n                      a\nformal system, iff\nℒ:=〈ℒ,𝒦,⊨〉\n                      is a\nlogical system, and\n𝒞\n                      a\ncalculus\n                      for\nℒ.\n\n\n▷Formal&#160;Proof\n\n\n▷Admissible&#160;Inference&#160;Rule\n\n\n▷Derivable&#160;Inference&#160;Rule\n\n\n▷\n\n\n\n:\n12024-12-14\n",
        "sectionId": "94a94813",
        "archive": "courses/Jacobs/GenCS/course",
        "filepath": "logic/slides/formal-system.en.xhtml"
    },
    {
        "slideContent": "\nAutomated Deduction as an Agent Inference Procedure\n\n▷Recall\n                  Our knowledge of the cave entails a definite\nWumpus\n                  position!(slide\n??)\n\n\n▷Problem\n                  That was human reasoning, can we build an\nagent function\n                  that does this?\n\n\n▷Answer\n                  As for\nconstraint networks, we use\ninference, here\nresolution/tableaux.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-15\n",
        "sectionId": "ddc5f395",
        "archive": "courses/FAU/AI/course",
        "filepath": "logic/slides/atp-inference.en.xhtml"
    },
    {
        "slideContent": "\nUnsatisfiability Theorem\n\n▷Unsatisfiability Theorem\nℋ⊨𝐀\n                  iff\nℋ∪{¬𝐀}\n                  is\nunsatisfiable.\n\n\n▷Proof:\nWe prove both directions separately\n\n1.“⇒”: Say\nℋ⊨𝐀\n\n\n\n1.1.For any\n𝜑\n                        with\n𝜑|=ℋ\n                        we have\n𝜑|=𝐀\n                        and thus\n𝜑̸=(¬𝐀).\n\n2.“⇐”: Say\nℋ∪{¬𝐀}\n                      is\nunsatisfiable.\n\n\n\n2.1.For any\n𝜑\n                        with\n𝜑|=ℋ\n                        we have\n𝜑̸=(¬𝐀)\n                        and thus\n𝜑|=𝐀.\n\n▷\nEntailment\n                  can be tested via\nsatisfiability.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "ddc5f395",
        "archive": "courses/FAU/AI/course",
        "filepath": "logic/slides/unsatisfiability-theorem.en.xhtml"
    },
    {
        "slideContent": "\nTest Calculi: A Paradigm for Automating Inference\n\n▷\n\n\n▷\nAutomated theorem proving\n                  (ATP) is the\nautomation\n                  of\ntheorem proving\n\n\n▷Idea\n                  A\nset\nℋ\n                  of\nhypotheses\n                  and a\nconjecture\n𝐀\n                  induce a\nsearch problem\nΠ𝒞ℋ|=𝐀:=〈𝒮,𝒜,𝒯,ℐ,𝒢〉, where the\nstates\n𝒮\n                      are\nsets\n                      of\nformulae, the\nactions\n𝒜\n                      are the\ninference rules\n                      from\n𝒞, the\ninitial state\nℐ=ℋ, and the\ngoal states\n                      are those with\n𝐀∊𝒮.\n\n\n▷Problem\nATP\n                  as a\nsearch problem\n                  does not admit good\nheuristics, since these need to take the\nconjecture\n𝒜\n                  into account.\n\n\n▷Idea\n                  Turn the search around — using the unsatisfiability theorem (??).\n\n\n▷\n\n\n▷Observation\n                  A\ntest calculus\n𝒞\n                  induces a\nsearch problem\n                  where the\ninitial state\n                  is\nℋ∪{¬𝐀}\n                  and\n𝑆∊𝒮\n                  is a\ngoal state\n                  iff\n⊥∊𝑆.(proximity of\n⊥\n                      easier for\nheuristics)\n\n\n▷Searching for\n⊥\n              admits simple heuristics, e.g. size reduction.\n(⊥\n                  minimal)\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "ddc5f395",
        "archive": "courses/FAU/AI/course",
        "filepath": "logic/slides/test-calculus.en.xhtml"
    },
    {
        "slideContent": "\nSummary\n\n▷Every propositional formula can be brought into\nconjunctive normal form\n            (CNF), which can be identified with a set of\nclauses.\n\n\n▷The\ntableau\n            and\nresolution calculi\n            are deduction procedures based on trying to\nderive\n            a\ncontradiction\n            from the negated theorem (a\nclosed\ntableau\n            or the\nempty clause). They are\nrefutation complete, and can be used to prove\nKB⊨𝐀\n            by showing that\nKB∪{¬𝐀}\n            is\nunsatisfiable.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-16\n",
        "sectionId": "ddc5f395",
        "archive": "courses/FAU/AI/course",
        "filepath": "logic/slides/atp0-concl.en.xhtml"
    },
    {
        "slideContent": "\nRecap: Atoms and Literals\n\n▷Atomic&#160;Formula\n\n\n▷\n\n\n▷\n\n\n▷Intuition\n                  To\nsatisfy\n                  a\nformula, we make it “true”. To satisfy a\nlabeled formula\n𝐀𝛼, it must have the truth value\n𝛼.\n\n\n▷\n\n\n\n:\n12024-12-14\n",
        "sectionId": "e7201c",
        "archive": "courses/Jacobs/GenCS/course",
        "filepath": "atp0/slides/labeled-formulae.en.xhtml"
    },
    {
        "slideContent": "\nAlternative Definition: Literals\n\n▷NoteLiterals\n                  are often defined without recurring to\nlabeled formulae:\n\n\n▷\n                  A\nliteral\n                  is an\natom\n𝐀\n                  (positive\nliteral) or\nnegated\natom\n¬𝐀\n                  (negative\nliteral).\n𝐀\n                  and\n¬𝐀\n                  are\nopposite literals.\n\n\n▷NoteThis notion of\nliteral\n                  is equivalent to the\nlabeled formulae-notion of\nliteral, but does not generalize as well to\nlogics\n                  with more than two\ntruth values.\n\n\n\n:\n12024-12-14\n",
        "sectionId": "e7201c",
        "archive": "courses/Jacobs/GenCS/course",
        "filepath": "atp0/slides/literals.en.xhtml"
    },
    {
        "slideContent": "\nNormal Forms\n\n▷There are two quintessential normal forms for propositional formulae:\n(there are others as well)\n\n\n▷A\nformula\n                  is in\nconjunctive normal form\n                  (CNF) if it is a\nconjunction\n                  of\ndisjunctions\n                  of\nliterals: i.e. if it is of the form\n⋀𝑖=1𝑛⋁𝑗=1𝑚𝑖𝑙𝑖𝑗\n\n\n▷A\nformula\n                  is in\ndisjunctive normal form\n                  (DNF) if it is a\ndisjunction\n                  of\nconjunctions\n                  of\nliterals: i.e. if it is of the form\n⋁𝑖=1𝑛⋀𝑗=1𝑚𝑖𝑙𝑖𝑗\n\n\n▷\n                  Every\nformula\n                  has\nequivalent\nformulae\n                  in\nCNF\n                  and\nDNF.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "e7201c",
        "archive": "courses/FAU/AI/course",
        "filepath": "logic/slides/pl0-normal-forms.en.xhtml"
    },
    {
        "slideContent": "\nTest Calculi: Tableaux and Model Generation\n\n▷Idea\n                  A\ntableau calculus\n                  is a\ntest calculus\n                  that\n\n\n▷analyzes a\nlabeled formulae\n                  in a tree to determine\nsatisfiability,\n\n\n▷its\nbranches\n                  correspond to\nvaluations\n                  (⤳\nmodels).\n\n\n▷Tableau calculi\n                    try to construct models for\nlabeled formulae:\n\n\nTableau refutation (Validity) Model generation (Satisfiability)⊨𝑃∧𝑄⇒𝑄∧𝑃 ⊨𝑃∧(𝑄∨¬𝑅)∧¬𝑄\n(𝑃∧𝑄⇒𝑄∧𝑃)𝖥(𝑃∧𝑄)𝖳(𝑄∧𝑃)𝖥𝑃𝖳𝑄𝖳𝑃𝖥⊥𝑄𝖥⊥\n \n(𝑃∧(𝑄∨¬𝑅)∧¬𝑄)𝖳(𝑃∧(𝑄∨¬𝑅))𝖳¬𝑄𝖳𝑄𝖥𝑃𝖳(𝑄∨¬𝑅)𝖳𝑄𝖳⊥¬𝑅𝖳𝑅𝖥\n No Model Herbrand model {𝑃𝖳,𝑄𝖥,𝑅𝖥}𝜑:={𝑃↦𝖳,𝑄↦𝖥,𝑅↦𝖥}\n\n\n▷Idea\nOpen\nbranches\n                  in\nsaturated\ntableaux\n                  yield\nmodels.\n\n\n▷Algorithm\n                  Fully expand all possible\ntableaux,(no rule can be applied)\n\n\n▷Satisfiable, iff there are\nopen\nbranches(correspond to\nmodels)\n\n\n\n:\n12024-12-15\n",
        "sectionId": "511dbc0f",
        "archive": "courses/Jacobs/GenCS/course",
        "filepath": "atp0/slides/tableaux-motivation.en.xhtml"
    },
    {
        "slideContent": "\nAnalytical Tableaux (Formal Treatment of\n𝒯0)\n\n▷Idea\n                  A\ntest calculus\n                  where\n\n\n▷A\nlabeled formula\n                  is analyzed in a\ntree\n                  to determine\nsatisfiability,\n\n\n▷branches\n                  correspond to valuations (models)\n\n\n▷\n                  The\npropositional tableau calculus\n𝒯0\n                  has two\ninference rules\n                  per\nconnective(one for each possible label)\n(𝐀∧𝐁)𝖳𝐀𝖳𝐁𝖳𝒯0∧(𝐀∧𝐁)𝖥𝐀𝖥\n|\n𝐁𝖥𝒯0∨¬𝐀𝖳𝐀𝖥𝒯0¬𝖳¬𝐀𝖥𝐀𝖳𝒯0¬𝖥𝐀𝛼𝐀𝛽𝛼≠𝛽⊥𝒯0⊥Use rules exhaustively as long as they contribute new material(⤳\n                      termination)\n\n\n▷\n                  We call any\ntree\n                  (\n|\n\n                  introduces\nbranches) produced by the\n𝒯0\ninference rules\n                  from a set\nΦ\n                  of\nlabeled formulae\n                  a\ntableau\n                  for\nΦ.\n\n\n▷\n                  Call a\ntableau\nsaturated, iff no\nrule\n                  adds new material and a\nbranch\nclosed, iff it ends in\n⊥, else\nopen. A\ntableau\n                  is\nclosed, iff all of its\nbranches\n                  are.\n\nIn analogy to the\n⊥\n                  at the end of\nclosed\nbranches, we sometimes decorate\nopen\nbranches\n                  with a\n□\n                  symbol.\n\n\n\n:\n12024-12-16\n",
        "sectionId": "511dbc0f",
        "archive": "courses/Jacobs/GenCS/course",
        "filepath": "atp0/slides/tableaux-formal.en.xhtml"
    },
    {
        "slideContent": "\nAnalytical Tableaux (𝒯0\n              continued)\n\n▷𝒯0-Theorem/Derivability\n𝐀\n                  is a\n𝒯0-theorem\n                  (⊢𝒯0𝐀), iff there is a\nclosed\ntableau\n                  with\n𝐀𝖥\n                  at the\nroot.\n\nΦ⊆𝑤𝑓𝑓0(𝒱0)\nderives\n𝐀\n                  in\n𝒯0\n                  (Φ⊢𝒯0𝐀), iff there is a\nclosed\ntableau\n                  starting with\n𝐀𝖥\n                  and\nΦ𝖳. The\ntableau\n                  with only a\nbranch\n                  of\n𝐀𝖥\n                  and\nΦ𝖳\n                  is called\ninitial\n                  for\nΦ⊢𝒯0𝐀.\n\n\n\n:\n22024-12-16\n",
        "sectionId": "511dbc0f",
        "archive": "courses/Jacobs/GenCS/course",
        "filepath": "atp0/slides/tableaux-formal.en.xhtml"
    },
    {
        "slideContent": "\nA Valid Real-World Example\n\n▷\nIf Mary loves Bill and John loves Mary, then John loves Mary\n(loves(mary,bill)∧loves(john,mary)⇒loves(john,mary))𝖥¬(¬¬(loves(mary,bill)∧loves(john,mary))∧¬loves(john,mary))𝖥(¬¬(loves(mary,bill)∧loves(john,mary))∧¬loves(john,mary))𝖳¬¬(loves(mary,bill)∧loves(john,mary))𝖳¬(loves(mary,bill)∧loves(john,mary))𝖥(loves(mary,bill)∧loves(john,mary))𝖳¬loves(john,mary)𝖳loves(mary,bill)𝖳loves(john,mary)𝖳loves(john,mary)𝖥⊥This is a\nclosed\ntableau, so the\nloves(mary,bill)∧loves(john,mary)⇒loves(john,mary)\n                  is a\n𝒯0-theorem.\n\nAs we will see,\n𝒯0\n                  is\nsound\n                  and\ncomplete, so\nloves(mary,bill)∧loves(john,mary)⇒loves(john,mary)is\nvalid.\n\n\n\n:\n12024-12-15\n",
        "sectionId": "511dbc0f",
        "archive": "courses/Jacobs/GenCS/course",
        "filepath": "atp0/slides/tableaux-example.en.xhtml"
    },
    {
        "slideContent": "\nDeriving Entailment in\n𝒯0\n\n▷\nMary loves Bill\n                  and\nJohn loves Mary\n                  together entail that\nJohn loves Mary\nloves(mary,bill)𝖳loves(john,mary)𝖳loves(john,mary)𝖥⊥This is a\nclosed\ntableau, so\n{loves(mary,bill),loves(john,mary)}⊢𝒯0loves(john,mary).\n\nAgain, as\n𝒯0\n                  is\nsound\n                  and\ncomplete\n                  we have\n{loves(mary,bill),loves(john,mary)}⊨loves(john,mary)\n\n\n:\n22024-12-15\n",
        "sectionId": "511dbc0f",
        "archive": "courses/Jacobs/GenCS/course",
        "filepath": "atp0/slides/tableaux-example.en.xhtml"
    },
    {
        "slideContent": "\nA Falsifiable Real-World Example\n\n▷\n                  *If Mary loves Bill or John loves Mary, then John loves MaryTry proving the implication(this fails)\n((loves(mary,bill)∨loves(john,mary))⇒loves(john,mary))𝖥¬(¬¬(loves(mary,bill)∨loves(john,mary))∧¬loves(john,mary))𝖥(¬¬(loves(mary,bill)∨loves(john,mary))∧¬loves(john,mary))𝖳¬loves(john,mary)𝖳loves(john,mary)𝖥¬¬(loves(mary,bill)∨loves(john,mary))𝖳¬(loves(mary,bill)∨loves(john,mary))𝖥(loves(mary,bill)∨loves(john,mary))𝖳loves(mary,bill)𝖳loves(john,mary)𝖳⊥Indeed we can make\nℐ𝜑(loves(mary,bill))=𝖳\n                  but\nℐ𝜑(loves(john,mary))=𝖥.\n\n\n\n:\n32024-12-15\n",
        "sectionId": "511dbc0f",
        "archive": "courses/Jacobs/GenCS/course",
        "filepath": "atp0/slides/tableaux-example.en.xhtml"
    },
    {
        "slideContent": "\nTesting for Entailment in\n𝒯0\n\n▷\n                  Does\nMary loves Bill or John loves Mary\n                  entail that\nJohn loves Mary?\n(loves(mary,bill)∨loves(john,mary))𝖳loves(john,mary)𝖥loves(mary,bill)𝖳loves(john,mary)𝖳⊥This\nsaturated\ntableau\n                  has an\nopen\nbranch\n                  that shows that the\ninterpretation\n                  with\nℐ𝜑(loves(mary,bill))=𝖳\n                  but\nℐ𝜑(loves(john,mary))=𝖥\n                  falsifies the derivability/entailment\n                  conjecture.\n\n\n\n:\n42024-12-15\n",
        "sectionId": "511dbc0f",
        "archive": "courses/Jacobs/GenCS/course",
        "filepath": "atp0/slides/tableaux-example.en.xhtml"
    },
    {
        "slideContent": "\nDerived Rules of Inference\n\n▷Derivable&#160;Inference&#160;Rule\n\n\n▷\n                  We have the following\nderivable\ninference rules\n                  in\n𝒯0:\n\n\n\n(𝐀⇒𝐁)𝖳𝐀𝖥\n|\n𝐁𝖳(𝐀⇒𝐁)𝖥𝐀𝖳𝐁𝖥𝐀𝖳(𝐀⇒𝐁)𝖳𝐁𝖳(𝐀∨𝐁)𝖳𝐀𝖳\n|\n𝐁𝖳(𝐀∨𝐁)𝖥𝐀𝖥𝐁𝖥(𝐀⇔𝐁)𝖳𝐀𝖳𝐁𝖳|𝐀𝖥𝐁𝖥(𝐀⇔𝐁)𝖥𝐀𝖳𝐁𝖥|𝐀𝖥𝐁𝖳\n\n\n𝐀𝖳(𝐀⇒𝐁)𝖳(¬𝐀∨𝐁)𝖳¬(¬¬𝐀∧¬𝐁)𝖳(¬¬𝐀∧¬𝐁)𝖥¬¬𝐀𝖥¬𝐀𝖳𝐀𝖥⊥¬𝐁𝖥𝐁𝖳\n\n\n\n \n\n\n:\n12024-12-16\n",
        "sectionId": "af45aa8c",
        "archive": "courses/Jacobs/GenCS/course",
        "filepath": "atp0/slides/tableaux-derived.en.xhtml"
    },
    {
        "slideContent": "\nTableaux with derived Rules (example)\n\n\n(loves(mary,bill)∧loves(john,mary)⇒loves(john,mary))𝖥(loves(mary,bill)∧loves(john,mary))𝖳loves(john,mary)𝖥loves(mary,bill)𝖳loves(john,mary)𝖳⊥\n\n\n:\n22024-12-16\n",
        "sectionId": "af45aa8c",
        "archive": "courses/Jacobs/GenCS/course",
        "filepath": "atp0/slides/tableaux-derived.en.xhtml"
    },
    {
        "slideContent": "\nSoundness (Tableau)\n\n▷Idea\n                  A\ntest calculus\n                  is\nrefutation sound, iff its\ninference rules\n                  preserve\nsatisfiability\n                  and the goal formulae are\nunsatisfiable.\n\n\n▷\n                  A\nlabeled formula\n𝐀𝛼\n                  is\nvalid under\n𝜑, iff\nℐ𝜑(𝐀)=𝛼.\n\n\n▷\n                  A\ntableau\n𝒯\n                  is\nsatisfiable, iff there is a\nsatisfiable\nbranch\n𝒫\n                  in\n𝒯, i.e. if the set of\nformulae\n                  on\n𝒫\n                  is\nsatisfiable.\n\n\n▷\n𝒯0\nrules\n                  transform\nsatisfiable\ntableaux\n                  into\nsatisfiable\n                  ones.\n\n\n▷Soundness\n𝒯0\n                  is\nsound, i.e.\nΦ⊆𝑤𝑓𝑓0(𝒱0)\nvalid, if there is a\nclosed\ntableau\n𝒯\n                  for\nΦ𝖥.\n\n\n▷Proof:\nby\ncontradiction\n\n\n\n1.Suppose\nΦ\n                    isfalsifiable\n=^\n                    not\nvalid.\n\n\n\n2.Then the\ninitial\ntableau\n                    is\nsatisfiable,(Φ𝖥\nsatisfiable)\n\n\n\n\n3.so\n𝒯\n                    is\nsatisfiable, by\n??.\n\n\n\n\n4.Thus there is a\nsatisfiable\nbranch(by definition)\n\n\n\n\n5.but all\nbranches\n                    are\nclosed(𝒯\nclosed)\n\n\n▷Completeness\n𝒯0\n                  is\ncomplete, i.e. if\nΦ⊆𝑤𝑓𝑓0(𝒱0)\n                  is\nvalid, then there is a\nclosed\ntableau\n𝒯\n                  for\nΦ𝖥.\n\n\n▷Proof sketch:\n                Proof difficult/interesting; see\n??\n\n\n\n:\n12024-12-14\n",
        "sectionId": "225b3d43",
        "archive": "courses/Jacobs/GenCS/course",
        "filepath": "atp0/slides/tableaux-sound.en.xhtml"
    },
    {
        "slideContent": "\nTermination for\nTableaux\n\n▷\n𝒯0\nterminates, i.e. every\n𝒯0\ntableau\n                  becomes\nsaturated\n                  after\nfinitely\n                  many\nrule\n                  applications.\n\n\n▷Proof:\nBy examining the rules wrt. a measure\n𝜇\n\n\n\n1.Let us call a\nlabeled formulae\n𝐀𝛼\nworked off\n                          in a\ntableau\n𝒯, if a\n𝒯0\nrule\n                          has already been applied to it.\n\n\n\n2.It is easy to see that applying rules to\nworked off\nformulae\n                      will only add\nformulae\n                      that are already present in its\nbranch.\n\n\n\n\n3.Let\n𝜇(𝒯)\n                          be the number of\nconnectives\n                          in\nlabeled formulae\n                          in\n𝒯\n                          that are not\nworked off.\n\n\n\n\n4.Then each rule application to a\nlabeled formula\n                      in\n𝒯\n                      that is not\nworked off\n                      reduces\n𝜇(𝒯)\n                      by at least one.(inspect the rules)\n\n\n\n\n5.At some point the\ntableau\n                      only contains\nworked off\n                      formulae and\nliterals.\n\n\n\n\n6.Since there are only\nfinitely\n                      many\nliterals\n                      in\n𝒯, so we can only apply\n𝒯0⊥\n                      a\nfinite\n                      number of times.\n\n\n▷\n𝒯0\n                    induces a\ndecision procedure\n                    for\nvalidity\n                    in\nPL0.\n\n\n▷Proof:\nWe combine the results so far\n\n\n\n1.By\n??\n                      it is\ndecidable\n                      whether\n⊢𝒯0𝐀\n\n\n\n2.By\nsoundness\n                      (??) and\ncompleteness\n                      (??),\n⊢𝒯0𝐀\n                      iff\n𝐀\n                      is\nvalid.\n\n\n:\n12024-12-14\n",
        "sectionId": "225b3d43",
        "archive": "courses/Jacobs/GenCS/course",
        "filepath": "atp0/slides/tableau-termination.en.xhtml"
    },
    {
        "slideContent": "\nAnother Test Calculus: Resolution\n\n▷\n\n\n▷Resolution Calculus\n                  The\nresolution calculus\nℛ0\n                  operates a\nclause sets\n                  via a single\ninference rule:\n𝑃𝖳∨𝐀𝑃𝖥∨𝐁𝐀∨𝐁ℛThis\nrule\n                  allows to add the\nresolvent\n                  (the\nclause\n                  below the line) to a\nclause set\n                  which contains the two\nclauses\n                  above. The\nliterals\n𝑃𝖳\n                  and\n𝑃𝖥\n                  are called\ncut literals.\n\n\n▷Resolution Refutation\n                  Let\n𝑆\n                  be a\nclause set, then we call an\nℛ0-derivation\n                  of\n□\n                  from\n𝑆\nℛ0-refutation\n                  and write\n𝒟:𝑆⊢ℛ0□.\n\n\n\n:\n12024-12-14\n",
        "sectionId": "7ceb2e1e",
        "archive": "courses/Jacobs/GenCS/course",
        "filepath": "atp0/slides/resolution-calculus.en.xhtml"
    },
    {
        "slideContent": "\nClause Normal Form Transformation (A calculus)\n\n▷We will often write a\nclause set\n{𝐶1,...,𝐶𝑛}\n                  as\n𝐶1;...;𝐶𝑛, use\n𝑆;𝑇\n                  for the\nunion\n                  of the\nclause sets\n𝑆\n                  and\n𝑇, and\n𝑆;𝐶\n                  for the extension by a\nclause\n𝐶.\n\n\n▷Transformation into Clause Normal Form\n                  The\nCNF transformation calculus\n𝐶𝑁𝐹0\n                  consists of the following four\ninference rules\n                  on sets of\nlabeled formulae.\n𝐂∨(𝐀∨𝐁)𝖳𝐂∨𝐀𝖳∨𝐁𝖳𝐂∨(𝐀∨𝐁)𝖥(𝐂∨𝐀𝖥);(𝐂∨𝐁𝖥)𝐂∨¬𝐀𝖳𝐂∨𝐀𝖥𝐂∨¬𝐀𝖥𝐂∨𝐀𝖳\n\n▷\n                  We write\n𝐶𝑁𝐹0(𝐀𝛼)\n                  for the set of all\nclauses\nderivable\n                  from\n𝐀𝛼\n                  via the\nrules\n                  above.\n\n\n\n:\n12024-12-14\n",
        "sectionId": "7ceb2e1e",
        "archive": "courses/Jacobs/GenCS/course",
        "filepath": "atp0/slides/propclauseNF.en.xhtml"
    },
    {
        "slideContent": "\nDerived Rules of Inference\n\n▷Derivable&#160;Inference&#160;Rule\n\n\n▷Idea\nDerived rules\n                  make\nproofs\n                  shorter.\n\n\n▷\n\n\n\n𝐂∨(𝐀⇒𝐁)𝖳\n\n\n𝐂∨(¬𝐀∨𝐁)𝖳\n\n\n\n\n𝐂∨¬𝐀𝖳∨𝐁𝖳\n\n\n\n\n𝐂∨𝐀𝖥∨𝐁𝖳\n\n\n⤳\n𝐂∨(𝐀⇒𝐁)𝖳𝐂∨𝐀𝖥∨𝐁𝖳\n\n\n▷Other Derived CNF Rules\n𝐂∨(𝐀⇒𝐁)𝖳𝐂∨𝐀𝖥∨𝐁𝖳𝐂∨(𝐀⇒𝐁)𝖥(𝐂∨𝐀𝖳);(𝐂∨𝐁𝖥)𝐂∨(𝐀∧𝐁)𝖳(𝐂∨𝐀𝖳);(𝐂∨𝐁𝖳)𝐂∨(𝐀∧𝐁)𝖥𝐂∨𝐀𝖥∨𝐁𝖥\n\n\n:\n12024-12-15\n",
        "sectionId": "7ceb2e1e",
        "archive": "courses/Jacobs/GenCS/course",
        "filepath": "atp0/slides/propclauseNF-derived.en.xhtml"
    },
    {
        "slideContent": "\nExample: Proving Axiom\nS\n              with Resolution\n\n▷\nClause Normal Form transformation\n\n\n((𝑃⇒𝑄⇒𝑅)⇒(𝑃⇒𝑄)⇒𝑃⇒𝑅)𝖥\n((𝑃⇒𝑄⇒𝑅)𝖳);(((𝑃⇒𝑄)⇒𝑃⇒𝑅)𝖥)(𝑃𝖥∨(𝑄⇒𝑅)𝖳);((𝑃⇒𝑄)𝖳);((𝑃⇒𝑅)𝖥)(𝑃𝖥∨𝑄𝖥∨𝑅𝖳);(𝑃𝖥∨𝑄𝖳);(𝑃𝖳);(𝑅𝖥)\n\n\n\nResult\n{𝑃𝖥∨𝑄𝖥∨𝑅𝖳,𝑃𝖥∨𝑄𝖳,𝑃𝖳,𝑅𝖥}\n\n\n▷\nResolution Proof\n\n\n1 𝑃𝖥∨𝑄𝖥∨𝑅𝖳 initial2 𝑃𝖥∨𝑄𝖳 initial 3 𝑃𝖳 initial 4 𝑅𝖥 initial 5 𝑃𝖥∨𝑄𝖥 resolve 1.3 with 4.16 𝑄𝖥 resolve 5.1 with 3.17 𝑃𝖥 resolve 2.2 with 6.18 □ resolve 7.1 with 3.1\n\n\n\n:\n12024-12-15\n",
        "sectionId": "7ceb2e1e",
        "archive": "courses/Jacobs/GenCS/course",
        "filepath": "atp0/slides/resolution-example.en.xhtml"
    },
    {
        "slideContent": "\nClause Set Simplification\n\n▷Observation\n                  Let\n∆\n                  be a\nclause set,\n𝑙\n                  a\nliteral, and\n∆'\n                  be\n∆\n                  where\n\n\n▷all\nclauses\n𝑙∨𝐶\n                  have been removed and\n\n\n▷and all\nclauses\n𝑙―∨𝐶\n                  have been shortened to\n𝐶.\n\n\nThen\n∆\n                  is\nsatisfiable, iff\n∆'\n                  is.\nWe call\n∆'\n                      the\nclause set simplification\n                      of\n∆\n                      wrt.\n𝑙.\n\n\n▷\n                  Adding\nclause set simplification\n                  wrt.\nunit clauses\n                  to\nℛ0\n                  does not affect\nsoundness\n                  and\ncompleteness.\n\n\n▷\n                  This is almost always a good idea!\n(clause set simplification\n                      is cheap)\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "7ceb2e1e",
        "archive": "courses/FAU/AI/course",
        "filepath": "logic/slides/clause-set-simplification.en.xhtml"
    },
    {
        "slideContent": "\nApplying Propositional Inference: Where is the Wumpus?\n\n▷Finding the Wumpus\n                  The situation and what the agent knows\n\n\n\n\n\n\n▷What should the agent do next and why?\n\n\n▷One possibility: Convince yourself that the Wumpus is in\n[1,3]\n                  and shoot it.\n\n\n▷What is the general mechanism here?\n(for the agent function)\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "78128695",
        "archive": "courses/FAU/AI/course",
        "filepath": "logic/slides/wumpus-inference.en.xhtml"
    },
    {
        "slideContent": "\nWhere is the Wumpus? Our Knowledge\n\n▷Idea\n                  We formalize the knowledge about the\nWumpus world\n                  in\nPL0\n                  and use a\ntest calculus\n                  to check for\nentailment.\n\n\n▷Simplification\n                  We worry only about the\nWumpus\n                  and stench:𝑆𝑖,𝑗\n=^\nstench in\n[𝑖,𝑗],\n𝑊𝑖,𝑗\n=^\nWumpus\n                    in\n[𝑖,𝑗].\n\n\n▷Propositions whose value we know\n¬𝑆1,1,\n¬𝑊1,1,\n¬𝑆2,1,\n¬𝑊2,1,\n𝑆1,2,\n¬𝑊1,2.\n\n\n▷Knowledge about the Wumpus and smellFrom\nCell adjacent to\nWumpus: Stench (else: None), we get\n𝑅1:=¬𝑆1,1⇒¬𝑊1,1∧¬𝑊1,2∧¬𝑊2,1\n𝑅2:=¬𝑆2,1⇒¬𝑊1,1∧¬𝑊2,1∧¬𝑊2,2∧¬𝑊3,1\n𝑅3:=¬𝑆1,2⇒¬𝑊1,1∧¬𝑊1,2∧¬𝑊2,2∧¬𝑊1,3\n𝑅4:=𝑆1,2⇒(𝑊1,3∨𝑊2,2∨𝑊1,1)...\n\n\n▷To show\n\n𝑅1,𝑅2,𝑅3,𝑅4⊨𝑊1,3(we will use\nresolution)\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "78128695",
        "archive": "courses/FAU/AI/course",
        "filepath": "logic/slides/wumpus-pl0.en.xhtml"
    },
    {
        "slideContent": "\nAnd Now Using Resolution Conventions\n\n▷We obtain the\nclause set\n∆\n              composed of the following\nclauses:\n\n\n▷Propositions whose value we know:\n𝑆1,1𝖥,\n𝑊1,1𝖥,\n𝑆2,1𝖥,\n𝑊2,1𝖥,\n𝑆1,2𝖳,\n𝑊1,2𝖥\n\n\n▷Knowledge about the Wumpus and smell:\n\n\nfrom clauses𝑅1 𝑆1,1𝖳∨𝑊1,1𝖥, 𝑆1,1𝖳∨𝑊1,2𝖥, 𝑆1,1𝖳∨𝑊2,1𝖥 𝑅2 𝑆2,1𝖳∨𝑊1,1𝖥, 𝑆2,1𝖳∨𝑊2,1𝖥, 𝑆2,1𝖳∨𝑊2,2𝖥, 𝑆2,1𝖳∨𝑊3,1𝖥 𝑅3 𝑆1,2𝖳∨𝑊1,1𝖥, 𝑆1,2𝖳∨𝑊1,2𝖥, 𝑆1,2𝖳∨𝑊2,2𝖥, 𝑆1,2𝖳∨𝑊1,3𝖥 𝑅4 𝑆1,2𝖥∨𝑊1,3𝖳∨𝑊2,2𝖳∨𝑊1,1𝖳 \n\n\n▷Negated goal formula:\n𝑊1,3𝖥\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "78128695",
        "archive": "courses/FAU/AI/course",
        "filepath": "logic/slides/wumpus-cnf.en.xhtml"
    },
    {
        "slideContent": "\nWhere does the Conjecture\n𝑊1,3𝖥\n              come from?\n\n▷Question\n                  Where did the\n𝑊1,3𝖥\n                  come from?\n\n\n▷\n                  We need a general mechanism for making\nconjectures.\n\n\n▷Idea\n                  Interpret the\nWumpus\n                  world as a\nsearch problem\n𝒫:=〈𝒮,𝒜,𝒯,ℐ,𝒢〉\n                  where\n\n\n▷the\nstates\n𝒮\n                  are given by the\ncells\n                  (and\nagent\n                  orientation) and\n\n\n▷the\nactions\n𝒜\n                  by the possible\nactions\n                  of the\nagent.\n\n\nUse\ntree search\n                  as the main\nagent function\n                  and a\ntest calculus\n                  for testing all dangers (pits), opportunities (gold) and the\nWumpus.\n\n\n▷Back to the Wumpus\n                  In\n??, the\nagent\n                  is in\n[1,2], it has perceived\nstench, and the possible\nactions\n                  include\nshoot, and\ngoForward. Evaluating either of these leads to the\nconjecture\n𝑊1,3. And since\n𝑊1,3\n                  is\nentailed, the\naction\nshoot\n                  probably comes out best,\nheuristically.\n\n\n▷RemarkAnalogous to the\nbacktracking with inference\nalgorithm\n                  from\nCSP.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "78128695",
        "archive": "courses/FAU/AI/course",
        "filepath": "logic/slides/wumpus-search.en.xhtml"
    },
    {
        "slideContent": "\nModel Existence (Overview)\n\n▷Definition\n                  Abstract consistency\n\n\n▷Definition\n                  Hintikka set (maximally abstract consistent)\n\n\n▷Theorem\n                  Hintikka sets are satisfiable\n\n\n▷Theorem\n                  If\nΦ\n                  is abstract consistent, then\nΦ\n                  can be extended to a Hintikka set.\n\n\n▷Corollary\n                  If\nΦ\n                  is abstract consistent, then\nΦ\n                  is\nsatisfiable.\n\n\n▷Application\n                  Let\n𝒞\n                  be a\ncalculus, if\nΦ\n                  is\n𝒞-consistent, then\nΦ\n                  is abstract consistent.\n\n\n▷Corollary\n𝒞\n                  is complete.\n\n\n\n:\n12024-12-15\n",
        "sectionId": "6e835e8b",
        "archive": "courses/Jacobs/GenCS/course",
        "filepath": "logic/slides/model-existence-overview.en.xhtml"
    },
    {
        "slideContent": "\nConsistency\n\n▷Let\n𝒞\n              be a\ncalculus,...\n\n▷\n\n\n▷\n\n\n▷\n                  So a set\nΦ\n                  is\n𝒞-refutable, if\n𝒞\n                  canderive\n                  a\ncontradiction\n                  from it.\n\n\n▷\n\n\n▷\n                  We call a\ncalculus\n𝒞\nreasonable, iff implication elimination and conjunction introduction are\nadmissible\n                  in\n𝒞\n                  and\n𝐀∧¬𝐀⇒𝐁\n                  is a\n𝒞-theorem.\n\n\n▷\n𝒞-inconsistency and\n𝒞-refutability coincide for\nreasonable\ncalculi.\n\n\n\n:\n12024-12-14\n",
        "sectionId": "6e835e8b",
        "archive": "courses/Jacobs/GenCS/course",
        "filepath": "logic/slides/consistency.en.xhtml"
    },
    {
        "slideContent": "\nAbstract Consistency\n\n▷\n                  Let\n∇\n                  be a\ncollection\n                  of sets. We call\n∇\nclosed under subsets, iff for each\nΦ∊∇, all subsets\nΨ⊆Φ\n                  are elements of\n∇.\n\n\n▷Notation\n                  We will use\nΦ*𝐀\n                  for\nΦ∪{𝐀}.\n\n\n▷\n                  A\ncollection\n∇\n                  of sets of propositional formulae is called an\nabstract consistency class, iff it is\nclosed under subsets, and for each\nΦ∊∇\n\n\n∇𝑐)𝑃∉Φ\n                  or\n¬𝑃∉Φ\n                  for\n𝑃∊𝒱0\n\n\n∇¬)¬¬𝐀∊Φ\n                  implies\nΦ*𝐀∊∇\n\n\n∇∨)𝐀∨𝐁∊Φ\n                  implies\nΦ*𝐀∊∇\n                  or\nΦ*𝐁∊∇\n\n\n∇∧)¬(𝐀∨𝐁)∊Φ\n                  implies\nΦ∪{¬𝐀,¬𝐁}∊∇\n\n\n▷\n                  The\nempty\nset\n                  is an\nabstract consistency class.\n\n\n▷\n                  The\nset\n{∅,{𝑄},{𝑃∨𝑄},{𝑃∨𝑄,𝑄}}\n                  is an\nabstract consistency class.\n\n\n▷\n                  The\nfamily\n                  of\nsatisfiable\nsets\n                  is an\nabstract consistency class.\n\n\n\n:\n12024-12-14\n",
        "sectionId": "6e835e8b",
        "archive": "courses/Jacobs/GenCS/course",
        "filepath": "pl0/slides/abstract-consistency.en.xhtml"
    },
    {
        "slideContent": "\nCompact Collections\n\n▷\n\n\n▷\n                  If\n∇\n                  is\ncompact, then\n∇\n                  is\nclosed under subsets.\n\n\n▷Proof:\n\n\n\n\n1.Suppose\n𝑆⊆𝑇\n                    and\n𝑇∊∇.\n\n\n\n2.Every\nfinite\n                    subset\n𝐴\n                    of\n𝑆\n                    is a\nfinite\n                    subset of\n𝑇.\n\n\n\n3.As\n∇\n                    is\ncompact, we know that\n𝐴∊∇.\n\n\n\n4.Thus\n𝑆∊∇.\n\n\n:\n12024-12-15\n",
        "sectionId": "6e835e8b",
        "archive": "courses/Jacobs/GenCS/course",
        "filepath": "logic/slides/compact-def.en.xhtml"
    },
    {
        "slideContent": "\nCompact Abstract Consistency Classes\n\n▷\n                  Any\nabstract consistency class\n                  can be extended to a\ncompact\n                  one.\n\n\n▷Proof:\n\n\n\n\n1.We choose\n∇':={Φ⊆𝑤𝑓𝑓0(𝒱0)|\nevery finite subset of Φ is in ∇\n}.\n\n\n\n\n2.Now suppose that\nΦ∊∇.\n∇\n                    is\nclosed under subsets, so every\nfinite\n                    subset of\nΦ\n                    is in\n∇\n                    and thus\nΦ∊∇'. Hence\n∇⊆∇'.\n\n\n3.Next let us show that each\n∇\n                      is\ncompact.’\n\n\n\n3.1.Suppose\nΦ∊∇'\n                        and\nΨ\n                        is an arbitrary\nfinite\n                        subset of\nΦ.\n\n\n\n\n3.2.By definition of\n∇'\n                        all\nfinite\n                        subsets of\nΦ\n                        are in\n∇\n                        and therefore\nΨ∊∇'.\n\n\n\n\n3.3.Thus all\nfinite\n                        subsets of\nΦ\n                        are in\n∇'\n                        whenever\nΦ\n                        is in\n∇'.\n\n\n\n\n3.4.On the other hand, suppose all\nfinite\n                        subsets of\nΦ\n                        are in\n∇'.\n\n\n\n\n3.5.Then by the definition of\n∇'\n                        the\nfinite\n                        subsets of\nΦ\n                        are also in\n∇, so\nΦ∊∇'. Thus\n∇'\n                        is\ncompact.\n\n\n\n\n4.Note that\n∇'\n                    is\nclosed under subsets\n                    by the Lemma above.\n\n5.Now we show that if\n∇\n                      satisfies\n∇*, then\n∇\n                      satisfies\n∇*.’\n\n\n\n5.1.To show\n∇𝑐, let\nΦ∊∇'\n                        and suppose there is an atom\n𝐀, such that\n{𝐀,¬𝐀}⊆Φ. Then\n{𝐀,¬𝐀}∊∇\n                        contradicting\n∇𝑐.\n\n\n5.2.To show\n∇¬, let\nΦ∊∇'\n                          and\n¬¬𝐀∊Φ, then\nΦ*𝐀∊∇'.\n\n\n\n5.2.1.Let\nΨ\n                            be any\nfinite\n                            subset of\nΦ*𝐀, and\nΘ:=(Ψ\\{𝐀})*¬¬𝐀.\n\n\n\n\n5.2.2.Θ\n                            is a\nfinite\n                            subset of\nΦ, so\nΘ∊∇.\n\n\n\n\n5.2.3.Since\n∇\n                            is an abstract consistency class and\n¬¬𝐀∊Θ, we get\nΘ*𝐀∊∇\n                            by\n∇¬.\n\n\n\n\n5.2.4.We know that\nΨ⊆Θ*𝐀\n                            and\n∇\n                            is closed under subsets, so\nΨ∊∇.\n\n\n\n\n5.2.5.Thus every\nfinite\n                            subset\nΨ\n                            of\nΦ*𝐀\n                            is in\n∇\n                            and therefore by definition\nΦ*𝐀∊∇'.\n\n\n\n\n5.3.the other cases are analogous to\n∇¬.\n\n\n\n:\n12024-12-15\n",
        "sectionId": "6e835e8b",
        "archive": "courses/Jacobs/GenCS/course",
        "filepath": "pl0/slides/compact-acc.en.xhtml"
    },
    {
        "slideContent": "\n∇-Hintikka Set\n\n▷\n                  Let\n∇\n                  be an abstract consistency class, then we call a set\nℋ∊∇\n                  a\n∇\n                      Hintikka Set, iff\nℋ\n                  is maximal in\n∇, i.e. for all\n𝐀\n                  with\nℋ*𝐀∊∇\n                  we already have\n𝐀∊ℋ.\n\n\n▷Hintikka Properties\n                  Let\n∇\n                  be an abstract consistency class and\nℋ\n                  be a\n∇-Hintikka set, then\n\nℋ𝑐)For all\n𝐀∊𝑤𝑓𝑓0(𝒱0)\n                      we have\n𝐀∉ℋ\n                      or\n¬𝐀∉ℋ\n\n\nℋ¬)If\n¬¬𝐀∊ℋ\n                      then\n𝐀∊ℋ\n\n\nℋ∨)If\n𝐀∨𝐁∊ℋ\n                      then\n𝐀∊ℋ\n                      or\n𝐁∊ℋ\n\n\nℋ∧)If\n¬(𝐀∨𝐁)∊ℋ\n                      then\n¬𝐀,¬𝐁∊ℋ\n\n\n\n:\n12024-12-15\n",
        "sectionId": "6e835e8b",
        "archive": "courses/Jacobs/GenCS/course",
        "filepath": "pl0/slides/Hintikka-set.en.xhtml"
    },
    {
        "slideContent": "\n∇-Hintikka Set\n\n▷Proof:\n\n\nWe prove the properties in turn\n\n\n1.ℋ𝑐\n\nby\ninduction on the structure of\n𝐀\n\n\n1.1.𝐀∊𝒱0\n\n\n                            Then\n𝐀∉ℋ\n                            or\n¬𝐀∉ℋ\n                            by\n∇𝑐.\n\n\n\n1.2.𝐀=¬𝐁\n\n\n\n1.2.1.Let us assume that\n¬𝐁∊ℋ\n                            and\n¬¬𝐁∊ℋ,\n\n\n\n\n1.2.2.then\nℋ*𝐁∊∇\n                            by\n∇¬, and therefore\n𝐁∊ℋ\n                            by maximality.\n\n\n\n\n1.2.3.So both\n𝐁\n                            and\n¬𝐁\n                            are in\nℋ, which contradicts the\ninduction hypothesis.\n\n\n1.3.𝐀=𝐁∨𝐂\n\nsimilar to the previous case\n\n\n2.We prove\nℋ¬\n                      by maximality of\nℋ\n                      in\n∇.\n\n\n\n2.1.If\n¬¬𝐀∊ℋ, then\nℋ*𝐀∊∇\n                        by\n∇¬.\n\n\n\n\n2.2.The maximality of\nℋ\n                        now gives us that\n𝐀∊ℋ.\n\n\nProof sketch:\n                    other\nℋ*\n                    are similar\n\n\n\n:\n22024-12-15\n",
        "sectionId": "6e835e8b",
        "archive": "courses/Jacobs/GenCS/course",
        "filepath": "pl0/slides/Hintikka-set.en.xhtml"
    },
    {
        "slideContent": "\nExtension Theorem\n\n▷\n                  If\n∇\n                  is an abstract consistency class and\nΦ∊∇, then there is a\n∇-Hintikka set\nℋ\n                  with\nΦ⊆ℋ.\n\n\n▷Proof:\n\n\n\n\n1.Wlog.\n                    we assume that\n∇\n                    is\ncompact(otherwise pass to\ncompact\n                        extension)\n\n\n\n\n2.We choose an\nenumeration\n𝐀1,...\n                    of the set\n𝑤𝑓𝑓0(𝒱0)\n\n\n\n\n3.and construct a sequence of sets\n𝐇𝑖\n                    with\n𝐇0:=Φ\n                    and\n𝐇𝑛+1:={𝐇𝑛if𝐇𝑛*𝐀𝑛∉∇𝐇𝑛*𝐀𝑛if𝐇𝑛*𝐀𝑛∊∇\n\n\n\n4.Note that all\n𝐇𝑖∊∇, choose\nℋ:=⋃𝑖∊ℕ𝐇𝑖\n\n\n\n\n5.Ψ⊆ℋ\nfinite\n                    implies there is a\n𝑗∊ℕ\n                    such that\nΨ⊆𝐇𝑗,\n\n\n\n\n6.so\nΨ∊∇\n                    as\n∇\n                    is\nclosed under subsets\n                    and\nℋ∊∇\n                    as\n∇\n                    is\ncompact.\n\n\n\n\n7.Let\nℋ*𝐁∊∇, then there is a\n𝑗∊ℕ\n                    with\n𝐁=𝐀𝑗, so that\n𝐁∊𝐇𝑗+1\n                    and\n𝐇𝑗+1⊆ℋ\n\n\n\n\n8.Thus\nℋ\n                    is\n∇-maximal\n\n\n:\n12024-12-15\n",
        "sectionId": "6e835e8b",
        "archive": "courses/Jacobs/GenCS/course",
        "filepath": "pl0/slides/extension-thm.en.xhtml"
    },
    {
        "slideContent": "\nValuation\n\n▷\n\n\n▷\n                  If\n𝜈:𝑤𝑓𝑓0(𝒱0)→𝒟𝑜\n                  is a\nvaluation\n                  and\nΦ⊆𝑤𝑓𝑓0(𝒱0)\n                  with\n𝜈(Φ)={𝖳}, then\nΦ\n                  is\nsatisfiable.\n\n\n▷Proof sketch:\n𝜈|𝒱0:𝒱0→𝒟𝑜\n                is a\nsatisfying\nvariable assignment.\n\n\n▷\n                  If\n𝜑:𝒱0→𝒟𝑜\n                  is a\nvariable assignment, then\nℐ𝜑:𝑤𝑓𝑓0(𝒱0)→𝒟𝑜\n                  is a\nvaluation.\n\n\n\n:\n12024-12-14\n",
        "sectionId": "6e835e8b",
        "archive": "courses/Jacobs/GenCS/course",
        "filepath": "pl0/slides/valuation.en.xhtml"
    },
    {
        "slideContent": "\nModel Existence\n\n▷Hintikka-Lemma\n                  If\n∇\n                  is an abstract consistency class and\nℋ\n                  a\n∇-Hintikka set, then\nℋ\n                  is satisfiable.\n\n\n▷Proof:\n\n\n\n\n1.We define\n𝜈(𝐀):=𝖳, iff\n𝐀∊ℋ\n\n\n\n\n2.then\n𝜈\n                    is a\nvaluation\n                    by the Hintikka properties\n\n\n\n\n3.and thus\n𝜈|𝒱0\n                    is a satisfying assignment.\n\n\n▷Model Existence\n                  If\n∇\n                  is an abstract consistency class and\nΦ∊∇, then\nΦ\n                  is satisfiable.\n\n\n▷Proof:\n\n\n\n\n1.There is a\n∇-Hintikka set\nℋ\n                    with\nΦ⊆ℋ(Extension Theorem)\n\n\n\n\n2.We know that\nℋ\n                    is satisfiable.(Hintikka-Lemma)\n\n\n\n\n3.In particular,\nΦ⊆ℋ\n                    is satisfiable.\n\n\n\n:\n12024-12-14\n",
        "sectionId": "6e835e8b",
        "archive": "courses/Jacobs/GenCS/course",
        "filepath": "pl0/slides/model-existence.en.xhtml"
    },
    {
        "slideContent": "\nAbstract Completeness for\n𝒯0\n\n▷\n{Φ|\nΦ𝖳 has no closed tableau\n}\n                  is an abstract consistency class.\n\n\n▷Proof:\nLet’s call the set above\n∇\n\nWe have to convince ourselves of the abstract consistency properties\n\n\n1.∇𝑐\n\n𝑃,¬𝑃∊Φ\n                        implies\n𝑃𝖥,𝑃𝖳∊Φ𝖳.\n\n\n2.∇¬\n\nLet\n¬¬𝐀∊Φ.\n\n2.1.For the proof of the contrapositive we assume that\nΦ*𝐀\n                        has a\nclosed\ntableau\n𝒯\n                        and show that already\nΦ\n                        has one:\n\n\n\n\n2.2.applying each of\n𝒯0¬𝖳\n                        and\n𝒯0¬𝖥\n                        once allows to extend any\ntableau\n                        with\n¬¬𝐁𝛼\n                        by\n𝐁𝛼.\n\n\n\n\n2.3.any path in\n𝒯\n                        that is\nclosed\n                        with\n¬¬𝐀𝛼, can be\nclosed\n                        by\n𝐀𝛼.\n\n\n3.∇∨\n\nSuppose\n𝐀∨𝐁∊Φ\n                        and both\nΦ*𝐀\n                        and\nΦ*𝐁\n                        have\nclosed\ntableaux\n\n3.1.consider the\ntableaux:\nΦ𝖳𝐀𝖳𝑅𝑒𝑠𝑡1Φ𝖳𝐁𝖳𝑅𝑒𝑠𝑡2\nΨ𝖳(𝐀∨𝐁)𝖳𝐀𝖳𝑅𝑒𝑠𝑡1𝐁𝖳𝑅𝑒𝑠𝑡2\n\n\n4.∇∧\n\nsuppose,\n¬(𝐀∨𝐁)∊Φ\n                        and\nΦ{¬𝐀,¬𝐁}\n                        have\nclosed\ntableau\n𝒯.\n\n4.1.We consider\nΦ𝖳𝐀𝖥𝐁𝖥𝑅𝑒𝑠𝑡Ψ𝖳(𝐀∨𝐁)𝖥𝐀𝖥𝐁𝖥𝑅𝑒𝑠𝑡where\nΦ=Ψ*¬(𝐀∨𝐁).\n\n\n\n:\n12024-12-15\n",
        "sectionId": "5fd49bf4",
        "archive": "courses/Jacobs/GenCS/course",
        "filepath": "atp0/slides/proptab-irrefutable-acc.en.xhtml"
    },
    {
        "slideContent": "\nCompleteness of\n𝒯0\n\n▷\n𝒯0\n                  is\ncomplete.\n\n\n▷Proof:\nby\ncontradiction\n\n\n\n1.We assume that\n𝐀∊𝑤𝑓𝑓0(𝒱0)\n                    is\nvalid, but there is no\nclosed\ntableau\n                    for\n𝐀𝖥.\n\n\n\n\n2.We have\n{¬𝐀}∊∇\n                    as\n¬𝐀𝖳=𝐀𝖥.\n\n\n\n\n3.so\n¬𝐀\n                    is\nsatisfiable\n                    by the model existence theorem (which is applicable as\n∇\n                    is an\nabstract consistency class\n                    by our Lemma above)\n\n\n\n\n4.this contradicts our assumption that\n𝐀\n                    is\nvalid.\n\n\n\n:\n12024-12-15\n",
        "sectionId": "5fd49bf4",
        "archive": "courses/Jacobs/GenCS/course",
        "filepath": "atp0/slides/proptab-complete.en.xhtml"
    },
    {
        "slideContent": "\nReminder: Our Agenda for Propositional Logic\n\n▷??: Basic definitions and concepts; machine-oriented calculi\n\n\n▷Sets up the framework.\nTableaux\n            and\nresolution\n            are the quintessential reasoning procedures underlying most successful\nSAT solvers.\n\n\n▷This chapter: The\nDavis Putnam procedure\n            and\nclause learning.\n\n\n▷State-of-the-art\nalgorithms\n            for reasoning about propositional logic, and an important observation about how they behave.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-15\n",
        "sectionId": "d445b4ae",
        "archive": "courses/FAU/AI/course",
        "filepath": "logic/slides/propsat-intro.en.xhtml",
        "video_name": "AI1_25thDec.m4v",
        "start_time": 2241.41,
        "end_time": 2303.01
    },
    {
        "slideContent": "\nSAT: The Propositional Satisfiability Problem\n\n▷\n                  The\nSAT problem\n                  (SAT): Given a\npropositional formula\n𝐀, decide whether or not\n𝐀\n                  is\nsatisfiable. We denote the class of all\nSAT problems\n                  with\nSAT\n\n\n▷The\nSAT problem\n              was the first problem proved to be\n𝐍𝐏-complete!\n\n\n▷𝐀\n              is commonly assumed to be in\nCNF. This is\nwithout loss of generality, because any\n𝐀\n              can be transformed into a satisfiability-equivalent\nCNF\n              formula (cf.\n??) in\npolynomial time.\n\n\n▷Active research area, annual\nSAT\n              conference, lots of tools etc. available:\nhttp://www.satlive.org/\n\n\n▷\n                  Tools addressing\nSAT\n                  are commonly referred to as\nSAT solvers.\n\n\n▷Recall\n                  To decide whether\nKB⊨𝐀, decide satisfiability of\n𝜃:=KB∪{¬𝐀}:\n𝜃\n                  is\nunsatisfiable\n                  iff\nKB⊨𝐀.\n\n\n▷Consequence\n                  Deduction can be performed using\nSAT solvers.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "d445b4ae",
        "archive": "courses/FAU/AI/course",
        "filepath": "logic/slides/SAT-problem.en.xhtml"
    },
    {
        "slideContent": "\nSAT vs. CSP\n\n▷Recall\nConstraint network\n〈𝑉,𝐷,𝐶〉\n                  has\nvariables\n𝑣∊𝑉\n                  with\nfinite\ndomains\n𝐷𝑣∊𝐷, and binary constraints\n𝐶𝑢𝑣∊𝐶\n                  which are\nrelations\n                  over\n𝑢,𝑣\n                  specifying the permissible combined\nassignments\n                  to\n𝑢\n                  and\n𝑣. One extension is to allow constraints of higher arity.\n\n\n▷SAT: A kind of CSP\nSAT\n                  can be viewed as a\nCSP\n                  problem in which all\nvariable\ndomains\n                  are Boolean, and the\nconstraints\n                  have unbounded arity.\n\n\n▷Encoding CSP as\nSATGiven any\nconstraint network\n𝒞, we can in low order\npolynomial time\n                  construct a\nCNF\n                  formula\n𝐀(𝒞)\n                  that is\nsatisfiable\n                  iff\n𝒞\n                  is\nsolvable.\n\n\n▷Proof:\nWe design a formula, relying on known transformation to\nCNF\n\n\n\n1.encode multi-XOR for each variable\n\n\n\n2.encode each\nconstraint\n                    by\nDNF\n                    over relation\n\n\n\n3.Running time:\n𝒪(𝑛𝑑2+𝑚𝑑2)\n                    where\n𝑛\n                    is the number of\nvariables,\n𝑑\n                    the\ndomain\nsize, and\n𝑚\n                    the number of\nconstraints.\n\n▷Upshot\n                  Anything we can do with\nCSP, we can (in principle) do with\nSAT.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "d445b4ae",
        "archive": "courses/FAU/AI/course",
        "filepath": "logic/slides/SAT-csp.en.xhtml"
    },
    {
        "slideContent": "\nExample Application:\nHardware\nVerification\n\n▷Hardware Verification\n\n\n\n\n\n\n\n▷Counter, repeatedly from\n𝑐=0\n                                  to\n𝑐=2.\n\n\n▷2 bits\n𝑥1\n                                  and\n𝑥0;\n𝑐=2*𝑥1+𝑥0.\n\n\n▷(FF=^\n                                  Flip-Flop,\nD\n=^\n                                  Data IN,\nCLK\n=^\n                                  Clock)\n\n\n▷To Verify: If\n𝑐<3\n                                  in current clock cycle, then\n𝑐<3\n                                  in next clock cycle.\n\n\n\n\n \n\n▷Step 1\n                Encode into\npropositional logic.\n\n\n▷Propositions:\n𝑥1,𝑥0; and\n𝑦1,𝑦0\n                (value in next cycle).\n\n\n▷Transition relation:\n𝑦1⇔𝑦0;\n𝑦0⇔¬(𝑥1∨𝑥0).\n\n\n▷Initial state:\n¬(𝑥1∧𝑥0).\n\n\n▷Error property:\n𝑥1∧𝑦0.\n\n\n▷Step 2\n                Transform to\nCNF, encode as a\nclause set\n∆.\n\n\n▷Clauses:\n𝑦1𝖥∨𝑥0𝖳,\n𝑦1𝖳∨𝑥0𝖥,\n𝑦0𝖳∨𝑥1𝖳∨𝑥0𝖳,\n𝑦0𝖥∨𝑥1𝖥,\n𝑦0𝖥∨𝑥0𝖥,\n𝑥1𝖥∨𝑥0𝖥,\n𝑦1𝖳,\n𝑦0𝖳.\n\n\n▷Step 3\n                Call a\nSAT solver\n                (up next).\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-16\n",
        "sectionId": "d445b4ae",
        "archive": "courses/FAU/AI/course",
        "filepath": "logic/slides/propsat-hwverif.en.xhtml"
    },
    {
        "slideContent": "\nOur Agenda for This Chapter\n\n▷The Davis-Putnam (Logemann-Loveland) Procedure\n                How to systematically test\nsatisfiability?\n\n\n▷The quintessential\nSAT solving\n                procedure,\nDPLL.\n\n\n▷DPLL is (A Restricted Form of) Resolution\n                How does this relate to what we did in the last chapter?\n\n\n▷mathematical\n                understanding of\nDPLL.\n\n\n▷Why Did Unit Propagation Yield a Conflict?\n                How can we analyze which mistakes were made in “dead” search\nbranches?\n\n\n▷Knowledge is power, see next.\n\n\n▷Clause Learning\n                How can we learn from our mistakes?\n\n\n▷One of the key concepts, perhaps\nthe\n                key concept, underlying the success of\nSAT.\n\n\n▷Phase Transitions — Where the Really Hard Problems Are\n                Are\nall\n                formulas “hard” to solve?\n\n\n▷The answer is “no”. And in some cases we can figure out exactly when they are/aren’t hard to solve.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "d445b4ae",
        "archive": "courses/FAU/AI/course",
        "filepath": "logic/slides/propsat-agenda.en.xhtml"
    },
    {
        "slideContent": "\nThe DPLL Procedure\n\n▷\n                  The\nDavis Putnam procedure\n                  (DPLL) is a\nSAT solver\n                  called on a\nclause set\n∆\n                  and the\nempty assignment\n𝜖. It interleaves\nunit propagation\n                  (UP) and\nsplitting:\n\n\nfunction DPLL(∆,𝐼) returns a partial assignment 𝐼, or ‘‘unsatisfiable’’\n/* Unit Propagation (UP) Rule: */\n∆' := a copy of ∆; 𝐼' := 𝐼\nwhile ∆' contains a unit clause 𝐶=𝑃𝛼 do\nextend 𝐼' with [𝛼/𝑃], clause―set simplify ∆'\n/* Termination Test: */\nif □∊∆' then return ‘‘unsatisfiable’’\nif ∆'={} then return 𝐼'\n/* Splitting Rule: */\nselect some proposition 𝑃 for which 𝐼' is not defined\n𝐼'' := 𝐼' extended with one truth value for 𝑃; ∆'':= a copy of ∆'; simplify ∆''\nif 𝐼''' := DPLL(∆'',𝐼'') ≠ ‘‘unsatisfiable’’ then return 𝐼'''\n𝐼'' := 𝐼' extended with the other truth value for 𝑃; ∆'':=∆'; simplify ∆''\nreturn DPLL(∆'',𝐼'')\n\n▷In practice, of course one uses flags etc. instead of “copy”.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "e79a2f0a",
        "archive": "courses/FAU/AI/course",
        "filepath": "logic/slides/DPLL.en.xhtml"
    },
    {
        "slideContent": "\nDPLL: Example (Vanilla1)\n\n▷UP and Splitting\n                Let\n∆:=(𝑃𝖳∨𝑄𝖳∨𝑅𝖥);(𝑃𝖥∨𝑄𝖥);(𝑅𝖳);(𝑃𝖳∨𝑄𝖥)\n\n\n1.UP\n                Rule:\n𝑅↦𝖳(𝑃𝖳∨𝑄𝖳);(𝑃𝖥∨𝑄𝖥);(𝑃𝖳∨𝑄𝖥)\n\n\n2.Splitting\n                Rule:\n\n\n\n\n2a.𝑃↦𝖥(𝑄𝖳);(𝑄𝖥)\n\n\n3a.UP\n                                  Rule:\n𝑄↦𝖳□returning “unsatisfiable”\n\n\n\n2b.𝑃↦𝖳(𝑄𝖥)\n\n\n3b.UP\n                                  Rule:\n𝑄↦𝖥clause set\nempty\nreturning “𝑅↦𝖳,𝑃↦𝖳,𝑄↦𝖥\n\n\n\n\n \n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-16\n",
        "sectionId": "e79a2f0a",
        "archive": "courses/FAU/AI/course",
        "filepath": "logic/slides/dpll-vanilla1.en.xhtml"
    },
    {
        "slideContent": "\nDPLL: Example (Vanilla2)\n\n▷Observation\n                Sometimes\nUP\n                is all we need.\n\n\n▷\n                Let\n∆:=(𝑄𝖥∨𝑃𝖥);(𝑃𝖳∨𝑄𝖥∨𝑅𝖥∨𝑆𝖥);(𝑄𝖳∨𝑆𝖥);(𝑅𝖳∨𝑆𝖥);(𝑆𝖳)\n\n\n\n1.UP\n                                  Rule:\n𝑆↦𝖳(𝑄𝖥∨𝑃𝖥);(𝑃𝖳∨𝑄𝖥∨𝑅𝖥);(𝑄𝖳);(𝑅𝖳)\n\n\n2.UP\n                                  Rule:\n𝑄↦𝖳(𝑃𝖥);(𝑃𝖳∨𝑅𝖥);(𝑅𝖳)\n\n\n3.UP\n                                  Rule:\n𝑅↦𝖳(𝑃𝖥);(𝑃𝖳)\n\n\n4.UP\n                                  Rule:\n𝑃↦𝖳□\n\n\n\n\n \n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-16\n",
        "sectionId": "e79a2f0a",
        "archive": "courses/FAU/AI/course",
        "filepath": "logic/slides/dpll-vanilla2.en.xhtml"
    },
    {
        "slideContent": "\nDPLL: Example (Redundance1)\n\n▷We introduce some nasty redundance to make\nDPLL\n                slow.∆:=(𝑃𝖥∨𝑄𝖥∨𝑅𝖳);(𝑃𝖥∨𝑄𝖥∨𝑅𝖥);(𝑃𝖥∨𝑄𝖳∨𝑅𝖳);(𝑃𝖥∨𝑄𝖳∨𝑅𝖥)DPLL\n                on\n∆;Θ\n                with\nΘ:=(map(/𝑚𝑛𝑡/𝑠𝑑𝑏1/𝑏𝑢𝑖𝑙𝑑𝑠𝑒𝑟𝑣𝑒𝑟/𝑀𝑎𝑡ℎ𝐻𝑢𝑏,(𝑋1𝖳)∨...∨(𝑋𝑛𝖳))𝑋1𝖳∨...∨𝑋𝑛𝖳);(map(/𝑚𝑛𝑡/𝑠𝑑𝑏1/𝑏𝑢𝑖𝑙𝑑𝑠𝑒𝑟𝑣𝑒𝑟/𝑀𝑎𝑡ℎ𝐻𝑢𝑏,(𝑋1𝖥)∨...∨(𝑋𝑛𝖥))𝑋1𝖥∨...∨𝑋𝑛𝖥)\n\n\n\n\n\n(𝑅𝖳);□  \n(𝑅𝖳);□  \n(𝑅𝖳);□  \n(𝑅𝖳);□  \n(𝑅𝖳);□  \n(𝑅𝖳);□  \n(𝑅𝖳);□  \n(𝑅𝖳);□  \n\n𝑄  \n\n𝑄  \n\n𝑄  \n\n𝑄  \n\n𝖳  \n\n𝖥  \n\n𝖳  \n\n𝖥  \n\n𝖳  \n\n𝖥  \n\n𝖳  \n\n𝖥  \n\n𝑋𝑛  \n\n𝑋𝑛  \n\n𝖳  \n\n𝖥  \n\n𝖳  \n\n𝖥  \n\n𝑋1  \n\n\n𝖳  \n\n\n\n𝖥  \n\n\n𝑃  \n  \n\n𝖳  \n\n𝖥  \n\n\n\n\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-15\n",
        "sectionId": "e79a2f0a",
        "archive": "courses/FAU/AI/course",
        "filepath": "logic/slides/dpll-redundance-ex1.en.xhtml"
    },
    {
        "slideContent": "\nProperties of DPLL\n\n▷Unsatisfiable case\n                What can we say if “unsatisfiable” is returned?\n\n\n▷In this case, we know that\n∆\n                is\nunsatisfiable: Unit propagation is\nsound, in the sense that it does not reduce the set of solutions.\n\n\n▷Satisfiable case\n                What can we say when a partial interpretation\n𝐼\n                is returned?\n\n\n▷Any extension of\n𝐼\n                to a complete interpretation satisfies\n∆. (By construction,\n𝐼\n                suffices to satisfy all\nclauses.)\n\n\n▷Déjà Vu, Anybody?\n\n\n▷DPLL\n=^\nbacktracking with inference, where inference\n=^\nunit propagation.\n\n\n▷Unit propagation\n                is\nsound: It does not reduce the set of solutions.\n\n\n▷Running time\n                is\nexponential\n                in worst case, good variable/value selection strategies required.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-16\n",
        "sectionId": "e79a2f0a",
        "archive": "courses/FAU/AI/course",
        "filepath": "logic/slides/dpll-properties.en.xhtml"
    },
    {
        "slideContent": "\nUP\n=^\n              Unit Resolution\n\n▷Observation\n                  The\nunit propagation\n                  (UP) rule corresponds to a\ncalculus:\n\n\nwhile ∆' contains a unit clause {𝑙} do\nextend 𝐼' with the respective truth value for the proposition underlying 𝑙\nsimplify ∆' /* remove false literals */\n\n▷Unit Resolution\nUnit resolution\n                  (UR) is the\ntest calculus\n                  consisting of the following\ninference rule:\n𝐶∨𝑃𝛼𝑃𝛽𝛼≠𝛽𝐶UR\n\n▷Unit propagation\n=^\nresolution\n              restricted to cases where one parent is\nunit clause.\n\n\n▷Soundness\nUR\n                  is\nrefutation sound.\n(since\nresolution\n                      is)\n\n\n▷Completeness\nUR\n                  is not\nrefutation complete\n                  (alone).\n\n\n▷\n(𝑃𝖳∨𝑄𝖳);(𝑃𝖳∨𝑄𝖥);(𝑃𝖥∨𝑄𝖳);(𝑃𝖥∨𝑄𝖥)\n                  is\nunsatisfiable\n                  but\nUR\n                  cannot\nderive\n                  the\nempty clause\n□.\n\n\n▷UR\n              makes only limited inferences, as long as there are\nunit clauses. It does not guarantee to infer everything that can be inferred.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-15\n",
        "sectionId": "e97bb7a6",
        "archive": "courses/FAU/AI/course",
        "filepath": "logic/slides/unit-propagation.en.xhtml"
    },
    {
        "slideContent": "\nDPLL vs. Resolution\n\n▷\n                  We define the\nnumber of decisions\n                  of a\nDPLL\n                  run as the total number of times a truth value was set by either\nunit propagation\n                  or\nsplitting.\n\n\n▷\n                  If\nDPLL\n                  returns “unsatisfiable” on\n∆, then\n∆⊢ℛ0□\n                  with a\nresolution proof\n                  whose length is at most the\nnumber of decisions.\n\n\n▷Proof:\nConsider first\nDPLL\n                  without\nUP\n\n\n\n1.Consider any\nleaf\nnode\n𝑁, for proposition\n𝑋, both of whose truth values directly result in a\nclause\n𝐶\n                    that has become\nempty.\n\n\n\n\n2.Then for\n𝑋=𝖥\n                    the respective\nclause\n𝐶\n                    must contain\n𝑋𝖳; and for\n𝑋=𝖳\n                    the respective\nclause\n𝐶\n                    must contain\n𝑋𝖥. Thus we can resolve these two\nclauses\n                    to a\nclause\n𝐶(𝑁)\n                    that does not contain\n𝑋.\n\n\n\n\n3.𝐶(𝑁)\n                    can contain only the negations of the decision\nliterals\n𝑙1,...,𝑙𝑘\n                    above\n𝑁. Remove\n𝑁\n                    from the\ntree, then iterate the argument. Once the tree is empty, we have derived the\nempty clause.\n\n\n\n\n4.Unit propagation\n                    can be simulated via applications of the\nsplitting\n                    rule, choosing a proposition that is constrained by a\nunit clause: One of the two truth values then immediately yields an\nempty clause.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "e97bb7a6",
        "archive": "courses/FAU/AI/course",
        "filepath": "logic/slides/DPLLvsResolution.en.xhtml"
    },
    {
        "slideContent": "\nDPLL vs. Resolution: Example (Vanilla2)\n\n▷Observation\n                  The\nproof\n                  of\n??\n                  is\nconstructive, so we can use it as a method to read of a\nresolution proof\n                  from a\nDPLL\n                  trace.\n\n\n▷\n                  We follow the steps in the\nproof\n                  of\n??\n                  for\n∆:=(𝑄𝖥∨𝑃𝖥);(𝑃𝖳∨𝑄𝖥∨𝑅𝖥∨𝑆𝖥);(𝑄𝖳∨𝑆𝖥);(𝑅𝖳∨𝑆𝖥);(𝑆𝖳)\n\n\n\nDPLL: (Without\nUP; leaves annotated with\nclauses\n                                    that became\nempty)\n\nResolution proof\n                                    from that\nDPLL\n                                    tree:\n\n\n\n\n\n𝑄𝖥∨𝑃𝖥  \n𝑃𝖳∨𝑄𝖥∨𝑅𝖥∨𝑆𝖥  \n𝑅𝖳∨𝑆𝖥  \n𝑄𝖳∨𝑆𝖥  \n𝑆𝖳  \n\n𝑆  \n\n𝑄  \n\n𝑅  \n\n𝑃  \n\n𝖳  \n\n𝖥  \n\n𝖳  \n\n𝖥  \n\n𝖳  \n\n𝖥  \n\n𝖳  \n\n𝖥  \n\n\n\n\n\n\n\n\n\n\n𝑄𝖥∨𝑃𝖥  \n𝑃𝖳∨𝑄𝖥∨𝑅𝖥∨𝑆𝖥  \n𝑅𝖳∨𝑆𝖥  \n𝑄𝖳∨𝑆𝖥  \n𝑆𝖳  \n□  \n𝑆𝖥  \n𝑄𝖥∨𝑆𝖥  \n𝑄𝖥∨𝑅𝖥∨𝑆𝖥  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n▷Intuition\n                  From a (top-down)\nDPLL\n                  tree, we generate a (bottom-up)\nresolution proof.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-16\n",
        "sectionId": "e97bb7a6",
        "archive": "courses/FAU/AI/course",
        "filepath": "logic/slides/DPLLvsResolution-ex.en.xhtml",
        "video_name": "AI1_25thDec.m4v",
        "start_time": 486.29,
        "end_time": 496.09
    },
    {
        "slideContent": "\nDPLL vs. Resolution: Discussion\n\n▷So What?\n                  The theorem we just proved helps to\nunderstand\nDPLL:DPLL\n                  is an\nefficient\n                  practical method for conducting\nresolution proofs.\n\n\n▷In fact\nDPLL\n=^\ntree resolution.\n\n\n▷\n                  In a\ntree resolution, each\nderived\nclause\n𝐶\n                  is used only once (at its\nparent).\n\n\n▷Problem\n                  The same\n𝐶\n                  must be\nderived\n                  anew every time it is used!\n\n\n▷This is a fundamental weakness\n                  There are inputs\n∆\n                  whose shortest\ntree resolution\n                  proof is\nexponentially\n                  longer than their shortest (general)\nresolution proof.\n\n\n▷Intuitively\nDPLL\n                  makes the same mistakes over and over again.\n\n\n▷Idea\nDPLL\n                  should learn from its mistakes on one search\nbranch, and apply the learned knowledge to other\nbranches.\n\n\n▷To the rescueclause learning(up next)\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-16\n",
        "sectionId": "e97bb7a6",
        "archive": "courses/FAU/AI/course",
        "filepath": "logic/slides/DPLLvsResolution-discussion.en.xhtml",
        "video_name": "AI1_25thDec.m4v",
        "start_time": 471.68,
        "end_time": 486.29
    },
    {
        "slideContent": "\nSummary\n\n▷SAT solvers\n            decide satisfiability of CNF formulas. This can be used for deduction, and is highly successful as a general problem solving technique (e.g., in\nverification).\n\n\n▷DPLL\n=^\nbacktracking\n            with inference performed by\nunit propagation\n            (UP), which iteratively instantiates\nunit clauses\n            and simplifies the\nformula.\n\n\n▷DPLL\n            proofs of unsatisfiability correspond to a restricted form of\nresolution. The restriction forces\nDPLL\n            to “makes the same mistakes over again”.\n\n\n▷Implication graphs\n            capture how\nUP\nderives\n            conflicts. Their analysis enables us to do\nclause learning.\nDPLL\n            with\nclause learning\n            is called\nCDCL. It corresponds to full\nresolution, not “making the same mistakes over again”.\n\n\n▷CDCL\n            is\nstate of the art\n            in applications, routinely solving formulas with millions of propositions.\n\n\n▷In particular random formula distributions, typical problem hardness is characterized by\nphase transitions.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-15\n",
        "sectionId": "ee2f5ce8",
        "archive": "courses/FAU/AI/course",
        "filepath": "logic/slides/propsat-summary.en.xhtml"
    },
    {
        "slideContent": "\nState of the Art in\nSAT\n\n▷SAT competitions\n\n\n▷Since beginning of the 90s\nhttp://www.satcompetition.org/\n\n\n▷random\n                vs.\nindustrial\n                vs.\nhandcrafted\nbenchmarks.\n\n\n▷Largest industrial instances:\n>1.000.000\n                propositions.\n\n\n▷State of the art is CDCL\n\n\n▷Vastly superior on handcrafted and industrial\nbenchmarks.\n\n\n▷Key techniques:\nclause learning! Also:\nEfficient\nimplementation\n                (UP!), good\nbranching\nheuristics, random restarts, portfolios.\n\n\n▷What about local search?\n\n\n▷Better on random instances.\n\n\n▷No “dramatic” progress in last decade.\n\n\n▷Parameters are difficult to adjust.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-16\n",
        "sectionId": "ee2f5ce8",
        "archive": "courses/FAU/AI/course",
        "filepath": "logic/slides/propsat-soa.en.xhtml",
        "video_name": "AI1_25thDec.m4v",
        "start_time": 680.16,
        "end_time": 942.81
    },
    {
        "slideContent": "\nBut — What About Local Search for SAT?\n\n▷There’s a wealth of research on local search for\nSAT, e.g.:\n\n\n▷\n                  The\nGSAT algorithm\nOUTPUT: a satisfying truth assignment of\n∆, if found\n\nfunction GSAT (∆, 𝑀𝑎𝑥𝐹𝑙𝑖𝑝𝑠 𝑀𝑎𝑥𝑇𝑟𝑖𝑒𝑠\nfor 𝑖 :=1 to 𝑀𝑎𝑥𝑇𝑟𝑖𝑒𝑠\n𝐼 := a randomly―generated truth assignment\nfor 𝑗 :=1 to 𝑀𝑎𝑥𝐹𝑙𝑖𝑝𝑠\nif 𝐼 satisfies ∆ then return 𝐼\n𝑋:= a proposition reversing whose truth assignment gives\nthe largest increase in the number of satisfied clauses\n𝐼 := 𝐼 with the truth assignment of 𝑋 reversed\nend for\nend for\nreturn ‘‘no satisfying assignment found’’\n\n▷local search\n              is not as successful in\nSAT\n              applications, and the underlying ideas are very similar to those presented in\n??(Not covered here)\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-15\n",
        "sectionId": "ee2f5ce8",
        "archive": "courses/FAU/AI/course",
        "filepath": "logic/slides/gsat.en.xhtml"
    },
    {
        "slideContent": "\nTopics We Didn’t Cover Here\n\n▷Variable/value selection\nheuristics: A whole zoo is out there.\n\n\n▷Implementation techniques: One of the most intensely researched subjects. Famous “watched\nliterals” technique for\nUP\n            had huge practical impact.\n\n\n▷Local search: In space of all truth value assignments. GSAT (slide\n??) had huge impact at the time (1992), caused huge amount of follow-up work. Less intensely researched since\nclause learning\n            hit the scene in the late 90s.\n\n\n▷Portfolios: How to combine several\nSAT solvers\nefficiently?\n\n\n▷Random restarts: Tackling heavy-tailed runtime distributions.\n\n\n▷Tractable\nSAT: Polynomial-time sub-classes (most prominent: 2-SAT, Horn formulas).\n\n\n▷MaxSAT: Assign weight to each\nclause,\nmaximize\n            weight of\nsatisfied\nclauses\n            (= optimization version of\nSAT).\n\n\n▷Resolution special cases: There’s a universe in between unit resolution and\nfull resolution: trade off inference vs.,search.\n\n\n▷Proof complexity: Can one\nresolution\n            special case\n𝑋\n            simulate another one\n𝑌\npolynomially? Or is there an\nexponential\n            separation (example families where\n𝑋\n            is\nexponentially\n            less\nefficient\n            than\n𝑌)?\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-15\n",
        "sectionId": "ee2f5ce8",
        "archive": "courses/FAU/AI/course",
        "filepath": "logic/slides/propsat-not.en.xhtml",
        "video_name": "AI1_25thDec.m4v",
        "start_time": 942.81,
        "end_time": 960.35
    },
    {
        "slideContent": "\nDPLL: Example (Redundance1)\n\n▷We introduce some nasty redundance to make\nDPLL\n                slow.∆:=(𝑃𝖥∨𝑄𝖥∨𝑅𝖳);(𝑃𝖥∨𝑄𝖥∨𝑅𝖥);(𝑃𝖥∨𝑄𝖳∨𝑅𝖳);(𝑃𝖥∨𝑄𝖳∨𝑅𝖥)DPLL\n                on\n∆;Θ\n                with\nΘ:=(map(/𝑚𝑛𝑡/𝑠𝑑𝑏1/𝑏𝑢𝑖𝑙𝑑𝑠𝑒𝑟𝑣𝑒𝑟/𝑀𝑎𝑡ℎ𝐻𝑢𝑏,(𝑋1𝖳)∨...∨(𝑋𝑛𝖳))𝑋1𝖳∨...∨𝑋𝑛𝖳);(map(/𝑚𝑛𝑡/𝑠𝑑𝑏1/𝑏𝑢𝑖𝑙𝑑𝑠𝑒𝑟𝑣𝑒𝑟/𝑀𝑎𝑡ℎ𝐻𝑢𝑏,(𝑋1𝖥)∨...∨(𝑋𝑛𝖥))𝑋1𝖥∨...∨𝑋𝑛𝖥)\n\n\n\n\n\n(𝑅𝖳);□  \n(𝑅𝖳);□  \n(𝑅𝖳);□  \n(𝑅𝖳);□  \n(𝑅𝖳);□  \n(𝑅𝖳);□  \n(𝑅𝖳);□  \n(𝑅𝖳);□  \n\n𝑄  \n\n𝑄  \n\n𝑄  \n\n𝑄  \n\n𝖳  \n\n𝖥  \n\n𝖳  \n\n𝖥  \n\n𝖳  \n\n𝖥  \n\n𝖳  \n\n𝖥  \n\n𝑋𝑛  \n\n𝑋𝑛  \n\n𝖳  \n\n𝖥  \n\n𝖳  \n\n𝖥  \n\n𝑋1  \n\n\n𝖳  \n\n\n\n𝖥  \n\n\n𝑃  \n  \n\n𝖳  \n\n𝖥  \n\n\n\n\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-15\n",
        "sectionId": "90081026",
        "archive": "courses/FAU/AI/course",
        "filepath": "logic/slides/dpll-redundance-ex1.en.xhtml"
    },
    {
        "slideContent": "\nHow To\nNot\n            Make the Same Mistakes Over Again?\n\n▷It’s not that difficult, really\n\n\n(A)Figure out what went wrong.\n\n\n(B)Learn to not do that again in the future.\n\n\n▷And now for DPLL\n\n\n(A)Why\n                did\nunit propagation\n                yield a Conflict?\n\n\n▷This Section. We will capture the “what went wrong” in terms of graphs over\nliterals\n                set during the search, and their dependencies.\n\n\n▷What can we learn from that information?\n\n\n▷A new\nclause! Next section.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "90081026",
        "archive": "courses/FAU/AI/course",
        "filepath": "logic/slides/dpll-conflict-intro.en.xhtml"
    },
    {
        "slideContent": "\nImplication Graphs for\nDPLL\n\n▷\n                  Let\n𝛽\n                  be a\nbranch\n                  in a\nDPLL\nderivation\n                  and\n𝑃\n                  a variable on\n𝛽\n                  then we call\n\n\n▷𝑃𝛼\n                  a\nchoice literal\n                  if its\nvalue\n                  is set to\n𝛼\n                  by the\nsplitting\n                  rule.\n\n\n▷𝑃𝛼\n                  an\nimplied literal, if the\nvalue\n                  of\n𝑃\n                  is set to\n𝛼\n                  by the\nUP\n                  rule.\n\n\n▷𝑃𝛼\n                  a\nconflict literal, if it contributes to a\nderivation\n                  of the\nempty clause.\n\n\n▷Implication Graph\n\nLet\n∆\n                  be a\nclause set,\n𝛽\n                  a\nDPLL\n                  search\nbranch\n                  on\n∆. The\nimplication graph\n𝐺𝛽impl\n                  is the\ndirected graph\n                  whose\nvertices\n                  are\nlabeled\n                  with the\nchoice\n                  and\nimplied literals\n                  along\n𝛽, as well as a separate\nconflict vertex\n□𝐶\n                  for every\nclause\n𝐶\n                  that became\nempty\n                  on\n𝛽.\n\nWhereever a\nclause\n𝑙1,...,𝑙𝑘∨𝑙'∊∆\n                  became\nunit\n                  with\nimplied literal\n𝑙',\n𝐺𝛽impl\n                  includes the\nedges\n(𝑙𝑖―,𝑙').\n\nWhere\n𝐶=𝑙1∨...∨𝑙𝑘∊∆\n                  became\nempty,\n𝐺𝛽impl\n                  includes the\nedges\n(𝑙𝑖―,□𝐶).\n\n\n▷Question\n                  How do we know that\n𝑙𝑖―\n                  are\nvertices\n                  in\n𝐺𝛽impl?\n\n\n▷Answer\n                  Because\n𝑙1∨...∨𝑙𝑘∨𝑙'\n                  became\nunit/empty.\n\n\n▷\n𝐺𝛽impl\n                  is\nacyclic.\n\n\n▷Proof sketch:\nUP\n                can’t\nderive\n𝑙'\n                whose\nvalue\n                was already set beforehand.\n\n\n▷Intuition\n                  The\ninitial\nvertices\n                  are the\nchoice literals\n                  and\nunit clauses\n                  of\n∆.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "90081026",
        "archive": "courses/FAU/AI/course",
        "filepath": "logic/slides/dpll-implication-graph.en.xhtml"
    },
    {
        "slideContent": "\nImplication Graphs: Example (Vanilla1) in Detail\n\n▷\n                Let\n∆:=(𝑃𝖳∨𝑄𝖳∨𝑅𝖥);(𝑃𝖥∨𝑄𝖥);(𝑅𝖳);(𝑃𝖳∨𝑄𝖥).\n\nWe look at the left\nbranch\n                of the\nderivation\n                from\n??:\n\n\n\n1.UP\n                                  Rule:\n𝑅↦𝖳Implied literal\n𝑅𝖳.(𝑃𝖳∨𝑄𝖳);(𝑃𝖥∨𝑄𝖥);(𝑃𝖳∨𝑄𝖥)\n\n\n2.Splitting\n                                  Rule:\n\n\n2a.𝑃↦𝖥Choice literal\n𝑃𝖥.(𝑄𝖳);(𝑄𝖥)\n\n\n3a.UP\n                                  Rule:\n𝑄↦𝖳Implied literal\n𝑄𝖳edges\n(𝑅𝖳,𝑄𝖳)\n                                  and\n(𝑃𝖥,𝑄𝖳).□Conflict vertex\n□𝑃𝖳∨𝑄𝖥edges\n(𝑃𝖥,□𝑃𝖳∨𝑄𝖥)\n                                  and\n(𝑄𝖳,□𝑃𝖳∨𝑄𝖥).\n\n\n\nImplication graph:\n\n\n\n\n\n𝑅𝖳  \n\n□𝑃𝖳∨𝑄𝖥  \n\n𝑄𝖳  \n\n𝑃𝖥  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-16\n",
        "sectionId": "90081026",
        "archive": "courses/FAU/AI/course",
        "filepath": "logic/slides/dpll-implication-graph-ex0.en.xhtml"
    },
    {
        "slideContent": "\nImplication Graphs: Example (Redundance1)\n\n▷Continuing from\n??:\n∆:=(𝑃𝖥∨𝑄𝖥∨𝑅𝖳);(𝑃𝖥∨𝑄𝖥∨𝑅𝖥);(𝑃𝖥∨𝑄𝖳∨𝑅𝖳);(𝑃𝖥∨𝑄𝖳∨𝑅𝖥)DPLL\n                on\n∆;Θ\n                with\nΘ:=(map(/𝑚𝑛𝑡/𝑠𝑑𝑏1/𝑏𝑢𝑖𝑙𝑑𝑠𝑒𝑟𝑣𝑒𝑟/𝑀𝑎𝑡ℎ𝐻𝑢𝑏,(𝑋1𝖳)∨...∨(𝑋𝑛𝖳))𝑋1𝖳∨...∨𝑋𝑛𝖳);(map(/𝑚𝑛𝑡/𝑠𝑑𝑏1/𝑏𝑢𝑖𝑙𝑑𝑠𝑒𝑟𝑣𝑒𝑟/𝑀𝑎𝑡ℎ𝐻𝑢𝑏,(𝑋1𝖥)∨...∨(𝑋𝑛𝖥))𝑋1𝖥∨...∨𝑋𝑛𝖥)Choice literals:\n𝑃𝖳,\nmap(/𝑚𝑛𝑡/𝑠𝑑𝑏1/𝑏𝑢𝑖𝑙𝑑𝑠𝑒𝑟𝑣𝑒𝑟/𝑀𝑎𝑡ℎ𝐻𝑢𝑏,(𝑋1𝖳),...,(𝑋𝑛𝖳))(𝑋1𝖳),...,(𝑋𝑛𝖳),\n𝑄𝖳.\nImplied literal:\n𝑅𝖳.\n\n\n\n\n\n\n(𝑅𝖳);□  \n(𝑅𝖳);□  \n(𝑅𝖳);□  \n(𝑅𝖳);□  \n(𝑅𝖳);□  \n(𝑅𝖳);□  \n(𝑅𝖳);□  \n(𝑅𝖳);□  \n\n𝑄  \n\n𝑄  \n\n𝑄  \n\n𝑄  \n\n𝖳  \n\n𝖥  \n\n𝖳  \n\n𝖥  \n\n𝖳  \n\n𝖥  \n\n𝖳  \n\n𝖥  \n\n𝑋𝑛  \n\n𝑋𝑛  \n\n𝖳  \n\n𝖥  \n\n𝖳  \n\n𝖥  \n\n𝑋1  \n\n\n𝖳  \n\n\n\n𝖥  \n\n\n𝑃  \n  \n\n𝖳  \n\n𝖥  \n\n\n\n\n\n\n\n\n\n\n\n𝑅𝖳  \n\n□𝑃𝖳∨𝑄𝖥∨𝑅𝖳  \n\n𝑄𝖳  \n\n𝑃𝖳  \n\n𝑋1𝖳  \n...  \n\n𝑋𝑛𝖳  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-15\n",
        "sectionId": "90081026",
        "archive": "courses/FAU/AI/course",
        "filepath": "logic/slides/dpll-implication-graph-ex1.en.xhtml"
    },
    {
        "slideContent": "\nImplication Graphs: Example (Redundance2)\n\n▷Continuing from\n??:\n∆:=(𝑃𝖥∨𝑄𝖥∨𝑅𝖳);(𝑃𝖥∨𝑄𝖥∨𝑅𝖥);(𝑃𝖥∨𝑄𝖳∨𝑅𝖳);(𝑃𝖥∨𝑄𝖳∨𝑅𝖥)\n\nΘ:=(map(/𝑚𝑛𝑡/𝑠𝑑𝑏1/𝑏𝑢𝑖𝑙𝑑𝑠𝑒𝑟𝑣𝑒𝑟/𝑀𝑎𝑡ℎ𝐻𝑢𝑏,(𝑋1𝖳)∨...∨(𝑋𝑛𝖳))𝑋1𝖳∨...∨𝑋𝑛𝖳);(map(/𝑚𝑛𝑡/𝑠𝑑𝑏1/𝑏𝑢𝑖𝑙𝑑𝑠𝑒𝑟𝑣𝑒𝑟/𝑀𝑎𝑡ℎ𝐻𝑢𝑏,(𝑋1𝖥)∨...∨(𝑋𝑛𝖥))𝑋1𝖥∨...∨𝑋𝑛𝖥)\n\nDPLL\n                on\n∆;Θ;Φ\n                with\nΦ:=(𝑄𝖥∨𝑆𝖳);(𝑄𝖥∨𝑆𝖥)Choice literals:\n𝑃𝖳,\nmap(/𝑚𝑛𝑡/𝑠𝑑𝑏1/𝑏𝑢𝑖𝑙𝑑𝑠𝑒𝑟𝑣𝑒𝑟/𝑀𝑎𝑡ℎ𝐻𝑢𝑏,(𝑋1𝖳),...,(𝑋𝑛𝖳))(𝑋1𝖳),...,(𝑋𝑛𝖳),\n𝑄𝖳.\nImplied literals:\n\n\n\n\n\n\n\n𝑅𝖳  \n\n□𝑃𝖳∨𝑄𝖥∨𝑅𝖳  \n\n𝑄𝖳  \n\n𝑃𝖳  \n\n𝑋1𝖳  \n...  \n\n𝑋𝑛𝖳  \n\n𝑆𝖳  \n\n□  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-15\n",
        "sectionId": "90081026",
        "archive": "courses/FAU/AI/course",
        "filepath": "logic/slides/dpll-implication-graph-ex2.en.xhtml"
    },
    {
        "slideContent": "\nImplication Graphs: A Remark\n\n▷The\nimplication graph\n            is\nnot\n            uniquely determined by the\nChoice literals.\n\n\n▷It depends on “ordering decisions” during\nUP: Which\nunit clause\n            is picked first.\n\n\n▷\n∆=(𝑃𝖥∨𝑄𝖥);(𝑄𝖳);(𝑃𝖳)\n\n\nOption 1 Option 2 \n\n\n\n\n□𝑃𝖥∨𝑄𝖥  \n\n𝑃𝖥  \n\n𝑄𝖳  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n\n\n\n\n□𝑃𝖥∨𝑄𝖥  \n\n𝑄𝖥  \n\n𝑃𝖳  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-16\n",
        "sectionId": "90081026",
        "archive": "courses/FAU/AI/course",
        "filepath": "logic/slides/dpll-implication-graph-nonunique.en.xhtml"
    },
    {
        "slideContent": "\nConflict Graphs\n\n▷A\nconflict graph\n              captures “what went wrong” in a failed node.\n\n\n▷Conflict Graph\n                  Let\n∆\n                  be a\nclause set, and let\n𝐺𝛽impl\n                  be the\nimplication graph\n                  for some search\nbranch\n𝛽\n                  of\nDPLL\n                  on\n∆. A subgraph\n𝐶\n                  of\n𝐺𝛽impl\n                  is a\nconflict graph\n                  if:\n\n\n(i)𝐶\n                  contains exactly one\nconflict vertex\n□𝐶.\n\n\n(ii)If\n𝑙'\n                  is a\nvertex\n                  in\n𝐶, then all\nparents\n                  of\n𝑙', i.e.\nvertices\n𝑙𝑖―\n                  with a\n𝐼\nedge\n(𝑙𝑖―,𝑙'), are\nvertices\n                  in\n𝐶\n                  as well.\n\n\n(iii)All\nvertices\n                  in\n𝐶\n                  have a path to\n□𝐶.\n\n\n▷Conflict graph\n=^\n              Starting at a\nconflict vertex,\nbackchain\n              through the\nimplication graph\n              until reaching\nchoice literals.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "90081026",
        "archive": "courses/FAU/AI/course",
        "filepath": "logic/slides/dpll-conflict-graph.en.xhtml"
    },
    {
        "slideContent": "\nConflict-Graphs: Example (Redundance1)\n\n▷Continuing from\n??:\n∆:=(𝑃𝖥∨𝑄𝖥∨𝑅𝖳);(𝑃𝖥∨𝑄𝖥∨𝑅𝖥);(𝑃𝖥∨𝑄𝖳∨𝑅𝖳);(𝑃𝖥∨𝑄𝖳∨𝑅𝖥)DPLL\n                on\n∆;Θ\n                with\nΘ:=(map(/𝑚𝑛𝑡/𝑠𝑑𝑏1/𝑏𝑢𝑖𝑙𝑑𝑠𝑒𝑟𝑣𝑒𝑟/𝑀𝑎𝑡ℎ𝐻𝑢𝑏,(𝑋1𝖳)∨...∨(𝑋100𝖳))𝑋1𝖳∨...∨𝑋100𝖳);(map(/𝑚𝑛𝑡/𝑠𝑑𝑏1/𝑏𝑢𝑖𝑙𝑑𝑠𝑒𝑟𝑣𝑒𝑟/𝑀𝑎𝑡ℎ𝐻𝑢𝑏,(𝑋1𝖥)∨...∨(𝑋100𝖥))𝑋1𝖥∨...∨𝑋100𝖥)Choice literals:\n𝑃𝖳,\nmap(/𝑚𝑛𝑡/𝑠𝑑𝑏1/𝑏𝑢𝑖𝑙𝑑𝑠𝑒𝑟𝑣𝑒𝑟/𝑀𝑎𝑡ℎ𝐻𝑢𝑏,(𝑋1𝖳),...,(𝑋100𝖳))(𝑋1𝖳),...,(𝑋100𝖳),\n𝑄𝖳.\nImplied literals:\n𝑅𝖳.\n\n\n\n\n\n\n\n𝑅𝖳  \n\n□𝑃𝖳∨𝑄𝖥∨𝑅𝖳  \n\n𝑄𝖳  \n\n𝑃𝖳  \n\n𝑋1𝖳  \n...  \n\n𝑋𝑛𝖳  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n  \n\n\n\n\n\n\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-15\n",
        "sectionId": "90081026",
        "archive": "courses/FAU/AI/course",
        "filepath": "logic/slides/dpll-conflict-graph-ex1.en.xhtml"
    },
    {
        "slideContent": "\nConflict Graphs: Example (Redundance2)\n\n▷Continuing from\n??\n                and\n??:\n∆:=(𝑃𝖥∨𝑄𝖥∨𝑅𝖳);(𝑃𝖥∨𝑄𝖥∨𝑅𝖥);(𝑃𝖥∨𝑄𝖳∨𝑅𝖳);(𝑃𝖥∨𝑄𝖳∨𝑅𝖥)\n\nΘ:=(map(/𝑚𝑛𝑡/𝑠𝑑𝑏1/𝑏𝑢𝑖𝑙𝑑𝑠𝑒𝑟𝑣𝑒𝑟/𝑀𝑎𝑡ℎ𝐻𝑢𝑏,(𝑋1𝖳)∨...∨(𝑋𝑛𝖳))𝑋1𝖳∨...∨𝑋𝑛𝖳);(map(/𝑚𝑛𝑡/𝑠𝑑𝑏1/𝑏𝑢𝑖𝑙𝑑𝑠𝑒𝑟𝑣𝑒𝑟/𝑀𝑎𝑡ℎ𝐻𝑢𝑏,(𝑋1𝖥)∨...∨(𝑋𝑛𝖥))𝑋1𝖥∨...∨𝑋𝑛𝖥)\n\nDPLL\n                on\n∆;Θ;Φ\n                with\nΦ:=(𝑄𝖥∨𝑆𝖳);(𝑄𝖥∨𝑆𝖥)Choice literals:\n𝑃𝖳,\nmap(/𝑚𝑛𝑡/𝑠𝑑𝑏1/𝑏𝑢𝑖𝑙𝑑𝑠𝑒𝑟𝑣𝑒𝑟/𝑀𝑎𝑡ℎ𝐻𝑢𝑏,(𝑋1𝖳),...,(𝑋𝑛𝖳))(𝑋1𝖳),...,(𝑋𝑛𝖳),\n𝑄𝖳.\nImplied literals:\n𝑅𝖳.\n\n\n\n\n\n\n\n𝑅𝖳  \n\n□𝑃𝖳∨𝑄𝖥∨𝑅𝖳  \n\n𝑄𝖳  \n\n𝑃𝖳  \n\n𝑋1𝖳  \n...  \n\n𝑋𝑛𝖳  \n\n𝑆𝖳  \n\n□  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n𝑅𝖳  \n\n□𝑃𝖳∨𝑄𝖥∨𝑅𝖳  \n\n𝑄𝖳  \n\n𝑃𝖳  \n\n𝑋1𝖳  \n...  \n\n𝑋𝑛𝖳  \n\n𝑆𝖳  \n\n□  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-15\n",
        "sectionId": "90081026",
        "archive": "courses/FAU/AI/course",
        "filepath": "logic/slides/dpll-conflict-graph-ex2.en.xhtml"
    },
    {
        "slideContent": "\nClause Learning\n\n▷Observation\nConflict graphs\n                  encode the\nentailment relation.\n\n\n▷\n                  Let\n∆\n                  be a\nclause set,\n𝐶\n                  be a\nconflict graph\n                  at some time point during a run of\nDPLL\n                  on\n∆, and\n𝐿\n                  be the\nchoice literals\n                  in\n𝐶, then we call\n𝑐:=⋁𝑙∊𝐿𝑙―\n                  the\nlearned clause\n                  for\n𝐶.\n\n\n▷\n                  Let\n∆,\n𝐶, and\n𝑐\n                  as in\n??, then\n∆⊨𝑐.\n\n\n▷Idea\n                  We can add\nlearned clauses\n                  to\nDPLL\nderivations\n                  at any time without losing\nsoundness.\n(maybe this helps, if we have a good notion of\nlearned clauses)\n\n\n▷\nClause learning\n                  is the process of adding\nlearned clauses\n                  to\nDPLL\nclause sets\n                  at specific points.\n(details coming up)\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "e913c905",
        "archive": "courses/FAU/AI/course",
        "filepath": "logic/slides/dpll-clause-learning.en.xhtml"
    },
    {
        "slideContent": "\nClause Learning: Example (Redundance1)\n\n▷Continuing from\n??:∆:=(𝑃𝖥∨𝑄𝖥∨𝑅𝖳);(𝑃𝖥∨𝑄𝖥∨𝑅𝖥);(𝑃𝖥∨𝑄𝖳∨𝑅𝖳);(𝑃𝖥∨𝑄𝖳∨𝑅𝖥)DPLL\n                on\n∆;Θ\n                with\nΘ:=(map(/𝑚𝑛𝑡/𝑠𝑑𝑏1/𝑏𝑢𝑖𝑙𝑑𝑠𝑒𝑟𝑣𝑒𝑟/𝑀𝑎𝑡ℎ𝐻𝑢𝑏,(𝑋1𝖳)∨...∨(𝑋𝑛𝖳))𝑋1𝖳∨...∨𝑋𝑛𝖳);(map(/𝑚𝑛𝑡/𝑠𝑑𝑏1/𝑏𝑢𝑖𝑙𝑑𝑠𝑒𝑟𝑣𝑒𝑟/𝑀𝑎𝑡ℎ𝐻𝑢𝑏,(𝑋1𝖥)∨...∨(𝑋𝑛𝖥))𝑋1𝖥∨...∨𝑋𝑛𝖥)Choice literals:\n𝑃𝖳,\nmap(/𝑚𝑛𝑡/𝑠𝑑𝑏1/𝑏𝑢𝑖𝑙𝑑𝑠𝑒𝑟𝑣𝑒𝑟/𝑀𝑎𝑡ℎ𝐻𝑢𝑏,(𝑋1𝖳),...,(𝑋𝑛𝖳))(𝑋1𝖳),...,(𝑋𝑛𝖳),\n𝑄𝖳.\nImplied literals:\n𝑅𝖳.\n\n\n\n\n\n\n\n𝑅𝖳  \n\n□𝑃𝖳∨𝑄𝖥∨𝑅𝖳  \n\n𝑄𝖳  \n\n𝑃𝖳  \n\n𝑋1𝖳  \n...  \n\n𝑋𝑛𝖳  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n  \n\n\n\n\n\n\n\n\nLearned clause:\n𝑃𝖥∨𝑄𝖥\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-16\n",
        "sectionId": "e913c905",
        "archive": "courses/FAU/AI/course",
        "filepath": "logic/slides/dpll-clause-learning-ex1.en.xhtml"
    },
    {
        "slideContent": "\nThe Effect of\nLearned Clauses\n(in Redundance1)\n\n▷What happens after we\nlearned\n              a new\nclause\n𝐶?\n\n\n1.We add\n𝐶\n              into\n∆.\ne.g.\n𝐶=𝑃𝖥∨𝑄𝖥.\n\n\n2.We retract the last choice\n𝑙'.\ne.g. the choice\n𝑙'=𝑄.\n\n\nObservation\n                  Let\n𝐶\n                  be a\nlearned clause, i.e.\n𝐶=⋁𝑙∊𝐿𝑙―, where\n𝐿\n                  is the set of\nconflict literals\n                  in a\nconflict graph\n𝐺.\n\nBefore we learn\n𝐶,\n𝐺\n                  must contain the most recent choice\n𝑙': otherwise, the conflict would have occured earlier on.\n\nSo\n𝐶=map(/𝑚𝑛𝑡/𝑠𝑑𝑏1/𝑏𝑢𝑖𝑙𝑑𝑠𝑒𝑟𝑣𝑒𝑟/𝑀𝑎𝑡ℎ𝐻𝑢𝑏,(𝑙1𝖳)∨...∨(𝑙𝑘𝖳))𝑙1𝖳∨...∨𝑙𝑘𝖳∨𝑙'―\n                  where\n𝑙1,...,𝑙𝑘\n                  are earlier choices.\n\n\n▷\n\n▷\n𝑙1=𝑃,\n𝐶=𝑃𝖥∨𝑄𝖥,\n𝑙'=𝑄.\n\n\n▷Observation\n                  Given the earlier choices\n𝑙1,...,𝑙𝑘, after we\nlearned\n                  the new\nclause\n𝐶=map(/𝑚𝑛𝑡/𝑠𝑑𝑏1/𝑏𝑢𝑖𝑙𝑑𝑠𝑒𝑟𝑣𝑒𝑟/𝑀𝑎𝑡ℎ𝐻𝑢𝑏,𝑙1―∨...∨𝑙𝑘―)𝑙1―∨...∨𝑙𝑘―∨𝑙'―, the value of\n𝑙'―\n                  is now set by\nUP!\n\n\n▷So we can continue:\n\n\n3.We set the\nopposite choice\n𝑙'―\n              as an\nimplied literal.\n\ne.g.\n𝑄𝖥\n                  as an\nimplied literal.\n\n\n4.We run\nUP\n              and analyze conflicts.\n\nLearned clause: earlier choices only!\ne.g.\n𝐶=𝑃𝖥, see next slide.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "e913c905",
        "archive": "courses/FAU/AI/course",
        "filepath": "logic/slides/dpll-clause-learning-effect.en.xhtml"
    },
    {
        "slideContent": "\nThe Effect of\nLearned Clauses: Example (Redundance1)\n\n▷Continuing from\n??:\n∆:=(𝑃𝖥∨𝑄𝖥∨𝑅𝖳);(𝑃𝖥∨𝑄𝖥∨𝑅𝖥);(𝑃𝖥∨𝑄𝖳∨𝑅𝖳);(𝑃𝖥∨𝑄𝖳∨𝑅𝖥)\n\nΘ:=(map(/𝑚𝑛𝑡/𝑠𝑑𝑏1/𝑏𝑢𝑖𝑙𝑑𝑠𝑒𝑟𝑣𝑒𝑟/𝑀𝑎𝑡ℎ𝐻𝑢𝑏,(𝑋1𝖳)∨...∨(𝑋100𝖳))𝑋1𝖳∨...∨𝑋100𝖳);(map(/𝑚𝑛𝑡/𝑠𝑑𝑏1/𝑏𝑢𝑖𝑙𝑑𝑠𝑒𝑟𝑣𝑒𝑟/𝑀𝑎𝑡ℎ𝐻𝑢𝑏,(𝑋1𝖥)∨...∨(𝑋100𝖥))𝑋1𝖥∨...∨𝑋100𝖥)\n\nDPLL\n                on\n∆;Θ;Φ\n                with\nΦ:=(𝑃𝖥∨𝑄𝖥)Choice literals:\n𝑃𝖳,\nmap(/𝑚𝑛𝑡/𝑠𝑑𝑏1/𝑏𝑢𝑖𝑙𝑑𝑠𝑒𝑟𝑣𝑒𝑟/𝑀𝑎𝑡ℎ𝐻𝑢𝑏,(𝑋1𝖳),...,(𝑋100𝖳))(𝑋1𝖳),...,(𝑋100𝖳),\n𝑄𝖳.\nImplied literals:\n𝑄𝖥,𝑅𝖳.\n\n\n\n\n\n\n\n𝑅𝖳  \n\n□  \n\n𝑄𝖥  \n\n𝑃𝖳  \n\n𝑋1𝖳  \n...  \n\n𝑋𝑛𝖳  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n  \n\n\n\n\n\n\n\n\nLearned clause:\n𝑃𝖥\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "e913c905",
        "archive": "courses/FAU/AI/course",
        "filepath": "logic/slides/dpll-clause-learning-ex2.en.xhtml"
    },
    {
        "slideContent": "\nNOT the same Mistakes over Again: (Redundance1)\n\n▷Continuing from\n??:\n∆:=(𝑃𝖥∨𝑄𝖥∨𝑅𝖳);(𝑃𝖥∨𝑄𝖥∨𝑅𝖥);(𝑃𝖥∨𝑄𝖳∨𝑅𝖳);(𝑃𝖥∨𝑄𝖳∨𝑅𝖥)DPLL\n                on\n∆;Θ\n                with\nΘ:=(map(/𝑚𝑛𝑡/𝑠𝑑𝑏1/𝑏𝑢𝑖𝑙𝑑𝑠𝑒𝑟𝑣𝑒𝑟/𝑀𝑎𝑡ℎ𝐻𝑢𝑏,(𝑋1𝖳)∨...∨(𝑋𝑛𝖳))𝑋1𝖳∨...∨𝑋𝑛𝖳);(map(/𝑚𝑛𝑡/𝑠𝑑𝑏1/𝑏𝑢𝑖𝑙𝑑𝑠𝑒𝑟𝑣𝑒𝑟/𝑀𝑎𝑡ℎ𝐻𝑢𝑏,(𝑋1𝖥)∨...∨(𝑋𝑛𝖥))𝑋1𝖥∨...∨𝑋𝑛𝖥)\n\n\n\n\n\nlearn 𝑃𝖥∨𝑄𝖥  \nlearn 𝑃𝖥  \n(𝑅𝖳);□  \n(𝑅𝖳);□  \n\n𝑄  \n\n𝖳  \n\n𝖥 set by UP  \n\n𝑋𝑛  \n\n𝖳  \n\n𝑋1  \n\n\n𝖳  \n\n\n𝑃  \n  \n\n𝖳  \n\n𝖥  \n\n\n\n\n\n\n▷Note\n                Here, the problem could be avoided by\nsplitting\n                over different variables.\n\n\n▷Problem\n                This is not so in general!\n(see next slide)\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-15\n",
        "sectionId": "e913c905",
        "archive": "courses/FAU/AI/course",
        "filepath": "logic/slides/dpll-no-redundance-ex1.en.xhtml"
    },
    {
        "slideContent": "\nClause Learning vs. Resolution\n\n▷Recall\nDPLL\n=^\ntree resolution\n(from slide\n??)\n\n\n1.in particular: each\nderived\nclause\n𝐶\n                (not in\n∆) is\nderived\n                anew every time it is used.\n\n\n2.Problem: there are\n∆\n                whose shortest\ntree resolution\n                proof is\nexponentially\n                longer than their shortest (general)\nresolution proof.\n\n\n▷Good News\n                This is no longer the case with\nclause learning!\n\n\n1.We add each\nlearned clause\n𝐶\n                to\n∆, can use it as often as we like.\n\n\n2.Clause learning\n                renders\nDPLL\n                equivalent to\nfull resolution\n                [BKS04;\nPD09]. (Inhowfar exactly this is the case was an open question for ca. 10 years, so it’s not as easy as I made it look here ...)\n\n\n▷In particular\n                Selecting different variables/values to split on can\nprovably\n                not bring\nDPLL\n                up to the power of\nDPLL+Clause Learning. (cf. slide\n??, and previous slide)\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-15\n",
        "sectionId": "e913c905",
        "archive": "courses/FAU/AI/course",
        "filepath": "logic/slides/clause-learning-vs-resolution.en.xhtml",
        "video_name": "AI1_25thDec.m4v",
        "start_time": 471.68,
        "end_time": 486.29
    },
    {
        "slideContent": "\n“DPLL\n              +\nClause Learning”?\n\n▷Disclaimer\n                  We have only seen\nhow to\nlearn a clause\n                    from a conflict.\n\n\n▷\n                  We will\nnot\n                  cover how the overall\nDPLL\nalgorithm\n                  changes, given this learning. Slides\n??\n                  —\n??\n                  are merely meant to give a\nrough intuition\n                  on “backjumping”.\n\n\n▷Just for the record\n(not\nexam\n                      or exercises relevant)\n\n\n▷One\ncould\n                  run “DPLL\n                  +\nClause Learning” by always\nbacktracking\n                  to the maximal-level choice variable contained in the\nlearned clause.\n\n\n▷The actual\nalgorithm\n                  is called\nConflict Directed Clause Learning\n                  (CDCL), and differs from\nDPLL\n                  more radically:\n\n\nlet 𝐿 := 0; 𝐼 := ∅\nrepeat\nexecute UP\nif a conflict was reached then /* learned clause 𝐶=𝑙1―∨...∨𝑙𝑘―∨𝑙'―*/\nif 𝐿=0 then return UNSAT\n𝐿 := max𝑖=1𝑘 level(𝑙𝑖); erase 𝐼 below 𝐿\nadd 𝐶 into ∆; add 𝑙'― to 𝐼 at level 𝐿\nelse\nif 𝐼 is a total interpretation then return 𝐼\nchoose a new decision literal 𝑙; add 𝑙 to 𝐼 at level 𝐿\n𝐿:=𝐿+1\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-15\n",
        "sectionId": "e913c905",
        "archive": "courses/FAU/AI/course",
        "filepath": "logic/slides/CDCL.en.xhtml"
    },
    {
        "slideContent": "\nRemarks\n\n▷Which clause(s) to learn?\n\n\n▷While we only select\nchoice literals, much more can be done.\n\n\n▷For any cut through the\nconflict graph, with\nChoice literals\n                on the “left hand” side of the cut and the\nconflict literals\n                on the right-hand side, the\nliterals\n                on the left border of the cut yield a\nlearnable clause.\n\n\n▷Must take care to\nnot learn too many\nclauses\n                  ...\n\n\n▷Origins of\nclause learning\n\n\n▷Clause learning\n                originates from “explanation-based (no-good) learning” developed in the CSP community.\n\n\n▷The distinguishing feature here is that the “no-good” is a\nclause:\n\n\n▷The exact same type of constraint as the rest of\n∆.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-15\n",
        "sectionId": "e913c905",
        "archive": "courses/FAU/AI/course",
        "filepath": "logic/slides/dpll-clause-learning-which.en.xhtml"
    },
    {
        "slideContent": "\nWhere Are the Hard Problems?\n\n▷SAT\n            is\n𝐍𝐏\n            hard. Worst case for\nDPLL\n            is\n𝒪(2𝑛), with\n𝑛\n            propositions.\n\n\n▷Imagine I gave you as homework to make a formula family\n{𝜑}\n            where\nDPLL\nrunning time\n            necessarily is in the order of\n𝒪(2𝑛).\n\n\n▷I promise you’re not gonna find this easy ...(although it is of course possible: e.g., the “Pigeon Hole Problem”).\n\n\n▷People noticed by the early 90s that, in practice, the\nDPLL\n            worst case does not tend to happen.\n\n\n▷Modern\nSAT solvers\n            successfully tackle practical instances where\n𝑛>1.000.000.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-16\n",
        "sectionId": "9f04d347",
        "archive": "courses/FAU/AI/course",
        "filepath": "logic/slides/SAT-hard-problems.en.xhtml"
    },
    {
        "slideContent": "\nWhere Are the Hard Problems?\n\n▷So, what’s the problem\n                Science is about\nunderstanding the world.\n\n\n▷Are “hard cases” just pathological outliers?\n\n\n▷Can we say something about the\ntypical case?\n\n\n▷Difficulty 1\n                What is the “typical case” in applications? E.g., what is the “average”\nhardware\nverification\n                instance?\n\n\n▷Consider precisely defined random distributions instead.\n\n\n▷Difficulty 2\n                Search trees get very complex, and are difficult to analyze\nmathematically, even in trivial examples. Never mind examples of practical relevance ...\n\n▷The most successful works are empirical. (Interesting theory is mainly concerned with\nhand-crafted\n                formulas, like the Pigeon Hole Problem.)\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 122024-12-16\n",
        "sectionId": "9f04d347",
        "archive": "courses/FAU/AI/course",
        "filepath": "logic/slides/SAT-hard-problems.en.xhtml"
    },
    {
        "slideContent": "\nPhase Transitions in\nSAT\n              [MSL92]\n\n▷Fixed clause length model\n                  Fix\nclause\n                  length\n𝑘;\n𝑛\n                  variables.Generate\n𝑚\nclauses, by uniformly choosing\n𝑘\nvariables\n𝑃\n                  for each\nclause\n𝐶, and for each\nvariable\n𝑃\n                  deciding uniformly whether to add\n𝑃\n                  or\n𝑃𝖥\n                  into\n𝐶.\n\n\n▷Order parameter\nClause/variable ratio\n𝑚𝑛.\n\n\n▷Phase transition\n                  (Fixing\n𝑘=3,\n𝑛=50)\n\n\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-16\n",
        "sectionId": "9f04d347",
        "archive": "courses/FAU/AI/course",
        "filepath": "logic/slides/SAT-phase-transitions.en.xhtml"
    },
    {
        "slideContent": "\nDoes\nDPLL\n              Care?\n\n▷Oh yes, it does\n                  Extreme\nrunning time\n                  peak at the\nphase transition!\n\n\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-15\n",
        "sectionId": "9f04d347",
        "archive": "courses/FAU/AI/course",
        "filepath": "logic/slides/SAT-phasetransition-dpll.en.xhtml"
    },
    {
        "slideContent": "\nWhy\n              Does\nDPLL\n              Care?\n\n▷Intuition\n\n\nUnder-Constrained:Satisfiability likelihood close to\n1. Many solutions, first\nDPLL\n                  search path usually successful. (“Deep but narrow”)\n\n\nOver-Constrained:Satisfiability likelihood close to\n0. Most\nDPLL\n                  search paths short, conflict reached after few applications of\nsplitting\n                  rule. (“Broad but shallow”)\n\n\nCritically Constrained:At the\nphase transition, many\nalmost-successful\nDPLL\n                  search paths. (“Close, but no cigar”)\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 122024-12-15\n",
        "sectionId": "9f04d347",
        "archive": "courses/FAU/AI/course",
        "filepath": "logic/slides/SAT-phasetransition-dpll.en.xhtml"
    },
    {
        "slideContent": "\nThe Phase Transition Conjecture\n\n▷\n                  We say that a class\n𝑃\n                  of problems exhibits a\nphase transition, if there is an\norder parameter\n𝑜, i.e. a structural parameter of\n𝑃, so that almost all the hard problems of\n𝑃\n                  cluster around a\ncritical value\n𝑐\n                  of\n𝑜\n                  and\n𝑐\n                  separates one region of the problem space from another, e.g. over-constrained and under-constrained regions.\n\n\n▷Phase Transition Conjecture\n                  All\n𝐍𝐏-complete problems exhibit at least one\nphase transition.\n\n\n▷[CKT91] confirmed this for Graph Coloring and Hamiltonian Circuits. Later work confirmed it for\nSAT\n              (see previous slides), and for numerous other\n𝐍𝐏-complete problems.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-15\n",
        "sectionId": "9f04d347",
        "archive": "courses/FAU/AI/course",
        "filepath": "logic/slides/SAT-phasetransition-conjecture.en.xhtml"
    },
    {
        "slideContent": "\nWhy Should\nWe\n              Care?\n\n▷Enlightenment\n\n\n▷Phase transitions\n                  contribute to the fundamental understanding of the behavior of search, even if it’s only in random distributions.\n\n\n▷There are interesting theoretical connections to\nphase transition\n                  phenomena in physics. (See\n[GS05]\n                  for a short summary.)\n\n\n▷Ok, but what can we use these results for?\n\n\n▷Benchmark\n                    design: Choose instances from\nphase transition\n                  region.\n\n\n▷Commonly used in competitions etc. (In\nSAT, random\nphase transition\n                  formulas are the most difficult for\nDPLL\n                  style searches.)\n\n\n▷Predicting solver performance: Yes, but very limited because:\n\n\n▷All this works only for the particular considered\ndistributions of instances! Not meaningful for any other instances.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-15\n",
        "sectionId": "9f04d347",
        "archive": "courses/FAU/AI/course",
        "filepath": "logic/slides/SAT-phasetransition-applications.en.xhtml"
    },
    {
        "slideContent": "\nLet’s Talk About Blocks, Baby ...\n\n▷Question\n                  What do you see here?\n\n\n\n\n▷You say\n                  “All blocks are red”; “All blocks are on the table”; “A is a block”.\n\n\n▷And now\n                  Say it in\npropositional logic!\n\n\n▷Answer\n                  “isRedA”,“isRedB”, ..., “onTableA”, “onTableB”, ..., “isBlockA”, ...\n\n▷Wait a sec!\n                  Why don’t we just say, e.g., “AllBlocksAreRed” and “isBlockA”?\n\n\n▷Problem\n                  Could we conclude that A is red?(No)\n\nThese statements are atomic (just strings); their inner structure (“all blocks”, “is a block”) is not captured.\n\n\n▷Idea\nPredicate Logic\n                  (PL1) extends\npropositional logic\n                  with the ability to explicitly speak about objects and their properties.\n\n\n▷How?\n                  Variables ranging over objects, predicates describing object properties, ...\n\n▷\n\n                      “∀𝑥.block(𝑥)⇒red(𝑥)”; “block(𝐀)”\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "91480d97",
        "archive": "courses/FAU/AI/course",
        "filepath": "logic/slides/pl1-blocks.en.xhtml",
        "video_name": "AI1_25thDec.m4v",
        "start_time": 1554.69,
        "end_time": 1868.28
    },
    {
        "slideContent": "\nLet’s Talk About the\nWumpus\n              Instead?\n\n▷\n\n\n\n\n\nPercepts:\n[𝑆𝑡𝑒𝑛𝑐ℎ,𝐵𝑟𝑒𝑒𝑧𝑒,𝐺𝑙𝑖𝑡𝑡𝑒𝑟,𝐵𝑢𝑚𝑝,𝑆𝑐𝑟𝑒𝑎𝑚]\n\n\n▷Cell adjacent to\nWumpus:\n𝑆𝑡𝑒𝑛𝑐ℎ\n                                (else:\n𝑁𝑜𝑛𝑒).\n\n\n▷Cell adjacent to Pit:\n𝐵𝑟𝑒𝑒𝑧𝑒\n                                (else:\n𝑁𝑜𝑛𝑒).\n\n\n▷Cell that contains gold:\n𝐺𝑙𝑖𝑡𝑡𝑒𝑟\n                                (else:\n𝑁𝑜𝑛𝑒).\n\n\n▷You walk into a wall:\n𝐵𝑢𝑚𝑝\n                                (else:\n𝑁𝑜𝑛𝑒).\n\n\n▷Wumpus\n                                shot by arrow:\n𝑆𝑐𝑟𝑒𝑎𝑚\n                                (else:\n𝑁𝑜𝑛𝑒).\n\n\n\n\n \n\n▷Say, in\npropositional logic: “Cell adjacent to\nWumpus:\n𝑆𝑡𝑒𝑛𝑐ℎ.”\n\n\n▷𝑊1,1⇒𝑆1,2∧𝑆2,1\n\n\n▷𝑊1,2⇒𝑆2,2∧𝑆1,1∧𝑆1,3\n\n\n▷𝑊1,3⇒𝑆2,3∧𝑆1,2∧𝑆1,4\n\n\n▷...\n\nNote\n                  Even when we\ncan\n                  describe the problem suitably, for the desired reasoning, the propositional formulation typically is way too large to write (by hand).\n\n\n▷\n\n▷PL1 solution\n                  “∀𝑥.Wumpus(𝑥)⇒(∀𝑦.adj(𝑥,𝑦)⇒stench(𝑦))”\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "91480d97",
        "archive": "courses/FAU/AI/course",
        "filepath": "logic/slides/pl1-wumpus.en.xhtml",
        "video_name": "AI1_25thDec.m4v",
        "start_time": 1868.28,
        "end_time": 2006.45
    },
    {
        "slideContent": "\nBlocks/Wumpus, Who Cares? Let’s Talk About Numbers!\n\n▷Even worse!\n\n\n▷Integers\n                  A limited vocabulary to talk about these\n\n\n\n▷The objects:\n{1,2,3,...}.\n\n\n▷Predicate 1: “even(𝑥)” should be true iff\n𝑥\n                      is even.\n\n\n▷Predicate 2: “eq(𝑥,𝑦)” should be true iff\n𝑥=𝑦.\n\n\n▷Function:\nsucc(𝑥)\n                      maps\n𝑥\n                      to\n𝑥+1.\n\n\n▷Old problem\n                  Say, in\npropositional logic, that “1+1=2”.\n\n\n▷Inner structure of vocabulary is ignored (cf. “AllBlocksAreRed”).\n\n\n▷PL1 solution: “eq(succ(1),2)”.\n\n\n▷New Problem\n                  Say, in\npropositional logic, “if\n𝑥\n                  is even, so is\n𝑥+2”.\n\n\n▷It is impossible to speak about\ninfinite\n                  sets of objects!\n\n\n▷PL1 solution: “∀𝑥.even(𝑥)⇒even(succ(succ(𝑥)))”.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-15\n",
        "sectionId": "91480d97",
        "archive": "courses/FAU/AI/course",
        "filepath": "logic/slides/pl1-numbers.en.xhtml",
        "video_name": "AI1_25thDec.m4v",
        "start_time": 2006.45,
        "end_time": 2061.21
    },
    {
        "slideContent": "\nNow We’re Talking\n\n▷\n\n∀𝑛.gt(𝑛,2)⇒¬(∃𝑎,𝑏,𝑐.eq(plus(pow(𝑎,𝑛),pow(𝑏,𝑛)),pow(𝑐,𝑛)))\n                  Read:\nForall\n𝑛>2, there are\n𝑎,𝑏,𝑐, such that\n𝑎𝑛+𝑏𝑛=𝑐𝑛(Fermat’s last theorem)\n\n\n▷Theorem proving in PL1\n                  Arbitrary theorems, in principle.\n\n\n▷Fermat’s last theorem is of course infeasible, but interesting theorems can and have been proved automatically.\n\n\n▷See\nhttp://en.wikipedia.org/wiki/Automated_theorem_proving.\n\n\n▷Note: Need to axiomatize “Plus”, “PowerOf”, “Equals”. See\nhttp://en.wikipedia.org/wiki/Peano_axioms\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 122024-12-15\n",
        "sectionId": "91480d97",
        "archive": "courses/FAU/AI/course",
        "filepath": "logic/slides/pl1-numbers.en.xhtml",
        "video_name": "AI1_25thDec.m4v",
        "start_time": 2061.21,
        "end_time": 2178.32
    },
    {
        "slideContent": "\nWhat Are the Practical Relevance/Applications?\n\n▷...\n              even asking this question is a sacrilege:\n\n\n▷(Quotes from Wikipedia)\n\n\n▷“In Europe, logic was first developed by Aristotle. Aristotelian logic became widely accepted in science and mathematics.”\n\n\n▷“The development of logic since Frege, Russell, and Wittgenstein had a profound influence on the practice of philosophy and the perceived nature of philosophical problems, and Philosophy of mathematics.”\n\n\n▷“During the later medieval period, major efforts were made to show that Aristotle’s ideas were compatible with Christian faith.”\n\n\n▷(In other words: the church issued for a long time that Aristotle’s ideas were\nincompatible with Christian faith.)\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-15\n",
        "sectionId": "91480d97",
        "archive": "courses/FAU/AI/course",
        "filepath": "logic/slides/pl1-applications.en.xhtml",
        "video_name": "AI1_25thDec.m4v",
        "start_time": 2178.32,
        "end_time": 2180.39
    },
    {
        "slideContent": "\nWhat Are the Practical Relevance/Applications?\n\n▷You’re asking it anyhow\n\n\n▷Logic programming. Prolog et al.\n\n\n▷Databases. Deductive databases where elements of logic allow to conclude additional facts. Logic is tied deeply with database theory.\n\n\n▷Semantic technology. Mega-trend since\n>\n                a decade. Use PL1 fragments to annotate data sets, facilitating their use and analysis.\n\n\n▷Prominent PL1 fragment:\nWeb Ontology Language\nOWL.\n\n\n▷Prominent data set: The\nWWW.\n(semantic web)\n\n\n▷Assorted quotes on Semantic Web and\nOWL\n\n\n▷The brain of humanity.\n\n\n▷The Semantic Web will never work.\n\n\n▷A TRULY meaningful way of\ninteracting\n                  with the\nWeb\n                  may finally be here: the Semantic Web. The idea was proposed 10 years ago. A triumvirate of internet heavyweights — Google, Twitter, and Facebook — are making it real.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 122024-12-15\n",
        "sectionId": "91480d97",
        "archive": "courses/FAU/AI/course",
        "filepath": "logic/slides/pl1-applications.en.xhtml"
    },
    {
        "slideContent": "\n(A Few) Semantic Technology Applications\n\nWeb Queries Jeopardy (IBM Watson) Context-Aware Apps Healthcare  \n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-16\n",
        "sectionId": "91480d97",
        "archive": "courses/FAU/AI/course",
        "filepath": "logic/slides/pl1-semantic-technology.en.xhtml",
        "video_name": "AI1_25thDec.m4v",
        "start_time": 2180.39,
        "end_time": 2241.41
    },
    {
        "slideContent": "\nOur Agenda for This Topic\n\n▷This Chapter: Basic definitions and concepts; normal forms.\n\n\n▷Sets up the framework and basic operations.\n\n\n▷Syntax: How to write PL1 formulas?(Obviously required)\n\n\n▷Semantics: What is the meaning of PL1 formulas?\n(Obviously required.)\n\n\n▷Normal Forms: What are the basic normal forms, and how to obtain them?\n(Needed for\nalgorithms, which are defined on these normal forms.)\n\n\n▷Next Chapter: Compilation to propositional reasoning; unification; lifted resolution/tableau.\n\n\n▷Algorithmic\n            principles for reasoning about predicate logic.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "91480d97",
        "archive": "courses/FAU/AI/course",
        "filepath": "logic/slides/pl1-agenda.en.xhtml",
        "video_name": "AI1_25thDec.m4v",
        "start_time": 2241.41,
        "end_time": 2303.01
    },
    {
        "slideContent": "\nFirst-Order Predicate Logic (PL1)\n\n▷Coverage\n                  We can talk about(All humans are mortal)\n\n\n▷individual things\n                  and denote them by variables or constants\n\n\n▷properties of individuals,\n(e.g. being human or mortal)\n\n\n▷relations of individuals,(e.g.\n𝑠𝑖𝑏𝑙𝑖𝑛𝑔\n_\n𝑜𝑓\n                      relationship)\n\n\n▷functions on individuals,(e.g. the\n𝑓𝑎𝑡ℎ𝑒𝑟\n_\n𝑜𝑓\n                      function)\n\n\nWe can also state the\nexistence\n                  of an individual with a certain property, or the\nuniversality\n                  of a property.\n\n\n▷But we cannot state assertions like\n\n\n▷There is a surjective function from the natural numbers into the reals.\n\n\n▷First-Order Predicate Logic has many good properties\n(complete calculi, compactness, unitary, linear unification,...)\n\n\n▷But too weak for formalizing:(at least directly)\n\n\n▷natural numbers, torsion groups, calculus, ...\n\n▷generalized quantifiers\n              (most, few,...)\n\n\n\n:\nComputational Logic12024-12-14\n",
        "sectionId": "fbc7839d",
        "archive": "courses/Jacobs/CompLog",
        "filepath": "pl1/slides/overview.en.xhtml",
        "video_name": "AI1_25thDec.m4v",
        "start_time": 2303.01,
        "end_time": 2716.45
    },
    {
        "slideContent": "\nPL1\n              Syntax (Signature and Variables)\n\n▷\nFirst-order logic\n                  (PL1), is a\nformal system\n                  extensively used in\nmathematics, philosophy, linguistics, and\ncomputer science. It combines\npropositional logic\n                  with the ability to quantify over individuals.\n\n\n▷\nPL1\n                  talks about two kinds of objects:(so we have two kinds of symbols)\n\n\n▷truth values\n                  by reusing\nPL0\n\n\n▷individuals, e.g. numbers, foxes, Pokémon,...\n\n\n▷A\nfirst-order signature\n                  consists of\n(all\ndisjoint;\n𝑘∊ℕ)\n\n\n▷connectives:\nΣ0={𝑇,𝐹,¬,∨,∧,⇒,⇔,...}(functions on truth values)\n\n\n▷function constants:\nΣ𝑘𝑓={𝑓,𝑔,ℎ,...}(𝑘-ary functions\n                      on\nindividuals)\n\n\n▷predicate constants:\nΣ𝑝𝑘={𝑝,𝑞,𝑟,...}\n(𝑘-ary relations\n                      among\nindividuals.)\n\n\n▷(Skolem constants:\nΣ𝑘𝑠𝑘={𝑓𝑘1,𝑓𝑘2,...})(witness constructors; countably\n∞)\n\n\n▷We take\nΣ1\n                  to be all of these together:\nΣ1:=Σ𝑓∪Σ𝑝∪Σ𝑠𝑘\n                  and define\nΣ:=Σ1∪Σ0.\n\n\n▷\n                  We assume a set of\nindividual variables:\n𝒱𝜄:={𝑋,𝑌,𝑍,...}.\n(countably\n∞)\n\n\n\n:\nComputational Logic12024-12-14\n",
        "sectionId": "ad95eaa4",
        "archive": "courses/Jacobs/CompLog",
        "filepath": "pl1/slides/pl1-signature.en.xhtml",
        "video_name": "AI1_25thDec.m4v",
        "start_time": 2716.45,
        "end_time": 3040.59
    },
    {
        "slideContent": "\nPL1\nSyntax\n              (Formulae)\n\n▷\nTerms:\n𝐀∊𝑤𝑓𝑓𝜄(Σ1,𝒱𝜄)\n(denote individuals)\n\n\n▷𝒱𝜄⊆𝑤𝑓𝑓𝜄(Σ1,𝒱𝜄),\n\n\n▷if\n𝑓∊Σ𝑘𝑓\n                  and\n𝐀𝑖∊𝑤𝑓𝑓𝜄(Σ1,𝒱𝜄)\n                  for\n𝑖≤𝑘, then\n𝑓(𝐀1,...,𝐀𝑘)∊𝑤𝑓𝑓𝜄(Σ1,𝒱𝜄).\n\n\n▷First-order propositions:\n𝐀∊𝑤𝑓𝑓𝑜(Σ1,𝒱𝜄):(denote truth values)\n\n\n▷if\n𝑝∊Σ𝑝𝑘\n                  and\n𝐀𝑖∊𝑤𝑓𝑓𝜄(Σ1,𝒱𝜄)\n                  for\n𝑖≤𝑘, then\n𝑝(𝐀1,...,𝐀𝑘)∊𝑤𝑓𝑓𝑜(Σ1,𝒱𝜄),\n\n\n▷if\n𝐀,𝐁∊𝑤𝑓𝑓𝑜(Σ1,𝒱𝜄)\n                  and\n𝑋∊𝒱𝜄, then\n𝑇,𝐀∧𝐁,¬𝐀,∀𝑋.𝐀∊𝑤𝑓𝑓𝑜(Σ1,𝒱𝜄).\n\n∀\n                  is a\nbinding operator\n                  called the\nuniversal quantifier.\n\n\n▷\n                  We define the\nconnectives\n𝐹,∨,⇒,⇔\n                  via the abbreviations\n𝐀∨𝐁:=¬(¬𝐀∧¬𝐁),\n𝐀⇒𝐁:=¬𝐀∨𝐁,\n𝐀⇔𝐁:=(𝐀⇒𝐁)∧(𝐁⇒𝐀), and\n𝐹:=¬𝑇. We will use them like the primary\nconnectives\n∧\n                  and\n¬\n\n\n▷\n                  We use\n∃𝑋.𝐀\n                  as an abbreviation for\n¬(∀𝑋.¬𝐀).\n∃\n                  is a\nbinding operator\n                  called the\nexistential quantifier.\n\n\n▷\n                  Call\nformulae\n                  without\nconnectives\n                  or\nquantifiers\natomic\n                  else\ncomplex.\n\n\n\n:\nComputational Logic12024-12-14\n",
        "sectionId": "ad95eaa4",
        "archive": "courses/Jacobs/CompLog",
        "filepath": "pl1/slides/pl1-syntax.en.xhtml",
        "video_name": "AI1_25thDec.m4v",
        "start_time": 3040.59,
        "end_time": 3195.51
    },
    {
        "slideContent": "\nAlternative Notations for Quantifiers\n\nHere Elsewhere∀𝑥.𝐀 ⋀𝑥.𝐀(𝑥)𝐀∃𝑥.𝐀 ⋁𝑥.𝐀\n\n\n\n:\nComputational Logic12024-12-16\n",
        "sectionId": "ad95eaa4",
        "archive": "courses/Jacobs/CompLog",
        "filepath": "pl1/slides/pl1-notations.en.xhtml",
        "video_name": "AI1_25thDec.m4v",
        "start_time": 3195.51,
        "end_time": 3244.8
    },
    {
        "slideContent": "\nFree\n              and\nBound\nVariables\n\n▷\n                  We call an\noccurrence\n                  of a\nvariable\n𝑋\nbound\n                  in a\nformula\n𝐀\n                  (otherwise\nfree), iff it occurs in a\nsub-formula\n∀𝑋.𝐁\n                  of\n𝐀.\n\nFor a\nformula\n𝐀, we will use\nBVar(𝐀)\n                  (and\nfree(𝐀)) for the\nset\n                  of\nbound\n                  (free)\nvariables\n                  of\n𝐀, i.e.\nvariables\n                  that have a\nfree/bound\noccurrence\n                  in\n𝐀.\n\n\n▷\n                  We define the\nset\nfree(𝐀)\n                  of\nfree\nvariables\n                  of a\nformula\n𝐀:\n\n\nfree(𝑋):={𝑋}free(𝑓(𝐀1,...,𝐀𝑛)):=⋃1≤𝑖≤𝑛free(𝐀𝑖)free(𝑝(𝐀1,...,𝐀𝑛)):=⋃1≤𝑖≤𝑛free(𝐀𝑖)free(¬𝐀):=free(𝐀)free(𝐀∧𝐁):=free(𝐀)∪free(𝐁)free(∀𝑋.𝐀):=free(𝐀)\\{𝑋}\n\n\n▷\n                  We call a\nformula\n𝐀\nclosed\n                  or\nground, iff\nfree(𝐀)=∅. We call a\nclosed\nproposition\n                  a\nsentence, and denote the\nset\n                  of all\nground\nterm\n                  with\n𝑐𝑤𝑓𝑓𝜄(Σ𝜄)\n                  and the\nset\n                  of\nsentences\n                  with\n𝑐𝑤𝑓𝑓𝑜(Σ𝜄).\n\n\n▷\nBound\nvariables\n                  can be renamed, i.e. any subterm\n∀𝑋.𝐁\n                  of a formula\n𝐀\n                  can be replaced by\n𝐀':=(∀𝑌.𝐁'), where\n𝐁'\n                  arises from\n𝐁\n                  by replacing all\n𝑋∊free(𝐁)\n                  with a new variable\n𝑌\n                  that does not occur in\n𝐀.\nWe call\n𝐀'\n                      an\nalphabetical variant\n                      of\n𝐀\n                      — and the other way around too.\n\n\n\n:\nComputational Logic12024-12-14\n",
        "sectionId": "ad95eaa4",
        "archive": "courses/Jacobs/CompLog",
        "filepath": "pl1/slides/free-bound-alpha.en.xhtml",
        "video_name": "AI1_25thDec.m4v",
        "start_time": 3244.8,
        "end_time": 3475.23
    },
    {
        "slideContent": "\nSemantics of\nPL1\n              (Models)\n\n▷\n                  We inherit the\ndomain\n𝒟0={𝖳,𝖥}\n                  of\ntruth values\n                  from\nPL0\n                  and assume an arbitrary\ndomain\n𝒟𝜄≠∅\n                  of\nindividuals.(this choice is a parameter to the semantics)\n\n\n▷\n                  An\ninterpretation\nℐ\nassigns\n                  values to\nconstants, e.g.\n\n\n▷ℐ(¬):𝒟0→𝒟0\n                  with\n𝖳↦𝖥,\n𝖥↦𝖳, and\nℐ(∧)=...(as in\nPL0)\n\n\n▷ℐ:Σ𝑘𝑓→𝒟𝜄𝑘→𝒟𝜄(interpret function symbols as arbitrary functions)\n\n\n▷ℐ:Σ𝑝𝑘→𝒫(𝒟𝜄𝑘)(interpret predicates as arbitrary relations)\n\n\n▷\n                  A\nvariable assignment\n𝜑:𝒱𝜄→𝒟𝜄\n                  maps\nvariables\n                  into the\ndomain.\n\n\n▷\n                  A\nmodel\nℳ=〈𝒟𝜄,ℐ〉\n                  of\nPL1\n                  consists of a\ndomain\n𝒟𝜄\n                  and an\ninterpretation\nℐ.\n\n\n\n:\nComputational Logic12024-12-14\n",
        "sectionId": "ad95eaa4",
        "archive": "courses/Jacobs/CompLog",
        "filepath": "pl1/slides/pl1-model.en.xhtml",
        "video_name": "AI1_25thDec.m4v",
        "start_time": 3500.12,
        "end_time": 3631.09
    },
    {
        "slideContent": "\nSemantics of\nPL1\n              (Evaluation)\n\n▷Given a model\n〈𝒟,ℐ〉, the\nvalue function\nℐ𝜑\n                  is recursively defined:(two parts: terms & propositions)\n\n\n▷ℐ𝜑:𝑤𝑓𝑓𝜄(Σ1,𝒱𝜄)→𝒟𝜄\n                  assigns values to terms.\n\n\n▷ℐ𝜑(𝑋):=𝜑(𝑋)\n                  and\n\n\n▷ℐ𝜑(𝑓(𝐀1,...,𝐀𝑘)):=ℐ(𝑓)(map(/𝑚𝑛𝑡/𝑠𝑑𝑏1/𝑏𝑢𝑖𝑙𝑑𝑠𝑒𝑟𝑣𝑒𝑟/𝑀𝑎𝑡ℎ𝐻𝑢𝑏,ℐ𝜑(𝐀1),...,ℐ𝜑(𝐀𝑘))ℐ𝜑(𝐀1),...,ℐ𝜑(𝐀𝑘))\n\n\n▷ℐ𝜑:𝑤𝑓𝑓𝑜(Σ1,𝒱𝜄)→𝒟0\n                  assigns values to formulae:\n\n\n▷ℐ𝜑(𝑇)=ℐ(𝑇)=𝖳,\n\n\n▷ℐ𝜑(¬𝐀)=ℐ(¬)(ℐ𝜑(𝐀))\n\n\n▷ℐ𝜑(𝐀∧𝐁)=ℐ(∧)(ℐ𝜑(𝐀),ℐ𝜑(𝐁))(just as in\nPL0)\n\n\n▷ℐ𝜑(𝑝(𝐀1,...,𝐀𝑘)):=𝖳, iff\n〈map(/𝑚𝑛𝑡/𝑠𝑑𝑏1/𝑏𝑢𝑖𝑙𝑑𝑠𝑒𝑟𝑣𝑒𝑟/𝑀𝑎𝑡ℎ𝐻𝑢𝑏,ℐ𝜑(𝐀1),...,ℐ𝜑(𝐀𝑘))ℐ𝜑(𝐀1),...,ℐ𝜑(𝐀𝑘)〉∊ℐ(𝑝)\n\n\n▷ℐ𝜑(∀𝑋.𝐀):=𝖳, iff\nℐ𝜑,[𝖺/𝑋](𝐀)=𝖳\n                  for all\n𝖺∊𝒟𝜄.\n\n\n▷Assignment&#160;Extension\n\n\n\n:\nComputational Logic12024-12-14\n",
        "sectionId": "ad95eaa4",
        "archive": "courses/Jacobs/CompLog",
        "filepath": "pl1/slides/pl1-semantics.en.xhtml"
    },
    {
        "slideContent": "\nSemantics Computation: Example\n\n▷\n                  We define an instance of first-order logic:\n\n\n▷Signature: Let\nΣ0𝑓:={𝑗,𝑚},\nΣ1𝑓:={𝑓}, and\nΣ𝑝2:={𝑜}\n\n\n▷Universe:\n𝒟𝜄:={𝐽,𝑀}\n\n\n▷Interpretation:\nℐ(𝑗):=𝐽,\nℐ(𝑚):=𝑀,\nℐ(𝑓)(𝐽):=𝑀,\nℐ(𝑓)(𝑀):=𝑀, and\nℐ(𝑜):={(𝑀,𝐽)}.\n\n\nThen\n∀𝑋.𝑜(𝑓(𝑋),𝑋)\n                  is a\nsentence\n                  and with\n𝜓:=𝜑,[𝖺/𝑋]\n                  for\n𝖺∊𝒟𝜄\n                  we have\nℐ𝜑(∀𝑋.𝑜(𝑓(𝑋),𝑋))=𝖳iff\nℐ𝜓(𝑜(𝑓(𝑋),𝑋))=𝖳 for all 𝖺∊𝒟𝜄\n\n\niff\n(ℐ𝜓(𝑓(𝑋)),ℐ𝜓(𝑋))∊ℐ(𝑜) for all 𝖺∊{𝐽,𝑀}\n\n\niff\n(ℐ(𝑓)(ℐ𝜓(𝑋)),𝜓(𝑋))∊{(𝑀,𝐽)} for all 𝖺∊{𝐽,𝑀}\n\n\niff\n(ℐ(𝑓)(𝜓(𝑋)),𝑎)=(𝑀,𝐽) for all 𝖺∊{𝐽,𝑀}\n\n\niff\nℐ(𝑓)(𝑎)=𝑀 and 𝑎=𝐽 for all 𝖺∊{𝐽,𝑀}\n\n\nBut\n𝖺≠𝐽\n                  for\n𝖺=𝑀, so\nℐ𝜑(∀𝑋.𝑜(𝑓(𝑋),𝑋))=𝖥\n                  in the model\n〈𝒟𝜄,ℐ〉.\n\n\n\n:\nComputational Logic22024-12-14\n",
        "sectionId": "ad95eaa4",
        "archive": "courses/Jacobs/CompLog",
        "filepath": "pl1/slides/pl1-semantics.en.xhtml",
        "video_name": "AI1_25thDec.m4v",
        "start_time": 3875.94,
        "end_time": 3906.6
    },
    {
        "slideContent": "\nSubstitutions on Terms\n\n▷Intuition\n                  If\n𝐁\n                  is a\nterm\n                  and\n𝑋\n                  is a\nvariable, then we denote the result of systematically replacing all\noccurrences\n                  of\n𝑋\n                  in a\nterm\n𝐀\n                  by\n𝐁\n                  with\n[𝐁/𝑋](𝐀).\n\n\n▷Problem\n                  What about\n[𝑍/𝑌],[𝑌/𝑋](𝑋), is that\n𝑌\n                  or\n𝑍?\n\n\n▷Folklore\n[𝑍/𝑌],[𝑌/𝑋](𝑋)=𝑌, but\n[𝑍/𝑌]([𝑌/𝑋](𝑋))=𝑍\n                  of course.\n(Parallel application)\n\n\n▷Substitutions\n\n\n▷Substitution&#160;Discharge\n\n\n▷Substitution ApplicationWe define\nsubstitution application\n                  by\n\n\n▷𝜎(𝑐)=𝑐\n                  for\n𝑐∊Σ\n\n\n▷𝜎(𝑋)=𝐀, iff\n𝑋∊𝒱\n                  and\n(𝑋,𝐀)∊𝜎.\n\n\n▷𝜎(𝑓(𝐀1,...,𝐀𝑛))=𝑓(map(/𝑚𝑛𝑡/𝑠𝑑𝑏1/𝑏𝑢𝑖𝑙𝑑𝑠𝑒𝑟𝑣𝑒𝑟/𝑀𝑎𝑡ℎ𝐻𝑢𝑏,(𝜎(𝐀1)),...,(𝜎(𝐀𝑛)))𝜎(𝐀1),...,𝜎(𝐀𝑛)),\n\n\n▷𝜎(∀𝑋.𝐀)=∀𝑋.𝜎−𝑋(𝐀).(∃\n                      analogous)\n\n\n▷\n[𝑎/𝑥],[𝑓(𝑏)/𝑦],[𝑎/𝑧]\n                  instantiates\n𝑔(𝑥,𝑦,ℎ(𝑧))\n                  to\n𝑔(𝑎,𝑓(𝑏),ℎ(𝑎)).\n\n\n\n:\nComputational Logic12024-12-14\n",
        "sectionId": "186555c6",
        "archive": "courses/Jacobs/CompLog",
        "filepath": "pl1/slides/substitutions.en.xhtml",
        "video_name": "AI1_25thDec.m4v",
        "start_time": 3991.72,
        "end_time": 4476.33
    },
    {
        "slideContent": "\nSubstitution Extension\n\n▷Substitution&#160;Extenion\n\n\n▷Note\n                  If\n𝜎\n                  is a\nsubstitution, then\n𝜎,[𝐀/𝑋]\n                  is also a\nsubstitution.\n\n\n▷We also need the dual operation: removing a variable from the support:\n\n\n▷Substitution&#160;Discharge\n\n\n\n:\n12024-12-14\n",
        "sectionId": "186555c6",
        "archive": "courses/Jacobs/GenCS/course",
        "filepath": "logic/slides/substitution-extension.en.xhtml",
        "video_name": "AI1_25thDec.m4v",
        "start_time": 4476.33,
        "end_time": 4483.4
    },
    {
        "slideContent": "\nSubstitutions on Propositions\n\n▷Problem\n                  We want to extend\nsubstitutions\n                  to propositions, in particular to quantified formulae: What is\n𝜎(∀𝑋.𝐀)?\n\n\n▷Idea\n𝜎\n                  should not instantiate\nbound\nvariables.\n([𝐀/𝑋](∀𝑋.𝐁)=∀𝐀.𝐁'\n                      ill-formed)\n\n\n▷\n𝜎(∀𝑋.𝐀):=(∀𝑋.𝜎−𝑋(𝐀)).\n\n\n▷Problem\n                  This can lead to\nvariable capture:\n[𝑓(𝑋)/𝑌](∀𝑋.𝑝(𝑋,𝑌))\n                  would evaluate to\n∀𝑋.𝑝(𝑋,𝑓(𝑋)), where the second\noccurrence\n                  of\n𝑋\n                  is\nbound\n                  after instantiation, whereas it was\nfree\n                  before.\n\n\nSolution\nRename\n                  away the\nbound\nvariable\n𝑋\n                  in\n∀𝑋.𝑝(𝑋,𝑌)\n                  before applying the\nsubstitution.\n\n\n▷Capture-Avoiding Substitution Application\n                  Let\n𝜎\n                  be a\nsubstitution,\n𝐀\n                  a\nformula, and\n𝐀'\n                  an\nalphabetic variant\n                  of\n𝐀, such that\nintro(𝜎)∩BVar(𝐀)=∅. Then we define\ncapture-avoiding\nsubstitution application\n                  via\n𝜎(𝐀):=𝜎(𝐀').\n\n\n\n:\nComputational Logic12024-12-14\n",
        "sectionId": "186555c6",
        "archive": "courses/Jacobs/CompLog",
        "filepath": "pl1/slides/substitutions-propositions-alpha.en.xhtml",
        "video_name": "AI1_25thDec.m4v",
        "start_time": 4483.4,
        "end_time": 4770.12
    },
    {
        "slideContent": "\nSubstitution Value Lemma for Terms\n\n▷\n                  Let\n𝐀\n                  and\n𝐁\n                  be terms, then\nℐ𝜑([𝐁/𝑋]𝐀)=ℐ𝜓(𝐀), where\n𝜓=𝜑,[ℐ𝜑(𝐁)/𝑋].\n\n\n▷Proof:\nby induction on the depth of\n𝐀:\n\n1.depth=0\n\nThen\n𝐀\n                        is a variable (say\n𝑌), or constant, so we have three cases\n\n\n1.1.𝐀=𝑌=𝑋\n\n\n\n1.1.1.then\nℐ𝜑([𝐁/𝑋](𝐀))=ℐ𝜑([𝐁/𝑋](𝑋))=ℐ𝜑(𝐁)=𝜓(𝑋)=ℐ𝜓(𝑋)=ℐ𝜓(𝐀).\n\n\n1.2.𝐀=𝑌≠𝑋\n\n\n\n1.2.1.then\nℐ𝜑([𝐁/𝑋](𝐀))=ℐ𝜑([𝐁/𝑋](𝑌))=ℐ𝜑(𝑌)=𝜑(𝑌)=𝜓(𝑌)=ℐ𝜓(𝑌)=ℐ𝜓(𝐀).\n\n\n1.3.𝐀\n                          is a constant\n\n\n\n1.3.1.Analogous to the preceding case (𝑌≠𝑋).\n\n\n\n1.4.This completes the\nbase case\n                        (depth = 0).\n\n2.depth>0\n\n\n\n2.1.then\n𝐀=𝑓(𝐀1,...,𝐀𝑛)\n                        and we have\nℐ𝜑([𝐁/𝑋](𝐀))=ℐ(𝑓)(map(/𝑚𝑛𝑡/𝑠𝑑𝑏1/𝑏𝑢𝑖𝑙𝑑𝑠𝑒𝑟𝑣𝑒𝑟/𝑀𝑎𝑡ℎ𝐻𝑢𝑏,ℐ𝜑([𝐁/𝑋](𝐀1)),...,ℐ𝜑([𝐁/𝑋](𝐀𝑛)))ℐ𝜑([𝐁/𝑋](𝐀1)),...,ℐ𝜑([𝐁/𝑋](𝐀𝑛)))\n\n=ℐ(𝑓)(map(/𝑚𝑛𝑡/𝑠𝑑𝑏1/𝑏𝑢𝑖𝑙𝑑𝑠𝑒𝑟𝑣𝑒𝑟/𝑀𝑎𝑡ℎ𝐻𝑢𝑏,ℐ𝜓(𝐀1),...,ℐ𝜓(𝐀𝑛))ℐ𝜓(𝐀1),...,ℐ𝜓(𝐀𝑛))\n\n=ℐ𝜓(𝐀).\n\nby\ninduction hypothesis\n\n\n\n\n2.2.This completes the\ninduction step, and we have proven the assertion.\n\n\n:\nComputational Logic12024-12-15\n",
        "sectionId": "186555c6",
        "archive": "courses/Jacobs/CompLog",
        "filepath": "pl1/slides/subst-value-lemma-terms.en.xhtml",
        "video_name": "AI1_25thDec.m4v",
        "start_time": 5120.2,
        "end_time": 5224.3
    },
    {
        "slideContent": "\nSubstitution Value Lemma for Propositions\n\n▷\nℐ𝜑([𝐁/𝑋](𝐀))=ℐ𝜓(𝐀), where\n𝜓=𝜑,[ℐ𝜑(𝐁)/𝑋].\n\n\n▷Proof:\nby induction on the number\n𝑛\n                  of\nconnectives\n                  and\nquantifiers\n                  in\n𝐀:\n\n1.𝑛=0\n\n\n\n1.1.then\n𝐀\n                        is an\natomic\nproposition, and we can argue like in the\ninduction step\n                        of the substitution value lemma for terms.\n\n\n2.𝑛>0\n                      and\n𝐀=¬𝐁\n                      or\n𝐀=𝐂◦𝐃\n\n\n\n2.1.Here we argue like in the\ninduction step\n                        of the term lemma as well.\n\n3.𝑛>0\n                      and\n𝐀=∀𝑌.𝐂\n                      where (WLOG)\n𝑋≠𝑌\n\n(otherwise rename)\n\n3.1.then\nℐ𝜓(𝐀)=ℐ𝜓(∀𝑌.𝐂)=𝖳, iff\nℐ𝜓,[𝑎/𝑌](𝐂)=𝖳\n                        for all\n𝑎∊𝒟𝜄.\n\n\n\n\n3.2.But\nℐ𝜓,[𝑎/𝑌](𝐂)=ℐ𝜑,[𝑎/𝑌]([𝐁/𝑋](𝐂))=𝖳, by\ninduction hypothesis.\n\n\n\n\n3.3.So\nℐ𝜓(𝐀)=ℐ𝜑(∀𝑌.[𝐁/𝑋](𝐂))=ℐ𝜑([𝐁/𝑋](∀𝑌.𝐂))=ℐ𝜑([𝐁/𝑋](𝐀))\n\n\n\n:\nComputational Logic12024-12-15\n",
        "sectionId": "186555c6",
        "archive": "courses/Jacobs/CompLog",
        "filepath": "pl1/slides/subst-value-lemma-propositions-alpha.en.xhtml",
        "video_name": "AI1_25thDec.m4v",
        "start_time": 5224.3,
        "end_time": 5363.98
    },
    {
        "slideContent": "\nFirst-Order Natural Deduction (𝒩𝒟1; Gentzen [Gen34])\n\n▷Rules for\nconnectives\n              just as always\n\n\n▷New Quantifier Rules\n                  The\nfirst-order natural deduction calculus\n𝒩𝒟1\n                  extends\n𝒩𝒟0\n                  by the following four rules:\n\n\n𝐀∀𝑋.𝐀𝒩𝒟1∀ℐ*∀𝑋.𝐀[𝐁/𝑋](𝐀)𝒩𝒟1∀ℰ\n[𝐁/𝑋](𝐀)∃𝑋.𝐀𝒩𝒟1∃ℐ∃𝑋.𝐀[[𝑐/𝑋](𝐀)]1\n...\n𝐂\n𝑐∊Σ0𝑠𝑘 new\n𝐂𝒩𝒟1∃ℰ1\n\n\n\n*\n                  means that\n𝐀\n                  does not depend on any hypothesis in which\n𝑋\n                  is\nfree.\n\n\n\n:\nComputational Logic12024-12-14\n",
        "sectionId": "93c8176a",
        "archive": "courses/Jacobs/CompLog",
        "filepath": "pl1/slides/nd.en.xhtml"
    },
    {
        "slideContent": "\nFirst-Order Natural Deduction in Sequent Formulation\n\n▷Rules for\nconnectives\n              from\n𝒩𝒟⊢0\n\n\n▷New Quantifier Rules\n                  The\ninference rules\n                  of the\nfirst-order sequent calculus\n𝒩𝒟⊢1\n                  consist of those from\n𝒩𝒟⊢0\n                  plus the following\nquantifier\nrules:\nΓ⊢𝐀𝑋∉free(Γ)Γ⊢∀𝑋.𝐀𝒩𝒟⊢1∀ℐΓ⊢∀𝑋.𝐀Γ⊢[𝐁/𝑋](𝐀)𝒩𝒟⊢1∀ℰΓ⊢[𝐁/𝑋](𝐀)Γ⊢∃𝑋.𝐀𝒩𝒟⊢1∃ℐΓ⊢∃𝑋.𝐀Γ,[𝑐/𝑋](𝐀)⊢𝐂\n𝑐∊Σ0𝑠𝑘 new\nΓ⊢𝐂𝒩𝒟⊢1∃ℰ\n\n\n:\nComputational Logic12024-12-14\n",
        "sectionId": "93c8176a",
        "archive": "courses/Jacobs/CompLog",
        "filepath": "pl1/slides/nd-sequents.en.xhtml"
    },
    {
        "slideContent": "\nNatural Deduction with Equality\n\n▷First-Order Logic with Equality\n                  We extend\nPL1\n                  with a new\nlogical constant\n                  for equality\n=∊Σ𝑝2\n                  and fix its\ninterpretation\n                  to\nℐ(=):={(𝑥,𝑥)|𝑥∊𝒟𝜄}. We call the extended logic\nfirst-order logic with equality\n                  (PL=1)\n\n\n▷We now extend natural deduction as well.\n\n\n▷\n                  For the\ncalculus of natural deduction with equality\n                  (𝒩𝒟=1) we add the following two\nrules\n                  to\n𝒩𝒟1\n                  to deal with equality:\n𝐀=𝐀=𝐼𝐀=𝐁𝐂[𝐀]𝑝[𝐁/𝑝]𝐂=𝐸where\n𝐂[𝐀]𝑝\n                  if the formula\n𝐂\n                  has a subterm\n𝐀\nat position\n𝑝\n                  and\n[𝐁/𝑝]𝐂\n                  is the result of replacing that subterm with\n𝐁.\n\n\n▷In many ways\nequivalence\n              behaves like\nequality, we will use the following rules in\n𝒩𝒟1\n\n\n▷\n⇔𝐼\n                      is\nderivable\n                      and\n⇔𝐸\n                      is\nadmissible\n                      in\n𝒩𝒟1:\n𝐀⇔𝐀⇔𝐼𝐀⇔𝐁𝐂[𝐀]𝑝[𝐁/𝑝]𝐂⇔𝐸\n\n\n:\nComputational Logic12024-12-14\n",
        "sectionId": "93c8176a",
        "archive": "courses/Jacobs/CompLog",
        "filepath": "pl1/slides/ndeq.en.xhtml"
    },
    {
        "slideContent": "\nPositions in Formulae\n\n▷Idea\n                  Formulae are (naturally) trees, so we can use tree positions to talk about subformulae\n\n\n▷Position&#160;in&#160;an&#160;Expression\n\n\n▷Position&#160;in&#160;an&#160;Expression\n\n\n▷Schematically\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n𝐀=𝐂|𝑝   \n\n𝑝  \n\n\n𝐂   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n𝐁   \n\n𝑝  \n\n\n[𝐁/𝑝]𝐂   \n\n\n\n\n\n\n\n\n:\n12024-12-14\n",
        "sectionId": "93c8176a",
        "archive": "courses/Jacobs/GenCS/course",
        "filepath": "logic/slides/positions.en.xhtml"
    },
    {
        "slideContent": "\n𝒩𝒟=1\n              Example:\n2\n              is Irrational\n\n▷We can do real\nmathematics\n              with\n𝒩𝒟=1:\n\n\n▷\n2\n                  is irrational\n\n\nProof:\nWe prove the assertion by\ncontradiction\n\n\n\n1.Assume that\n2\n                    is rational.\n\n\n\n\n2.Then there are numbers\n𝑝\n                    and\n𝑞\n                    such that\n2=𝑝/𝑞.\n\n\n\n\n3.So we know\n2𝑞2=𝑝2.\n\n\n\n\n4.But\n2𝑞2\n                    has an odd number of\nprime factors\n                    while\n𝑝2\n                    an even number.\n\n\n\n\n5.This is a\ncontradiction\n                    (since they are equal), so we have proven the assertion\n\n\n\n:\nComputational Logic12024-12-14\n",
        "sectionId": "93c8176a",
        "archive": "courses/Jacobs/CompLog",
        "filepath": "pl1/slides/nd-sqrt2-irrational.en.xhtml"
    },
    {
        "slideContent": "\n𝒩𝒟=1\n              Example:\n2\n              is Irrational (the Proof)\n\n# hyp formula NDjust1 ∀𝑛,𝑚.¬(2𝑛+1)=(2𝑚) lemma2 ∀𝑛,𝑚.#(𝑛𝑚)=𝑚#(𝑛) lemma3 ∀𝑛,𝑝.prime(𝑝)⇒#(𝑝𝑛)=(#(𝑛)+1) lemma4 ∀𝑥.irr(𝑥)⇔¬(∃𝑝,𝑞.𝑥=𝑝/𝑞) definition5 irr(2)⇔¬(∃𝑝,𝑞.2=𝑝/𝑞) 𝒩𝒟⊢1∀ℰ(4)6 6 ¬irr(2) 𝒩𝒟⊢0Ax7 6 ¬¬(∃𝑝,𝑞.2=𝑝/𝑞) ⇔𝐸(6,5)8 6 ∃𝑝,𝑞.2=𝑝/𝑞 𝒩𝒟⊢0¬ℰ(7)9 6,9 2=𝑝/𝑞 𝒩𝒟⊢0Ax10 6,9 2𝑞2=𝑝2 arith(9)11 6,9#(𝑝2)=2#(𝑝) 𝒩𝒟⊢1∀ℰ2(2)12 6,9prime(2)⇒#(2𝑞2)=(#(𝑞2)+1) 𝒩𝒟⊢1∀ℰ2(1)\n\n\n\n:\nComputational Logic22024-12-14\n",
        "sectionId": "93c8176a",
        "archive": "courses/Jacobs/CompLog",
        "filepath": "pl1/slides/nd-sqrt2-irrational.en.xhtml"
    },
    {
        "slideContent": "\n𝒩𝒟=1\n              Example:\n2\n              is Irrational (the Proof continued)\n\n13 prime(2)lemma14 6,9 #(2𝑞2)=#(𝑞2)+1 𝒩𝒟0⇒𝐸(13,12)15 6,9#(𝑞2)=2#(𝑞) 𝒩𝒟1∀ℰ2(2)16 6,9#(2𝑞2)=2#(𝑞)+1 =𝐸(14,15)17 #(𝑝2)=#(𝑝2) =𝐼18 6,9 #(2𝑞2)=#(𝑞2) =𝐸(17,10)19 6.9 2#(𝑞)+1=#(𝑝2) =𝐸(18,16)20 6.9 2#(𝑞)+1=2#(𝑝) =𝐸(19,11)21 6.9 ¬(2#(𝑞)+1)=(2#(𝑝)) 𝒩𝒟1∀ℰ2(1)22 6,9 𝐹 𝒩𝒟0𝐹𝐼(20,21) 23 6 𝐹 𝒩𝒟1∃ℰ6(22) 24 ¬¬irr(2) 𝒩𝒟0¬ℐ6(23) 25 irr(2) 𝒩𝒟0¬ℰ2(23) \n\n\n\n:\nComputational Logic32024-12-14\n",
        "sectionId": "93c8176a",
        "archive": "courses/Jacobs/CompLog",
        "filepath": "pl1/slides/nd-sqrt2-irrational.en.xhtml"
    },
    {
        "slideContent": "\nSummary (Predicate Logic)\n\n▷Predicate logic\n            allows to explicitly speak about objects and their properties. It is thus a more natural and compact representation language than\npropositional logic; it also enables us to speak about\ninfinite\n            sets of objects.\n\n\n▷Logic has thousands of years of history. A major current application in\nAI\n            is\nSemantic Technology.\n\n\n▷First-order predicate logic (PL1)\n            allows\nuniversal\n            and\nexistential quantification\n            over objects.\n\n\n▷A PL1\ninterpretation\n            consists of a\nuniverse\n𝑈\n            and a function\n𝐼\n            mapping\nconstant symbols/predicate symbols/function symbols\n            to elements/relations/functions on\n𝑈.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-15\n",
        "sectionId": "f9b7f2af",
        "archive": "courses/FAU/AI/course",
        "filepath": "logic/slides/pl1-summary.en.xhtml"
    },
    {
        "slideContent": "\nTest Calculi: Tableaux and Model Generation\n\n▷Idea\n                  A\ntableau calculus\n                  is a\ntest calculus\n                  that\n\n\n▷analyzes a\nlabeled formulae\n                  in a tree to determine\nsatisfiability,\n\n\n▷its\nbranches\n                  correspond to\nvaluations\n                  (⤳\nmodels).\n\n\n▷Tableau calculi\n                    try to construct models for\nlabeled formulae:\n\n\nTableau refutation (Validity) Model generation (Satisfiability)⊨𝑃∧𝑄⇒𝑄∧𝑃 ⊨𝑃∧(𝑄∨¬𝑅)∧¬𝑄\n(𝑃∧𝑄⇒𝑄∧𝑃)𝖥(𝑃∧𝑄)𝖳(𝑄∧𝑃)𝖥𝑃𝖳𝑄𝖳𝑃𝖥⊥𝑄𝖥⊥\n \n(𝑃∧(𝑄∨¬𝑅)∧¬𝑄)𝖳(𝑃∧(𝑄∨¬𝑅))𝖳¬𝑄𝖳𝑄𝖥𝑃𝖳(𝑄∨¬𝑅)𝖳𝑄𝖳⊥¬𝑅𝖳𝑅𝖥\n No Model Herbrand model {𝑃𝖳,𝑄𝖥,𝑅𝖥}𝜑:={𝑃↦𝖳,𝑄↦𝖥,𝑅↦𝖥}\n\n\n▷Idea\nOpen\nbranches\n                  in\nsaturated\ntableaux\n                  yield\nmodels.\n\n\n▷Algorithm\n                  Fully expand all possible\ntableaux,(no rule can be applied)\n\n\n▷Satisfiable, iff there are\nopen\nbranches(correspond to\nmodels)\n\n\n\n:\n12024-12-15\n",
        "sectionId": "7a6901a1",
        "archive": "courses/Jacobs/GenCS/course",
        "filepath": "atp0/slides/tableaux-motivation.en.xhtml"
    },
    {
        "slideContent": "\nAnalytical Tableaux (Formal Treatment of\n𝒯0)\n\n▷Idea\n                  A\ntest calculus\n                  where\n\n\n▷A\nlabeled formula\n                  is analyzed in a\ntree\n                  to determine\nsatisfiability,\n\n\n▷branches\n                  correspond to valuations (models)\n\n\n▷\n                  The\npropositional tableau calculus\n𝒯0\n                  has two\ninference rules\n                  per\nconnective(one for each possible label)\n(𝐀∧𝐁)𝖳𝐀𝖳𝐁𝖳𝒯0∧(𝐀∧𝐁)𝖥𝐀𝖥\n|\n𝐁𝖥𝒯0∨¬𝐀𝖳𝐀𝖥𝒯0¬𝖳¬𝐀𝖥𝐀𝖳𝒯0¬𝖥𝐀𝛼𝐀𝛽𝛼≠𝛽⊥𝒯0⊥Use rules exhaustively as long as they contribute new material(⤳\n                      termination)\n\n\n▷\n                  We call any\ntree\n                  (\n|\n\n                  introduces\nbranches) produced by the\n𝒯0\ninference rules\n                  from a set\nΦ\n                  of\nlabeled formulae\n                  a\ntableau\n                  for\nΦ.\n\n\n▷\n                  Call a\ntableau\nsaturated, iff no\nrule\n                  adds new material and a\nbranch\nclosed, iff it ends in\n⊥, else\nopen. A\ntableau\n                  is\nclosed, iff all of its\nbranches\n                  are.\n\nIn analogy to the\n⊥\n                  at the end of\nclosed\nbranches, we sometimes decorate\nopen\nbranches\n                  with a\n□\n                  symbol.\n\n\n\n:\n12024-12-16\n",
        "sectionId": "7a6901a1",
        "archive": "courses/Jacobs/GenCS/course",
        "filepath": "atp0/slides/tableaux-formal.en.xhtml"
    },
    {
        "slideContent": "\nAnalytical Tableaux (𝒯0\n              continued)\n\n▷𝒯0-Theorem/Derivability\n𝐀\n                  is a\n𝒯0-theorem\n                  (⊢𝒯0𝐀), iff there is a\nclosed\ntableau\n                  with\n𝐀𝖥\n                  at the\nroot.\n\nΦ⊆𝑤𝑓𝑓0(𝒱0)\nderives\n𝐀\n                  in\n𝒯0\n                  (Φ⊢𝒯0𝐀), iff there is a\nclosed\ntableau\n                  starting with\n𝐀𝖥\n                  and\nΦ𝖳. The\ntableau\n                  with only a\nbranch\n                  of\n𝐀𝖥\n                  and\nΦ𝖳\n                  is called\ninitial\n                  for\nΦ⊢𝒯0𝐀.\n\n\n\n:\n22024-12-16\n",
        "sectionId": "7a6901a1",
        "archive": "courses/Jacobs/GenCS/course",
        "filepath": "atp0/slides/tableaux-formal.en.xhtml"
    },
    {
        "slideContent": "\nFirst-Order Standard Tableaux (𝒯1)\n\n▷\n                  The\nstandard tableau calculus\n                  (𝒯1) extends\n𝒯0\n                  (propositional tableau calculus) with the following\nquantifier\n                  rules:\n(∀𝑋.𝐀)𝖳𝐂∊𝑐𝑤𝑓𝑓𝜄(Σ𝜄)([𝐂/𝑋](𝐀))𝖳𝒯1∀(∀𝑋.𝐀)𝖥\n𝑐∊Σ0𝑠𝑘 new\n([𝑐/𝑋](𝐀))𝖥𝒯1∃\n\n▷Problem\n                  The rule\n𝒯1∀\n                  displays a case of “don’t know indeterminism”: to find a\nrefutation\n                  we have to guess a formula\n𝐂\n                  from the (usually\ninfinite) set\n𝑐𝑤𝑓𝑓𝜄(Σ𝜄).\n\nFor proof search, this means that we have to systematically try all, so\n𝒯1∀\n                  is\ninfinitely\n                  branching in general.\n\n\n\n:\nComputational Logic12024-12-14\n",
        "sectionId": "7a6901a1",
        "archive": "courses/Jacobs/CompLog",
        "filepath": "atp1/slides/tableau.en.xhtml"
    },
    {
        "slideContent": "\nFree variable Tableaux (𝒯1𝑓)\n\n▷\n                  The\nfree variable tableau calculus\n                  (𝒯1𝑓) extends\n𝒯0\n                  (propositional tableau calculus) with the\nquantifier\n                  rules:\n(∀𝑋.𝐀)𝖳\n𝑌 new\n([𝑌/𝑋](𝐀))𝖳𝒯1𝑓∀(∀𝑋.𝐀)𝖥free(∀𝑋.𝐀)={𝑋1,...,𝑋𝑘}\n𝑓∊Σ𝑘𝑠𝑘 new\n([𝑓(𝑋1,...,𝑋𝑘)/𝑋](𝐀))𝖥𝒯1𝑓∃\n                  and generalizes its cut rule\n𝒯0⊥\n                  to:\n𝐀𝛼𝐁𝛽𝛼≠𝛽𝜎(𝐀)=𝜎(𝐁)⊥:𝜎𝒯1𝑓⊥𝒯1𝑓⊥\n                  instantiates the whole tableau by\n𝜎.\n\n\n▷Advantage\n                  No guessing necessary in\n𝒯1𝑓∀-rule!\n\n\n▷New Problem\n                  find suitable\nsubstitution\n                  (most general unifier)(later)\n\n\n\n:\nComputational Logic12024-12-14\n",
        "sectionId": "7a6901a1",
        "archive": "courses/Jacobs/CompLog",
        "filepath": "atp1/slides/fotab-freevars.en.xhtml"
    },
    {
        "slideContent": "\nFree variable Tableaux (𝒯1𝑓): Derivable Rules\n\n▷\nDerivable\nquantifier\n                  rules in\n𝒯1𝑓:\n(∃𝑋.𝐀)𝖳free(∀𝑋.𝐀)={𝑋1,...,𝑋𝑘}\n𝑓∊Σ𝑘𝑠𝑘 new\n([𝑓(𝑋1,...,𝑋𝑘)/𝑋](𝐀))𝖳(∃𝑋.𝐀)𝖥\n𝑌 new\n([𝑌/𝑋](𝐀))𝖥\n\n\n:\nComputational Logic22024-12-14\n",
        "sectionId": "7a6901a1",
        "archive": "courses/Jacobs/CompLog",
        "filepath": "atp1/slides/fotab-freevars.en.xhtml"
    },
    {
        "slideContent": "\nTableau Reasons about Blocks\n\n▷Reasoning about Blocks\n                Returing to slide\n??\n\n\n\n\nCan we prove\nred(𝐀)\n                from\n∀𝑥.block(𝑥)⇒red(𝑥)\n                and\nblock(𝐀)?\n\n(∀𝑋.block(𝑋)⇒red(𝑋))𝖳block(𝐀)𝖳red(𝐀)𝖥(block(𝑌)⇒red(𝑌))𝖳block(𝑌)𝖥⊥:[𝐀/𝑌]red(𝐀)𝖳⊥\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "7a6901a1",
        "archive": "courses/FAU/AI/course",
        "filepath": "logic/slides/pl1-blocks-tableau.en.xhtml"
    },
    {
        "slideContent": "\nUnification (Definitions)\n\n▷\n                  For given\nterms\n𝐀\n                  and\n𝐁,\nunification\n                  is the problem of finding a\nsubstitution\n𝜎, such that\n𝜎(𝐀)=𝜎(𝐁).\n\n\n▷Notation\n                  We write\nterm\npairs\n                      as\n𝐀=?𝐁\n                  e.g.\n𝑓(𝑋)=?𝑓(𝑔(𝑌)).\n\n\n▷\n                  Solutions (e.g.\n[𝑔(𝑎)/𝑋],[𝑎/𝑌],\n[𝑔(𝑔(𝑎))/𝑋],[𝑔(𝑎)/𝑌], or\n[𝑔(𝑍)/𝑋],[𝑍/𝑌]) are called\nunifiers,\n𝐔(𝐀=?𝐁):={𝜎|𝜎(𝐀)=𝜎(𝐁)}.\n\n\n▷Idea\n                  Find representatives in\n𝐔(𝐀=?𝐁), that generate the set of solutions.\n\n\n▷\n                  Let\n𝜎\n                  and\n𝜃\n                  be\nsubstitutions\n                  and\n𝑊⊆𝒱𝜄, we say that a\nsubstitution\n𝜎\n                  is\nmore general\n                  than\n𝜃\n                  (on\n𝑊; write\n𝜎≤𝜃[𝑊]), iff there is a\nsubstitution\n𝜌, such that\n𝜃=(𝜌◦𝜎)[𝑊], where\n𝜎=𝜌[𝑊], iff\n𝜎(𝑋)=𝜌(𝑋)\n                  for all\n𝑋∊𝑊.\n\n\n▷\n𝜎\n                  is called a\nmost general unifier\n                  (mgu) of\n𝐀\n                  and\n𝐁, iff it is\nminimal\n                  in\n𝐔(𝐀=?𝐁)\n                  wrt.\n≤[(free(𝐀)∪free(𝐁))].\n\n\n\n:\nComputational Logic12024-12-14\n",
        "sectionId": "fb048f3b",
        "archive": "courses/Jacobs/CompLog",
        "filepath": "unif/slides/unification.en.xhtml"
    },
    {
        "slideContent": "\nUnification Problems (=^\n              Equational Systems)\n\n▷Idea\n                  Unification is equation solving.\n\n\n▷We call a formula\n𝐀1=?𝐁1∧...∧𝐀𝑛=?𝐁𝑛\n                  an\nunification problem\n                  iff\n𝐀𝑖,𝐁𝑖∊𝑤𝑓𝑓𝜄(Σ𝜄,𝒱𝜄).\n\n\n▷Note\n                  We consider\nunification problems\n                  as sets of equations (∧\n                  is\nACI), and equations as two-element\nmultisets\n                  (=?\n                  is\nC).\n\n\n▷\n                  A\nsubstitution\n                  is called a\nunifier\n                  for a\nunification problem\nℰ\n                  (and thus\n𝒟\nunifiable), iff it is a (simultaneous)\nunifier\n                  for all\npairs\n                  in\nℰ.\n\n\n\n:\nComputational Logic12024-12-14\n",
        "sectionId": "fb048f3b",
        "archive": "courses/Jacobs/CompLog",
        "filepath": "unif/slides/unif-eq.en.xhtml"
    },
    {
        "slideContent": "\nSolved forms and Most General Unifiers\n\n▷\n                  We call a\npair\n𝐀=?𝐁\nsolved\n                  in a\nunification problem\nℰ, iff\n𝐀=𝑋,\nℰ=𝑋=?𝐀∧ℰ, and\n𝑋∉(free(𝐀)∪free(ℰ)). We call an\nunification problem\nℰ\n                  a\nsolved form, iff all its\npairs\n                  are\nsolved.\n\n\n▷Solved forms are of the form\n𝑋1=?𝐁1∧...∧𝑋𝑛=?𝐁𝑛\n                  where the\n𝑋𝑖\n                  are distinct and\n𝑋𝑖∉free(𝐁𝑗).\n\n\n▷Any\nsubstitution\n𝜎=[𝐁1/𝑋1],...,[𝐁𝑛/𝑋𝑛]\n                  induces a\nsolved\nunification problem\nℰ𝜎:=(𝑋1=?𝐁1∧...∧𝑋𝑛=?𝐁𝑛).\n\n\n▷If\nℰ=𝑋1=?𝐁1∧...∧𝑋𝑛=?𝐁𝑛\n                  is a\nsolved form, then\nℰ\n                  has the\nunique most general unifier\n𝜎ℰ:=[𝐁1/𝑋1],...,[𝐁𝑛/𝑋𝑛].\n\n\n▷Proof:\nLet\n𝜃∊𝐔(ℰ)\n\n\n\n1.then\n𝜃(𝑋𝑖)=𝜃(𝐁𝑖)=𝜃◦𝜎ℰ(𝑋𝑖)\n\n\n\n\n2.and thus\n𝜃=(𝜃◦𝜎ℰ)[supp(𝜎)].\n\n\n▷Note\n                  We can rename the\nintroduced\nvariables\n                  in\nmost general unifiers!\n\n\n\n:\nComputational Logic12024-12-14\n",
        "sectionId": "fb048f3b",
        "archive": "courses/Jacobs/CompLog",
        "filepath": "unif/slides/solved-form.en.xhtml"
    },
    {
        "slideContent": "\nUnification Algorithm\n\n▷The inference system\n𝒰\n                  consists of the following rules:\nℰ∧𝑓(𝐀1,...,𝐀𝑛)=?𝑓(𝐁1,...,𝐁𝑛)ℰ∧𝐀1=?𝐁1∧...∧𝐀𝑛=?𝐁𝑛𝒰decℰ∧𝐀=?𝐀ℰ𝒰trivℰ∧𝑋=?𝐀𝑋∉free(𝐀)𝑋∊free(ℰ)[𝐀/𝑋](ℰ)∧𝑋=?𝐀𝒰elim\n\n▷\n𝒰\n                  is\ncorrect:\nℰ⊢𝒰ℱ\n                      implies\n𝐔(ℱ)⊆𝐔(ℰ).\n\n\n▷\n𝒰\n                  is\ncomplete:\nℰ⊢𝒰ℱ\n                      implies\n𝐔(ℰ)⊆𝐔(ℱ).\n\n\n▷\n𝒰\n                  is\nconfluent: the order of derivations does not matter.\n\n\n▷\nFirst-order\nunification\n                  is\nunitary: i.e.\nmost general unifiers\n                      are unique up to renaming of\nintroduced\nvariables.\n\n\n▷Proof sketch:\n𝒰\n                is trivially branching.\n\n\n\n:\nComputational Logic12024-12-14\n",
        "sectionId": "fb048f3b",
        "archive": "courses/Jacobs/CompLog",
        "filepath": "unif/slides/unif-alg.en.xhtml"
    },
    {
        "slideContent": "\nUnification Examples\n\n▷\n                  Two similar\nunification problems:\n\n\n\n\n\n\n\n𝑓(𝑔(𝑋,𝑋),ℎ(𝑎))=?𝑓(𝑔(𝑎,𝑍),ℎ(𝑍))\n𝒰dec\n\n𝑔(𝑋,𝑋)=?𝑔(𝑎,𝑍)∧ℎ(𝑎)=?ℎ(𝑍)\n\n\n𝒰dec\n\n𝑋=?𝑎∧𝑋=?𝑍∧ℎ(𝑎)=?ℎ(𝑍)\n\n\n𝒰dec\n\n𝑋=?𝑎∧𝑋=?𝑍∧𝑎=?𝑍\n\n\n𝒰elim\n\n𝑋=?𝑎∧𝑎=?𝑍∧𝑎=?𝑍\n\n\n𝒰elim\n\n𝑋=?𝑎∧𝑍=?𝑎∧𝑎=?𝑎\n\n\n𝒰triv\n\n𝑋=?𝑎∧𝑍=?𝑎\n \n\n\n\n𝑓(𝑔(𝑋,𝑋),ℎ(𝑎))=?𝑓(𝑔(𝑏,𝑍),ℎ(𝑍))\n𝒰dec\n\n𝑔(𝑋,𝑋)=?𝑔(𝑏,𝑍)∧ℎ(𝑎)=?ℎ(𝑍)\n\n\n𝒰dec\n\n𝑋=?𝑏∧𝑋=?𝑍∧ℎ(𝑎)=?ℎ(𝑍)\n\n\n𝒰dec\n\n𝑋=?𝑏∧𝑋=?𝑍∧𝑎=?𝑍\n\n\n𝒰elim\n\n𝑋=?𝑏∧𝑏=?𝑍∧𝑎=?𝑍\n\n\n𝒰elim\n\n𝑋=?𝑏∧𝑍=?𝑏∧𝑎=?𝑏\n MGU: [𝑎/𝑋],[𝑎/𝑍] 𝑎=?𝑏 not unifiable\n\n\n\n:\nComputational Logic12024-12-15\n",
        "sectionId": "fb048f3b",
        "archive": "courses/Jacobs/CompLog",
        "filepath": "unif/slides/unif-ex.en.xhtml"
    },
    {
        "slideContent": "\nUnification (Termination)\n\n▷Multiset&#160;Ordering\n\n\n▷\n                  We call a\nvariable\n𝑋\nsolved\n                  in an\nunification problem\nℰ, iff\nℰ\n                  contains a\nsolved pair\n𝑋=?𝐀.\n\n\n▷\n                  If\n≺\n                  is\nlinear/terminating\n                  On\n𝑆, then\n≺𝑚\n                  is\nlinear/terminating\n                  on\n𝒫(𝑆).\n\n\n▷\n𝒰\n                  is\nterminating.(any\n𝒰-derivation is\nfinite)\n\n\n▷Proof:\nWe prove termination by mapping\n𝒰\n                  transformation into a Noetherian space.\n\n\n\n1.Let\n𝜇(ℰ):=〈𝑛,𝒩〉, where\n\n▷𝑛\n                    is the number of\nunsolved variables\n                    in\nℰ\n\n\n▷𝒩\n                    is the\nmultiset\n                    of term depths in\nℰ\n\n\n2.The\nlexicographic order\n≺\n                      on\npairs\n𝜇(ℰ)\n                      is decreased by all\ninference rules.\n\n\n\n2.1.𝒰dec\n                        and\n𝒰triv\n                        decrease the\nmultiset\n                        of term depths without increasing the\nunsolved variables.\n\n\n\n2.2.𝒰elim\n                        decreases the number of\nunsolved variables\n                        (by one), but may increase term depths.\n\n\n:\nComputational Logic12024-12-16\n",
        "sectionId": "fb048f3b",
        "archive": "courses/Jacobs/CompLog",
        "filepath": "unif/slides/termination.en.xhtml"
    },
    {
        "slideContent": "\nFirst-Order Unification is Decidable\n\n▷\n                  We call an equational problem\nℰ\n𝒰-reducible, iff there is a\n𝒰-step\nℰ⊢𝒰ℱ\n                  from\nℰ.\n\n\n▷\n                  If\nℰ\n                  is\nunifiable\n                  but not\nsolved, then it is\n𝒰-reducible.\n\n\n▷Proof:\nWe assume that\nℰ\n                  is\nunifiable\n                  but\nunsolved\n                  and show the\n𝒰\n                  rule that applies.\n\n\n\n1.There is an\nunsolved pair\n𝐀=?𝐁\n                    in\nℰ=ℰ∧𝐀=?𝐁'.\n\n\nwe have two cases\n\n\n2.𝐀,𝐁∉𝒱𝜄\n\n\n\n2.1.then\n𝐀=𝑓(𝐀1...𝐀𝑛)\n                        and\n𝐁=𝑓(𝐁1...𝐁𝑛), and thus\n𝒰dec\n                        is applicable\n\n\n3.𝐀=𝑋∊free(ℰ)\n\n\n\n3.1.then\n𝒰elim\n                        (if\n𝐁≠𝑋) or\n𝒰triv\n                        (if\n𝐁=𝑋) is applicable.\n\n\n▷\n                  First-order unification is\ndecidable\n                  in\nPL1.\n\n\n▷Proof:\n\n\n\n\n1.𝒰-irreducible\nunification problems\n                    can be reached in\nfinite\n                    time by\n??.\n\n\n\n\n2.They are either\nsolved\n                    or unsolvable by\n??, so they provide the answer.\n\n\n\n:\nComputational Logic12024-12-14\n",
        "sectionId": "fb048f3b",
        "archive": "courses/Jacobs/CompLog",
        "filepath": "unif/slides/decidable.en.xhtml"
    },
    {
        "slideContent": "\nComplexity of Unification\n\n▷Observation\n                  Naive\nimplementations\n                  of unification are exponential in time and space.\n\n\n▷Consider the terms\n𝑠𝑛=𝑓(𝑓(𝑥0,𝑥0),𝑓(𝑓(𝑥1,𝑥1),𝑓(...,𝑓(𝑥𝑛−1,𝑥𝑛−1))...))\n\n𝑡𝑛=𝑓(𝑥1,𝑓(𝑥2,𝑓(𝑥3,𝑓(···,𝑥𝑛)···)))\n\n\n\n▷The\nmost general unifier\n                  of\n𝑠𝑛\n                  and\n𝑡𝑛\n                  is\n𝜎𝑛:=[𝑓(𝑥0,𝑥0)/𝑥1],[𝑓(𝑓(𝑥0,𝑥0),𝑓(𝑥0,𝑥0))/𝑥2],[𝑓(𝑓(𝑓(𝑥0,𝑥0),𝑓(𝑥0,𝑥0)),𝑓(𝑓(𝑥0,𝑥0),𝑓(𝑥0,𝑥0)))/𝑥3],...\n\n\n▷It contains\n∑𝑖=1𝑛2𝑖=2𝑛+1−2\noccurrences\n                  of the variable\n𝑥0.(exponential)\n\n\n▷Problem\n                  The variable\n𝑥0\n                  has been copied too often.\n\n\n▷Idea\n                  Find a term representation that re-uses subterms.\n\n\n\n:\nComputational Logic12024-12-15\n",
        "sectionId": "143df1b7",
        "archive": "courses/Jacobs/CompLog",
        "filepath": "unif/slides/complexity.en.xhtml"
    },
    {
        "slideContent": "\nDirected Acyclic Graphs (DAGs) for Terms\n\n▷Recall\nTerms\n                  in\nfirst-order logic\n                  are essentially\ntrees.\n\n\n▷Concrete Idea\n                  Use\ndirected acyclic graphs\n                  for representing\nterms:\n\n\n▷variables my only occur once in the\nDAG.\n\n\n▷subterms can be referenced multiply.(subterm sharing)\n\n\n▷we can even represent multiple terms in a common\nDAG\n\n\n▷\nTerms\n                  can be transformed into\nDAGs\n                  in linear time.\n\n\n▷Continuing from\n??\n                  ...𝑠3,\n𝑡3, and\n𝜎3(𝑠3)\n                  as\nDAGs:\n\n\n\n\n\n\n𝑥1  \n𝑥2  \n𝑥3  \n𝑥0  \n𝑓  \n𝑓  \n𝑓  \n𝑓  \n𝑓  \n𝑓  \n𝑓  \n𝑠3  \n𝑡3  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n𝑥0  \n𝑓  \n𝑓  \n𝑓  \n𝑓  \n𝑓  \n𝜎3(𝑡3)  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\nIn general:\n𝑠𝑛,\n𝑡𝑛, and\n𝜎𝑛(𝑠𝑛)\n                  only need space in\n𝒪(𝑛).(just count)\n\n\n\n:\nComputational Logic12024-12-15\n",
        "sectionId": "143df1b7",
        "archive": "courses/Jacobs/CompLog",
        "filepath": "unif/slides/dags.en.xhtml"
    },
    {
        "slideContent": "\nDAG Unification Algorithm\n\n▷Observation\n                  In\n𝒰, the\n𝒰elim\n                  rule applies\nsolved pairs\n⤳\n                  subterm duplication.\n\n\n▷Idea\n                  Replace\n𝒰elim\n                  the notion of\nsolved forms\n                  by something better.\n\n\n▷We say that\n𝑋1=?𝐁1∧...∧𝑋𝑛=?𝐁𝑛\n                  is a\nDAG solved form, iff the\n𝑋𝑖\n                  are distinct and\n𝑋𝑖∉free(𝐁𝑗)\n                  for\n𝑖≤𝑗.\n\n\n▷\n                  The inference system\n𝒟𝒰\n                  contains rules\n𝒰dec\n                  and\n𝒰triv\n                  from\n𝒰\n                  plus the following:\nℰ∧𝑋=?𝐀∧𝑋=?𝐁𝐀,𝐁∉𝒱𝜄|𝐀|≤|𝐁|ℰ∧𝑋=?𝐀∧𝐀=?𝐁𝒟𝒰mergeℰ∧𝑋=?𝑌𝑋≠𝑌𝑋,𝑌∊free(ℰ)[𝑌/𝑋](ℰ)∧𝑋=?𝑌𝒟𝒰evarwhere\n|𝐀|\n                  is the number of symbols in\n𝐀.\n\n\n▷The analysis for\n𝒰\n              applies mutatis mutandis.\n\n\n\n:\nComputational Logic12024-12-14\n",
        "sectionId": "143df1b7",
        "archive": "courses/Jacobs/CompLog",
        "filepath": "unif/slides/dag-alg.en.xhtml"
    },
    {
        "slideContent": "\nUnification by DAG-chase\n\n▷Idea\n                  Extend the Input-DAGs\n                  by\nedges\n                  that represent\nunifiers.\n\n\n▷\n                  Write\n𝑛.𝑎, if\n𝑎\n                  is the symbol of node\n𝑛.\n\n\n▷(standard) auxiliary procedures:\n(all constant or linear time in\nDAGs)\n\n\n▷find(𝑛)\n              follows the path from\n𝑛\n              and returns the end node.\n\n\n▷union(𝑛,𝑚)\n              adds an edge between\n𝑛\n              and\n𝑚.\n\n\n▷occur(𝑛,𝑚)\n              determines whether\n𝑛.𝑥\n              occurs in the\nDAG\n              with root\n𝑚.\n\n\n\n:\nComputational Logic12024-12-15\n",
        "sectionId": "143df1b7",
        "archive": "courses/Jacobs/CompLog",
        "filepath": "unif/slides/dagchase.en.xhtml"
    },
    {
        "slideContent": "\nAlgorithm\ndag―unify\n\n▷Input: symmetric\npairs\n              of\nnodes\n              in\nDAGs\n\n\nfun dag―unify(𝑛,𝑛) = true\n| dag―unify(𝑛.𝑥,𝑚) = if occur(𝑛,𝑚) then true else union(𝑛,𝑚)\n| dag―unify(𝑛.𝑓,𝑚.𝑔) =\nif 𝑔!=𝑓 then false\nelse\nforall (𝑖,𝑗) => dag―unify(find(𝑖),find(𝑗)) (chld 𝑚,chld 𝑛)\nend\n\n\ndag―unify\n                  uses\nlinear\n                  space, since no new\nnodes\n                  are created, and at most one link per variable.\n\n\n▷\n\n▷Problem\ndag―unify\n                  still uses exponential time.\n\n\n▷Consider terms\n𝑓(𝑠𝑛,𝑓(𝑡'𝑛,𝑥𝑛)),𝑓(𝑡𝑛,𝑓(𝑠'𝑛,𝑦𝑛))), where\n𝑠'𝑛=[𝑦𝑖/𝑥𝑖](𝑠𝑛)\n                  und\n𝑡'𝑛=[𝑦𝑖/𝑥𝑖](𝑡𝑛).\n\ndag―unify\n                  needs exponentially many recursive calls to unify the nodes\n𝑥𝑛\n                  and\n𝑦𝑛.\n(they are unified after\n𝑛\n                      calls, but checking needs the time)\n\n\n\n:\nComputational Logic22024-12-15\n",
        "sectionId": "143df1b7",
        "archive": "courses/Jacobs/CompLog",
        "filepath": "unif/slides/dagchase.en.xhtml"
    },
    {
        "slideContent": "\nAlgorithm\nuf―unify\n\n▷Recall\ndag―unify\n                  still uses exponential time.\n\n\n▷Idea\n                  Also bind the function nodes, if the arguments are unified.\n\n\nuf―unify(𝑛.𝑓,𝑚.𝑔) =\nif 𝑔!=𝑓 then false\nelse union(𝑛,𝑚);\nforall (𝑖,𝑗) => uf―unify(find(𝑖),find(𝑗)) (chld 𝑚,chld 𝑛)\nend\n\n▷This only needs linearly many recursive calls as it directly returns with true or makes a node inaccessible for\nfind.\n\n\n▷Linearly many calls to linear procedures give quadratic\nrunning time.\n\n\n▷Remark\n                  There are versions of\nuf―unify\n                  that are linear in time and space, but for most purposes, our\nalgorithm\n                  suffices.\n\n\n\n:\nComputational Logic32024-12-15\n",
        "sectionId": "143df1b7",
        "archive": "courses/Jacobs/CompLog",
        "filepath": "unif/slides/dagchase.en.xhtml"
    },
    {
        "slideContent": "\nTermination and Multiplicity in Tableaux\n\n▷RecallIn\n𝒯0, all rules only needed to be applied once.⤳\n𝒯0\n                  terminates and thus induces a\ndecision procedure\n                  for\nPL0.\n\n\n▷\n                  All\n𝒯1𝑓\n                  rules except\n𝒯1𝑓∀\n                  only need to be applied once.\n\n\n▷\n                  A tableau proof for\n(𝑝(𝑎)∨𝑝(𝑏))⇒(∃.𝑝()).\n\n\nStart, close left branch use 𝒯1𝑓∀ again (right branch)\n((𝑝(𝑎)∨𝑝(𝑏))⇒(∃.𝑝()))𝖥(𝑝(𝑎)∨𝑝(𝑏))𝖳(∃𝑥.𝑝(𝑥))𝖥(∀𝑥.¬𝑝(𝑥))𝖳¬𝑝(𝑦)𝖳𝑝(𝑦)𝖥𝑝(𝑎)𝖳⊥:[𝑎/𝑦]𝑝(𝑏)𝖳\n \n((𝑝(𝑎)∨𝑝(𝑏))⇒(∃.𝑝()))𝖥(𝑝(𝑎)∨𝑝(𝑏))𝖳(∃𝑥.𝑝(𝑥))𝖥(∀𝑥.¬𝑝(𝑥))𝖳¬𝑝(𝑎)𝖳𝑝(𝑎)𝖥𝑝(𝑎)𝖳⊥:[𝑎/𝑦]𝑝(𝑏)𝖳¬𝑝(𝑧)𝖳𝑝(𝑧)𝖥⊥:[𝑏/𝑧]\n\n\n\nAfter we have used up\n𝑝(𝑦)𝖥\n                  by applying\n[𝑎/𝑦]\n                  in\n𝒯1𝑓⊥, we have to get a new instance\n𝑝(𝑧)𝖥\n                  via\n𝒯1𝑓∀.\n\n\n▷\n                  Let\n𝒯\n                  be a\ntableau\n                  for\n𝐀, and a positive\noccurrence\n                  of\n∀𝑥.𝐁\n                  in\n𝐀, then we call the number of applications of\n𝒯1𝑓∀\n                  to\n∀𝑥.𝐁\n                  its\nmultiplicity.\n\n\n▷\n                  Given a prescribed\nmultiplicity\n                  for each positive\n∀, saturation with\n𝒯1𝑓\n                  terminates.\n\n\n▷Proof sketch:\n                All\n𝒯1𝑓\n                rules reduce the number of\nconnectives\n                and negative\n∀\n                or the multiplicity of positive\n∀.\n\n\n▷\n𝒯1𝑓\n                  is only complete with unbounded\nmultiplicities.\n\n\n▷Proof sketch:\n                Replace\n𝑝(𝑎)∨𝑝(𝑏)\n                with\n𝑝(𝑎1)∨...∨𝑝(𝑎𝑛)\n                in\n??.\n\n\n▷Remark\n                  Otherwise validity in\nPL1\n                  would be\ndecidable.\n\n\n▷Implementation\n                  We need an iterative\nmultiplicity\n                  deepening process.\n\n\n\n:\nComputational Logic12024-12-16\n",
        "sectionId": "a783d605",
        "archive": "courses/Jacobs/CompLog",
        "filepath": "atp1/slides/fotab-multiplicity.en.xhtml"
    },
    {
        "slideContent": "\nTreating\n𝒯1𝑓⊥\n\n▷Recall\n                  The\n𝒯1𝑓⊥\n                  rule instantiates the whole tableau.\n\n\n▷Problem\n                  There may be more than one\n𝒯1𝑓⊥\n                  opportunity on a branch.\n\n\n▷\n                  Choosing which matters — this tableau does not close!\n(∃𝑥.(𝑝(𝑎)∧𝑝(𝑏)⇒𝑝())∧(𝑞(𝑏)⇒𝑞(𝑥)))𝖥((𝑝(𝑎)∧𝑝(𝑏)⇒𝑝())∧(𝑞(𝑏)⇒𝑞(𝑦)))𝖥(𝑝(𝑎)⇒𝑝(𝑏)⇒𝑝())𝖥𝑝(𝑎)𝖳𝑝(𝑏)𝖳𝑝(𝑦)𝖥⊥:[𝑎/𝑦](𝑞(𝑏)⇒𝑞(𝑦))𝖥𝑞(𝑏)𝖳𝑞(𝑦)𝖥choosing the other\n𝒯1𝑓⊥\n                  in the left branch allows closure.\n\n\n▷IdeaTwo ways of systematic proof search in\n𝒯1𝑓:\n\n\n▷backtracking search\n                  over\n𝒯1𝑓⊥\n                  opportunities\n\n\n▷saturate\n                  without\n𝒯1𝑓⊥\n                  and find spanning matings(next slide)\n\n\n\n:\nComputational Logic12024-12-14\n",
        "sectionId": "a783d605",
        "archive": "courses/Jacobs/CompLog",
        "filepath": "atp1/slides/fotab-cut.en.xhtml"
    },
    {
        "slideContent": "\nSpanning Matings for\n𝒯1𝑓⊥\n\n▷\n𝒯1𝑓\n                  without\n𝒯1𝑓⊥\n                  is terminating and confluent for given multiplicities.\n\n\n▷Idea\n                  Saturate without\n𝒯1𝑓⊥\n                  and treat all cuts at the same time (later).\n\n\n▷\nLet\n𝒯\n                  be a\n𝒯1𝑓\n                  tableau, then we call a unification problem\nℰ:=𝐀1=?𝐁1∧...∧𝐀𝑛=?𝐁𝑛\n                  a\nmating\n                  for\n𝒯, iff\n𝐀𝑖𝖳\n                  and\n𝐁𝑖𝖥\n                  occur in the same branch in\n𝒯.\n\nWe say that\nℰ\n                  is a\nspanning mating, if\nℰ\n                  is unifiable and every branch\nℬ\n                  of\n𝒯\n                  contains\n𝐀𝑖𝖳\n                  and\n𝐁𝑖𝖥\n                  for some\n𝑖.\n\n\n▷\n                  A\n𝒯1𝑓-tableau with a\nspanning mating\n                  induces a closed\n𝒯1\n                  tableau.\n\n\n▷Proof sketch:\n                Just apply the unifier of the\nspanning mating.\n\n\n▷Idea\n                  Existence is sufficient, we do not need to compute the unifier.\n\n\n▷Implementation\nSaturate\n                  without\n𝒯1𝑓⊥,\nbacktracking search\n                  for\nspanning matings\n                  with\n𝒟𝒰, adding pairs\nincrementally.\n\n\n\n:\nComputational Logic12024-12-15\n",
        "sectionId": "a783d605",
        "archive": "courses/Jacobs/CompLog",
        "filepath": "atp1/slides/fotab-matings.en.xhtml"
    },
    {
        "slideContent": "\nFirst-Order Resolution (and CNF)\n\n▷\n                  The\nfirst-order CNF calculus\n𝐶𝑁𝐹1\n                  is given by the\ninference rules\n                  of\n𝐶𝑁𝐹0\n                  extended by the following\nquantifier\n                  rules:\n(∀𝑋.𝐀)𝖳∨𝐂𝑍∉(free(𝐀)∪free(𝐂))([𝑍/𝑋](𝐀))𝖳∨𝐂(∀𝑋.𝐀)𝖥∨𝐂{𝑋1,...,𝑋𝑘}=free(∀𝑋.𝐀)\n𝑓∊Σ𝑘𝑠𝑘 new\n([𝑓(𝑋1,...,𝑋𝑘)/𝑋](𝐀))𝖥∨𝐂the\nfirst-order CNF\n𝐶𝑁𝐹1(Φ)\n                  of\nΦ\n                  is the set of all\nclauses\n                  that can be derived from\nΦ.\n\n\n▷First-Order Resolution Calculus\n                  The\nFirst-order resolution calculus\n                  (ℛ1) is a\ntest calculus\n                  that manipulates formulae in\nconjunctive normal form.\nℛ1\n                  has two\ninference rules:\n𝐀𝖳∨𝐂𝐁𝖥∨𝐃𝜎=𝐦𝐠𝐮(𝐀,𝐁)(𝜎(𝐂))∨(𝜎(𝐃))𝐀𝛼∨𝐁𝛼∨𝐂𝜎=𝐦𝐠𝐮(𝐀,𝐁)(𝜎(𝐀))∨(𝜎(𝐂))\n\n\n:\nComputational Logic12024-12-14\n",
        "sectionId": "e4cb1bf",
        "archive": "courses/Jacobs/CompLog",
        "filepath": "atp1/slides/resolution.en.xhtml"
    },
    {
        "slideContent": "\nFirst-Order CNF — Derived Rules\n\n▷\n                  The following\ninference rules\n                  are\nderivable\n                  from the ones above via\n(∃𝑋.𝐀)=¬(∀𝑋.¬𝐀):\n(∃𝑋.𝐀)𝖳∨𝐂{𝑋1,...,𝑋𝑘}=free(∀𝑋.𝐀)\n𝑓∊Σ𝑘𝑠𝑘 new\n([𝑓(𝑋1,...,𝑋𝑘)/𝑋](𝐀))𝖳∨𝐂(∃𝑋.𝐀)𝖥∨𝐂𝑍∉(free(𝐀)∪free(𝐂))([𝑍/𝑋](𝐀))𝖥∨𝐂\n\n\n:\nComputational Logic22024-12-14\n",
        "sectionId": "e4cb1bf",
        "archive": "courses/Jacobs/CompLog",
        "filepath": "atp1/slides/resolution.en.xhtml"
    },
    {
        "slideContent": "\nCol. West,\na Criminal?\n\n▷\n                  From [RN09]\n\n\nThe law says it is a crime for an American to sell weapons to hostile nations. The country Nono, an enemy of America, has some missiles, and all of its missiles were sold to it by Colonel West, who is American.\n\n\nProve that Col. West is a criminal.\n\n\n▷RemarkModern\nresolution\ntheorem provers\n                  prove this in less than\n50ms.\n\n\n▷Problem\n                  That is only true, if we\nonly\n                  give the\ntheorem prover\n                  exactly the right laws and background knowledge. If we give it all of them, it drowns in the\ncombinatorial explosion.\n\n\n▷\n                  Let us build a\nresolution\nproof\n                  for the claim above.\n\n\n▷But first\n                  we must translate the situation into\nfirst-order logic\nclauses.\n\n\n▷Convention\n                  In what follows, for better readability we will sometimes write\nimplications\n𝑃∧𝑄∧𝑅⇒𝑆\n                  instead of\nclauses\n𝑃𝖥∨𝑄𝖥∨𝑅𝖥∨𝑆𝖳.\n\n\n\n:\nComputational Logic12024-12-15\n",
        "sectionId": "22793340",
        "archive": "courses/Jacobs/CompLog",
        "filepath": "atp1/slides/west-criminal-ex.en.xhtml"
    },
    {
        "slideContent": "\nCol. West,\na Criminal?\n\n\n▷It is a crime for an American to sell weapons to hostile nations:Clause:\nami(𝑋1)∧weap(𝑌1)∧sell(𝑋1,𝑌1,𝑍1)∧host(𝑍1)⇒crook(𝑋1)\n\n\n▷Nono has some missiles:\n∃𝑋.own(NN,𝑋)∧mle(𝑋)Clauses:\nown(NN,𝑐)𝖳\n              and\nmle(𝑐)(𝑐\n                  is\nSkolem constant)\n\n\n▷All of Nono’s missiles were sold to it by Colonel West.Clause:\nmle(𝑋2)∧own(NN,𝑋2)⇒sell(West,𝑋2,NN)\n\n\n▷Missiles are weapons:Clause:\nmle(𝑋3)⇒weap(𝑋3)\n\n\n▷An enemy of America counts as “hostile”:Clause:\nenmy(𝑋4,USA)⇒host(𝑋4)\n\n\n▷West is an American:Clause:\nami(West)\n\n\n▷The country Nono is an enemy of America:enmy(NN,USA)\n\n\n\n:\nComputational Logic22024-12-15\n",
        "sectionId": "22793340",
        "archive": "courses/Jacobs/CompLog",
        "filepath": "atp1/slides/west-criminal-ex.en.xhtml"
    },
    {
        "slideContent": "\nCol. West,\na Criminal!\n              PL1 Resolution Proof\n\n\n\n\n\nami(𝑋1)𝖥∨weapon(𝑌1)𝖥∨sell(𝑋1,𝑌1,𝑍1)𝖥∨hostile(𝑍1)𝖥∨crook(𝑋1)𝖳  \ncrook(West)𝖥  \nami(West)𝖳  \nami(West)𝖥∨weapon(𝑌1)𝖥∨sell(West,𝑌1,𝑍1)𝖥∨hostile(𝑍1)𝖥  \nmissile(𝑋3)𝖥∨weapon(𝑋3)𝖳  \nweapon(𝑌1)𝖥∨sell(West,𝑌1,𝑍1)𝖥∨hostile(𝑍1)𝖥  \nmissile(𝑐)𝖳  \nmissile(𝑌1)𝖥∨sell(West,𝑌1,𝑍1)𝖥∨hostile(𝑍1)𝖥  \nmissile(𝑋2)𝖥∨own(NoNo,𝑋2)𝖥∨sell(West,𝑋2,NoNo)𝖳  \nsell(West,𝑐,𝑍1)𝖥∨hostile(𝑍1)𝖥  \nmissile(𝑐)𝖳  \nmissile(𝑐)𝖥∨own(NoNo,𝑐)𝖥∨hostile(NoNo)𝖥  \nown(NoNo,𝑐)𝖳  \nown(NoNo,𝑐)𝖥∨hostile(NoNo)𝖥  \nenemy(𝑋4,𝑈𝑆𝐴)𝖥∨hostile(𝑋4)𝖳  \nhostile(NoNo)𝖥  \nenemy(NoNo,𝑈𝑆𝐴)𝖳  \nenemy(NoNo,𝑈𝑆𝐴)𝖥  \n□  \n\n\n[West/𝑋1]  \n\n\n\n\n[𝑌1/𝑋3]  \n\n\n[𝑐/𝑌1]  \n\n[𝑐/𝑋2]  \n\n[NoNo/𝑍1]  \n\n\n\n\n\n\n[NoNo/𝑋4]  \n\n\n\n\n\n\n\n\n\n:\nComputational Logic32024-12-15\n",
        "sectionId": "22793340",
        "archive": "courses/Jacobs/CompLog",
        "filepath": "atp1/slides/west-criminal-ex.en.xhtml"
    },
    {
        "slideContent": "\nCuriosity\n              Killed the Cat?\n\n▷\n                  From [RN09]\n\n\nEveryone who loves all animals is loved by someone.Anyone who kills an animal is loved by noone.Jack loves all animals.Cats are animals.Either Jack or curiosity killed the cat (whose name is “Garfield”).\n\nProve that curiosity killed the cat.\n\n\n\n:\nComputational Logic12024-12-16\n",
        "sectionId": "22793340",
        "archive": "courses/Jacobs/CompLog",
        "filepath": "atp1/slides/curiosity-cat-ex.en.xhtml"
    },
    {
        "slideContent": "\nCuriosity\n              Killed the Cat?\nClauses\n\n▷Everyone who loves all animals is loved by someone:∀𝑋.(∀𝑌.animal(𝑌)⇒love(𝑋,𝑌))⇒(∃.love(𝑍,𝑋))Clauses:\nanimal(𝑔(𝑋1))𝖳∨love(𝑔(𝑋1),𝑋1)𝖳\n              and\nlove(𝑋2,𝑓(𝑋2))𝖥∨love(𝑔(𝑋2),𝑋2)𝖳\n\n\n▷Anyone who kills an animal is loved by noone:∀𝑋.∃𝑌.animal(𝑌)∧kill(𝑋,𝑌)⇒(∀.¬love(𝑍,𝑋))Clause:\nanimal(𝑌3)𝖥∨kill(𝑋3,𝑌3)𝖥∨love(𝑍3,𝑋3)𝖥\n\n\n▷Jack loves all animals:Clause:\nanimal(𝑋4)𝖥∨love(jack,𝑋4)𝖳\n\n\n▷Cats are animals:Clause:\ncat(𝑋5)𝖥∨animal(𝑋5)𝖳\n\n\n▷Either Jack or curiosity killed the cat (whose name is “Garfield”):Clauses:\nkill(jack,garf)𝖳∨kill(curiosity,garf)𝖳\n              and\ncat(garf)𝖳\n\n\n\n:\nComputational Logic22024-12-16\n",
        "sectionId": "22793340",
        "archive": "courses/Jacobs/CompLog",
        "filepath": "atp1/slides/curiosity-cat-ex.en.xhtml"
    },
    {
        "slideContent": "\nCuriosity\n              Killed the Cat! PL1 Resolution Proof\n\n\n\n\n\ncat(garf)𝖳  \ncat(𝑋5)𝖥∨anl(𝑋5)𝖳  \nanl(garf)𝖳  \nanl(𝑌3)𝖥∨kill(𝑋3,𝑌3)𝖥∨love(𝑍3,𝑋3)𝖥  \nkill(𝑋3,garf)𝖥∨love(𝑍3,𝑋3)𝖥  \nkill(jack,garf)𝖳∨kill(curty,garf)𝖳  \nkill(curty,garf)𝖥  \nkill(jack,garf)𝖳  \nlove(𝑍3,jack)𝖥  \nlove(𝑋2,𝑓(𝑋2))𝖥∨love(𝑔(𝑋2),𝑋2)𝖳  \nanl(𝑋4)𝖥∨love(jack,𝑋4)𝖳  \nlove(𝑔(jack),jack)𝖳∨anl(𝑓(jack))𝖥  \nanl(𝑓(𝑋1))𝖳∨love(𝑔(𝑋1),𝑋1)𝖳  \nlove(𝑔(jack),jack)𝖳  \n□  \n\n[garf/𝑋5]  \n\n\n\n\n[garf/𝑌3]  \n\n\n[jack/𝑋3]  \n\n\n[jack/𝑋2],[𝑓(jack)/𝑋4]  \n\n\n[jack/𝑋1]  \n\n\n[𝑔(jack)/𝑍3]  \n\n\n\n\n\n\n\n\n:\nComputational Logic32024-12-16\n",
        "sectionId": "22793340",
        "archive": "courses/Jacobs/CompLog",
        "filepath": "atp1/slides/curiosity-cat-ex.en.xhtml"
    },
    {
        "slideContent": "\nWe know all this already\n\n▷Goals, goal sets,\nrules, and\nfacts\n              are just\nclauses.(called\nHorn clauses)\n\n\n▷Rule𝐻:―𝐵1,...,𝐵𝑛.\n                  corresponds to\n𝐻𝖳∨map(/𝑚𝑛𝑡/𝑠𝑑𝑏1/𝑏𝑢𝑖𝑙𝑑𝑠𝑒𝑟𝑣𝑒𝑟/𝑀𝑎𝑡ℎ𝐻𝑢𝑏,(𝐵1𝖥)∨...∨(𝐵𝑛𝖥))𝐵1𝖥∨...∨𝐵𝑛𝖥(head the only positive\nliteral)\n\n\n▷Goal set?― 𝐺1,...,𝐺𝑛.\n                  corresponds to\nmap(/𝑚𝑛𝑡/𝑠𝑑𝑏1/𝑏𝑢𝑖𝑙𝑑𝑠𝑒𝑟𝑣𝑒𝑟/𝑀𝑎𝑡ℎ𝐻𝑢𝑏,(𝐺1𝖥)∨...∨(𝐺𝑛𝖥))𝐺1𝖥∨...∨𝐺𝑛𝖥\n\n\n▷Fact\n𝐹.\n                  corresponds to the unit\nclause\n𝐹𝖳.\n\n\n▷\n                  A\nHorn clause\n                  is a\nclause\n                  with at most one\npositive\nliteral.\n\n\n▷Recall\nBackchaining\n                  as\nsearch:\n\n\n▷state = tuple of\ngoals; goal state = empty list (of\ngoals).\n\n\n▷𝑛𝑒𝑥𝑡(〈𝐺,𝑅1,...,𝑅𝑙〉):=〈map(/𝑚𝑛𝑡/𝑠𝑑𝑏1/𝑏𝑢𝑖𝑙𝑑𝑠𝑒𝑟𝑣𝑒𝑟/𝑀𝑎𝑡ℎ𝐻𝑢𝑏,(𝜎(𝐵1)),...,(𝜎(𝐵𝑚)))𝜎(𝐵1),...,𝜎(𝐵𝑚),map(/𝑚𝑛𝑡/𝑠𝑑𝑏1/𝑏𝑢𝑖𝑙𝑑𝑠𝑒𝑟𝑣𝑒𝑟/𝑀𝑎𝑡ℎ𝐻𝑢𝑏,(𝜎(𝑅1)),...,(𝜎(𝑅𝑙)))𝜎(𝑅1),...,𝜎(𝑅𝑙)〉\n                  if there is a rule\n𝐻:―𝐵1,..., 𝐵𝑚.\n                  and a\nsubstitution\n𝜎\n                  with\n𝜎(𝐻)=𝜎(𝐺).\n\n\n▷Note\nBackchaining\n                  becomes resolution\n𝑃𝖳∨𝐀𝑃𝖥∨𝐁𝐀∨𝐁positive, unit-resulting hyperresolution (PURR)\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "dafd3f7a",
        "archive": "courses/FAU/AI/course",
        "filepath": "prolog/slides/prolog-resolution.en.xhtml"
    },
    {
        "slideContent": "\nPROLOG (Horn Logic)\n\n▷A\nclause\n                  is called a\nHorn clause, iff contains at most one positive\nliteral, i.e. if it is of the form\nmap(/𝑚𝑛𝑡/𝑠𝑑𝑏1/𝑏𝑢𝑖𝑙𝑑𝑠𝑒𝑟𝑣𝑒𝑟/𝑀𝑎𝑡ℎ𝐻𝑢𝑏,(𝐵1𝖥)∨...∨(𝐵𝑛𝖥))𝐵1𝖥∨...∨𝐵𝑛𝖥∨𝐴𝖳\n                  — i.e.\nA:―𝐵1,...,𝐵𝑛.\n                  in\nProlog\n                  notation.\n\n\n▷Rule clause: general case,\ne.g.\nfallible(X) : human(X).\n\n\n▷Fact clause: no negative\nliterals,\ne.g.\nhuman(sokrates).\n\n\n▷Program: set of rule and fact\nclauses.\n\n\n▷Query: no positive\nliterals:\ne.g.\n?― fallible(X),greek(X).\n\n\n▷\nHorn logic\n                  is the\nformal system\n                  whose language is the set of\nHorn clauses\n                  together with the\ncalculus\nℋ\n                  given by\nMP,\n∧𝐼, and\nSubst.\n\n\n▷\n                  A\nlogic program\n𝑃\nentails\n                  a\nquery\n𝑄\n                  with\nanswer substitution\n𝜎, iff there is a\nℋ\n                  derivation\n𝐷\n                  of\n𝑄\n                  from\n𝑃\n                  and\n𝜎\n                  is the combined\nsubstitution\n                  of the\nSubst\n                  instances in\n𝐷.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "dafd3f7a",
        "archive": "courses/FAU/AI/course",
        "filepath": "prolog/slides/prolog-Hornclauses.en.xhtml"
    },
    {
        "slideContent": "\nPROLOG: Our Example\n\n▷Program\n\n\nhuman(leibniz).\nhuman(sokrates).\ngreek(sokrates).\nfallible(X):―human(X).\n\n▷Query\n?― fallible(X),greek(X).\n\n\n▷Answer substitution\n[sokrates/𝑋]\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 122024-12-14\n",
        "sectionId": "dafd3f7a",
        "archive": "courses/FAU/AI/course",
        "filepath": "prolog/slides/prolog-Hornclauses.en.xhtml"
    },
    {
        "slideContent": "\nKnowledge Base (Example)\n\n▷\ncar(c).\n                  is in the knowlege base generated by\n\n\nhas_motor(c).\nhas_wheels(c,4).\ncar(X):― has_motor(X),has_wheels(X,4).\n\n𝑚(𝑐)𝑤(𝑐,4)\n∧𝐼\n\n𝑚(𝑐)∧𝑤(𝑐,4)\n𝑚(𝑥)∧𝑤(𝑥,4)⇒𝑐𝑎𝑟()\nSubst\n\n𝑚(𝑐)∧𝑤(𝑐,4)⇒𝑐𝑎𝑟()\n\nMP\n\n𝑐𝑎𝑟(𝑐)\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-15\n",
        "sectionId": "dafd3f7a",
        "archive": "courses/FAU/AI/course",
        "filepath": "prolog/slides/prolog-kb-ex.en.xhtml"
    },
    {
        "slideContent": "\nWhy Only\nHorn Clauses?\n\n▷General\nclauses\n              of the form\nA1,...,An : B1,...,Bn.\n\n\n▷e.g.\ngreek(sokrates),greek(perikles)\n\n\n▷Question: Are there fallible greeks?\n\n\n▷Indefinite answer: Yes, Perikles or Sokrates\n\n\n▷Warning: how about\nSokrates and Perikles?\n\n\n▷e.g.\ngreek(sokrates),roman(sokrates):―.\n\n\n▷Query: Are there fallible greeks?\n\n\n▷Answer: Yes, Sokrates, if he is not a roman\n\n\n▷Is this abduction?????\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-16\n",
        "sectionId": "dafd3f7a",
        "archive": "courses/FAU/AI/course",
        "filepath": "prolog/slides/prolog-why-horn.en.xhtml"
    },
    {
        "slideContent": "\nThree Principal Modes of Inference\n\n▷\nDeduction\n=^\n                  knowledge extension\n\n\n▷\n𝑟𝑎𝑖𝑛𝑠⇒𝑤𝑒𝑡\n_\n𝑠𝑡𝑟𝑒𝑒𝑡𝑟𝑎𝑖𝑛𝑠𝑤𝑒𝑡\n_\n𝑠𝑡𝑟𝑒𝑒𝑡𝐷\n\n\n▷\nAbduction\n=^\n                  explanation\n\n\n▷\n𝑟𝑎𝑖𝑛𝑠⇒𝑤𝑒𝑡\n_\n𝑠𝑡𝑟𝑒𝑒𝑡𝑤𝑒𝑡\n_\n𝑠𝑡𝑟𝑒𝑒𝑡𝑟𝑎𝑖𝑛𝑠𝐴\n\n\n▷\nInduction\n=^\n                  learning general rules from examples\n\n\n▷\n𝑤𝑒𝑡\n_\n𝑠𝑡𝑟𝑒𝑒𝑡𝑟𝑎𝑖𝑛𝑠𝑟𝑎𝑖𝑛𝑠⇒𝑤𝑒𝑡\n_\n𝑠𝑡𝑟𝑒𝑒𝑡𝐼\n\n\n\n:\n12024-12-15\n",
        "sectionId": "dafd3f7a",
        "archive": "courses/Jacobs/GenCS/course",
        "filepath": "logic/slides/modes-of-inference.en.xhtml"
    },
    {
        "slideContent": "\nModel Existence (Overview)\n\n▷Definition\n                  Abstract consistency\n\n\n▷Definition\n                  Hintikka set (maximally abstract consistent)\n\n\n▷Theorem\n                  Hintikka sets are satisfiable\n\n\n▷Theorem\n                  If\nΦ\n                  is abstract consistent, then\nΦ\n                  can be extended to a Hintikka set.\n\n\n▷Corollary\n                  If\nΦ\n                  is abstract consistent, then\nΦ\n                  is\nsatisfiable.\n\n\n▷Application\n                  Let\n𝒞\n                  be a\ncalculus, if\nΦ\n                  is\n𝒞-consistent, then\nΦ\n                  is abstract consistent.\n\n\n▷Corollary\n𝒞\n                  is complete.\n\n\n\n:\n12024-12-15\n",
        "sectionId": "4d0da2f",
        "archive": "courses/Jacobs/GenCS/course",
        "filepath": "logic/slides/model-existence-overview.en.xhtml"
    },
    {
        "slideContent": "\nConsistency\n\n▷Let\n𝒞\n              be a\ncalculus,...\n\n▷\n\n\n▷\n\n\n▷\n                  So a set\nΦ\n                  is\n𝒞-refutable, if\n𝒞\n                  canderive\n                  a\ncontradiction\n                  from it.\n\n\n▷\n\n\n▷\n                  We call a\ncalculus\n𝒞\nreasonable, iff implication elimination and conjunction introduction are\nadmissible\n                  in\n𝒞\n                  and\n𝐀∧¬𝐀⇒𝐁\n                  is a\n𝒞-theorem.\n\n\n▷\n𝒞-inconsistency and\n𝒞-refutability coincide for\nreasonable\ncalculi.\n\n\n\n:\n12024-12-14\n",
        "sectionId": "4d0da2f",
        "archive": "courses/Jacobs/GenCS/course",
        "filepath": "logic/slides/consistency.en.xhtml"
    },
    {
        "slideContent": "\nAbstract Consistency\n\n▷\n\n\n▷Notation\n                  We will use\nΦ*𝐀\n                  for\nΦ∪{𝐀}.\n\n\n▷\n                  A family\n∇⊆𝑤𝑓𝑓𝑜(Σ𝜄,𝒱𝜄)\n                  of sets of formulae is called a (first-order)\nabstract consistency class, iff it is\nclosed under subsets, and for each\nΦ∊∇\n\n\n∇𝑐)𝐀∉Φ\n                  or\n¬𝐀∉Φ\n                  for\natomic\n𝐀∊𝑤𝑓𝑓𝑜(Σ𝜄,𝒱𝜄).\n\n\n∇¬)¬¬𝐀∊Φ\n                  implies\nΦ*𝐀∊∇\n\n\n∇∧)𝐀∧𝐁∊Φ\n                  implies\nΦ∪{𝐀,𝐁}∊∇\n\n\n∇∨)¬(𝐀∧𝐁)∊Φ\n                  implies\nΦ*¬𝐀∊∇\n                  or\nΦ*¬𝐁∊∇\n\n\n∇∀)If\n∀𝑋.𝐀∊Φ, then\nΦ*([𝐁/𝑋](𝐀))∊∇\n                  for each closed term\n𝐁.\n\n\n∇∃)If\n¬(∀𝑋.𝐀)∊Φ\n                  and\n𝑐\n                  is an individual constant that does not occur in\nΦ, then\nΦ*¬([𝑐/𝑋](𝐀))∊∇\n\n\n\n:\nComputational Logic12024-12-14\n",
        "sectionId": "4d0da2f",
        "archive": "courses/Jacobs/CompLog",
        "filepath": "pl1/slides/abstract-consistency.en.xhtml"
    },
    {
        "slideContent": "\nCompact Collections\n\n▷\n\n\n▷\n                  If\n∇\n                  is\ncompact, then\n∇\n                  is\nclosed under subsets.\n\n\n▷Proof:\n\n\n\n\n1.Suppose\n𝑆⊆𝑇\n                    and\n𝑇∊∇.\n\n\n\n2.Every\nfinite\n                    subset\n𝐴\n                    of\n𝑆\n                    is a\nfinite\n                    subset of\n𝑇.\n\n\n\n3.As\n∇\n                    is\ncompact, we know that\n𝐴∊∇.\n\n\n\n4.Thus\n𝑆∊∇.\n\n\n:\n12024-12-15\n",
        "sectionId": "4d0da2f",
        "archive": "courses/Jacobs/GenCS/course",
        "filepath": "logic/slides/compact-def.en.xhtml"
    },
    {
        "slideContent": "\nCompact Abstract Consistency Classes\n\n▷\n                  Any first-order\nabstract consistency class\n                  can be extended to a\ncompact\n                  one.\n\n\n▷Proof:\n\n\n\n\n1.We choose\n∇':={Φ⊆𝑐𝑤𝑓𝑓𝑜(Σ𝜄)|\nevery finite subset of Φis in ∇\n}.\n\n\n\n\n2.Now suppose that\nΦ∊∇.\n∇\n                    is\nclosed under subsets, so every\nfinite\n                    subset of\nΦ\n                    is in\n∇\n                    and thus\nΦ∊∇'. Hence\n∇⊆∇'.\n\n\n3.Let us now show that each\n∇\n                      is\ncompact.’\n\n\n\n3.1.Suppose\nΦ∊∇'\n                        and\nΨ\n                        is an arbitrary\nfinite\n                        subset of\nΦ.\n\n\n\n\n3.2.By definition of\n∇'\n                        all\nfinite\n                        subsets of\nΦ\n                        are in\n∇\n                        and therefore\nΨ∊∇'.\n\n\n\n\n3.3.Thus all\nfinite\n                        subsets of\nΦ\n                        are in\n∇'\n                        whenever\nΦ\n                        is in\n∇'.\n\n\n\n\n3.4.On the other hand, suppose all\nfinite\n                        subsets of\nΦ\n                        are in\n∇'.\n\n\n\n\n3.5.Then by the definition of\n∇'\n                        the\nfinite\n                        subsets of\nΦ\n                        are also in\n∇, so\nΦ∊∇'. Thus\n∇'\n                        is\ncompact.\n\n\n\n\n4.Note that\n∇'\n                    is\nclosed under subsets\n                    by the Lemma above.\n\n\n5.Next we show that if\n∇\n                      satisfies\n∇*, then\n∇\n                      satisfies\n∇*.’\n\n\n\n5.1.To show\n∇𝑐, let\nΦ∊∇'\n                        and suppose there is an atom\n𝐀, such that\n{𝐀,¬𝐀}⊆Φ. Then\n{𝐀,¬𝐀}∊∇\n                        contradicting\n∇𝑐.\n\n\n5.2.To show\n∇¬, let\nΦ∊∇'\n                          and\n¬¬𝐀∊Φ, then\nΦ*𝐀∊∇'.\n\n\n\n5.2.1.Let\nΨ\n                            be any\nfinite\n                            subset of\nΦ*𝐀, and\nΘ:=(Ψ\\{𝐀})*¬¬𝐀.\n\n\n\n\n5.2.2.Θ\n                            is a\nfinite\n                            subset of\nΦ, so\nΘ∊∇.\n\n\n\n\n5.2.3.Since\n∇\n                            is an abstract consistency class and\n¬¬𝐀∊Θ, we get\nΘ*𝐀∊∇\n                            by\n∇¬.\n\n\n\n\n5.2.4.We know that\nΨ⊆Θ*𝐀\n                            and\n∇\n                            is closed under subsets, so\nΨ∊∇.\n\n\n\n\n5.2.5.Thus every\nfinite\n                            subset\nΨ\n                            of\nΦ*𝐀\n                            is in\n∇\n                            and therefore by definition\nΦ*𝐀∊∇'.\n\n\n\n\n5.3.the other cases are analogous to\n∇¬.\n\n\n\n:\nComputational Logic12024-12-15\n",
        "sectionId": "4d0da2f",
        "archive": "courses/Jacobs/CompLog",
        "filepath": "pl1/slides/compact-acc.en.xhtml"
    },
    {
        "slideContent": "\n∇-Hintikka Set\n\n▷\n                  Let\n∇\n                  be an abstract consistency class, then we call a set\nℋ∊∇\n                  a\n∇\n                      Hintikka Set, iff\nℋ\n                  is maximal in\n∇, i.e. for all\n𝐀\n                  with\nℋ*𝐀∊∇\n                  we already have\n𝐀∊ℋ.\n\n\n▷Hintikka Properties\n                  Let\n∇\n                  be an abstract consistency class and\nℋ\n                  be a\n∇-Hintikka set, then\n\n\nℋ𝑐)For all\n𝐀∊𝑤𝑓𝑓𝑜(Σ𝜄,𝒱𝜄)\n                  we have\n𝐀∉ℋ\n                  or\n¬𝐀∉ℋ.\n\n\nℋ¬)If\n¬¬𝐀∊ℋ\n                  then\n𝐀∊ℋ.\n\n\nℋ∧)If\n𝐀∧𝐁∊ℋ\n                  then\n𝐀,𝐁∊ℋ.\n\n\nℋ∨)If\n¬(𝐀∧𝐁)∊ℋ\n                  then\n¬𝐀∊ℋ\n                  or\n¬𝐁∊ℋ.\n\n\nℋ∀)If\n∀𝑋.𝐀∊ℋ, then\n[𝐁/𝑋](𝐀)∊ℋ\n                      for each closed term\n𝐁.\n\n\nℋ∃)If\n¬(∀𝑋.𝐀)∊ℋ\n                      then\n¬([𝐁/𝑋](𝐀))∊ℋ\n                      for some term closed term\n𝐁.\n\n\n▷Proof:\n\n\nWe prove the properties in turn\nℋ𝑐\n                      goes by induction on the structure of\n𝐀\n\n\n1.𝐀\natomic\n\n\n\n1.1.Then\n𝐀∉ℋ\n                        or\n¬𝐀∉ℋ\n                        by\n∇𝑐.\n\n\n2.𝐀=¬𝐁\n\n\n\n2.1.Let us assume that\n¬𝐁∊ℋ\n                        and\n¬¬𝐁∊ℋ,\n\n\n\n\n2.2.then\nℋ*𝐁∊∇\n                        by\n∇¬, and therefore\n𝐁∊ℋ\n                        by maximality.\n\n\n\n\n2.3.So\n{𝐁,¬𝐁}⊆ℋ, which contradicts the\ninduction hypothesis.\n\n\n3.𝐀=𝐁∨𝐂\n\nsimilar to the previous case\n\n\n4.We prove\nℋ¬\n                      by maximality of\nℋ\n                      in\n∇.\n\n\n\n4.1.If\n¬¬𝐀∊ℋ, then\nℋ*𝐀∊∇\n                        by\n∇¬.\n\n\n\n\n4.2.The maximality of\nℋ\n                        now gives us that\n𝐀∊ℋ.\n\n\n\n\n5.The other\nℋ*\n                    are similar\n\n\n\n:\nComputational Logic12024-12-15\n",
        "sectionId": "4d0da2f",
        "archive": "courses/Jacobs/CompLog",
        "filepath": "pl1/slides/Hintikka-set.en.xhtml"
    },
    {
        "slideContent": "\nExtension Theorem\n\n▷\n                  If\n∇\n                  is an abstract consistency class and\nΦ∊∇\nfinite, then there is a\n∇-Hintikka set\nℋ\n                  with\nΦ⊆ℋ.\n\n\n▷Proof:\n\n\n\n\n1.Wlog.\n                    assume that\n∇\ncompact(else use\ncompact\n                        extension)\n\n\n\n2.Choose an\nenumeration\n𝐀1,...\n                    of\n𝑐𝑤𝑓𝑓𝑜(Σ𝜄)\n                    and\n𝑐1,...\n                    of\nΣ0𝑠𝑘.\n\n\n\n\n3.and construct a sequence of sets\n𝐇𝑖\n                    with\n𝐇0:=Φ\n                    and\n𝐇𝑛+1:={𝐇𝑛if𝐇𝑛*𝐀𝑛∉∇𝐇𝑛∪{𝐀𝑛,¬([𝑐𝑛/𝑋](𝐁))}if𝐇𝑛*𝐀𝑛∊∇and𝐀𝑛=¬(∀𝑋.𝐁)𝐇𝑛*𝐀𝑛else\n\n\n\n4.Note that all\n𝐇𝑖∊∇, choose\nℋ:=⋃𝑖∊ℕ𝐇𝑖\n\n\n\n\n5.Ψ⊆ℋ\nfinite\n                    implies there is a\n𝑗∊ℕ\n                    such that\nΨ⊆𝐇𝑗,\n\n\n\n\n6.so\nΨ∊∇\n                    as\n∇\nclosed under subsets\n                    and\nℋ∊∇\n                    as\n∇\n                    is\ncompact.\n\n\n\n\n7.Let\nℋ*𝐁∊∇, then there is a\n𝑗∊ℕ\n                    with\n𝐁=𝐀𝑗, so that\n𝐁∊𝐇𝑗+1\n                    and\n𝐇𝑗+1⊆ℋ\n\n\n\n\n8.Thus\nℋ\n                    is\n∇-maximal\n\n\n\n:\nComputational Logic12024-12-15\n",
        "sectionId": "4d0da2f",
        "archive": "courses/Jacobs/CompLog",
        "filepath": "pl1/slides/extension-thm.en.xhtml"
    },
    {
        "slideContent": "\nValuations\n\n▷\n\n\n▷\n                  If\n𝜑:𝒱𝜄→𝑈\n                  is a\nvariable assignment, then\nℐ𝜑:𝑐𝑤𝑓𝑓𝑜(Σ𝜄)→𝒟0\n                  is a\nvaluation.\n\n\n▷Proof sketch:\n                Immediate from the definitions\n\n\n\n:\nComputational Logic12024-12-15\n",
        "sectionId": "4d0da2f",
        "archive": "courses/Jacobs/CompLog",
        "filepath": "pl1/slides/valuation.en.xhtml"
    },
    {
        "slideContent": "\nValuation and Satisfiability\n\n▷\n                  If\n𝜈:𝑐𝑤𝑓𝑓𝑜(Σ𝜄)→𝒟0\n                  is a\nvaluation\n                  and\nΦ⊆𝑐𝑤𝑓𝑓𝑜(Σ𝜄)\n                  with\n𝜈(Φ)={𝖳}, then\nΦ\n                  is\nsatisfiable.\n\n\n▷Proof:\nWe construct a model for\nΦ.\n\n\n\n1.Let\n𝒟𝜄:=𝑐𝑤𝑓𝑓𝜄(Σ𝜄), and\n\n▷ℐ(𝑓):𝒟𝜄𝑘→𝒟𝜄;〈𝐀1,...,𝐀𝑘〉↦𝑓(𝐀1,...,𝐀𝑘)\n                    for\n𝑓∊Σ𝑓\n\n\n▷ℐ(𝑝):𝒟𝜄𝑘→𝒟0;〈𝐀1,...,𝐀𝑘〉↦𝜈(𝑝(𝐀1,...,𝐀𝑘))\n                    for\n𝑝∊Σ𝑝.\n\n\n\n\n2.Then\nvariable assignments\n                    into\n𝒟𝜄\n                    are\nground\nsubstitutions.\n\n3.We show\nℐ𝜑(𝐀)=𝜑(𝐀)\n                      for\n𝐀∊𝑤𝑓𝑓𝜄(Σ𝜄,𝒱𝜄)\n                      by induction on\n𝐀:\n\n\n3.1.𝐀=𝑋\n\n\n\n3.1.1.then\nℐ𝜑(𝐀)=𝜑(𝑋)\n                            by definition.\n\n\n3.2.𝐀=𝑓(𝐀1,...,𝐀𝑘)\n\n\n\n3.2.1.then\nℐ𝜑(𝐀)=ℐ(𝑓)(ℐ𝜑(𝐀1),...,ℐ𝜑(𝐀𝑛))=ℐ(𝑓)(𝜑(𝐀1),...,𝜑(𝐀𝑛))=𝑓(𝜑(𝐀1),...,𝜑(𝐀𝑛))=𝜑(𝑓(𝐀1,...,𝐀𝑘))=𝜑(𝐀)\n\n\nWe show\nℐ𝜑(𝐀)=𝜈(𝜑(𝐀))\n                        for\n𝐀∊𝑤𝑓𝑓𝑜(Σ𝜄,𝒱𝜄)\n                        by induction on\n𝐀.\n\n\n3.3.𝐀=𝑝(𝐀1,...,𝐀𝑘)\n\n\n\n3.3.1.then\nℐ𝜑(𝐀)=ℐ(𝑝)(ℐ𝜑(𝐀1),...,ℐ𝜑(𝐀𝑛))=ℐ(𝑝)(𝜑(𝐀1),...,𝜑(𝐀𝑛))=𝜈(𝑝(𝜑(𝐀1),...,𝜑(𝐀𝑛)))=𝜈(𝜑(𝑝(𝐀1,...,𝐀𝑘)))=𝜈(𝜑(𝐀))\n\n\n3.4.𝐀=¬𝐁\n\n\n\n3.4.1.then\nℐ𝜑(𝐀)=𝖳, iff\nℐ𝜑(𝐁)=𝜈(𝜑(𝐁))=𝖥, iff\n𝜈(𝜑(𝐀))=𝖳.\n\n\n3.5.𝐀=𝐁∧𝐂\n\n\n\n3.5.1.similar\n\n3.6.𝐀=∀𝑋.𝐁\n\n\n\n3.6.1.then\nℐ𝜑(𝐀)=𝖳, iff\nℐ𝜓(𝐁)=𝜈(𝜓(𝐁))=𝖳, for all\n𝐂∊𝒟𝜄, where\n𝜓=𝜑,[𝐂/𝑋]. This is the case, iff\n𝜈(𝜑(𝐀))=𝖳.\n\n\n\n\n4.Thus\nℐ𝜑(𝐀)𝜈(𝜑(𝐀))=𝜈(𝐀)=𝖳\n                    for all\n𝐀∊Φ.\n\n\n\n5.Hence\nℳ⊨𝐀\n                    for\nℳ:=〈𝒟𝜄,ℐ〉.\n\n\n:\nComputational Logic22024-12-15\n",
        "sectionId": "4d0da2f",
        "archive": "courses/Jacobs/CompLog",
        "filepath": "pl1/slides/valuation.en.xhtml"
    },
    {
        "slideContent": "\nModel Existence\n\n▷Hintikka-Lemma\n                  If\n∇\n                  is an abstract consistency class and\nℋ\n                  a\n∇-Hintikka set, then\nℋ\n                  is satisfiable.\n\n\n▷Proof:\n\n\n\n\n1.we define\n𝜈(𝐀):=𝖳, iff\n𝐀∊ℋ,\n\n\n\n\n2.then\n𝜈\n                    is a valuation by the Hintikka set properties.\n\n\n\n\n3.We have\n𝜈(ℋ)={𝖳}, so\nℋ\n                    is satisfiable.\n\n\n▷Model Existence\n                  If\n∇\n                  is an abstract consistency class and\nΦ∊∇, then\nΦ\n                  is satisfiable.\n\n\n▷Proof:\n\n\n\n\n1.There is a\n∇-Hintikka set\nℋ\n                    with\nΦ⊆ℋ(Extension Theorem)\n\n\n\n\n2.We know that\nℋ\n                    is satisfiable.(Hintikka-Lemma)\n\n\n\n\n3.In particular,\nΦ⊆ℋ\n                    is satisfiable.\n\n\n\n:\nComputational Logic12024-12-15\n",
        "sectionId": "4d0da2f",
        "archive": "courses/Jacobs/CompLog",
        "filepath": "pl1/slides/model-existence.en.xhtml"
    },
    {
        "slideContent": "\nConsistency, Refutability and Abstract Consistency\n\n▷Non-Refutability is an Abstract Consistency Property\nΓ:={Φ⊆𝑐𝑤𝑓𝑓𝑜(Σ𝜄)|Φnot𝒩𝒟1−refutable}\n                  is an abstract consistency class.\n\n\n▷Proof:\nWe check the properties of an ACC\n\n\n\n1.If\nΦ\n                    is non-refutable, then any subset is as well, so\nΓ\n                    is closed under subsets.\n\n\nWe show the abstract consistency conditions\n∇*\n                    for\nΦ∊Γ.\n\n\n2.∇𝑐\n\n\n\n2.1.We have to show that\n𝐀∉Φ\n                        or\n¬𝐀∉Φ\n                        for\natomic\n𝐀∊𝑤𝑓𝑓𝑜(Σ𝜄,𝒱𝜄).\n\n\n\n\n2.2.Equivalently, we show the contrapositive: If\n{𝐀,¬𝐀}⊆Φ, then\nΦ∉Γ.\n\n\n\n\n2.3.So let\n{𝐀,¬𝐀}⊆Φ, then\nΦ\n                        is\n𝒩𝒟1-refutable by construction.\n\n\n\n\n2.4.So\nΦ∉Γ.\n\n\n3.∇¬\n\nWe show the contrapositive again\n\n3.1.Let\n¬¬𝐀∊Φ\n                        and\nΦ*𝐀∉Γ\n\n\n\n\n3.2.Then we have a\nrefutation\n𝒟:Φ*𝐀⊢𝒩𝒟1𝐹\n\n\n\n\n3.3.By prepending an application of\n𝒩𝒟0¬ℰ\n                        for\n¬¬𝐀\n                        to\n𝒟, we obtain a\nrefutation\n𝒟:Φ⊢𝒩𝒟1𝐹'.\n\n\n\n\n3.4.Thus\nΦ∉Γ.\n\n\nProof sketch:\n                    other\n∇*\n                    similar\n\n\n\n:\nComputational Logic12024-12-14\n",
        "sectionId": "37446263",
        "archive": "courses/Jacobs/CompLog",
        "filepath": "pl1/slides/consistency-acc.en.xhtml"
    },
    {
        "slideContent": "\nHenkin’s Theorem\n\n▷Henkin’s Theorem\n                  Every\n𝒩𝒟1-consistent\n                  set of sentences has a model.\n\n\n▷Proof:\n\n\n\n\n1.Let\nΦ\n                    be a\n𝒩𝒟1-consistent\n                    set of sentences.\n\n\n\n\n2.The class of sets of\n𝒩𝒟1-consistent\n                    propositions constitute an abstract consistency class.\n\n\n\n\n3.Thus the model existence theorem guarantees a model for\nΦ.\n\n\n▷Löwenheim&Skolem Theorem\n                  Satisfiable set\nΦ\n                  of first-order sentences has a countable model.\n\n\n▷Proof sketch:\n                The model we constructed is countable, since the set of ground terms is.\n\n\n\n:\nComputational Logic12024-12-14\n",
        "sectionId": "37446263",
        "archive": "courses/Jacobs/CompLog",
        "filepath": "pl1/slides/FOND-Henkin.en.xhtml"
    },
    {
        "slideContent": "\nCompleteness and Compactness\n\n▷Completeness Theorem for\n𝒩𝒟1\n                  If\nΦ⊨𝐀, then\nΦ⊢𝒩𝒟1𝐀.\n\n\n▷Proof:\nWe prove the result by playing with negations.\n\n\n\n1.If\n𝐀\n                    is valid in all models of\nΦ, then\nΦ*¬𝐀\n                    has no model\n\n\n\n\n2.Thus\nΦ*¬𝐀\n                    is\ninconsistent\n                    by (the contrapositive of) Henkins Theorem.\n\n\n\n\n3.So\nΦ⊢𝒩𝒟1¬¬𝐀\n                    by\n𝒩𝒟0¬ℐ\n                    and thus\nΦ⊢𝒩𝒟1𝐀\n                    by\n𝒩𝒟0¬ℰ.\n\n\n▷Compactness Theorem for first-order logic\n                  If\nΦ⊨𝐀, then there is already a\nfinite\n                  set\nΨ⊆Φ\n                  with\nΨ⊨𝐀.\n\n\n▷Proof:\nThis is a direct consequence of the completeness theorem\n\n\n\n1.We have\nΦ⊨𝐀, iff\nΦ⊢𝒩𝒟1𝐀.\n\n\n\n\n2.As a proof is a\nfinite\n                    object, only a\nfinite\n                    subset\nΨ⊆Φ\n                    can appear as leaves in the proof.\n\n\n\n:\nComputational Logic12024-12-15\n",
        "sectionId": "37446263",
        "archive": "courses/Jacobs/CompLog",
        "filepath": "pl1/slides/FOND-complete.en.xhtml"
    },
    {
        "slideContent": "\nSoundness of\n𝒯1𝑓\n\n▷\n                  Tableau rules transform satisfiable tableaux into satisfiable ones.\n\n\n▷Proof:\n\n\nwe examine the tableau rules in turn\n\n\n1.propositional rules\n\nas in propositional tableaux\n\n\n2.𝒯1𝑓∃\n\nby\n??\n\n\n3.𝒯1𝑓⊥\n\nby\n??\n                        (substitution value lemma)\n\n\n4.𝒯1𝑓∀\n\n\n\n4.1.ℐ𝜑(∀𝑋.𝐀)=𝖳, iff\nℐ𝜓(𝐀)=𝖳\n                        for all\n𝑎∊𝒟𝜄\n\n\n\n\n4.2.so in particular for some\n𝑎∊𝒟𝜄≠∅.\n\n\n▷\n𝒯1𝑓\n                  is correct.\n\n\n\n:\nComputational Logic12024-12-15\n",
        "sectionId": "c7759c5a",
        "archive": "courses/Jacobs/CompLog",
        "filepath": "atp1/slides/fotab-sound.en.xhtml"
    },
    {
        "slideContent": "\nSoundness of\n𝒯1𝑓∃\n\n▷\n𝒯1𝑓∃\n                  transforms satisfiable tableaux into satisfiable ones.\n\n\n▷Proof:\nLet\n𝒯'\n                  be obtained by applying\n𝒯1𝑓∃\n                  to\n(∀𝑋.𝐀)𝖥\n                  in\n𝒯, extending it with\n([𝑓(𝑋1,...,𝑋𝑘)/𝑋](𝐀))𝖥, where\n𝑊:=free(∀𝑋.𝐀)={𝑋1,...,𝑋𝑘}\n\n\n\n1.Let\n𝒯\n                    be satisfiable in\nℳ:=〈𝒟,ℐ〉, then\nℐ𝜑(∀𝑋.𝐀)=𝖥.\n\n\nWe need to find a model\nℳ'\n                    that satisfies\n𝒯'(find interpretation for\n𝑓)\n\n2.By definition\nℐ𝜑,[𝑎/𝑋](𝐀)=𝖥\n                    for some\n𝑎∊𝒟(depends on\n𝜑|𝑊)\n\n\n\n\n3.Let\n𝑔:𝒟𝑘→𝒟\n                    be defined by\n𝑔(𝑎1,...,𝑎𝑘):=𝑎, if\n𝜑(𝑋𝑖)=𝑎𝑖\n\n\n\n\n4.choose\nℳ=〈𝒟,ℐ'〉'\n                    with\nℐ':=ℐ,[𝑔/𝑓], then by subst. value lemma\nℐ'𝜑([𝑓(𝑋1,...,𝑋𝑘)/𝑋](𝐀))=ℐ'𝜑,[ℐ'𝜑(𝑓(𝑋1,...,𝑋𝑘))/𝑋](𝐀)\n\n=ℐ'𝜑,[𝑎/𝑋](𝐀)=𝖥\n\n\n\n\n\n5.So\n([𝑓(𝑋1,...,𝑋𝑘)/𝑋](𝐀))𝖥\n                    satisfiable in\nℳ'\n\n\n\n:\nComputational Logic12024-12-14\n",
        "sectionId": "c7759c5a",
        "archive": "courses/Jacobs/CompLog",
        "filepath": "atp1/slides/fotabexists-sound.en.xhtml"
    },
    {
        "slideContent": "\nCompleteness of (𝒯1𝑓)\n\n▷\n𝒯1𝑓\n                  is\nrefutation complete.\n\n\n▷Proof:\nWe show that\n∇:={Φ|\nΦ𝖳 has no closed Tableau\n}\n                  is an abstract consistency class\n\n\n\n1.as for propositional case.\n\n\n\n\n2.by the lifting lemma below\n\n\n\n\n3.Let\n𝒯\n                    be a closed tableau for\n¬(∀𝑋.𝐀)∊Φ\n                    and\nΦ𝖳*([𝑐/𝑋](𝐀))𝖥∊∇.\nΨ𝖳(∀𝑋.𝐀)𝖥([𝑐/𝑋](𝐀))𝖥𝑅𝑒𝑠𝑡Ψ𝖳(∀𝑋.𝐀)𝖥([𝑓(𝑋1,...,𝑋𝑘)/𝑋](𝐀))𝖥[𝑓(𝑋1,...,𝑋𝑘)/𝑐](𝑅𝑒𝑠𝑡)\n\n\n:\nComputational Logic12024-12-14\n",
        "sectionId": "c7759c5a",
        "archive": "courses/Jacobs/CompLog",
        "filepath": "atp1/slides/tableau-complete.en.xhtml"
    },
    {
        "slideContent": "\nTableau-Lifting\n\n▷\n                  If\n𝒯𝜃\n                  is a\nclosed\ntableau\n                  for a set\n𝜃(Φ)\n                  of formulae, then there is a closed tableau\n𝒯\n                  for\nΦ.\n\n\n▷Proof:\nby induction over the structure of\n𝒯𝜃\n                  we build an isomorphic tableau\n𝒯, and a tableau-isomorphism\n𝜔:𝒯→𝒯𝜃, such that\n𝜔(𝐀)=𝜃(𝐀).\n\nonly the tableau-substitution rule is interesting.\n\n1.Let\n(𝜃(𝐀𝑖))𝖳\n                    and\n(𝜃(𝐁𝑖))𝖥\n                    cut formulae in the branch\nΘ𝜃𝑖\n                    of\n𝒯𝜃\n\n\n\n\n2.there is a joint unifier\n𝜎\n                    of\n(𝜃(𝐀1))=?(𝜃(𝐁1))∧...∧(𝜃(𝐀𝑛))=?(𝜃(𝐁𝑛))\n\n\n\n\n3.thus\n𝜎◦𝜃\n                    is a unifier of\n𝐀\n                    and\n𝐁\n\n\n\n\n4.hence there is a most general unifier\n𝜌\n                    of\n𝐀1=?𝐁1∧...∧𝐀𝑛=?𝐁𝑛\n\n\n\n\n5.so\nΘ\n                    is closed.\n\n\n\n:\nComputational Logic12024-12-14\n",
        "sectionId": "c7759c5a",
        "archive": "courses/Jacobs/CompLog",
        "filepath": "atp1/slides/tableau-lifting.en.xhtml"
    },
    {
        "slideContent": "\nCorrectness (CNF)\n\n▷\n                  A set\nΦ\n                  of sentences is satisfiable, iff\n𝐶𝑁𝐹1(Φ)\n                  is.\n\n\n▷Proof:\npropositional rules and\n∀-rule are trivial; do the\n∃-rule\n\n\n\n1.Let\n(∀𝑋.𝐀)𝖥\n                    satisfiable in\nℳ:=〈𝒟,ℐ〉\n                    and\nfree(𝐀)={𝑋1,...,𝑋𝑛}\n\n\n\n\n2.ℐ𝜑(∀𝑋.𝐀)=𝖥, so there is an\n𝑎∊𝒟\n                    with\nℐ𝜑,[𝑎/𝑋](𝐀)=𝖥(only depends on\n𝜑|free(𝐀))\n\n\n\n\n3.let\n𝑔:𝒟𝑛→𝒟\n                    be defined by\n𝑔(𝑎1,...,𝑎𝑛):=𝑎, iff\n𝜑(𝑋𝑖)=𝑎𝑖.\n\n\n\n\n4.choose\nℳ':=〈𝒟,ℐ'〉\n                    with\nℐ(𝑓)':=𝑔, then\nℐ'𝜑([𝑓(𝑋1,...,𝑋𝑘)/𝑋](𝐀))=𝖥\n\n\n\n\n5.Thus\n([𝑓(𝑋1,...,𝑋𝑘)/𝑋](𝐀))𝖥\n                    is satisfiable in\nℳ'\n\n\n\n:\nComputational Logic12024-12-16\n",
        "sectionId": "8d71aa",
        "archive": "courses/Jacobs/CompLog",
        "filepath": "atp1/slides/resolution-correct.en.xhtml"
    },
    {
        "slideContent": "\nResolution (Correctness)\n\n▷\n                  A\nclause\n                  is called\nsatisfiable, iff\nℐ𝜑(𝐀)=𝛼\n                  for one of its\nliterals\n𝐀𝛼.\n\n\n▷\n□\n                  is unsatisfiable\n\n\n▷\nCNF transformations\n                  preserve satisfiability(see above)\n\n\n▷\n                  Resolution and factorization too!\n\n\n\n:\nComputational Logic22024-12-16\n",
        "sectionId": "8d71aa",
        "archive": "courses/Jacobs/CompLog",
        "filepath": "atp1/slides/resolution-correct.en.xhtml"
    },
    {
        "slideContent": "\nCompleteness (ℛ1)\n\n▷\nℛ1\n                  is\nrefutation complete.\n\n\n▷Proof:\n∇:={Φ|\nΦ𝖳 has no closed tableau\n}\n                  is an abstract consistency class\n\n\n\n1.as for propositional case.\n\n\n\n\n2.by the lifting lemma below\n\n\n\n3.Let\n𝒯\n                    be a closed tableau for\n¬(∀𝑋.𝐀)∊Φ\n                    and\nΦ𝖳*([𝑐/𝑋](𝐀))𝖥∊∇.\n\n\n\n\n4.𝐶𝑁𝐹1(Φ𝖳)=𝐶𝑁𝐹1(Ψ𝖳)∪𝐶𝑁𝐹1(([𝑓(𝑋1,...,𝑋𝑘)/𝑋](𝐀))𝖥)\n\n\n\n\n5.([𝑓(𝑋1,...,𝑋𝑘)/𝑐](𝐶𝑁𝐹1(Φ𝖳)))*([𝑐/𝑋](𝐀))𝖥=𝐶𝑁𝐹1(Φ𝖳)\n\n\n\n\n6.so\nℛ1:𝐶𝑁𝐹1(Φ𝖳)⊢𝒟'□, where\n𝒟=[𝑓(𝑋1',...,𝑋𝑘')/𝑐](𝒟).\n\n\n\n:\nComputational Logic12024-12-15\n",
        "sectionId": "8d71aa",
        "archive": "courses/Jacobs/CompLog",
        "filepath": "atp1/slides/resolution-complete.en.xhtml"
    },
    {
        "slideContent": "\nClause Set Isomorphism\n\n▷\n                  Let\n𝐁\n                  and\n𝐂\n                  be\nclauses, then a\nclause isomorphism\n𝜔:𝐂→𝐃\n                  is a\nbijection\n                  of the\nliterals\n                  of\n𝐂\n                  and\n𝐃, such that\n𝜔(𝐋)𝛼=𝐌𝛼(conserves labels)\n                  We call\n𝜔\n𝜃\n                      compatible, iff\n𝜔(𝐋𝛼)=(𝜃(𝐋))𝛼\n\n\n▷\n                  Let\nΦ\n                  and\nΨ\n                  be\nclause sets, then we call a\nbijection\nΩ:Φ→Ψ\n                  a\nclause set isomorphism, iff there is a\nclause isomorphism\n𝜔:𝐂→Ω(𝐂)\n                  for each\n𝐂∊Φ.\n\n\n▷\n                  If\n𝜃(Φ)\n                  is set of formulae, then there is a\n𝜃-compatible\nclause set isomorphism\nΩ:𝐶𝑁𝐹1(Φ)→𝐶𝑁𝐹1(𝜃(Φ)).\n\n\n▷Proof sketch:\n                by induction on the\nCNF\n                derivation of\n𝐶𝑁𝐹1(Φ).\n\n\n\n:\nComputational Logic22024-12-15\n",
        "sectionId": "8d71aa",
        "archive": "courses/Jacobs/CompLog",
        "filepath": "atp1/slides/resolution-complete.en.xhtml"
    },
    {
        "slideContent": "\nLifting for\nℛ1\n\n▷\n                  If\nℛ1:(𝜃(Φ))⊢𝒟𝜃□\n                  for a set\n𝜃(Φ)\n                  of formulae, then there is a\nℛ1-refutation\n                  for\nΦ.\n\n\n▷Proof:\nby induction over\n𝒟𝜃\n                  we construct a\nℛ1-derivation\nℛ1:Φ⊢𝒟𝐂\n                  and a\n𝜃-compatible\nclause set isomorphism\nΩ:𝒟→𝒟𝜃\n\n\n\n1.If\n𝒟𝜃\n                    ends in𝒟𝜃'\n\n\n((𝜃(𝐀))∨(𝜃(𝐂)))𝖳\n𝒟𝜃''\n\n\n(𝜃(𝐁))𝖥∨(𝜃(𝐃))\n\n𝑟𝑒𝑠\n\n(𝜎(𝜃(𝐂)))∨(𝜎(𝜃(𝐁)))\nthen we have (IH)\nclause isormorphisms\n𝜔':𝐀𝖳∨𝐂→(𝜃(𝐀))𝖳∨(𝜃(𝐂))\n                    and\n𝜔':𝐁𝖳∨𝐃→(𝜃(𝐁))𝖳,𝜃(𝐃)\n\n\n\n\n2.thus𝐀𝖳∨𝐂𝐁𝖥∨𝐃(𝜌(𝐂))∨(𝜌(𝐁))𝑅𝑒𝑠where\n𝜌=𝐦𝐠𝐮(𝐀,𝐁)(exists, as\n𝜎◦𝜃\n                        unifier)\n\n\n\n:\nComputational Logic32024-12-15\n",
        "sectionId": "8d71aa",
        "archive": "courses/Jacobs/CompLog",
        "filepath": "atp1/slides/resolution-complete.en.xhtml"
    },
    {
        "slideContent": "\nWhat is knowledge? Why Representation?\n\n▷Lots/all of (academic) disciplines deal with knowledge!\n\n\n▷According to Probst/Raub/Romhardt [PRR97]\n\n\n\n\nFor the purposes of this course\nKnowledge\n                  is the\ninformation\n                  necessary to support\nintelligent reasoning!\n\n▷representation can be used to determineset of words whether a word is admissiblelist of words the rank of a worda lexicon translation and/or grammatical functionstructure function \n\n\n\n:\nComputational Logic12024-12-15\n",
        "sectionId": "5fa37aca",
        "archive": "courses/Jacobs/CompLog",
        "filepath": "kr/slides/probst-raub-romhardt.en.xhtml"
    },
    {
        "slideContent": "\nKnowledge Representation vs. Data Structures\n\n▷Idea\n                  Representation as structure\nand\n                  function.\n\n\n▷the\nrepresentation\n                  determines the content theory(what is the data?)\n\n\n▷the\nfunction\n                  determines the process model(what do we do with the data?)\n\n\n▷Question\n                  Why do we use the term “knowledge representation” rather than\n\n\n▷data structures?(sets, lists, ... above)\n\n\n▷information representation?(it is information)\n\n\n▷Answer\nNo good reason other than\nAI\n                  practice, with the intuition that\n\n\n▷data\n                  is simple and general(supports many\nalgorithms)\n\n\n▷knowledge\n                  is complex(has distinguished process model)\n\n\n\n:\nComputational Logic12024-12-15\n",
        "sectionId": "5fa37aca",
        "archive": "courses/Jacobs/CompLog",
        "filepath": "kr/slides/kr-vs-ds.en.xhtml"
    },
    {
        "slideContent": "\nSome Paradigms for Knowledge Representation in\nAI/NLP\n\n▷GOFAI(good old-fashioned AI)\n\n\n▷symbolic knowledge representation, process model based on\nheuristic search\n\n\n▷Statistical, corpus-based approaches.\n\n\n▷symbolic representation, process model based on\nmachine learning\n\n\n▷knowledge is divided into symbolic- and statistical (search) knowledge\n\n\n▷The connectionist approach\n\n\n▷sub-symbolic representation, process model based on primitive processing elements (nodes) and weighted links\n\n\n▷knowledge is only present in activation patters, etc.\n\n\n\n:\nComputational Logic12024-12-14\n",
        "sectionId": "5fa37aca",
        "archive": "courses/Jacobs/CompLog",
        "filepath": "kr/slides/kr-approaches.en.xhtml"
    },
    {
        "slideContent": "\nKR Approaches/Evaluation Criteria\n\n▷\n                  The\nevaluation criteria\n                  for knowledge representation approaches are:\n\n\n▷Expressive adequacy: What can be represented, what distinctions are supported.\n\n\n▷Reasoning efficiency: Can the representation support processing that generates results in acceptable speed?\n\n\n▷Primitives: What are the primitive elements of representation, are they intuitive, cognitively adequate?\n\n\n▷Meta representation: Knowledge about knowledge\n\n\n▷Completeness: The problems of reasoning with knowledge that is known to be incomplete.\n\n\n\n:\nComputational Logic12024-12-15\n",
        "sectionId": "5fa37aca",
        "archive": "courses/Jacobs/CompLog",
        "filepath": "kr/slides/kr-evaluation.en.xhtml"
    },
    {
        "slideContent": "\nSemantic Networks [CQ69]\n\n▷\n                  A\nsemantic network\n                  is a\ndirected graph\n                  for representing knowledge:\n\n\n▷nodes\n                  represent\nobjects\n                  and\nconcepts\n                  (classes of\nobjects)(e.g. John (object) and bird (concept))\n\n\n▷edges\n                  (called\nlinks) represent relations between these(isa, father_of, belongs_to)\n\n\n▷\n                  A\nsemantic network\n                  for birds and persons:\n\n\n\n\n\n\n\nwings  \n\nMary  \n\nJohn  \n\nrobin  \n\nbird  \n\nJack  \n\nPerson  \n\n\n\n\n\n\n\n\n\n\nhas_part  \n\n\n\n\n\n\n\n\n\n\nloves  \n\n\n\n\n\n\n\n\n\n\nowner_of  \n\n\n\n\n\n\n\n\n\n\ninst  \n\n\n\n\n\n\n\n\n\n\nisa  \n\n\n\n\n\n\n\n\n\n\ninst  \n\n\n\n\n\n\n\n\n\n\ninst  \n\n\n\n \n\n▷Problem\n                  How do we derive new information from such a network?\n\n\n▷Idea\n                  Encode taxonomic information about\nobjects\n                  and\nconcepts\n                  in special\nlinks\n                  (“isa” and “inst”) and specify property inheritance along them in the process model.\n\n\n\n:\nComputational Logic12024-12-14\n",
        "sectionId": "b44575c4",
        "archive": "courses/Jacobs/CompLog",
        "filepath": "kr/slides/semnet-nutshell.en.xhtml"
    },
    {
        "slideContent": "\nDeriving Knowledge Implicit in Semantic Networks\n\n▷\n                  There is more knowledge in a\nsemantic network\n                  than is explicitly written down.\n\n\n▷\n                  In the network below, we “know” that\nrobins have wings\n                  and in particular,\nJack has wings.\n\n\n\n\n\n\n\nwings  \n\nMary  \n\nJohn  \n\nrobin  \n\nbird  \n\nJack  \n\nPerson  \n\n\n\n\n\n\n\n\n\n\nhas_part  \n\n\n\n\n\n\n\n\n\n\nloves  \n\n\n\n\n\n\n\n\n\n\nowner_of  \n\n\n\n\n\n\n\n\n\n\ninst  \n\n\n\n\n\n\n\n\n\n\nisa  \n\n\n\n\n\n\n\n\n\n\ninst  \n\n\n\n\n\n\n\n\n\n\ninst  \n\n\n\n \n\n▷Idea\nLinks\n                  labeled with “isa” and “inst” are special: they propagate properties encoded by other\nlinks.\n\n\n▷\n                  We call\nlinks\n                  labeled by\n\n\n▷“isa” an\ninclusion\n                  or\nisa link(inclusion of\nconcepts)\n\n\n▷“inst”\ninstance\n                  or\ninst link\n(concept membership)\n\n\n\n:\nComputational Logic12024-12-14\n",
        "sectionId": "b44575c4",
        "archive": "courses/Jacobs/CompLog",
        "filepath": "kr/slides/semnet-inference.en.xhtml"
    },
    {
        "slideContent": "\nDeriving Knowledge Semantic Networks\n\n▷Inference in Semantic Networks\n                  We call all\nlink\n                  labels except “inst” and “isa” in a\nsemantic network\nrelations.\n\nLet\n𝑁\n                  be a\nsemantic network\n                  and\n𝑅\n                  a\nrelation\n                  in\n𝑁\n                  such that\n𝐴\n−\n→isa𝐵\n−\n→𝑅𝐶\n                  or\n𝐴\n−\n→inst𝐵\n−\n→𝑅𝐶, then we can\nderive\n                  a\nrelation\n𝐴\n−\n→𝑅𝐶\n                  in\n𝑁.\n\nThe process of\nderiving\n                  new\nconcepts\n                  and\nrelations\n                  from existing ones is called\ninference\n                  and\nconcepts/relations\n                  that are only available via\ninference\nimplicit\n                  (in a\nsemantic network).\n\n\n▷Intuition\nDerived\nrelations\n                  represent knowledge that is implicit in the network; they could be added, but usually are not to avoid clutter.\n\n\n▷\nDerived\nrelations\n                  in\n??\n\n\n\n\n\n\n\nwings  \n\nMary  \n\nJohn  \n\nrobin  \n\nbird  \n\nJack  \n\nPerson  \n\n\n\n\n\n\n\n\n\n\nhas_part  \n\n\n\n\n\n\n\n\n\n\nloves  \n\n\n\n\n\n\n\n\n\n\nowner_of  \n\n\n\n\n\n\n\n\n\n\ninst  \n\n\n\n\n\n\n\n\n\n\nisa  \n\n\n\n\n\n\n\n\n\n\ninst  \n\n\n\n\n\n\n\n\n\n\ninst  \n\n\n\n\n\n\n\n\n\n\n\nhas_part   \n\n\n\n\n\n\n\n\n\n\n\n\nhas_part   \n\n\n\n\n\n\n\n\n\n\n\n\nisa   \n/   \n\n\n\n\n \n\n▷Slogan\n                  Get out more knowledge from a\nsemantic networks\n                  than you put in.\n\n\n\n:\nComputational Logic22024-12-14\n",
        "sectionId": "b44575c4",
        "archive": "courses/Jacobs/CompLog",
        "filepath": "kr/slides/semnet-inference.en.xhtml"
    },
    {
        "slideContent": "\nTerminologies and Assertions\n\n▷\n                  We should distinguish\nconcepts\n                  from\nobjects.\n\n\n▷\n                  We call the\nsubgraph\n                  of a\nsemantic network\n𝑁\n                  spanned by the\nisa links\n                  and\nrelations\n                  between\nconcepts\n                  the\nterminology\n                  (or\nTBox, or the famous\nIsa Hierarchy) and the\nsubgraph\n                  spanned by the\ninst links\n                  and\nrelations\n                  between objects, the\nassertions\n                  (together the\nABox) of\n𝑁.\n\n\n▷\n                  In this\nsemantic network\n                  we keep\nobjects\nconcept\n                  apart notationally:\n\n\n  \n\n\n\n\n\nABox   \n\nClyde  \nRex  \nRoy  \n\n\n\n\n\nTBox   \n\n\nelephant  \n\ngray  \n\ntiger  \n\nstriped  \n\nhigher animal  \n\nhead  \n\nlegs  \n\namoeba  \n\nmove  \n\nanimal  \n\n\n\n\n\n\n\n\n\n\n\n\ninst   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\ninst   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\ninst   \n\n\n\n\n\n\n\n\n\n\n\n\ncolor  \n\n\n\n\n\n\n\n\n\n\n\nisa   \n\n\n\n\n\n\n\n\n\n\n\n\nisa   \n\n\n\n\n\n\n\n\n\n\n\npattern  \n\n\n\n\n\n\n\n\n\n\nhas_part  \n\n\n\n\n\n\n\n\n\n\nhas_part  \n\n\n\n\n\n\n\n\n\n\n\nisa   \n\n\n\n\n\n\n\n\n\n\n\n\nisa   \n\n\n\n\n\n\n\n\n\n\n\ncan  \n\n\n\n\n\n\n\n\n\n\neat  \n\n\n\n\n\n\n\n\n\n\n\n\neat   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\neat   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncolor   \n\n\n\n\n\n \n\nIn particular we have\nobjects\n                  “Rex”, “Roy”, and “Clyde”, which have (derived)\nrelations\n                  (e.g.\nClyde\n                  is\ngray).\n\n\n\n:\nComputational Logic12024-12-14\n",
        "sectionId": "b44575c4",
        "archive": "courses/Jacobs/CompLog",
        "filepath": "kr/slides/terminology-assertions.en.xhtml"
    },
    {
        "slideContent": "\nLimitations of Semantic Networks\n\n▷What is the\nmeaning\n              of a\nlink?\n\n\n▷link\n              labels are very suggestive(misleading for humans)\n\n\n▷meaning\n              of\nlink\n              types defined in the process model(no denotational semantics)\n\n\nProblem\n                  No distinction of optional and defining traits!\n\n\n▷\n\n▷\n                  Consider a robin that has lost its wings in an accident:\n\n\n\n\n\n\nwings  \nrobin  \nbird  \njack  \n\n\n\n\n\n\n\n\n\n\nhas_part  \n\n\n\n\n\n\n\n\n\n\nisa  \n\n\n\n\n\n\n\n\n\n\ninst  \n\n\n\n \n\n\n\nwings  \nrobin  \njoe  \nbird  \n\n\n\n\n\n\n\n\n\n\nhas_part  \n\n\n\n\n\n\n\n\n\n\ninst  \n\n\n\n\n\n\n\n\n\n\nisa  \n\n\n\n\n\n\n\n\n\n\n\ncancel   \n\n\n\n\n \n\n“Cancel-links” have been proposed, but their status and process model are debatable.\n\n\n\n:\nComputational Logic12024-12-15\n",
        "sectionId": "b44575c4",
        "archive": "courses/Jacobs/CompLog",
        "filepath": "kr/slides/semnet-limitations.en.xhtml"
    },
    {
        "slideContent": "\nAnother Notation for Semantic Networks\n\n▷\nFunction/argument notation\n                  for\nsemantic networks\n\n\n▷interprets\nnodes\n                  as arguments(reification to individuals)\n\n\n▷interprets\nlinks\n                  as functions(predicates actually)\n\n\n▷\n\n\n\n\n\n\n\nwings  \n\nMary  \n\nJohn  \n\nrobin  \n\nbird  \n\nJack  \n\nPerson  \n\n\n\n\n\n\n\n\n\n\nhas_part  \n\n\n\n\n\n\n\n\n\n\nloves  \n\n\n\n\n\n\n\n\n\n\nowner_of  \n\n\n\n\n\n\n\n\n\n\ninst  \n\n\n\n\n\n\n\n\n\n\nisa  \n\n\n\n\n\n\n\n\n\n\ninst  \n\n\n\n\n\n\n\n\n\n\ninst  \n\n\n\n \n\n\nisa(robin,bird)haspart(bird,wings)inst(Jack,robin)owner_of(John, robin)loves(John,Mary) \n\n\n\n\n \n\n▷Evaluation\n\n+linear notation(equivalent, but better to\nimplement\n                      on a\ncomputer)\n\n\n+easy to give process model by deduction(e.g. in\nProlog)\n\n\n—worse locality properties(networks are associative)\n\n\n\n:\nComputational Logic12024-12-15\n",
        "sectionId": "b44575c4",
        "archive": "courses/Jacobs/CompLog",
        "filepath": "kr/slides/semnet-funcarg-notation.en.xhtml"
    },
    {
        "slideContent": "\nA Denotational Semantics for Semantic Networks\n\n▷Observation\n                  If we handle\nisa\n                  and\ninst links\n                  specially in\nfunction/argument notation\n\n\n\n\n\n\n\n\nwings  \n\nMary  \n\nJohn  \n\nrobin  \n\nbird  \n\nJack  \n\nPerson  \n\n\n\n\n\n\n\n\n\n\nhas_part  \n\n\n\n\n\n\n\n\n\n\nloves  \n\n\n\n\n\n\n\n\n\n\nowner_of  \n\n\n\n\n\n\n\n\n\n\ninst  \n\n\n\n\n\n\n\n\n\n\nisa  \n\n\n\n\n\n\n\n\n\n\ninst  \n\n\n\n\n\n\n\n\n\n\ninst  \n\n\n\n \n\n\nrobin⊆birdhaspart(bird,wings)Jack∊robinowner_of(John, Jack)loves(John,Mary) \n\n\n\n\n\n                  it looks like\nfirst-order logic, if we take\n\n\n▷𝑎∊𝑆\n                  to mean\n𝑆(𝑎)\n                  for an\nobject\n𝑎\n                  and a\nconcept\n𝑆.\n\n\n▷𝐴⊆𝐵\n                  to mean\n∀𝑋.𝐴(𝑋)⇒𝐵(𝑋)\n                  and\nconcepts\n𝐴\n                  and\n𝐵\n\n\n▷𝑅(𝐴,𝐵)\n                  to mean\n∀𝑋.𝐴(𝑋)⇒(∃𝑌.𝐵(𝑌)∧𝑅(𝑋,𝑌))\n                  for a\nrelation\n𝑅.\n\n\n▷Idea\n                  Take first-order deduction as process model(gives inheritance for free)\n\n\n\n:\nComputational Logic12024-12-15\n",
        "sectionId": "b44575c4",
        "archive": "courses/Jacobs/CompLog",
        "filepath": "kr/slides/semnet-semantics.en.xhtml"
    },
    {
        "slideContent": "\nWhat is the Information a User sees?\n\n▷\n                  Take the following web-site with a conference announcement\n\n\nWWW2002The eleventh International World Wide Web ConferenceSheraton Waikiki HotelHonolulu, Hawaii, USA7-11 May 2002\nRegistered participants coming fromAustralia, Canada, Chile Denmark, France, Germany, Ghana, Hong Kong, India,Ireland, Italy, Japan, Malta, New Zealand, The Netherlands, Norway,Singapore, Switzerland, the United Kingdom, the United States, Vietnam, Zaire\n\n\nOn the 7th May Honolulu will provide the backdrop of the eleventhInternational World Wide Web Conference.\n\n\n\nSpeakers confirmedTim Berners-Lee: Tim is the well known inventor of the Web,\nIan Foster: Ian is the pioneer of the Grid, the next generation internet.\n\n\n\n:\nComputational Logic12024-12-14\n",
        "sectionId": "73d7425",
        "archive": "courses/Jacobs/CompLog",
        "filepath": "semweb/slides/machine-understandable-web-ex.en.xhtml"
    },
    {
        "slideContent": "\nWhat the machine sees\n\n▷\n                  Here is what the machine “sees” from the conference announcement:\n\n\nWWW∊''∊T〈⌉ ⌉↕⌉⊑⌉\\⊔〈 I\\⊔⌉∇\\⊣⊔〉≀\\⊣↕ W≀∇↕⌈ W〉⌈⌉ W⌉⌊ C≀\\{⌉∇⌉\\⌋⌉S〈⌉∇⊣⊔≀\\ W⊣〉∥〉∥〉 H≀⊔⌉↕H≀\\≀↕⊓↕⊓⇔ H⊣⊒⊣〉〉⇔ USA/↖∞∞ M⊣† ∊''∊\nR⌉}〉∫⊔⌉∇⌉⌈ √⊣∇⊔〉⌋〉√⊣\\⊔∫ ⌋≀⇕〉\\} {∇≀⇕A⊓∫⊔∇⊣↕〉⊣⇔ C⊣\\⊣⌈⊣⇔ C〈〉↕⌉ D⌉\\⇕⊣∇∥⇔ F∇⊣\\⌋⌉⇔ G⌉∇⇕⊣\\†⇔ G〈⊣\\⊣⇔ H≀\\} K≀\\}⇔ I\\⌈〉⊣⇔I∇⌉↕⊣\\⌈⇔ I⊔⊣↕†⇔ J⊣√⊣\\⇔ M⊣↕⊔⊣⇔ N⌉⊒ Z⌉⊣↕⊣\\⌈⇔ T〈⌉ N⌉⊔〈⌉∇↕⊣\\⌈∫⇔ N≀∇⊒⊣†⇔S〉\\}⊣√≀∇⌉⇔ S⊒〉⊔‡⌉∇↕⊣\\⌈⇔ ⊔〈⌉ U\\〉⊔⌉⌈ K〉\\}⌈≀⇕⇔ ⊔〈⌉ U\\〉⊔⌉⌈ S⊔⊣⊔⌉∫⇔ V〉⌉⊔\\⊣⇕⇔ Z⊣〉∇⌉\n\n\nO\\ ⊔〈⌉ /⊔〈 M⊣† H≀\\≀↕⊓↕⊓ ⊒〉↕↕ √∇≀⊑〉⌈⌉ ⊔〈⌉ ⌊⊣⌋∥⌈∇≀√ ≀{ ⊔〈⌉ ⌉↕⌉⊑⌉\\⊔〈I\\⊔⌉∇\\⊣⊔〉≀\\⊣↕ W≀∇↕⌈ W〉⌈⌉ W⌉⌊ C≀\\{⌉∇⌉\\⌋⌉↙\n\n\n\nS√⌉⊣∥⌉∇∫ ⌋≀\\{〉∇⇕⌉⌈T〉⇕ B⌉∇\\⌉∇∫↖L⌉⌉¬ T〉⇕ 〉∫ ⊔〈⌉ ⊒⌉↕↕ ∥\\≀⊒\\ 〉\\⊑⌉\\⊔≀∇ ≀{ ⊔〈⌉ W⌉⌊⇔\nI⊣\\ F≀∫⊔⌉∇¬ I⊣\\ 〉∫ ⊔〈⌉ √〉≀\\⌉⌉∇ ≀{ ⊔〈⌉ G∇〉⌈⇔ ⊔〈⌉ \\⌉§⊔ }⌉\\⌉∇⊣⊔〉≀\\ 〉\\⊔⌉∇\\⌉⊔↙\n\n\n\n:\nComputational Logic22024-12-14\n",
        "sectionId": "73d7425",
        "archive": "courses/Jacobs/CompLog",
        "filepath": "semweb/slides/machine-understandable-web-ex.en.xhtml"
    },
    {
        "slideContent": "\nSolution:\nXML\nmarkup\n              with “meaningful” Tags\n\n▷\n                  Let’s annotate (parts of) the\nmeaning\n                  via\nXML\nmarkup\n\n\n<title>WWW∊''∊T〈⌉ ⌉↕⌉⊑⌉\\⊔〈 I\\⊔⌉∇\\⊣⊔〉≀\\⊣↕ W≀∇↕⌈ W〉⌈⌉ W⌉⌊ C≀\\{⌉∇⌉\\⌋⌉</title><place>\n                    S〈⌉∇⊣⊔≀\\ W⊣〉∥〉∥〉 H≀⊔⌉↕ H≀\\≀↕⊓↕⊓⇔ H⊣⊒⊣〉〉⇔ USA</place><date>\n                    /↖∞∞ M⊣† ∊''∊</date><participants>\n                    R⌉}〉∫⊔⌉∇⌉⌈ √⊣∇⊔〉⌋〉√⊣\\⊔∫ ⌋≀⇕〉\\} {∇≀⇕A⊓∫⊔∇⊣↕〉⊣⇔ C⊣\\⊣⌈⊣⇔ C〈〉↕⌉ D⌉\\⇕⊣∇∥⇔ F∇⊣\\⌋⌉⇔ G⌉∇⇕⊣\\†⇔ G〈⊣\\⊣⇔ H≀\\} K≀\\}⇔ I\\⌈〉⊣⇔I∇⌉↕⊣\\⌈⇔ I⊔⊣↕†⇔ J⊣√⊣\\⇔ M⊣↕⊔⊣⇔ N⌉⊒ Z⌉⊣↕⊣\\⌈⇔ T〈⌉ N⌉⊔〈⌉∇↕⊣\\⌈∫⇔ N≀∇⊒⊣†⇔S〉\\}⊣√≀∇⌉⇔ S⊒〉⊔‡⌉∇↕⊣\\⌈⇔ ⊔〈⌉ U\\〉⊔⌉⌈ K〉\\}⌈≀⇕⇔ ⊔〈⌉ U\\〉⊔⌉⌈ S⊔⊣⊔⌉∫⇔ V〉⌉⊔\\⊣⇕⇔ Z⊣〉∇⌉</participants><introduction>\n                    O\\ ⊔〈⌉ /⊔〈 M⊣† H≀\\≀↕⊓↕⊓ ⊒〉↕↕ √∇≀⊑〉⌈⌉ ⊔〈⌉ ⌊⊣⌋∥⌈∇≀√ ≀{ ⊔〈⌉ ⌉↕⌉⊑⌉\\⊔〈 I\\⊔⌉∇\\⊣⊔〉≀\\⊣↕ W≀∇↕⌈ W〉⌈⌉ W⌉⌊ C≀\\{⌉∇⌉\\⌋⌉↙</introduction><program>S√⌉⊣∥⌉∇∫ ⌋≀\\{〉∇⇕⌉⌈<speaker>T〉⇕ B⌉∇\\⌉∇∫↖L⌉⌉¬ T〉⇕ 〉∫ ⊔〈⌉ ⊒⌉↕↕ ∥\\≀⊒\\ 〉\\⊑⌉\\⊔≀∇ ≀{ ⊔〈⌉ W⌉⌊</speaker><speaker>I⊣\\ F≀∫⊔⌉∇¬ I⊣\\ 〉∫ ⊔〈⌉ √〉≀\\⌉⌉∇ ≀{ ⊔〈⌉ G∇〉⌈⇔ ⊔〈⌉ \\⌉§⊔ }⌉\\⌉∇⊣⊔〉≀\\ 〉\\⊔⌉∇\\⌉⊔<speaker></program>\n\n\n\n:\nComputational Logic32024-12-14\n",
        "sectionId": "73d7425",
        "archive": "courses/Jacobs/CompLog",
        "filepath": "semweb/slides/machine-understandable-web-ex.en.xhtml"
    },
    {
        "slideContent": "\nWhat can we do with this?\n\n▷\n                  Consider the following fragments:\n\n\n???⊔〉⊔↕⌉⊤WWW∊''∊T〈⌉ ⌉↕⌉⊑⌉\\⊔〈 I\\⊔⌉∇\\⊣⊔〉≀\\⊣↕ W≀∇↕⌈ W〉⌈⌉ W⌉⌊ C≀\\{⌉∇⌉\\⌋⌉???∝⊔〉⊔↕⌉⊤???√↕⊣⌋⌉⊤\n                    S〈⌉∇⊣⊔≀\\ W⊣〉∥〉∥〉 H≀⊔⌉↕ H≀\\≀↕⊓↕⊓⇔ H⊣⊒⊣〉〉⇔ USA???∝√↕⊣⌋⌉⊤???⌈⊣⊔⌉⊤\n                    /↖∞∞ M⊣† ∊''∊???∝⌈⊣⊔⌉⊤\n\n\nGiven the\nmarkup\n                  above, a machine agent can\n\n\n▷parse\n/ ∞∞ M⊣† ∊''∊\n                  as the date May 7 11 2002 and add this to the user’s calendar,\n\n\n▷parse\nS〈⌉∇⊣⊔≀\\ W⊣〉∥〉∥〉 H≀⊔⌉↕ H≀\\≀↕⊓↕⊓⇔ H⊣⊒⊣〉〉⇔ USA\n                  as a destination and find flights.\n\n\n▷But\n                  do not be deceived by your ability to understand English!\n\n\n\n:\nComputational Logic42024-12-14\n",
        "sectionId": "73d7425",
        "archive": "courses/Jacobs/CompLog",
        "filepath": "semweb/slides/machine-understandable-web-ex.en.xhtml"
    },
    {
        "slideContent": "\nWhat the machine sees of the\nXML\n\n▷\n                  Here is what the machine sees of the\nXML\n\n\n<title>WWW∊''∊T〈⌉ ⌉↕⌉⊑⌉\\⊔〈 I\\⊔⌉∇\\⊣⊔〉≀\\⊣↕ W≀∇↕⌈ W〉⌈⌉ W⌉⌊ C≀\\{⌉∇⌉\\⌋⌉</⊔〉⊔↕⌉><√↕⊣⌋⌉>\nS〈⌉∇⊣⊔≀\\ W⊣〉∥〉∥〉 H≀⊔⌉↕ H≀\\≀↕⊓↕⊓⇔ H⊣⊒⊣〉〉⇔ USA</√↕⊣⌋⌉><⌈⊣⊔⌉>\n/↖∞∞ M⊣† ∊''∊</⌈⊣⊔⌉><√⊣∇⊔〉⌋〉√⊣\\⊔∫>\nR⌉}〉∫⊔⌉∇⌉⌈ √⊣∇⊔〉⌋〉√⊣\\⊔∫ ⌋≀⇕〉\\} {∇≀⇕A⊓∫⊔∇⊣↕〉⊣⇔ C⊣\\⊣⌈⊣⇔ C〈〉↕⌉ D⌉\\⇕⊣∇∥⇔ F∇⊣\\⌋⌉⇔ G⌉∇⇕⊣\\†⇔ G〈⊣\\⊣⇔ H≀\\} K≀\\}⇔ I\\⌈〉⊣⇔I∇⌉↕⊣\\⌈⇔ I⊔⊣↕†⇔ J⊣√⊣\\⇔ M⊣↕⊔⊣⇔ N⌉⊒ Z⌉⊣↕⊣\\⌈⇔ T〈⌉ N⌉⊔〈⌉∇↕⊣\\⌈∫⇔ N≀∇⊒⊣†⇔S〉\\}⊣√≀∇⌉⇔ S⊒〉⊔‡⌉∇↕⊣\\⌈⇔ ⊔〈⌉ U\\〉⊔⌉⌈ K〉\\}⌈≀⇕⇔ ⊔〈⌉ U\\〉⊔⌉⌈ S⊔⊣⊔⌉∫⇔ V〉⌉⊔\\⊣⇕⇔ Z⊣〉∇⌉</√⊣∇⊔〉⌋〉√⊣\\⊔∫><〉\\⊔∇≀⌈⊓⌋⊔〉≀\\>\nO\\ ⊔〈⌉ /⊔〈 M⊣† H≀\\≀↕⊓↕⊓ ⊒〉↕↕ √∇≀⊑〉⌈⌉ ⊔〈⌉ ⌊⊣⌋∥⌈∇≀√ ≀{ ⊔〈⌉ ⌉↕⌉⊑⌉\\⊔〈 I\\⊔⌉∇\\⊣⊔〉≀\\⊣↕ W≀∇↕⌈ W〉⌈⌉ W⌉⌊ C≀\\{⌉∇⌉\\⌋⌉↙</〉\\⊔∇≀⌈⊓⌋⊔〉≀\\><√∇≀}∇⊣⇕>S√⌉⊣∥⌉∇∫ ⌋≀\\{〉∇⇕⌉⌈<∫√⌉⊣∥⌉∇>T〉⇕ B⌉∇\\⌉∇∫↖L⌉⌉¬ T〉⇕ 〉∫ ⊔〈⌉ ⊒⌉↕↕ ∥\\≀⊒\\ 〉\\⊑⌉\\⊔≀∇ ≀{ ⊔〈⌉ W⌉⌊</∫√⌉⊣∥⌉∇><∫√⌉⊣∥⌉∇>I⊣\\ F≀∫⊔⌉∇¬ I⊣\\ 〉∫ ⊔〈⌉ √〉≀\\⌉⌉∇ ≀{ ⊔〈⌉ G∇〉⌈⇔ ⊔〈⌉ \\⌉§⊔ }⌉\\⌉∇⊣⊔〉≀\\ 〉\\⊔⌉∇\\⌉⊔<∫√⌉⊣∥⌉∇></√∇≀}∇⊣⇕>\n\n\n\n:\nComputational Logic52024-12-14\n",
        "sectionId": "73d7425",
        "archive": "courses/Jacobs/CompLog",
        "filepath": "semweb/slides/machine-understandable-web-ex.en.xhtml"
    },
    {
        "slideContent": "\nThe Current Web\n\n\n\n▷Resources\n                                  identified by\nURIs, untyped\n\n\n▷Links\nhref,\nsrc, ...limited, non-descriptive\n\n\n▷User\n                                  Exciting world - semantics of the resource, however, gleaned from content\n\n\n▷Machine\n                                  Very little information available - significance of the links only evident from the context around the anchor.\n\n\n\n\n\n\n\n\n \n\n\n:\nComputational Logic12024-12-15\n",
        "sectionId": "73d7425",
        "archive": "courses/Jacobs/CompLog",
        "filepath": "semweb/slides/current-web-graph.en.xhtml"
    },
    {
        "slideContent": "\nThe Semantic Web\n\n\n\n▷Resources\n                                  Globally identified by\nURIs\n                                  or Locally scoped (Blank), Extensible, Relational.\n\n\n▷Links\n                                  Identified by\nURIs, Extensible, Relational.\n\n\n▷User\n                                  Even more exciting world, richer user experience.\n\n\n▷Machine\n                                  More processable information is available (Data Web).\n\n\n▷Computers and people\n                                  Work, learn and exchange knowledge\neffectively.\n\n\n\n\n\n\n\n\n \n\n\n:\nComputational Logic12024-12-15\n",
        "sectionId": "73d7425",
        "archive": "courses/Jacobs/CompLog",
        "filepath": "semweb/slides/semantic-web-graph.en.xhtml"
    },
    {
        "slideContent": "\nTowards a “Machine-Actionable Web”\n\n▷Recall\n                  We need external agreement on\nmeaning\n                  of annotation tags.\n\n\n▷Idea\n                  standardize them in a community process(e.g. DIN or ISO)\n\n\n▷Problem\n                  Inflexible, Limited number of things can be expressed\n\n\n▷Better\n                  Use\nontologies\n                  to specify\nmeaning\n                  of annotations\n\n\n▷Ontologies provide a vocabulary of terms\n\n\n▷New terms can be formed by combining existing ones\n\n\n▷Meaning\n                  (semantics) of such terms is formally specified\n\n\n▷Can also specify relationships between terms in multiple ontologies\n\n\n▷Inference with annotations and ontologies(get out more than you put in!)\n\n\n▷Standardize annotations in\nRDF\n                  [KC04] or\nRDFa\n                  [Her+13] and ontologies on\nOWL\n                  [OWL09]\n\n\n▷Harvest\nRDF\n                  and\nRDFa\n                  in to a\ntriplestore\n                  or\nOWL\n                  reasoner.\n\n\n▷Query\n                  that for implied knowledge(e.g. chaining multiple facts from Wikipedia)\n\n\nSPARQL:Who was US President when Barack Obama was Born?\n\n\nDBPedia:John F. Kennedy(was president in August 1961)\n\n\n\n:\nComputational Logic12024-12-14\n",
        "sectionId": "73d7425",
        "archive": "courses/Jacobs/CompLog",
        "filepath": "semweb/slides/machine-understandable-web.en.xhtml"
    },
    {
        "slideContent": "\nFrame Notation as Logic with Locality\n\n▷Predicate Logic:(where is the locality?)\n𝑐𝑎𝑡𝑐ℎ\n_\n22∊𝑐𝑎𝑡𝑐ℎ\n_\n𝑜𝑏𝑗𝑒𝑐𝑡 There is an instance of catching𝑐𝑎𝑡𝑐ℎ𝑒𝑟(𝑐𝑎𝑡𝑐ℎ\n_\n22,𝑗𝑎𝑐𝑘\n_\n2) Jack did the catching𝑐𝑎𝑢𝑔ℎ𝑡(𝑐𝑎𝑡𝑐ℎ\n_\n22,𝑏𝑎𝑙𝑙\n_\n5) He caught a certain ball \n\n\n▷\nFrames(group everything around the object)\n\n\n(catch_object catch_22\n(catcher jack_2)\n(caught ball_5))\n\n+Once you have decided on a\nframe, all the information is local\n\n\n+easy to define schemes for concept(aka. types in feature structures)\n\n\n—how to determine\nframe, when to choose\nframe(log/chair)\n\n\n\n:\nComputational Logic12024-12-14\n",
        "sectionId": "4cb9b783",
        "archive": "courses/Jacobs/CompLog",
        "filepath": "kr/slides/frames-nutshell.en.xhtml"
    },
    {
        "slideContent": "\nKR involving Time (Scripts [Shank ’77])\n\n▷Idea\n                  Organize typical event sequences, actors and props into representation.\n\n\n\n\n▷\n                                  A\nscript\n                                  is a structured representation describing a stereotyped sequence of events in a particular context. Structurally,\nscripts\n                                  are very much like\nframes, except the values that fill the slots must be ordered.\n\n\n▷\n                                  getting your hair cut (at a beauty parlor)\n\n\n▷props, actors as “script variables”\n\n\n▷events in a (generalized) sequence\n\n\n▷use\nscript\n                              material for\n\n\n▷anaphora, bridging references\n\n\n▷default common ground\n\n\n▷to fill in missing material into situations\n\n\n\n \n\n\n\n\nbig tip  \n\nsmall tip  \n\nhappy  \n\nunhappy  \n\npay  \n\nBeautician cuts hair  \n\ntell receptionist you’re here  \n\ngo into beauty parlor  \n\nmake appointment  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n\n\n\n\n \n\n\n:\nComputational Logic12024-12-14\n",
        "sectionId": "4cb9b783",
        "archive": "courses/Jacobs/CompLog",
        "filepath": "kr/slides/scripts-nutshell.en.xhtml"
    },
    {
        "slideContent": "\nOther Representation Formats (not covered)\n\n▷Procedural Representations(production systems)\n\n\n▷Analogical representations(interesting but not here)\n\n\n▷Iconic representations(interesting but very difficult to formalize)\n\n\n▷If you are interested, come see me off-line\n\n\n\n:\nComputational Logic12024-12-16\n",
        "sectionId": "4cb9b783",
        "archive": "courses/Jacobs/CompLog",
        "filepath": "kr/slides/other.en.xhtml"
    },
    {
        "slideContent": "\nLogic-Based Knowledge Representation\n\n▷Logic (and related formalisms) have a well-defined semantics\n\n\n▷explicitly(gives more understanding than statistical/neural methods)\n\n\n▷transparently(symbolic methods are monotonic)\n\n\n▷systematically(we can prove theorems about our systems)\n\n\n▷Problems with logic-based approaches\n\n\n▷Where does the\nworld knowledge\n              come from?(Ontology problem)\n\n\n▷How to guide search induced by logical\ncalculi(combinatorial explosion)\n\n\nOne possible answerdescription logics.(next couple of times)\n\n\n▷\n\n\n:\nComputational Logic12024-12-14\n",
        "sectionId": "e5726e39",
        "archive": "courses/Jacobs/CompLog",
        "filepath": "kr/slides/logic-based-kr.en.xhtml"
    },
    {
        "slideContent": "\nPropositional Logic as Set Description Language\n\n▷Idea\n                  Use\npropositional logic\n                  as a set description language:(variant\nsyntax/semantics)\n\n\n▷\n                  Let\nPLDL0\n                  be given by the following grammar for the\nPLDL0\nconcepts.\n(formulae)\nℒ::=𝐶|⊤|⊥|ℒ―|ℒ⊓ℒ|ℒ⊔ℒ|ℒ⊑ℒ|ℒ≡ℒi.e.\nPLDL0\n                  formed from\n\n\n▷atomic\nformulae(=^\npropositional variables)\n\n\n▷concept\nintersection\n                  (⊓)\n(=^\nconjunction\n∧)\n\n\n▷concept\ncomplement\n                  (·―)\n(=^\nnegation\n¬)\n\n\n▷concept\nunion\n                  (⊔),\nsubsumption\n                  (⊑), and\nequivalence\n                  (≡) defined from these.(=^\n∨,\n⇒, and\n⇔)\n\n\n▷Formal SemanticsLet\n𝒟\n                  be a given\nset\n                  (called the\ndomain of discourse) and\n𝜑:𝒱0→𝒫(𝒟), then we define\n\n\n▷[[𝑃]]:=𝜑(𝑃), (remember\n𝜑(𝑃)⊆𝒟).\n\n\n▷[[𝐀⊓𝐁]]:=[[𝐀]]∩[[𝐁]]\n                  and\n[[𝐀―]]:=𝒟\\[[𝐀]]\n                  ...\n\nWe call this construction the\nset description semantics\n                  of\nPL0.\n\n\n▷Note\n〈PLDL0,𝒮,[[·]]〉, where\n𝒮\n                  is the class of possible\ndomains\n                  forms a\nlogical system.\n\n\n\n:\nComputational Logic12024-12-14\n",
        "sectionId": "d727edec",
        "archive": "courses/Jacobs/CompLog",
        "filepath": "kr/slides/kr-pl0.en.xhtml"
    },
    {
        "slideContent": "\nConcept Axioms\n\n▷Observation\n                  Set-theoretic semantics of ‘true’ and ‘false’(⊤:=𝜑⊔𝜑―⊥:=𝜑⊓𝜑―)\n\n\n[[⊤]]=[[𝑝]]∪[[𝑝―]]=[[𝑝]]∪𝒟\\[[𝑝]]=𝒟\n\n                  Analogously:\n[[⊥]]=∅\n\n\n▷Idea\n                  Use logical axioms to describe the world(Axioms restrict the class of admissible domain structures)\n\n\n▷\n                  A\nconcept axiom\n                  is a\nPLDL0\n                  formula\n𝐀\n                  that is assumed to be true in the world.\n\n\n▷Set-Theoretic Semantics of Axioms\n𝐀\n                  is\ntrue\n                  in\ndomain of discourse\n𝒟\n                  iff\n[[𝐀]]=𝒟.\n\n\n▷\n                  A world with three\nconcepts\n                  and no\nconcept axioms\n\n\nconceptsSet Semantics𝖼𝗁𝗂𝗅𝖽𝖽𝖺𝗎𝗀𝗁𝗍𝖾𝗋𝗌𝗈𝗇 \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ndaughters  \n\n\n\n\n\nsons  \n\n\n\n\n\nchildren  \n\n\n\n\n \n\n\n\n\n\n:\nComputational Logic12024-12-15\n",
        "sectionId": "d727edec",
        "archive": "courses/Jacobs/CompLog",
        "filepath": "kr/slides/dl-concept-axioms.en.xhtml"
    },
    {
        "slideContent": "\nEffects of Axioms to Siblings\n\n▷\n                  We can use\nconcept axioms\n                  to describe the world from\n??.\n\n\nAxioms Semantics 𝗌𝗈𝗇⊑𝖼𝗁𝗂𝗅𝖽iff [[𝗌𝗈𝗇―]]∪[[𝖼𝗁𝗂𝗅𝖽]]=𝒟iff [[𝗌𝗈𝗇]]⊆[[𝖼𝗁𝗂𝗅𝖽]] 𝖽𝖺𝗎𝗀𝗁𝗍𝖾𝗋⊑𝖼𝗁𝗂𝗅𝖽iff [[𝖽𝖺𝗎𝗀𝗁𝗍𝖾𝗋―]]∪[[𝖼𝗁𝗂𝗅𝖽]]=𝒟iff [[𝖽𝖺𝗎𝗀𝗁𝗍𝖾𝗋]]⊆[[𝖼𝗁𝗂𝗅𝖽]]  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ndaughters  \n\n\n\n\n\nsons  \n\n\n\n\n\nchildren  \n\n\n\n\n \n\n𝗌𝗈𝗇⊓𝖽𝖺𝗎𝗀𝗁𝗍𝖾𝗋―𝖼𝗁𝗂𝗅𝖽⊑𝗌𝗈𝗇⊔𝖽𝖺𝗎𝗀𝗁𝗍𝖾𝗋\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ndaughters  \n\n\n\n\n\nsons  \n\n\n\n\n \n\n\n\n\n\n:\nComputational Logic12024-12-16\n",
        "sectionId": "d727edec",
        "archive": "courses/Jacobs/CompLog",
        "filepath": "kr/slides/pl0-set-axioms-ex.en.xhtml"
    },
    {
        "slideContent": "\nPropositional Identities\n\nName for ⊓ for ⊔ Idempot. 𝜑⊓𝜑=𝜑 𝜑⊔𝜑=𝜑 Identity 𝜑⊓⊤=𝜑 𝜑⊔⊥=𝜑Absorpt. 𝜑⊔⊤=⊤ 𝜑⊓⊥=⊥Commut. 𝜑⊓𝜓=𝜓⊓𝜑 𝜑⊔𝜓=𝜓⊔𝜑 Assoc. 𝜑⊓(𝜓⊓𝜃)=(𝜑⊓𝜓)⊓𝜃 𝜑⊔(𝜓⊔𝜃)=(𝜑⊔𝜓)⊔𝜃 Distrib. 𝜑⊓(𝜓⊔𝜃)=(𝜑⊓𝜓)⊔(𝜑⊓𝜃) 𝜑⊔(𝜓⊓𝜃)=(𝜑⊔𝜓)⊓(𝜑⊔𝜃) Absorpt. 𝜑⊓(𝜑⊔𝜃)=𝜑 𝜑⊔𝜑⊓𝜃=𝜑⊓𝜃Morgan 𝜑⊓𝜓―=𝜑―⊔𝜓― 𝜑⊔𝜓―=𝜑―⊓𝜓―dneg 𝜑――=𝜑\n\n\n\n:\nComputational Logic12024-12-14\n",
        "sectionId": "d727edec",
        "archive": "courses/Jacobs/CompLog",
        "filepath": "kr/slides/prop-identities.en.xhtml"
    },
    {
        "slideContent": "\nSet-Theoretic Semantics and Predicate Logic\n\n▷\n                  Translation into\nPL1(borrow semantics from that)\n\n\n▷recursively add argument variable\n𝑥\n\n\n▷change back\n⊓,⊔,⊑,≡\n                  to\n∧,∨,⇒,⇔\n\n\n▷universal closure for\n𝑥\n                  at formula level.\n\n\nDefinition Comment𝑝―𝑓𝑜(𝑥):=𝑝(𝑥) 𝐀――𝑓𝑜(𝑥):=¬𝐀―𝑓𝑜(𝑥)𝐀⊓𝐁―𝑓𝑜(𝑥):=𝐀―𝑓𝑜(𝑥)∧𝐁―𝑓𝑜(𝑥) ∧ vs. ⊓𝐀⊔𝐁―𝑓𝑜(𝑥):=𝐀―𝑓𝑜(𝑥)∨𝐁―𝑓𝑜(𝑥) ∨ vs. ⊔𝐀⊑𝐁―𝑓𝑜(𝑥):=𝐀―𝑓𝑜(𝑥)⇒𝐁―𝑓𝑜(𝑥) ⇒ vs. ⊑𝐀=𝐁―𝑓𝑜(𝑥):=𝐀―𝑓𝑜(𝑥)⇔𝐁―𝑓𝑜(𝑥) ⇔ vs. =𝐀―𝑓𝑜:=(∀𝑥.𝐀―𝑓𝑜(𝑥)) for formulae\n\n\n\n:\nComputational Logic12024-12-14\n",
        "sectionId": "d727edec",
        "archive": "courses/Jacobs/CompLog",
        "filepath": "kr/slides/pl0-set-semantics-pl1.en.xhtml",
        "video_name": "AI1_25thDec.m4v",
        "start_time": 960.35,
        "end_time": 1111.09
    },
    {
        "slideContent": "\nTranslation Examples\n\n▷We translate the\nconcept axioms\n                  from\n??\n                  to fortify our intuition:\n𝗌𝗈𝗇⊑𝖼𝗁𝗂𝗅𝖽―𝑓𝑜=∀𝑥.𝗌𝗈𝗇(𝑥)⇒𝖼𝗁𝗂𝗅𝖽(𝑥)\n\n𝖽𝖺𝗎𝗀𝗁𝗍𝖾𝗋⊑𝖼𝗁𝗂𝗅𝖽―𝑓𝑜=∀𝑥.𝖽𝖺𝗎𝗀𝗁𝗍𝖾𝗋(𝑥)⇒𝖼𝗁𝗂𝗅𝖽(𝑥)\n\n𝗌𝗈𝗇⊓𝖽𝖺𝗎𝗀𝗁𝗍𝖾𝗋――𝑓𝑜=∀𝑥.𝗌𝗈𝗇(𝑥)∧𝖽𝖺𝗎𝗀𝗁𝗍𝖾𝗋(𝑥)―\n\n𝖼𝗁𝗂𝗅𝖽⊑𝗌𝗈𝗇⊔𝖽𝖺𝗎𝗀𝗁𝗍𝖾𝗋―𝑓𝑜=∀𝑥.𝖼𝗁𝗂𝗅𝖽(𝑥)⇒(𝗌𝗈𝗇(𝑥)∨𝖽𝖺𝗎𝗀𝗁𝗍𝖾𝗋(𝑥))\n\n\n\n▷What are the advantages of translation to\nPL1?\n\n\n▷theoretically: A better understanding of the semantics\n\n\n▷computationally: Description Logic Framework, but\nNOTHING for\nPL0\n\n▷we can follow this pattern for richer\ndescription logics.\n\n\n▷many tests are\ndecidable\n              for\nPL0, but not for\nPL1.(Description Logics?)\n\n\n\n:\nComputational Logic22024-12-14\n",
        "sectionId": "d727edec",
        "archive": "courses/Jacobs/CompLog",
        "filepath": "kr/slides/pl0-set-semantics-pl1.en.xhtml"
    },
    {
        "slideContent": "\nOntologies aka. “World Descriptions”\n\n▷Classical\n                  An\nontology\n                  is a representation of the types, properties, and interrelationships of the entities that really or fundamentally exist for a particular\ndomain of discourse.\n\n\n▷Remark??\n                  is very general, and depends on what we mean by “representation”, “entities”, “types”, and “interrelationships”.\n\nThis may be a feature, and not a\nbug, since we can use the same intuitions across a variety of representations.\n\n\n▷\n\n\n▷Semantic networks\n                  are\nontologies.(relatively informal)\n\n\n▷\nPLDL0\n                  is an\nontology\n                  format.(formal, but relatively weak)\n\n\n▷PL1\n                  is an\nontology\n                  format as well.(formal, expressive)\n\n\n\n:\nComputational Logic12024-12-14\n",
        "sectionId": "babe8430",
        "archive": "courses/Jacobs/CompLog",
        "filepath": "kr/slides/ontology.en.xhtml"
    },
    {
        "slideContent": "\nThe Description Logic Paradigm\n\n▷Idea\n                  Build a whole family of\nlogics\n                  for describing\nsets\n                  and their\nrelations.(tailor their expressivity and computational properties)\n\n\n▷\n                  A\ndescription logic\n                  is a\nformal system\n                  for talking about\ncollections\n                  of\nobjects\n                  and their\nrelations\n                  that is at least as expressive as\nPL0\n                  with set-theoretic semantics and offers\nindividuals\n                  and\nrelations.\n\nA\ndescription logic\n                  has the following four components:\n\n\n\n▷a\nformal language\nℒ\n                                    with\nlogical constants\n⊓,\n·―,\n⊔,\n⊑, and\n≡,\n\n\n▷a set-theoretic semantics\n〈𝒟,[[·]]〉,\n\n\n▷a translation into\nfirst-order logic\n                                    that is compatible with\n〈𝒟,[[·]]〉, and\n\n\n▷a\ncalculus\n                                    for\nℒ\n                                    that induces a\ndecision procedure\n                                    for\nℒ-satisfiability.\n\n\n\n\n\n\n\nPL0  \nDL  \nPL1  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n𝜑  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n𝜓  \n\n\n\n\nundecideable  \ndecideable  \n𝜓:={𝐶↦𝑝∊Σ𝑝1⊓↦∩·―↦𝒟\\·}  \n𝜑:={𝑋∊𝒱0↦𝐶∧↦⊓¬↦·―}  \n\n\n\n\n\n\n\n\n \n\n▷\n                  Given a\ndescription logic\n𝒟, a\n𝒟\n                      ontology\n                  consists of\n\n\n▷a\nterminology\n                  (or\nTBox):\nconcepts\n                  and\nroles\n                  and a set of\nconcept axioms\n                  that describe them, and\n\n\n▷assertions\n                  (or\nABox): a set of\nindividuals\n                  and statements about\nconcept\n                  membership and role relationships for them.\n\n\n\n:\nComputational Logic12024-12-14\n",
        "sectionId": "babe8430",
        "archive": "courses/Jacobs/CompLog",
        "filepath": "kr/slides/dl-paradigm.en.xhtml"
    },
    {
        "slideContent": "\nTBoxes\n              in Description Logics\n\n▷Let\n𝒟\n              be a\ndescription logic\n              with\nconcepts\n𝒞.\n\n\n▷\n                  A\nconcept definition\n                  is a pair\n𝑐=𝐂, where\n𝑐\n                  is a new\nconcept\n                  name and\n𝐂∊𝒞\n                  is a\n𝒟-formula.\n\n\n▷\n                  A\nconcept definition\n𝑐=𝐶\n                  is called\nrecursive, iff\n𝑐\n                  occurs in\n𝐶.\n\n\n▷\n                  We can define\n𝗆𝗈𝗍𝗁𝖾𝗋=𝗐𝗈𝗆𝖺𝗇⊓𝗁𝖺𝗌\n_\n𝖼𝗁𝗂𝗅𝖽.\n\n\n▷\n                  An\nTBox\n                  is a\nfinite\nset\n                  of\nconcept definitions\n                  and\nconcept axioms. It is called\nacyclic, iff it does not contain\nrecursive\ndefinitions.\n\n\n▷\n                  A formula\n𝐀\n                  is called\nnormalized\n                  wrt. an\nTBox\n𝒯, iff it does not contain\nconcepts\n                  defined in\n𝒯.\n(convenient)\n\n\n▷Algorithm(for arbitrary DLs)Input: A formula\n𝐀\n                  and a\nTBox\n𝒯.\n\n\n▷While\n                  [𝐀\n                  contains\nconcept\n𝑐\n                  and\n𝒯\n                  a\nconcept definition\n𝑐=𝐂]\n\n\n▷substitute\n𝑐\n                  by\n𝐂\n                  in\n𝐀.\n\n\n▷\n                  This\nalgorithm\nterminates\n                  for\nacyclic\nTBoxes, but results can be\nexponentially\n                  large.\n\n\n\n:\nComputational Logic12024-12-14\n",
        "sectionId": "babe8430",
        "archive": "courses/Jacobs/CompLog",
        "filepath": "kr/slides/dl-tbox.en.xhtml"
    },
    {
        "slideContent": "\nKinds of Inference in Description Logics\n\n▷\nOntology systems\n                  employ three main reasoning services:\n\n\n▷Consistency test: is a\nconcept definition\n                  satisfiable?\n\n\n▷Subsumption test: does a\nconcept\nsubsume\n                  another?\n\n\n▷Instance test: is an individual an example of a\nconcept?\n\n\n▷Problem\ndecidability,\ncomplexity,\nalgorithm\n\n\n\n:\nComputational Logic12024-12-14\n",
        "sectionId": "1679397f",
        "archive": "courses/Jacobs/CompLog",
        "filepath": "kr/slides/dl-inference.en.xhtml"
    },
    {
        "slideContent": "\nConsistency Test\n\n▷\n                  We call a\nconcept\n𝐶\nconsistent, iff there is no\nconcept\n𝐴, with both\n𝐶⊑𝐴\n                  and\n𝐶⊑𝐴―.\n\n\n▷Or equivalently:\n\n\n▷\n                  A\nconcept\n𝐶\n                  is called\ninconsistent, iff\n[[𝐶]]=∅\n                  for all\n𝒟.\n\n\n▷T-Box\n\n𝗆𝖺𝗇 =𝗉𝖾𝗋𝗌𝗈𝗇⊓𝗁𝖺𝗌\n_\n𝖸 person with y-chromosome𝗐𝗈𝗆𝖺𝗇 =𝗉𝖾𝗋𝗌𝗈𝗇⊓𝗁𝖺𝗌\n_\n𝖸― person without y-chromosome𝗁𝖾𝗋𝗆𝖺𝗉𝗁𝗋𝗈𝖽𝗂𝗍𝖾 =𝗆𝖺𝗇⊓𝗐𝗈𝗆𝖺𝗇 man and woman \n\n\n▷This specification is\ninconsistent, i.e.\n[[𝗁𝖾𝗋𝗆𝖺𝗉𝗁𝗋𝗈𝖽𝗂𝗍𝖾]]=∅\n              for all\n𝒟.\n\n\n▷AlgorithmPropositional\nsatisfiability test\n(NP complete)we know how to do this, e.g.\ntableaux,\nresolution.\n\n\n\n:\nComputational Logic12024-12-14\n",
        "sectionId": "1679397f",
        "archive": "courses/Jacobs/CompLog",
        "filepath": "kr/slides/consistency-test.en.xhtml"
    },
    {
        "slideContent": "\nSubsumption Test\n\n▷In this case trivial\n\n\naxiom entailed subsumption relation𝗆𝖺𝗇=𝗉𝖾𝗋𝗌𝗈𝗇⊓𝗁𝖺𝗌\n_\n𝖸 𝗆𝖺𝗇⊑𝗉𝖾𝗋𝗌𝗈𝗇𝗐𝗈𝗆𝖺𝗇=𝗉𝖾𝗋𝗌𝗈𝗇⊓𝗁𝖺𝗌\n_\n𝖸― 𝗐𝗈𝗆𝖺𝗇⊑𝗉𝖾𝗋𝗌𝗈𝗇\n\n\n▷\n𝐀\nsubsumes\n𝐁\n                  (modulo a set\n𝒜\n                  of\nconcept axioms), iff\n[[𝐁]]⊆[[𝐀]]\n                  for all\ninterpretations\n𝒟\n                  that\nsatisfy\n𝒜.\n\n\n▷Reduction to consistency test(need to\nimplement\n                      only one)𝒜⇒(𝐀⇒𝐁)\n                  is\nvalid\n                  iff\n𝒜∧𝐀∧¬𝐁\n                  is\nconsistentin.\n\n\n▷ObservationOr equivalently, iff\n𝒜⇒𝐁⇒𝐀\n                  is\nvalid\n                  in\nPL0.\n\n\n▷In our example𝗉𝖾𝗋𝗌𝗈𝗇\n                  subsumes\n𝗐𝗈𝗆𝖺𝗇\n                  and\n𝗆𝖺𝗇\n\n\n\n:\nComputational Logic12024-12-14\n",
        "sectionId": "1679397f",
        "archive": "courses/Jacobs/CompLog",
        "filepath": "kr/slides/subsumption-test.en.xhtml"
    },
    {
        "slideContent": "\nClassification\n\n▷The\nsubsumption\nrelation\n              among\nall\nconcepts(subsumption\ngraph)\n\n\n▷Visualization of the\nsubsumption\ngraph\n              for inspection(plausibility)\n\n\n▷\nClassification\n                  is the computation of the\nsubsumption\ngraph.\n\n\n▷(not always so trivial)\n\n\n\n\n\n\nmale_student  \nfemale_student  \nboy  \ngirl  \nman  \nwoman  \nstudent  \nprofessor  \nchild  \nperson  \nobject  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n:\nComputational Logic12024-12-14\n",
        "sectionId": "1679397f",
        "archive": "courses/Jacobs/CompLog",
        "filepath": "kr/slides/classification.en.xhtml"
    },
    {
        "slideContent": "\nMotivation for\n𝒜ℒ𝒞\n              (Prototype Description Logic)\n\n▷Propositional logic\n              (PL0) is not expressive enough!\n\n\n▷\n                  “mothers are women that have a child”\n\n\n▷Reason\n                  There are no\nquantifiers\n                  in\nPL0(existential (∃) and universal (∀))\n\n\n▷Idea\n                  Use first-order predicate logic (PL1)\n∀𝑥.𝑚𝑜𝑡ℎ𝑒𝑟(𝑥)⇔𝑤𝑜𝑚𝑎𝑛(𝑥)∧(∃𝑦.ℎ𝑎𝑠\n_\n𝑐ℎ𝑖𝑙𝑑(𝑥,𝑦))\n\n▷Problem\n                  Complex\nalgorithms,\nnon-termination(PL1\n                      is too expressive)\n\n\n▷Idea\n                  Try to travel the middle groundMore expressive than\nPL0\n                  (quantifiers) but weaker than\nPL1.(still\ntractable)\n\n\n▷Technique\n                  Allow only “restricted quantification”, where quantified variables only range over values that can be reached via a\nbinary\nrelation\n                  like\nℎ𝑎𝑠\n_\n𝑐ℎ𝑖𝑙𝑑.\n\n\n\n:\nComputational Logic12024-12-14\n",
        "sectionId": "1860e307",
        "archive": "courses/Jacobs/CompLog",
        "filepath": "kr/slides/alc-motivation.en.xhtml"
    },
    {
        "slideContent": "\nSyntax of\n𝒜ℒ𝒞\n\n▷Concepts(aka. “predicates” in\nPL1\n                      or “propositional variables” in\nPLDL0)\n\nConcepts\n                  in\nDLs\n                  represent collections of objects.\n\n\n▷...like\nclasses\n                  in\nOOP.\n\n\n▷Special Concepts\n                  The\ntop concept\n⊤\n                  (for “true” or “all”) and the\nbottom concept\n⊥\n                  (for “false” or “none”).\n\n\n▷\n                  person, woman, man, mother, professor, student, car, BMW, computer, computer program, heart attack risk, furniture, table, leg of a chair, ...\n\n▷\nRoles\n                  represent\nbinary\nrelations(like in\nPL1)\n\n\n▷\n                  has_child, has_son, has_daughter, loves, hates, gives_course, executes_computer_program, has_leg_of_table, has_wheel, has_motor, ...\n\n▷Grammar\n                  The formulae of\n𝒜ℒ𝒞\n                  are given by the following\ngrammar:\n𝐹𝒜ℒ𝒞::=𝐶|⊤|⊥|𝐹𝒜ℒ𝒞―|𝐹𝒜ℒ𝒞⊓𝐹𝒜ℒ𝒞|𝐹𝒜ℒ𝒞⊔𝐹𝒜ℒ𝒞|∃\nR\n.𝐹𝒜ℒ𝒞|∀\nR\n.𝐹𝒜ℒ𝒞\n\n\n\n:\nComputational Logic12024-12-14\n",
        "sectionId": "1860e307",
        "archive": "courses/Jacobs/CompLog",
        "filepath": "kr/slides/alc-syntax.en.xhtml"
    },
    {
        "slideContent": "\nSyntax of\n𝒜ℒ𝒞: Examples\n\n▷\n𝗉𝖾𝗋𝗌𝗈𝗇⊓∃\nhas_child\n.𝗌𝗍𝗎𝖽𝖾𝗇𝗍\n\n=^\n                  The set of persons that have a child which is a student\n\n=^\n                  parents of students\n\n\n▷\n𝗉𝖾𝗋𝗌𝗈𝗇⊓∃\nhas_child\n.∃\nhas_child\n.𝗌𝗍𝗎𝖽𝖾𝗇𝗍\n\n=^\n                  grandparents of students\n\n\n▷\n𝗉𝖾𝗋𝗌𝗈𝗇⊓∃\nhas_child\n.∃\nhas_child\n.(𝗌𝗍𝗎𝖽𝖾𝗇𝗍⊔𝗍𝖾𝖺𝖼𝗁𝖾𝗋)\n\n=^\n                  grandparents of students or teachers\n\n\n▷\n𝗉𝖾𝗋𝗌𝗈𝗇⊓∀\nhas_child\n.𝗌𝗍𝗎𝖽𝖾𝗇𝗍\n\n=^\n                  parents whose children are\nall\n                  students\n\n\n▷\n𝗉𝖾𝗋𝗌𝗈𝗇⊓∀haschild.∃\nhas_child\n.𝗌𝗍𝗎𝖽𝖾𝗇𝗍\n\n=^\n                  grandparents, whose children\nall\n                  have at least one child that is a student\n\n\n\n:\nComputational Logic22024-12-14\n",
        "sectionId": "1860e307",
        "archive": "courses/Jacobs/CompLog",
        "filepath": "kr/slides/alc-syntax.en.xhtml"
    },
    {
        "slideContent": "\nMore\n𝒜ℒ𝒞\n              Examples\n\n▷\n𝖼𝖺𝗋⊓∃\nhas_part\n.∃\nmade_in\n.𝖤𝖴―\n\n=^\n                  cars that have at least one part that has not been made in the EU\n\n\n▷\n𝗌𝗍𝗎𝖽𝖾𝗇𝗍⊓∀\naudits_course\n.𝗀𝗋𝖺𝖽𝗎𝖺𝗍𝖾𝗅𝖾𝗏𝖾𝗅𝖼𝗈𝗎𝗋𝗌𝖾\n\n=^\n                  students, that only audit graduate level courses\n\n\n▷\n𝗁𝗈𝗎𝗌𝖾⊓∀\nhas_parking\n.𝗈𝖿𝖿\n_\n𝗌𝗍𝗋𝖾𝖾𝗍\n=^\n                  houses with off-street parking\n\n\n▷Note\n𝑝⊑𝑞\n                  can still be used as an abbreviation for\n𝑝―⊔𝑞.\n\n\n▷\n𝗌𝗍𝗎𝖽𝖾𝗇𝗍⊓∀\naudits_course\n.(∃\nhastutorial\n.⊤⊑∀\nhas_TA\n.𝗐𝗈𝗆𝖺𝗇)\n\n=^\n                  students that only audit courses that either have no tutorial or tutorials that are TAed by women\n\n\n\n:\nComputational Logic12024-12-14\n",
        "sectionId": "1860e307",
        "archive": "courses/Jacobs/CompLog",
        "filepath": "kr/slides/alc-syntax-ex.en.xhtml"
    },
    {
        "slideContent": "\n𝒜ℒ𝒞\n              Concept Definitions\n\n▷Idea\n                  Define new\nconcepts\n                  from known ones.\n\n\n▷\n                  A\nconcept definition\n                  is a pair consisting of a new\nconcept\n                  name (the\ndefiniendum) and an\n𝒜ℒ𝒞\n                  formula (the\ndefiniens).\nConcepts\n                  that are not\ndefinienda\n                  are called\nprimitive.\n\n\n▷\n                  We extend the\n𝒜ℒ𝒞\ngrammar\n                  from\n??\n                  by the\nproduction\n\n𝐶𝐷𝒜ℒ𝒞::=𝐶=𝐹𝒜ℒ𝒞\n\n▷\n\nDefinition rec?𝗆𝖺𝗇=𝗉𝖾𝗋𝗌𝗈𝗇⊓∃\nhas_chrom\n.𝖸\n_\n𝖼𝗁𝗋𝗈𝗆 -𝗐𝗈𝗆𝖺𝗇=𝗉𝖾𝗋𝗌𝗈𝗇⊓∀\nhas_chrom\n.𝖸\n_\n𝖼𝗁𝗋𝗈𝗆― -𝗆𝗈𝗍𝗁𝖾𝗋=𝗐𝗈𝗆𝖺𝗇⊓∃\nhas_child\n.𝗉𝖾𝗋𝗌𝗈𝗇 - 𝖿𝖺𝗍𝗁𝖾𝗋=𝗆𝖺𝗇⊓∃\nhas_child\n.𝗉𝖾𝗋𝗌𝗈𝗇 - 𝗀𝗋𝖺𝗇𝖽𝗉𝖺𝗋𝖾𝗇𝗍=𝗉𝖾𝗋𝗌𝗈𝗇⊓∃\nhas_child\n.(𝗆𝗈𝗍𝗁𝖾𝗋⊔𝖿𝖺𝗍𝗁𝖾𝗋) - 𝗀𝖾𝗋𝗆𝖺𝗇=𝗉𝖾𝗋𝗌𝗈𝗇⊓∃\nhas_parents\n.𝗀𝖾𝗋𝗆𝖺𝗇 + 𝗇𝗎𝗆𝖻𝖾𝗋\n_\n𝗅𝗂𝗌𝗍=𝖾𝗆𝗉𝗍𝗒\n_\n𝗅𝗂𝗌𝗍⊔∃\nis_first\n.𝗇𝗎𝗆𝖻𝖾𝗋⊓∃\nis_rest\n.𝗇𝗎𝗆𝖻𝖾𝗋\n_\n𝗅𝗂𝗌𝗍+ \n\n\n\n:\nComputational Logic12024-12-14\n",
        "sectionId": "1860e307",
        "archive": "courses/Jacobs/CompLog",
        "filepath": "kr/slides/concept-definitions.en.xhtml"
    },
    {
        "slideContent": "\nTBox\n              Normalization in\n𝒜ℒ𝒞\n\n▷\n                  We call an\n𝒜ℒ𝒞\nformula\n𝜑\nnormalized\n                  wrt. a set of\nconcept definitions, iff all\nconcepts\n                  occurring in\n𝜑\n                  are\nprimitive.\n\n\n▷\n                  Given a set\n𝒟\n                  of\nconcept definitions,\nnormalization\n                  is the process of replacing in an\n𝒜ℒ𝒞\n                  formula\n𝜑\n                  all\noccurrences\n                  of\ndefinienda\n                  in\n𝒟\n                  with their\ndefinientia.\n\n\n▷Normalizing grandparent𝗀𝗋𝖺𝗇𝖽𝗉𝖺𝗋𝖾𝗇𝗍\n\n↦𝗉𝖾𝗋𝗌𝗈𝗇⊓∃\nhas_child\n.(𝗆𝗈𝗍𝗁𝖾𝗋⊔𝖿𝖺𝗍𝗁𝖾𝗋)\n\n↦𝗉𝖾𝗋𝗌𝗈𝗇⊓∃\nhas_child\n.(𝗐𝗈𝗆𝖺𝗇⊓∃\nhas_child\n.𝗉𝖾𝗋𝗌𝗈𝗇⊓𝗆𝖺𝗇⊓∃\nhas_child\n.𝗉𝖾𝗋𝗌𝗈𝗇)\n\n↦𝗉𝖾𝗋𝗌𝗈𝗇⊓∃\nhas_child\n.(𝗉𝖾𝗋𝗌𝗈𝗇⊓∃\nhas_chrom\n.𝖸\n_\n𝖼𝗁𝗋𝗈𝗆⊓∃\nhas_child\n.𝗉𝖾𝗋𝗌𝗈𝗇⊓𝗉𝖾𝗋𝗌𝗈𝗇⊓∃\nhas_chrom\n.𝖸\n_\n𝖼𝗁𝗋𝗈𝗆⊓∃\nhas_child\n.𝗉𝖾𝗋𝗌𝗈𝗇)\n\n\n\n\n\n▷\nNormalization\n                  results can be\nexponential.(contain redundancies)\n\n\n▷\nNormalization\n                  need not\nterminate\n                  on\ncyclic\nTBoxes.\n\n\n▷𝗀𝖾𝗋𝗆𝖺𝗇↦𝗉𝖾𝗋𝗌𝗈𝗇⊓∃\nhas_parents\n.𝗀𝖾𝗋𝗆𝖺𝗇\n\n↦𝗉𝖾𝗋𝗌𝗈𝗇⊓∃\nhas_parents\n.(𝗉𝖾𝗋𝗌𝗈𝗇⊓∃\nhas_parents\n.𝗀𝖾𝗋𝗆𝖺𝗇)\n\n↦...\n\n\n\n\n:\nComputational Logic12024-12-14\n",
        "sectionId": "1860e307",
        "archive": "courses/Jacobs/CompLog",
        "filepath": "kr/slides/tbox-normalization.en.xhtml"
    },
    {
        "slideContent": "\nSemantics of\n𝒜ℒ𝒞\n\n▷𝒜ℒ𝒞\n              semantics is an extension of the set-semantics of\npropositional logic.\n\n\n▷\n                  A\nmodel\n                  for\n𝒜ℒ𝒞\n                  is a pair\n〈𝒟,[[·]]〉, where\n𝒟\n                  is a non-empty set called the\ndomain of discourse\n                  and\n[[·]]\n                  a mapping called the\ninterpretation, such that\n\n\nOp.formula semantics[[𝑐]]⊆𝒟=[[⊤]][[⊥]]=∅[[𝑟]]⊆𝒟×𝒟·― [[𝜑―]]=[[𝜑]]―=𝒟\\[[𝜑]]⊓ [[𝜑⊓𝜓]]=[[𝜑]]∩[[𝜓]]⊔ [[𝜑⊔𝜓]]=[[𝜑]]∪[[𝜓]]∃\nR\n. [[∃\nR\n.𝜑]]={𝑥∊𝒟|∃𝑦.\n〈𝑥,𝑦〉∊[[\nR\n]] and 𝑦∊[[𝜑]]\n}∀\nR\n. [[∀\nR\n.𝜑]]={𝑥∊𝒟|∀𝑦.\nif 〈𝑥,𝑦〉∊[[\nR\n]] then 𝑦∊[[𝜑]]\n}\n\n\n▷Alternatively we can define the semantics of\n𝒜ℒ𝒞\n              by translation into\nPL1.\n\n\n▷\n                  The translation of\n𝒜ℒ𝒞\n                  into\nPL1\n                  extends the one from\n??\n                  by the following\nquantifier\n                  rules:\n∀\nR\n.𝜑―𝑓𝑜(𝑥):=(∀𝑦.\nR\n(𝑥,𝑦)⇒𝜑―𝑓𝑜(𝑦))∃\nR\n.𝜑―𝑓𝑜(𝑥):=(∃𝑦.\nR\n(𝑥,𝑦)∧𝜑―𝑓𝑜(𝑦))\n\n▷\n                  The set-theoretic semantics from\n??\n                  and the “semantics-by-translation” from\n??\n                  induce the same notion of\nsatisfiability.\n\n\n\n:\nComputational Logic12024-12-14\n",
        "sectionId": "1860e307",
        "archive": "courses/Jacobs/CompLog",
        "filepath": "kr/slides/alc-semantics.en.xhtml"
    },
    {
        "slideContent": "\n𝒜ℒ𝒞\n              Identities\n\n▷1 ∃\nR\n.𝜑―=∀\nR\n.𝜑― 3 ∀\nR\n.𝜑―=∃\nR\n.𝜑―2 ∀\nR\n.(𝜑⊓𝜓)=∀\nR\n.𝜑⊓∀\nR\n.𝜓4 ∃\nR\n.(𝜑⊔𝜓)=∃\nR\n.𝜑⊔∃\nR\n.𝜓\n\n\n▷Proof of 1\n[[∃\nR\n.𝜑―]]=𝒟\\[[∃\nR\n.𝜑]]=𝒟\\{𝑥∊𝒟|∃𝑦.\n(〈𝑥,𝑦〉∊[[\nR\n]]) and (𝑦∊[[𝜑]])\n}\n\n={𝑥∊𝒟|\nnot ∃𝑦.(〈𝑥,𝑦〉∊[[\nR\n]])\nand\n(𝑦∊[[𝜑]])\n}\n\n={𝑥∊𝒟|∀𝑦.\nif (〈𝑥,𝑦〉∊[[\nR\n]]) then (𝑦∉[[𝜑]])\n}\n\n={𝑥∊𝒟|∀𝑦.\nif (〈𝑥,𝑦〉∊[[\nR\n]]) then (𝑦∊(𝒟\\[[𝜑]]))\n}\n\n={𝑥∊𝒟|∀𝑦.\nif (〈𝑥,𝑦〉∊[[\nR\n]]) then (𝑦∊[[𝜑―]])\n}\n\n=[[∀\nR\n.𝜑―]]\n\n\n\n\n:\nComputational Logic12024-12-14\n",
        "sectionId": "1860e307",
        "archive": "courses/Jacobs/CompLog",
        "filepath": "kr/slides/alc-identities.en.xhtml"
    },
    {
        "slideContent": "\nNegation Normal Form\n\n▷NNF\n                  An\n𝒜ℒ𝒞\n                  formula is in\nnegation normal form\n                  (NNF), iff\ncomplement\n                  (·―) is only applied to\nprimitive\nconcept.\n\n\n▷Use the\n𝒜ℒ𝒞\n              identities as rules to compute it.(in\nlinear\ntime)\n\n\n▷\n\n\nexample by rule ∃\nR\n.(∀\nS\n.𝑒⊓∀\nS\n.𝑑―)―↦∀\nR\n.∀\nS\n.𝑒⊓∀\nS\n.𝑑―― ∃\nR\n.𝜑―↦∀\nR\n.𝜑― ↦∀\nR\n.(∀\nS\n.𝑒―⊔∀\nS\n.𝑑――) 𝜑⊓𝜓―↦𝜑―⊔𝜓―↦∀\nR\n.(∃\nS\n.𝑒―⊔∀\nS\n.𝑑――) ∀\nR\n.𝜑―↦∃\nR\n.𝜑―↦∀\nR\n.(∃\nS\n.𝑒―⊔∀\nS\n.𝑑) 𝜑――↦𝜑 \n\n\n\n:\nComputational Logic12024-12-14\n",
        "sectionId": "1860e307",
        "archive": "courses/Jacobs/CompLog",
        "filepath": "kr/slides/nnf.en.xhtml"
    },
    {
        "slideContent": "\n𝒜ℒ𝒞\n              with Assertions about Individuals\n\n▷\n                  We define the ABox\nassertions\n                  for\n𝒜ℒ𝒞:\n\n\n▷Role assertions𝑎:𝜑\n(𝑎\n                      is a\n𝜑)\n\n\n▷𝑎\nR\n𝑏\n(𝑎\n                      stands in relation\n\nR\n\n                      to\n𝑏)\n\n\nassertions\n                  make up the\nABox\n                  in\n𝒜ℒ𝒞.\n\n\n▷\n                  Let\n〈𝒟,[[·]]〉\n                  be a\nmodel\n                  for\n𝒜ℒ𝒞, then we define\n\n\n▷[[𝑎:𝜑]]=𝖳, iff\n[[𝑎]]∊[[𝜑]], and\n\n\n▷[[𝑎\nR\n𝑏]]=𝖳, iff\n([[𝑎]],[[𝑏]])∊[[\nR\n]].\n\n\n▷\n                  We extend the\nPL1\n                  translation of\n𝒜ℒ𝒞\n                  to\n𝒜ℒ𝒞\nassertions:\n\n\n▷𝑎:𝜑―𝑓𝑜:=𝜑―𝑓𝑜(𝑎), and\n\n\n▷𝑎\nR\n𝑏―𝑓𝑜:=\nR\n(𝑎,𝑏).\n\n\n\n:\nComputational Logic12024-12-14\n",
        "sectionId": "1860e307",
        "archive": "courses/Jacobs/CompLog",
        "filepath": "kr/slides/alc-abox.en.xhtml"
    },
    {
        "slideContent": "\n𝒯𝒜ℒ𝒞: A Tableau-Calculus for\n𝒜ℒ𝒞\n\n▷Recap Tableaux\n                  A tableau calculus develops an initial tableau in a tree-formed scheme using tableau extension rules.\n\nA\nsaturated\n                  tableau (no rules applicable) constitutes a\nrefutation, if all branches are\nclosed\n                  (end in\n⊥).\n\n\n▷\n                  The\n𝒜ℒ𝒞\n                      tableau calculus\n𝒯𝒜ℒ𝒞\n                  acts on\nassertions:\n\n\n▷𝑥:𝜑\n(𝑥\n                      inhabits\nconcept\n𝜑)\n\n\n▷𝑥\nR\n𝑦\n(𝑥\n                      and\n𝑦\n                      are in relation\n\nR\n)\n\n\nwhere\n𝜑\n                  is a\nnormalized\n𝒜ℒ𝒞\nconcept\n                  in\nnegation normal form\n                  with the following rules:\n𝑥:𝑐𝑥:𝑐―⊥𝒯⊥𝑥:𝜑⊓𝜓𝑥:𝜑𝑥:𝜓𝒯⊓𝑥:𝜑⊔𝜓𝑥:𝜑\n|\n𝑥:𝜓𝒯⊔𝑥:∀\nR\n.𝜑𝑥\nR\n𝑦𝑦:𝜑𝒯∀𝑥:∃\nR\n.𝜑𝑥\nR\n𝑦𝑦:𝜑𝒯∃\n\n▷To test\nconsistency\n              of a\nconcept\n𝜑, normalize\n𝜑\n              to\n𝜓, initialize the\ntableau\n              with\n𝑥:𝜓,\nsaturate.\nOpen\nbranches\n⤳\nconsistent.\n(𝑥\n                  arbitrary)\n\n\n\n:\nComputational Logic12024-12-14\n",
        "sectionId": "7725f4a4",
        "archive": "courses/Jacobs/CompLog",
        "filepath": "kr/slides/alc-tableau.en.xhtml"
    },
    {
        "slideContent": "\n𝒯𝒜ℒ𝒞\n              Examples\n\n▷Tableau Proofs\n                  We have two similar\nconjectures\n                  about children.\n\n\n▷𝑥:∀\nhas_child\n.𝗆𝖺𝗇⊓∃\nhas_child\n.𝗆𝖺𝗇―(all sons, but a daughter)\n\n\n𝑥:∀\nhas_child\n.𝗆𝖺𝗇⊓∃\nhas_child\n.𝗆𝖺𝗇― initial𝑥:∀\nhas_child\n.𝗆𝖺𝗇 𝒯⊓ 𝑥:∃\nhas_child\n.𝗆𝖺𝗇― 𝒯⊓𝑥\nhas_child\n𝑦 𝒯∃𝑦:𝗆𝖺𝗇― 𝒯∃ ⊥ 𝒯⊥ inconsistent\n\n\n▷𝑥:∀\nhas_child\n.𝗆𝖺𝗇⊓∃\nhas_child\n.𝗆𝖺𝗇(only sons, and at least one)\n\n\n𝑥:∀\nhas_child\n.𝗆𝖺𝗇⊓∃\nhas_child\n.𝗆𝖺𝗇 initial 𝑥:∀\nhas_child\n.𝗆𝖺𝗇 𝒯⊓𝑥:∃\nhas_child\n.𝗆𝖺𝗇 𝒯⊓ 𝑥\nhas_child\n𝑦 𝒯∃𝑦:𝗆𝖺𝗇 𝒯∃open \n\n\nThis\ntableau\n                  shows a\nmodel: there are two persons,\n𝑥\n                  and\n𝑦.\n𝑦\n                  is the only child of\n𝑥,\n𝑦\n                  is a man.\n\n\n\n:\nComputational Logic12024-12-16\n",
        "sectionId": "7725f4a4",
        "archive": "courses/Jacobs/CompLog",
        "filepath": "kr/slides/alc-tableau-ex.en.xhtml"
    },
    {
        "slideContent": "\nAnother\n𝒯𝒜ℒ𝒞\n              Example\n\n▷\n∀\nhas_child\n.(𝗎𝗀𝗋𝖺𝖽⊔𝗀𝗋𝖺𝖽)⊓∃\nhas_child\n.𝗎𝗀𝗋𝖺𝖽―\n                  is satisfiable.\n\n\n▷Let’s try it on the board\n\n\n▷Tableau proof for the notes\n\n\n1 𝑥:∀\nhas_child\n.(𝗎𝗀𝗋𝖺𝖽⊔𝗀𝗋𝖺𝖽)⊓∃\nhas_child\n.𝗎𝗀𝗋𝖺𝖽―initial 2 𝑥:∀\nhas_child\n.(𝗎𝗀𝗋𝖺𝖽⊔𝗀𝗋𝖺𝖽) 𝒯⊓3 𝑥:∃\nhas_child\n.𝗎𝗀𝗋𝖺𝖽― 𝒯⊓4 𝑥\nhas_child\n𝑦 𝒯∃5 𝑦:𝗎𝗀𝗋𝖺𝖽― 𝒯∃6 𝑦:𝗎𝗀𝗋𝖺𝖽⊔𝗀𝗋𝖺𝖽 𝒯∀7 𝑦:𝗎𝗀𝗋𝖺𝖽𝑦:𝗀𝗋𝖺𝖽 𝒯⊔8 ⊥open\n\n\nThe left\nbranch\n                  is\nclosed, the right one represents a\nmodel:\n𝑦\n                  is a child of\n𝑥,\n𝑦\n                  is a graduate student,\n𝑥\n                  hat exactly one child:\n𝑦.\n\n\n\n:\nComputational Logic22024-12-16\n",
        "sectionId": "7725f4a4",
        "archive": "courses/Jacobs/CompLog",
        "filepath": "kr/slides/alc-tableau-ex.en.xhtml"
    },
    {
        "slideContent": "\nProperties of Tableau Calculi\n\n▷We study the following properties of a tableau calculus\n𝒞:\n\n\n▷Termination: there are no\ninfinite sequences\n              of\ninference rule\n              applications.\n\n\n▷Soundness: If\n𝜑\n              is\nsatisfiable, then\n𝒞\nterminates\n              with an\nopen\nbranch.\n\n\n▷Completeness: If\n𝜑\n              is in\nunsatisfiable, then\n𝒞\nterminates\n              and all\nbranches\n              are\nclosed.\n\n\n▷complexity\n              of the\nalgorithm\n              (time\n              and\nspace complexity).\n\n\n▷Additionally, we are interested in the\ncomplexity\n              of\nsatisfiability\n              itself\n(as a\nbenchmark)\n\n\n\n:\nComputational Logic12024-12-14\n",
        "sectionId": "7725f4a4",
        "archive": "courses/Jacobs/CompLog",
        "filepath": "kr/slides/alc-tableau-properties.en.xhtml"
    },
    {
        "slideContent": "\nCorrectness\n\n▷\n                  If\n𝜑\nsatisfiable, then\n𝒯𝒜ℒ𝒞\nterminates\n                  on\n𝑥:𝜑\n                  with\nopen\nbranch.\n\n\n▷Proof:\nLet\nℳ:=〈𝒟,[[·]]〉\n                  be a\nmodel\n                  for\n𝜑\n                  and\n𝑤∊[[𝜑]].\n\n\n\n1.We define\n[[𝑥]]:=𝑤\n                    and\nℳ|=(𝑥:𝜓) iff[[𝑥]]∊[[𝜓]]ℳ|=𝑥\nR\n𝑦 iff〈𝑥,𝑦〉∊[[\nR\n]]ℳ|=𝑆 iffℐ|=𝑐 for all 𝑐∊𝑆 \n\n\n\n\n2.This gives us\nℳ|=(𝑥:𝜑)(base case)\n\n\n\n\n3.If the\nbranch\n                    is\nsatisfiable, then either\n\n▷no\nrule\n                    applicable to\nleaf,(open\nbranch)\n\n\n▷or\nrule\n                    applicable and one new\nbranch\nsatisfiable.(inductive case: next)\n\n\n\n\n4.There must be an\nopen\nbranch.(by\ntermination)\n\n\n\n:\nComputational Logic12024-12-15\n",
        "sectionId": "7725f4a4",
        "archive": "courses/Jacobs/CompLog",
        "filepath": "kr/slides/alct-correct.en.xhtml"
    },
    {
        "slideContent": "\nCase analysis on the rules\n\n𝒯⊓ appliesthen\nℳ|=(𝑥:𝜑⊓𝜓), i.e.\n[[𝑥]]∊[[𝜑⊓𝜓]]so\n[[𝑥]]∊[[𝜑]]\n              and\n[[𝑥]]∊[[𝜓]], thus\nℳ|=(𝑥:𝜑)\n              and\nℳ|=(𝑥:𝜓).\n\n\n𝒯⊔ appliesthen\nℳ|=(𝑥:𝜑⊔𝜓), i.e\n[[𝑥]]∊[[𝜑⊔𝜓]]so\n[[𝑥]]∊[[𝜑]]\n              or\n[[𝑥]]∊[[𝜓]], thus\nℳ|=(𝑥:𝜑)\n              or\nℳ|=(𝑥:𝜓),wlog.\nℳ|=(𝑥:𝜑).\n\n\n𝒯∀ appliesthen\nℳ|=(𝑥:∀\nR\n.𝜑)\n              and\nℳ|=𝑥\nR\n𝑦, i.e.\n[[𝑥]]∊[[∀\nR\n.𝜑]]\n              and\n〈𝑥,𝑦〉∊[[\nR\n]], so\n[[𝑦]]∊[[𝜑]]\n\n\n𝒯∃ appliesthen\nℳ|=(𝑥:∃\nR\n.𝜑), i.e\n[[𝑥]]∊[[∃\nR\n.𝜑]],so there is a\n𝑣∊𝐷\n              with\n〈[[𝑥]],𝑣〉∊[[\nR\n]]\n              and\n𝑣∊[[𝜑]].\nWe define\n[[𝑦]]:=𝑣, then\nℳ|=𝑥\nR\n𝑦\n              and\nℳ|=(𝑦:𝜑)\n\n\n\n:\nComputational Logic22024-12-15\n",
        "sectionId": "7725f4a4",
        "archive": "courses/Jacobs/CompLog",
        "filepath": "kr/slides/alct-correct.en.xhtml"
    },
    {
        "slideContent": "\nCompleteness of the Tableau Calculus\n\n▷\nOpen\nsaturated\ntableau\nbranches\n                  for\n𝜑\n                  induce\nmodels\n                  for\n𝜑.\n\n\n▷Proof:\nconstruct a\nmodel\n                  for the\nbranch\n                  and verify for\n𝜑\n\n\n\n1.Let\nℬ\n                    be an\nopen,\nsaturated\nbranch\n\n▷we define\n𝒟:={𝑥|\n𝑥:𝜓∊ℬ or 𝑧\nR\n𝑥∊ℬ\n}\n\n[[𝑐]]:={𝑥|𝑥:𝑐∊ℬ}\n\n[[\nR\n]]:={〈𝑥,𝑦〉|𝑥\nR\n𝑦∊ℬ}\n\n\n\n▷well-defined since never\n𝑥:𝑐,𝑥:𝑐―∊ℬ(otherwise\n𝒯⊥\n                        applies)\n\n\n▷ℳ\n                    satisfies all\nassertions\n𝑥:𝑐,\n𝑥:𝑐―\n                    and\n𝑥\nR\n𝑦,(by construction)\n\n\n\n\n2.ℳ|=(𝑦:𝜓), for all\n𝑦:𝜓∊ℬ(on\n𝑘=𝑠𝑖𝑧𝑒(𝜓)\n                        next slide)\n\n\n\n\n3.ℳ|=(𝑥:𝜑).\n\n\n\n:\nComputational Logic12024-12-15\n",
        "sectionId": "7725f4a4",
        "archive": "courses/Jacobs/CompLog",
        "filepath": "kr/slides/alct-complete.en.xhtml"
    },
    {
        "slideContent": "\nCase Analysis for Induction\n\ncase 𝑦:𝜓=𝑦:𝜓1⊓𝜓2Then\n{𝑦:𝜓1,𝑦:𝜓2}⊆ℬ\n(𝒯⊓-rule, saturation)\n\nso\nℳ|=(𝑦:𝜓1)\n              and\nℳ|=(𝑦:𝜓2)\n              and\nℳ|=(𝑦:𝜓1⊓𝜓2)(IH, Definition)\n\n\ncase 𝑦:𝜓=𝑦:𝜓1⊔𝜓2Then\n𝑦:𝜓1∊𝐁\n              or\n𝑦:𝜓2∊𝐁(𝒯⊔, saturation)\n\nso\nℳ|=(𝑦:𝜓1)\n              or\nℳ|=(𝑦:𝜓2)\n              and\nℳ|=(𝑦:𝜓1⊔𝜓2)(IH, Definition)\n\n\ncase 𝑦:𝜓=𝑦:∃\nR\n.𝜃then\n{𝑦\nR\n𝑧,𝑧:𝜃}⊆𝐁\n              (𝑧\n              new variable)\n(𝒯∃-rules, saturation)\n\nso\nℳ|=(𝑧:𝜃)\n              and\nℳ|=𝑦\nR\n𝑧, thus\nℳ|=(𝑦:∃\nR\n.𝜃).(IH, Definition)\n\n\ncase 𝑦:𝜓=𝑦:∀\nR\n.𝜃Let\n〈[[𝑦]],𝑣〉∊[[\nR\n]]\n              for some\n𝑟∊𝒟\nthen\n𝑣=𝑧\n              for some variable\n𝑧\n              with\n𝑦\nR\n𝑧∊𝐁(construction of\n[[\nR\n]])\n\nSo\n𝑧:𝜃∊ℬ\n              and\nℳ|=(𝑧:𝜃).\n(𝒯∀-rule, saturation, Def)\n\nAs\n𝑣\n              was arbitrary we have\nℳ|=(𝑦:∀\nR\n.𝜃).\n\n\n\n:\nComputational Logic22024-12-15\n",
        "sectionId": "7725f4a4",
        "archive": "courses/Jacobs/CompLog",
        "filepath": "kr/slides/alct-complete.en.xhtml"
    },
    {
        "slideContent": "\nTermination\n\n▷\n𝒯𝒜ℒ𝒞\nterminates.\n\n\n▷To prove\ntermination\n              of a\ntableau\nalgorithm, find a well-founded measure (function) that is decreased by all rules\n𝑥:𝑐𝑥:𝑐―⊥𝒯⊥𝑥:𝜑⊓𝜓𝑥:𝜑𝑥:𝜓𝒯⊓𝑥:𝜑⊔𝜓𝑥:𝜑\n|\n𝑥:𝜓𝒯⊔𝑥:∀\nR\n.𝜑𝑥\nR\n𝑦𝑦:𝜑𝒯∀𝑥:∃\nR\n.𝜑𝑥\nR\n𝑦𝑦:𝜑𝒯∃\n\n\n▷Proof:\nSketch (full proof very technical)\n\n\n\n1.Any rule except\n𝒯∀\n                    can only be applied once to\n𝑥:𝜓.\n\n\n\n\n2.Rule\n𝒯∀\n                    applicable to\n𝑥:∀\nR\n.𝜓\n                    at most as the number of\n\nR\n-successors of\n𝑥.(those\n𝑦\n                        with\n𝑥\nR\n𝑦\n                        above)\n\n\n\n\n3.The\n\nR\n-successors are generated by\n𝑥:∃\nR\n.𝜃\n                    above,(number bounded by size of input formula)\n\n\n\n\n4.Every rule application to\n𝑥:𝜓\n                    generates constraints\n𝑧:𝜓', where\n𝜓'\n                    a proper sub-formula of\n𝜓.\n\n\n\n:\nComputational Logic12024-12-14\n",
        "sectionId": "7725f4a4",
        "archive": "courses/Jacobs/CompLog",
        "filepath": "kr/slides/alct-termination.en.xhtml"
    },
    {
        "slideContent": "\nComplexity of\n𝒯𝒜ℒ𝒞\n\n▷Idea\n                  Work off\ntableau\nbranches\n                  one after the other.\n(Branch size\n=^\nspace complexity)\n\n\n▷\n                  The size of the\nbranches\n                  is\npolynomial\n                  in the size of the input\nformula:\nbranchsize=#(\ninput formulae\n)+#(\n∃-formulae\n)·#(\n∀-formulae\n)\n\n▷Proof sketch:\n                Re-examine the\ntermination\nproof\n                and count: the first\nsummand\n                comes from\n??, the second one from\n??\n                and\n??\n\n\n▷\n                  The\nsatisfiability\n                  problem for\n𝒜ℒ𝒞\n                  is in\n𝐏𝐒𝐏𝐀𝐂𝐄.\n\n\n▷\n                  The\nsatisfiability\n                  problem for\n𝒜ℒ𝒞\n                  is\n𝐏𝐒𝐏𝐀𝐂𝐄-Complete.\n\n\n▷Proof sketch:\n                Reduce a\n𝐏𝐒𝐏𝐀𝐂𝐄-complete problem to\n𝒜ℒ𝒞-satisfiability\n\n\n▷Time Complexity\n                  The\n𝒜ℒ𝒞\nsatisfiability\n                  problem is in\n𝐄𝐗𝐏𝐓𝐈𝐌𝐄.\n\n\n▷Proof sketch:\n                There can be exponentially many\nbranches\n                (already for\nPL0)\n\n\n\n:\nComputational Logic12024-12-14\n",
        "sectionId": "7725f4a4",
        "archive": "courses/Jacobs/CompLog",
        "filepath": "kr/slides/alc-tableau-complexity.en.xhtml"
    },
    {
        "slideContent": "\nThe functional Algorithm for\n𝒜ℒ𝒞\n\n▷Observation\n(leads to a better treatment for\n∃)\n\n▷the\n𝒯∃-rule generates the constraints\n𝑥\nR\n𝑦\n                  and\n𝑦:𝜓\n                  from\n𝑥:∃\nR\n.𝜓\n\n\n▷this triggers the\n𝒯∀-rule for\n𝑥:∀\nR\n.𝜃𝑖, which generate\n𝑦:𝜃1, ...,\n𝑦:𝜃𝑛\n\n\n▷for\n𝑦\n                  we have\n𝑦:𝜓\n                  and\n𝑦:𝜃1, ...,\n𝑦:𝜃𝑛.(do all of this in a single step)\n\n\n▷we are only interested in non-emptiness, not in particular witnesses(leave them out)\n\n\n▷\n                  The\nfunctional algorithm for\n𝒯𝒜ℒ𝒞\n                  is\n\n\nconsistent(S) =\nif {𝑐,𝑐―}⊆𝑆 then false\nelif ‘𝜑⊓𝜓'∊𝑆 and (‘φ'∉𝑆 or ‘ψ'∉𝑆)\nthen consistent(𝑆∪{𝜑,𝜓})\nelif ‘𝜑⊔𝜓'∊𝑆 and {𝜑,𝜓}∉𝑆\nthen consistent(𝑆∪{𝜑}) or consistent(𝑆∪{𝜓})\nelif forall ‘∃\nR\n.𝜓'∊𝑆\nconsistent({𝜓}∪{𝜃∊𝜃|‘∀\nR\n.𝜃'∊𝑆})\nelse true\n\n▷\n                  Relatively simple to\nimplement.(good implementations optimized)\n\n\n▷But\n                  This is restricted to\n𝒜ℒ𝒞.(extension to other DL difficult)\n\n\n\n:\nComputational Logic12024-12-15\n",
        "sectionId": "7725f4a4",
        "archive": "courses/Jacobs/CompLog",
        "filepath": "kr/slides/alc-functional.en.xhtml"
    },
    {
        "slideContent": "\nExtending the Tableau Algorithm by Concept Axioms\n\n▷concept axioms, e.g.\n𝖼𝗁𝗂𝗅𝖽⊑𝗌𝗈𝗇⊔𝖽𝖺𝗎𝗀𝗁𝗍𝖾𝗋\n              cannot be handled in\n𝒯𝒜ℒ𝒞\n              yet.\n\n\n▷Idea\n                  Whenever a new variable\n𝑦\n                  is introduced (by\n𝒯∃-rule) add the information that axioms hold for\n𝑦.\n\n\n▷Initialize tableau with\n{𝑥:𝜑}∪𝒞𝒜(𝒞𝒜:=\n                      set of\nconcept axioms)\n\n\n▷New rule for\n∃:\n𝑥:∃\nR\n.𝜑𝒞𝒜={𝛼1,...,𝛼𝑛}\n𝑦:𝜑𝑥\nR\n𝑦𝑦:𝛼1...𝑦:𝛼𝑛\n𝒯𝒞𝒜∃\n(instead of\n𝒯∃)\n\n\n▷Problem\n𝒞𝒜:={∃\nR\n.𝑐}\n                  and start tableau with\n𝑥:𝑑\n(non-termination)\n\n\n\n:\nComputational Logic12024-12-15\n",
        "sectionId": "7725f4a4",
        "archive": "courses/Jacobs/CompLog",
        "filepath": "kr/slides/tableau-concept-axioms.en.xhtml"
    },
    {
        "slideContent": "\nNon-Termination of\n𝒯𝒜ℒ𝒞\n              with Concept Axioms\n\n▷Problem\n𝒞𝒜:={∃\nR\n.𝑐}\n                  and start tableau with\n𝑥:𝑑.\n(non-termination)\n\n\n\n𝑥:𝑑 start𝑥:∃\nR\n.𝑐 in 𝒞𝒜𝑥\nR\n𝑦1 𝒯∃𝑦1:𝑐 𝒯∃𝑦1:∃\nR\n.𝑐 𝒯𝒞𝒜∃𝑦1\nR\n𝑦2 𝒯∃𝑦2:𝑐 𝒯∃𝑦2:∃\nR\n.𝑐 𝒯𝒞𝒜∃...\n\n\n\nSolution: Loop-Check\n\n\n▷Instead of a new variable\n𝑦\n                        take an old variable\n𝑧, if we can guarantee that whatever holds for\n𝑦\n                        already holds for\n𝑧.\n\n\n▷We can only do this, iff the\n𝒯∀-rule has been exhaustively applied.\n\n\n\n\n\n                  The consistency problem of\n𝒜ℒ𝒞\n                  with\nconcept axioms\n                  is\ndecidable.\n\n\n▷\n\n▷Proof sketch:\n𝒯𝒜ℒ𝒞\n                with a suitable loop check\nterminates.\n\n\n\n:\nComputational Logic22024-12-15\n",
        "sectionId": "7725f4a4",
        "archive": "courses/Jacobs/CompLog",
        "filepath": "kr/slides/tableau-concept-axioms.en.xhtml"
    },
    {
        "slideContent": "\nInstance Test: Concept Membership\n\n▷\n                  An\ninstance test\n                  computes whether given an\n𝒜ℒ𝒞\nontology\n                  an\nindividual\n                  is a\nmember\n                  of a given\nconcept.\n\n\n▷An Ontology\n\nTBox (terminological Box)ABox (assertional Box, data base)𝗐𝗈𝗆𝖺𝗇 =𝗉𝖾𝗋𝗌𝗈𝗇⊓𝗁𝖺𝗌\n_\n𝖸― 𝗍𝗈𝗇𝗒:𝗉𝖾𝗋𝗌𝗈𝗇 Tony is a person𝗆𝖺𝗇 =𝗉𝖾𝗋𝗌𝗈𝗇⊓𝗁𝖺𝗌\n_\n𝖸 𝗍𝗈𝗇𝗒:𝗁𝖺𝗌\n_\n𝖸 Tony has a y-chrom\n\n\nThis\nentails:\n𝗍𝗈𝗇𝗒:𝗆𝖺𝗇\n                  (Tony is a man).\n\n\n▷Problem\n                  Can we compute this?\n\n\n\n:\nComputational Logic12024-12-14\n",
        "sectionId": "561fbe56",
        "archive": "courses/Jacobs/CompLog",
        "filepath": "kr/slides/instance-test.en.xhtml"
    },
    {
        "slideContent": "\nRealization\n\n▷\nRealization\n                  is the computation of all instance relations between\nABox\n                  objects and\nTBox\nconcepts.\n\n\n▷Observation\n                  It is sufficient to remember the lowest\nconcepts\n                  in the\nsubsumption\ngraph.\n(rest by\nsubsumption)\n\n\n  \n\n\n\nmale_student  \nfemale_student  \ngirl  \nboy  \nman  \nwoman  \nstudent  \nprofessor  \nchild  \nperson  \nobject  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTony  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTimmy  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTerry  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n▷If\n𝗍𝗈𝗇𝗒:𝗆𝖺𝗅𝖾\n_\n𝗌𝗍𝗎𝖽𝖾𝗇𝗍\n                  is known, we do not need\n𝗍𝗈𝗇𝗒:𝗆𝖺𝗇.\n\n\n\n:\nComputational Logic12024-12-14\n",
        "sectionId": "561fbe56",
        "archive": "courses/Jacobs/CompLog",
        "filepath": "kr/slides/realization.en.xhtml"
    },
    {
        "slideContent": "\nABox\n              Inference in\n𝒜ℒ𝒞: Phenomena\n\n▷There are different kinds of interactions between\nTBox\n              and\nABox\n              in\n𝒜ℒ𝒞\n              and in\ndescription logics\n              in general.\n\n\n▷\n\n\nproperty\n\n\nexample\n\n\ninternally\ninconsistent\n\n\n𝗍𝗈𝗇𝗒:𝗌𝗍𝗎𝖽𝖾𝗇𝗍,𝗍𝗈𝗇𝗒:𝗌𝗍𝗎𝖽𝖾𝗇𝗍―\n\ninconsistent\n                                      with a\nTBox\n\n\nTBox: 𝗌𝗍𝗎𝖽𝖾𝗇𝗍⊓𝗉𝗋𝗈𝖿―ABox: 𝗍𝗈𝗇𝗒:𝗌𝗍𝗎𝖽𝖾𝗇𝗍,𝗍𝗈𝗇𝗒:𝗉𝗋𝗈𝖿 \n\n\nimplicit info that is not explicit\n\n\nABox: 𝗍𝗈𝗇𝗒:∀\nhas_grad\n.𝗀𝖾𝗇𝗂𝗎𝗌𝗍𝗈𝗇𝗒\nhas_grad\n𝗆𝖺𝗋𝗒|=𝗆𝖺𝗋𝗒:𝗀𝖾𝗇𝗂𝗎𝗌 \n\ninformation that can be combined with\nTBox\n                                      info\n\n\nTBox: 𝗁𝖺𝗉𝗉𝗒\n_\n𝗉𝗋𝗈𝖿=𝗉𝗋𝗈𝖿⊓∀\nhas_grad\n.𝗀𝖾𝗇𝗂𝗎𝗌ABox: 𝗍𝗈𝗇𝗒:𝗁𝖺𝗉𝗉𝗒\n_\n𝗉𝗋𝗈𝖿,𝗍𝗈𝗇𝗒\nhas_grad\n𝗆𝖺𝗋𝗒|=𝗆𝖺𝗋𝗒:𝗀𝖾𝗇𝗂𝗎𝗌 \n\n\n\n\n:\nComputational Logic12024-12-15\n",
        "sectionId": "561fbe56",
        "archive": "courses/Jacobs/CompLog",
        "filepath": "kr/slides/aboxes.en.xhtml"
    },
    {
        "slideContent": "\nTableau-based Instance Test and Realization\n\n▷Query\n                  Do the\nABox\n                  and\nTBox\n                  together entail\n𝑎:𝜑?(𝑎∊𝜑?)\n\n\n▷Algorithm\n                  Test\n𝑎:𝜑―\n                  for\nconsistency\n                  with\nABox\n                  and\nTBox.(use our\ntableau\nalgorithm)\n\n\n▷Necessary changes(no big deal)\n\n\n▷Normalize\nABox\n                  wrt.\nTBox.(definition expansion)\n\n\n▷Initialize the\ntableau\n                  with\nABox\n                  in\nNNF.(so it can be used)\n\n\n▷\n\nExample: add 𝗆𝖺𝗋𝗒:𝗀𝖾𝗇𝗂𝗎𝗌― to determine 𝐴𝐵𝑜𝑥,𝑇𝐵𝑜𝑥|=𝗆𝖺𝗋𝗒:𝗀𝖾𝗇𝗂𝗎𝗌TBox \n𝗁𝖺𝗉𝗉𝗒\n_\n𝗉𝗋𝗈𝖿=𝗉𝗋𝗈𝖿⊓∀\nhas_grad\n.𝗀𝖾𝗇𝗂𝗎𝗌\n\n\n\n𝗍𝗈𝗇𝗒:𝗉𝗋𝗈𝖿⊓∀\nhas_grad\n.𝗀𝖾𝗇𝗂𝗎𝗌 TBox𝗍𝗈𝗇𝗒\nhas_grad\n𝗆𝖺𝗋𝗒 ABox𝗆𝖺𝗋𝗒:𝗀𝖾𝗇𝗂𝗎𝗌― Query𝗍𝗈𝗇𝗒:𝗉𝗋𝗈𝖿 𝒯⊓𝗍𝗈𝗇𝗒:∀\nhas_grad\n.𝗀𝖾𝗇𝗂𝗎𝗌 𝒯⊓𝗆𝖺𝗋𝗒:𝗀𝖾𝗇𝗂𝗎𝗌 𝒯∀⊥ 𝒯⊥ \n\nABox\n \n𝗍𝗈𝗇𝗒:𝗁𝖺𝗉𝗉𝗒\n_\n𝗉𝗋𝗈𝖿\n\n\n𝗍𝗈𝗇𝗒\nhas_grad\n𝗆𝖺𝗋𝗒\n\n\n\n\n\n\n▷NoteThe\ninstance test\n                  is the base for\nrealization.(remember?)\n\n\n▷Idea\n                  Extend to more complex\nABox\nqueries.\n(e.g. give me all\ninstances\n                      of\n𝜑)\n\n\n\n:\nComputational Logic12024-12-15\n",
        "sectionId": "561fbe56",
        "archive": "courses/Jacobs/CompLog",
        "filepath": "kr/slides/abox-tableau.en.xhtml"
    },
    {
        "slideContent": "\nResource Description Framework\n\n▷\n                  The\nResource Description Framework\n                  (RDF) is a framework for describing resources on the web. It is an\nXML\n                  vocabulary developed by the\nW3C.\n\n\n▷Note\nRDF\n                  is designed to be read and understood by\ncomputers, not to be displayed to people.(it shows)\n\n\n▷\nRDF\n                  can be used for describing(all “objects on the\nWWW”)\n\n\n▷properties for shopping items, such as price and availability\n\n\n▷time schedules for web events\n\n\n▷information about\nweb pages\n                  (content, author, created and modified date)\n\n\n▷content and rating for web pictures\n\n\n▷content for search engines\n\n\n▷electronic libraries\n\n\n\n:\nComputational Logic12024-12-14\n",
        "sectionId": "3c9a87ea",
        "archive": "courses/Jacobs/CompLog",
        "filepath": "semweb/slides/rdf-nutshell.en.xhtml"
    },
    {
        "slideContent": "\nResources and\nURIs\n\n▷RDF\n              describes resources with properties and property values.\n\n\n▷RDF\n              uses Web identifiers (URIs) to identify resources.\n\n\n▷\n                  A\nresource\n                  is anything that can have a\nURI,\nsuch as\nhttp://www.fau.de.\n\n\n▷\n                  A\nproperty\n                  is a resource that has a name, such as\nauthor\n                  or\nhomepage, and a\nproperty value\n                  is the value of a property,\nsuch as\nMichael Kohlhase\n                      or\nhttp://kwarc.info/kohlhase.(a property value can be another resource)\n\n\n▷\n                  A\nRDF\nstatement\n𝑠\n                  (also known as a\ntriple) consists of a\nresource\n                  (the\nsubject\n                  of\n𝑠), a\nproperty\n                  (the\npredicate\n                  of\n𝑠), and a\nproperty value\n                  (the\nobject\n                  of\n𝑠). A\nset\n                  of\nRDF\ntriples\n                  is called an\nRDF graph.\n\n\n▷\n                  Statements:\n[This slide]\nsubj\n\n                    has been [author]\npred\ned by [Michael Kohlhase]\nobj\n\n\n\n\n:\nComputational Logic12024-12-14\n",
        "sectionId": "3c9a87ea",
        "archive": "courses/Jacobs/CompLog",
        "filepath": "semweb/slides/rdf-resources.en.xhtml"
    },
    {
        "slideContent": "\nXML\n              Syntax for\nRDF\n\n▷RDF\n              is a concrete\nXML\n              vocabulary for writing statements\n\n\n▷\n                  The following\nRDF\n                  document could describe the slides as a resource\n\n\n<?xml version=\"1.0\"?>\n<rdf:RDF xmlns:rdf=\"http://www.w3.org/1999/02/22―rdf―syntax―ns#\"\nxmlns:dc= \"http://purl.org/dc/elements/1.1/\">\n<rdf:Description about=\"https://.../CompLog/kr/en/rdf.tex\">\n<dc:creator>Michael Kohlhase</dc:creator>\n<dc:source>http://www.w3schools.com/rdf</dc:source>\n</rdf:Description>\n</rdf:RDF>\n\nThis\nRDF\n                  document makes two statements:\n\n\n▷The subject of both is given in the\nabout\n                  attribute of the\nrdf:Description\n                  element\n\n\n▷The\npredicates\n                  are given by the element names of its\nchildren\n\n\n▷The\nobjects\n                  are given in the elements as\nURIs\n                  or\nliteral\n                  content.\n\n\n▷Intuitively\nRDF\n                  is a web-scalable way to write down\nABox\n                  information.\n\n\n\n:\nComputational Logic12024-12-14\n",
        "sectionId": "3c9a87ea",
        "archive": "courses/Jacobs/CompLog",
        "filepath": "semweb/slides/rdf-xml.en.xhtml"
    },
    {
        "slideContent": "\nRDFa\n              as an Inline\nRDF\n              Markup Format\n\n▷Problem\nRDF\n                  is a standoff markup format(annotate by\nURIs pointing into other files)\n\n\n\nRDFa\n                  (RDF\n                  annotations) is a markup scheme for inline annotation (as\nXML\nattributes) of\nRDF\ntriples.\n\n\n▷\n\n\n<div xmlns:dc=\"http://purl.org/dc/elements/1.1/\" id=\"address\">\n<h2 about=\"#address\" property=\"dc:title\">RDF as an Inline RDF Markup Format</h2>\n<h3 about=\"#address\" property=\"dc:creator\">Michael Kohlhase</h3>\n<em about=\"#address\" property=\"dc:date\" datatype=\"xsd:date\"\ncontent=\"2009―11―11\">November 11., 2009</em>\n</div>\n\n\n\n\n\nhttps://svn.kwarc.info/.../CompLog/kr/slides/rdfa.tex  \nRDFa as an Inline RDF Markup Format  \n\n\n2009―11―11\n\n (\n\nxsd:date\n\n)  \nMichael Kohlhase  \n\nhttp://purl.org/dc/elements/1.1/title  \n\nhttp://purl.org/dc/elements/1.1/date  \n\nhttp://purl.org/dc/elements/1.1/creator  \n\n\n\n \n\n\n:\nComputational Logic12024-12-14\n",
        "sectionId": "3c9a87ea",
        "archive": "courses/Jacobs/CompLog",
        "filepath": "semweb/slides/rdfa-nutshell.en.xhtml"
    },
    {
        "slideContent": "\nRDF\n              as an ABox Language for the Semantic Web\n\n▷Idea\nRDF\n                  triples are ABox entries\nℎ\nR\n𝑠\n                  or\nℎ:𝜑.\n\n\n▷\nℎ\n                  is the resource for Ian Horrocks,\n𝑠\n                  is the resource for Ulrike Sattler,\n\nR\n\n                  is the relation “hasColleague”, and\n𝜑\n                  is the class\nfoaf:Person\n\n\n<rdf:Description about=\"some.uri/person/ian_horrocks\">\n<rdf:type rdf:resource=\"http://xmlns.com/foaf/0.1/Person\"/>\n<hasColleague resource=\"some.uri/person/uli_sattler\"/>\n</rdf:Description>\n\n▷Idea\n                  Now, we need an similar language for TBoxes(based on\n𝒜ℒ𝒞)\n\n\n\n:\nComputational Logic12024-12-14\n",
        "sectionId": "3c9a87ea",
        "archive": "courses/Jacobs/CompLog",
        "filepath": "semweb/slides/rdf-dl.en.xhtml"
    },
    {
        "slideContent": "\nSPARQL\n              an\nRDF\n              Query language\n\n▷\nSPARQL, the “SPARQL\n                  Protocol and\nRDF\n                  Query Language” is an\nRDF\nquery language, able to retrieve and manipulate\ndata\n                  stored in\nRDF. The\nSPARQL\n                  language was standardized by the World Wide Web Consortium in 2008 [PS08].\n\n\n▷SPARQL\n              is pronounced like the word “sparkle”.\n\n\n▷\n                  A system is called a\nSPARQL endpoint,\niff\n                  it answers\nSPARQL\nqueries.\n\n\n▷Query\n                  for person names and their e-mails from a\ntriplestore\n                  with FOAF data.\n\n\nPREFIX foaf: <http://xmlns.com/foaf/0.1/>\nSELECT ?name ?email\nWHERE {\n?person a foaf:Person.\n?person foaf:name ?name.\n?person foaf:mbox ?email.\n}\n\n\n:\nComputational Logic12024-12-14\n",
        "sectionId": "3c9a87ea",
        "archive": "courses/Jacobs/CompLog",
        "filepath": "semweb/slides/sparql.en.xhtml"
    },
    {
        "slideContent": "\nSPARQL\n              Applications: DBPedia\n\n\n\n▷Typical Application\n                                  DBPedia screen-scrapes Wikipedia fact boxes for\nRDF\n                                  triples and uses\nSPARQL\n                                  for\nquerying\n                                  the induced\ntriplestore.\n\n\n▷DBPedia Query\n                                  People who were born in Erlangen before 1900(http://dbpedia.org/snorql)\n\n\nSELECT ?name ?birth ?death ?person WHERE {\n?person dbo:birthPlace :Erlangen .\n?person dbo:birthDate ?birth .\n?person foaf:name ?name .\n?person dbo:deathDate ?death .\nFILTER (?birth < \"1900―01―01\"^^xsd:date) .\n}\nORDER BY ?name\n\n▷The answers include Emmy Noether and Georg Simon Ohm.\n\n\n\n\n\n\n\n \n\n\n:\nComputational Logic12024-12-14\n",
        "sectionId": "3c9a87ea",
        "archive": "courses/Jacobs/CompLog",
        "filepath": "semweb/slides/dbpedia.en.xhtml"
    },
    {
        "slideContent": "\nA more complex DBPedia Query\n\n▷Demo\n                  DBPedia\nhttp://dbpedia.org/snorql/Query: Soccer players born in a country with more than 10 M inhabitants, who play as goalie in a club that has a stadium with more than 30.000 seats.Answer:\ncomputed by DBPedia from a\nSPARQL\nquery\n\n\n\n\n\n:\nComputational Logic22024-12-14\n",
        "sectionId": "3c9a87ea",
        "archive": "courses/Jacobs/CompLog",
        "filepath": "semweb/slides/dbpedia.en.xhtml"
    },
    {
        "slideContent": "\nTriple Stores: the Semantic Web Databases\n\n▷\n                  A\ntriplestore\n                  or\nRDF store\n                  is a purpose-built database for the storage\nRDF graphs\n                  and retrieval of\nRDF\ntriples\n                  usually through variants of\nSPARQL.\n\n\n▷\n                  Common\ntriplestores\n                  include\n\n\n▷Virtuoso:\nhttps://virtuoso.openlinksw.com/(used in DBpedia)\n\n\n▷GraphDB:\nhttp://graphdb.ontotext.com/(often used in WissKI)\n\n\n▷blazegraph:\nhttps://blazegraph.com/(open source; used in WikiData)\n\n\n▷\n                  A\ndescription logic reasoner\nimplements\n                  of reaonsing services based on a satisfiabiltiy test for\ndescription logics.\n\n\n▷\n                  Common\ndescription logic reasoners\n                  include\n\n\n▷FACT++:\nhttp://owl.man.ac.uk/factplusplus/\n\n\n▷HermiT:\nhttp://www.hermit-reasoner.com/\n\n\n▷Intuition\nTriplestores\n                  concentrate on\nquerying\n                  very large\nABoxes\n                  with partial consideration of the\nTBox, while\nDL reasoners\n                  concentrate on the full set of ontology inference services, but fail on large\nABoxes.\n\n\n\n:\nComputational Logic12024-12-14\n",
        "sectionId": "3c9a87ea",
        "archive": "courses/Jacobs/CompLog",
        "filepath": "semweb/slides/triple-store.en.xhtml"
    },
    {
        "slideContent": "\nReminder: Classical Search Problems\n\n▷Solitaire as a Search Problem\n\n\n\n\n▷States: Card positions (e.g.\nposition_Jspades=Qhearts).\n\n\n▷Actions: Card moves (e.g.\nmove_Jspades_Qhearts_freecell4).\n\n\n▷Initial state: Start configuration.\n\n\n▷Goal states: All cards “home”.\n\n\n▷Solutions: Card moves solving this game.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-15\n",
        "sectionId": "b6901db7",
        "archive": "courses/FAU/AI/course",
        "filepath": "search/slides/recap.en.xhtml"
    },
    {
        "slideContent": "\nPlanning\n\n▷Ambition\n                  Write one program that can solve all classical\nsearch problems.\n\n\n▷IdeaFor\nCSP, going from “state/action-level search” to “problem-description level search” did the trick.\n\n\n▷\n                  Let\nΠ\n                  be a\nsearch problem\n(see\n??)\n\n\n▷The\nblackbox description\n                  of\nΠ\n                  is an\nAPI\n                  providing functionality allowing to construct the state space:\nInitialState(),\nGoalTest(𝑠), ...\n\n▷“Specifying the problem”\n=^\nprogramming\n                  the\nAPI.\n\n\n▷The\ndeclarative description\n                  of\nΠ\n                  comes in a\nproblem description language. This allows to\nimplement\n                  the\nAPI, and much more.\n\n\n▷“Specifying the problem”\n=^\n                  writing a problem description.\n\n\n▷Here, “problem description language”\n=^\nplanning language.(up next)\n\n\n▷But Wait\n                  Didn’t we do this already in the last chapter with logics?\n(For the Wumpus?)\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "b6901db7",
        "archive": "courses/FAU/AI/course",
        "filepath": "planning/slides/planning-vs-search.en.xhtml"
    },
    {
        "slideContent": "\nFluents: Time-Dependent Knowledge in Planning\n\n▷Recall from\n??We can represent the Wumpus rules in\nlogical systems.\n(propositional/first-order/ALC)\n\n\n▷Use\ninference\n                  systems to deduce new\nworld knowledge\n                  from\npercepts\n                  and\nactions.\n\n\n▷Problem\n                  Representing (changing)\npercepts\n                  immediately leads to\ncontradictions!\n\n\n▷If the\nagent\n                  moves and a\ncell\n                  with\na\ndraft\n                      (a\nperceived\n                      breeze)\n                  is followed by one without.\n\n\n▷Obvious Idea\n                  Make representations of\npercepts\n                  time-dependent\n\n\n▷𝐷𝑡\n                  for\n𝑡∊ℕ\n                  for\nPL0\n                  and\ndraft(𝑡)\n                  in\nPL1\n                  and\nPLnq.\n\n\n▷\n                  We use the word\nfluent\n                  to refer an aspect of the world that changes, all others we call\natemporal.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "7136b75a",
        "archive": "courses/FAU/AI/course",
        "filepath": "logic/slides/fluents.en.xhtml"
    },
    {
        "slideContent": "\nRecap: Logic-Based Agents\n\n▷Recall\n                  A\nmodel-based agent\n                  uses\ninference\n                  to model the\nenvironment,\npercepts, and\nactions.\n\n\n\n\nfunction KB―AGENT (𝑝𝑒𝑟𝑐𝑒𝑝𝑡) returns an action\npersistent: 𝐾𝐵, a knowledge base\n𝑡, a counter, initially 0, indicating time\nTELL(𝐾𝐵, MAKE―PERCEPT―SENTENCE(𝑝𝑒𝑟𝑐𝑒𝑝𝑡,𝑡))\n𝑎𝑐𝑡𝑖𝑜𝑛 := ASK(𝐾𝐵, MAKE―ACTION―QUERY(𝑡))\nTELL(𝐾𝐵, MAKE―ACTION―SENTENCE(𝑎𝑐𝑡𝑖𝑜𝑛,𝑡))\n𝑡 := 𝑡+1\nreturn 𝑎𝑐𝑡𝑖𝑜𝑛\n\n▷Still Unspecified\n(up next)\n\n\n▷MAKE―PERCEPT―SENTENCE: the effects of\npercepts.\n\n\n▷MAKE―ACTION―QUERY: what is the best next\naction?\n\n\n▷MAKE―ACTION―SENTENCE: the effects of that\naction.\n\n\nIn particular, we will look at the effect of time/change.\n(neglected so far)\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-16\n",
        "sectionId": "7136b75a",
        "archive": "courses/FAU/AI/course",
        "filepath": "logic/slides/logic-agent-recap.en.xhtml"
    },
    {
        "slideContent": "\nFluents: Modeling the Agent’s Sensors\n\n▷Idea\n                  Relate\npercept\nfluents\n                  to\natemporal\n                  cell attributes.\n\n\n▷E.g., if the\nagent\nperceives\n                  a\ndraft\n                  at time\n𝑡, when it is in cell\n[𝑥,𝑦], then there must be a\nbreeze\n                  there:\n∀𝑡,𝑥,𝑦.Ag@(𝑡,𝑥,𝑦)⇒(draft(𝑡)⇔breeze(𝑥,𝑦))\n\n▷\nAxioms\n                  like these model the\nagent’s\nsensors\n                  —here that they are totally reliable: there is a\nbreeze, iff the\nagent\n                      feels a\ndraft.\n\n\n▷\n                  We call\nfluents\n                  that describe the\nagent’s\nsensors\nsensor axioms.\n\n\n▷ProblemWhere do\nfluents\n                  like\nAg@(𝑡,𝑥,𝑦)\n                  come from?\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "7136b75a",
        "archive": "courses/FAU/AI/course",
        "filepath": "logic/slides/sensor-fluents.en.xhtml"
    },
    {
        "slideContent": "\nDigression: Fluents and Finite Temporal Domains\n\n▷ObservationFluents\n                  like\n∀𝑡,𝑥,𝑦.Ag@(𝑡,𝑥,𝑦)⇒(draft(𝑡)⇔breeze(𝑥,𝑦))\n                  from\n??\n                  are best represented in\nfirst-order logic. In\nPL0\n                  and\nPLnq\n                  we would have to use concrete instances like\nAg@(7,2,1)⇒(draft(7)⇔breeze(2,1))\n                  for all suitable\n𝑡,\n𝑥, and\n𝑦.\n\n\n▷Problem\n                  Unless we restrict ourselves to\nfinite\n                  domains and\nan\nend time\n𝑡end\n                  we have\ninfinitely\n                  many\naxioms. Even then, formalization in\nPL0\n                  and\nPLnq\n                  is very tedious.\n\n\n▷Solution\n                  Formalize in\nfirst-order logic\n                  and then compile down:\n\n\n1.enumerate ranges of\nbound\nvariables, instantiate body,\n(⤳\nPLnq)\n\n\n2.translate\nPLnq\n                  atoms to\npropositional variables.(⤳\nPL0)\n\n\n▷In Practice\n                  The choice of domain,\nend time, and logic is up to\nagent\n                  designer, weighing expressivity vs.\nefficiency\n                  of inference.\n\n\n▷WLOG: We will use\nPL1\n              in the following.\n(easier to read)\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "7136b75a",
        "archive": "courses/FAU/AI/course",
        "filepath": "logic/slides/end-fluent.en.xhtml"
    },
    {
        "slideContent": "\nFluents: Effect Axioms for the Transition Model\n\n▷ProblemWhere do\nfluents\n                  like\nAg@(𝑡,𝑥,𝑦)\n                  come from?\n\n\n▷Thus\n                  We also need\nfluents\n                  to keep track of the\nagent’s\nactions.\n(The\ntransition model\n                      of the underlying\nsearch problem).\n\n\n▷Idea\n                  We also use\nfluents\n                  for the representation of\nactions.\n\n\n▷The\naction\n                  of “going forward” at time\n𝑡\n                  is captured by the\nfluent\nforw(𝑡).\n\n\n▷\nEffect axioms\n                  describe how the\nenvironment\n                  changes under an\nagent’s\nactions.\n\n\n▷If the\nagent\n                  is in\ncell\n[1,1]\nfacing east\n                  at time 0 and goes\nforward, she is in\ncell\n[2,1]\n                  and no longer in\n[1,1]:\nAg@(0,1,1)∧faceeast(0)∧forw(0)⇒Ag@(1,2,1)∧¬Ag@(1,1,1)Generally:\n(barring exceptions for domain border cells)\n∀𝑡,𝑥,𝑦.Ag@(𝑡,𝑥,𝑦)∧faceeast(𝑡)∧forw(𝑡)⇒Ag@(𝑡+1,𝑥+1,𝑦)∧¬Ag@(𝑡+1,𝑥,𝑦)This compiles down to\n16·𝑡end\nPLnq/PL0\naxioms.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "7136b75a",
        "archive": "courses/FAU/AI/course",
        "filepath": "logic/slides/transition-fluents.en.xhtml"
    },
    {
        "slideContent": "\nFrames and Frame Axioms\n\n▷Problem\nEffect axioms\n                  are not enough.\n\n\n▷Say that the\nagent\n                  has an arrow at time 0, and then moves\nforward\n                  into\n[2,1],\nperceives\n                  a\nglitter, and knows that the\nWumpus\n                  is ahead.\n\nTo evaluate the\naction\nshoot(1)\n                  the corresponding\neffect axiom\n                  needs to know\nhavarrow(1), but cannot prove it from\nhavarrow(0).\n\nProblem: The information of having an arrow has been lost in the move forward.\n\n\n▷\n                  The\nframe problem\n                  describes that for a representation of\nactions\n                  we need to formalize their effects on the aspects they change, but also their non-effect on the static\nframe of reference.\n\n\n▷Partial Solution(there are many many more; some better)\n\nFrame axioms\n                      formalize that particular\nfluents\n                      are invariant under a given\naction.\n\n\n▷Problem\n                  For an\nagent\n                  with\n𝑛\nactions\n                  and an\nenvironment\n                  with\n𝑚\nfluents, we need\n𝒪(𝑛𝑚)\nframe axioms.\n\nRepresenting and reasoning with them easily drowns out the\nsensor\n                  and\ntransition models.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "7136b75a",
        "archive": "courses/FAU/AI/course",
        "filepath": "logic/slides/frame-problem.en.xhtml"
    },
    {
        "slideContent": "\nA Hybrid Agent for the Wumpus World\n\n▷A Hybrid AgentThis\nagent\n                  uses\n\n\n▷logic\ninference\n                  for\nsensor\n                  and\ntransition modeling,\n\n\n▷special\ncode\n                  and\n𝐴*\n                  for\naction\n                  selection & route planning.\n\n\nfunction HYBRID―WUMPUS―AGENT(𝑝𝑒𝑟𝑐𝑒𝑝𝑡) returns an action\ninputs: 𝑝𝑒𝑟𝑐𝑒𝑝𝑡, a list, [stench,breeze,glitter,bump,scream]\npersistent: 𝐾𝐵, a knowledge base, initially the atemporal\n\"wumpus physics\"\n𝑡, a counter, initially 0, indicating time\n𝑝𝑙𝑎𝑛, an action sequence, initially empty\nTELL(𝐾𝐵, MAKE―PERCEPT―SENTENCE(𝑝𝑒𝑟𝑐𝑒𝑝𝑡,𝑡))\n\nthen some special\ncode\n                  for action selection, and then\n(up next)\n\n\n𝑎𝑐𝑡𝑖𝑜𝑛 := POP(𝑝𝑙𝑎𝑛)\nTELL(𝐾𝐵, MAKE―ACTION―SENTENCE(𝑎𝑐𝑡𝑖𝑜𝑛,𝑡))\n𝑡 := 𝑡+1\nreturn 𝑎𝑐𝑡𝑖𝑜𝑛\n\nSo far, not much new over our original version.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-15\n",
        "sectionId": "7136b75a",
        "archive": "courses/FAU/AI/course",
        "filepath": "logic/slides/hybrid-agent.en.xhtml"
    },
    {
        "slideContent": "\nA Hybrid Agent: Custom Action Selection\n\n▷A Hybrid Agent (continued)So that we can plan the best strategy:\n\n\nTELL(𝐾𝐵, the temporal \"physics\" sentences for time 𝑡)\n𝑠𝑎𝑓𝑒 := {[𝑥,𝑦]|\nASK(𝐾𝐵,OK(𝑡,𝑥,𝑦))=𝖳\n}\nif ASK(𝐾𝐵,glitter(𝑡)) = 𝖳 then\n𝑝𝑙𝑎𝑛 := [grab] + PLAN―ROUTE(𝑐𝑢𝑟𝑟𝑒𝑛𝑡,{[1,1]},𝑠𝑎𝑓𝑒) + [exit]\nif 𝑝𝑙𝑎𝑛 is empty then\n𝑢𝑛𝑣𝑖𝑠𝑖𝑡𝑒𝑑 := {[𝑥,𝑦]|\nASK(𝐾𝐵,Ag@(𝑡',𝑥,𝑦))=𝖥\n} for all 𝑡'≤𝑡\n𝑝𝑙𝑎𝑛 := PLAN―ROUTE(𝑐𝑢𝑟𝑟𝑒𝑛𝑡,𝑢𝑛𝑣𝑖𝑠𝑖𝑡𝑒𝑑∪𝑠𝑎𝑓𝑒,𝑠𝑎𝑓𝑒)\nif 𝑝𝑙𝑎𝑛 is empty and ASK(𝐾𝐵,havarrow(𝑡)) = 𝖳 then\n𝑝𝑜𝑠𝑠𝑖𝑏𝑙𝑒\n_\n𝑤𝑢𝑚𝑝𝑢𝑠 := {𝑥,𝑦|[𝑥,𝑦]}\nASK(𝐾𝐵,¬wumpus(𝑡,𝑥,𝑦)) = 𝖥\n\n𝑝𝑙𝑎𝑛 := PLAN―SHOT(𝑐𝑢𝑟𝑟𝑒𝑛𝑡,𝑝𝑜𝑠𝑠𝑖𝑏𝑙𝑒\n_\n𝑤𝑢𝑚𝑝𝑢𝑠,𝑠𝑎𝑓𝑒)\nif 𝑝𝑙𝑎𝑛 is empty then // no choice but to take a risk\n𝑛𝑜𝑡\n_\n𝑢𝑛𝑠𝑎𝑓𝑒 := {[𝑥,𝑦]|\nASK(𝐾𝐵,¬OK(𝑡,𝑥,𝑦)) = 𝖥\n}\n𝑝𝑙𝑎𝑛 := PLAN―ROUTE(𝑐𝑢𝑟𝑟𝑒𝑛𝑡,𝑢𝑛𝑣𝑖𝑠𝑖𝑡𝑒𝑑∪𝑛𝑜𝑡\n_\n𝑢𝑛𝑠𝑎𝑓𝑒,𝑠𝑎𝑓𝑒)\nif 𝑝𝑙𝑎𝑛 is empty then\n𝑝𝑙𝑎𝑛 := PLAN―ROUTE(𝑐𝑢𝑟𝑟𝑒𝑛𝑡,{[1,1]},𝑠𝑎𝑓𝑒) + [exit]\n\nNote that\nOK\nwumpus, and\nglitter\n                  are\nfluents, since the Wumpus might have died or the gold might have been\ngrabbed.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 122024-12-15\n",
        "sectionId": "7136b75a",
        "archive": "courses/FAU/AI/course",
        "filepath": "logic/slides/hybrid-agent.en.xhtml"
    },
    {
        "slideContent": "\nA Hybrid Agent: Custom Action Selection\n\n▷Action SelectionAnd the\ncode\n                  for\nPLAN―ROUTE\n(PLAN―SHOT\n                      similar)\n\n\nfunction PLAN―ROUTE(curr,goals,allowed) returns an action sequence\ninputs: curr, the agent’s current position\ngoals, a set of squares;\ntry to plan a route to one of them\nallowed, a set of squares that can form part of the route\nproblem := ROUTE―PROBLEM(curr,goals,allowed)\nreturn 𝐴*(problem)\n\n▷Evaluation\n                  Even though this works for the Wumpus world, it is not the “universal, logic-based problem solver” we dreamed of!\n\n\n▷\n                  Planning tries to solve this with another representation of\nactions.(up next)\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 132024-12-15\n",
        "sectionId": "7136b75a",
        "archive": "courses/FAU/AI/course",
        "filepath": "logic/slides/hybrid-agent.en.xhtml"
    },
    {
        "slideContent": "\nHow does a\nplanning language\n              describe a problem?\n\n▷\n                  A\nplanning language\n                  is a way of describing the components of a\nsearch problem\n                  via\nformulae\n                  of a\nlogical system. In particular the\n\n\n▷states\n                  (vs. blackbox:\ndata structures).\n(E.g.: predicate\n𝐸𝑞(.,.).)\n\n\n▷initial state\n𝐼\n                  (vs.\ndata structures).\n(E.g.:\n𝐸𝑞(𝑥,1).)\n\n\n▷goal states\n𝐺\n                  (vs. a goal test).\n(E.g.:\n𝐸𝑞(𝑥,2).)\n\n\n▷set\n𝐴\n                  of\nactions\n                  in terms of\npreconditions\n                  and\neffects\n                  (vs. functions returning applicable\nactions\n                  and\nsuccessor states).\n(E.g.: “increment\n𝑥: pre\n𝐸𝑞(𝑥,1), eff\n𝐸𝑞(𝑥∧2)∧¬𝐸𝑞(𝑥,1)”.)\n\n\nA logical description of all of these is called a\nplanning task.\n\n\n▷\n                  Solution (plan)\n=^\n                  sequence of\nactions\n                  from\n𝒜, transforming\nℐ\n                  into a\nstate\n                  that satisfies\n𝒢.\n(E.g.: “increment\n𝑥”.)\n\nThe process of finding a\nplan\n                  given a\nplanning task\n                  is called\nplanning.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "5f883ad1",
        "archive": "courses/FAU/AI/course",
        "filepath": "planning/slides/planning-task.en.xhtml"
    },
    {
        "slideContent": "\nPlanning Language Overview\n\n▷Disclaimer\nPlanning languages\n                go way beyond classical\nsearch problems. There are variants for inaccessible, stochastic, dynamic, continuous, and multi-agent settings.\n\n\n▷We focus on classical search for simplicity (and practical relevance).\n\n\n▷For a comprehensive overview, see [GNT04].\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-16\n",
        "sectionId": "5f883ad1",
        "archive": "courses/FAU/AI/course",
        "filepath": "planning/slides/planning-languages-overview.en.xhtml"
    },
    {
        "slideContent": "\nApplication:\nNatural Language Generation\n\n\n\n▷Input: Tree-adjoining grammar, intended meaning.\n\n\n▷Output: Sentence expressing that meaning.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "5f883ad1",
        "archive": "courses/FAU/AI/course",
        "filepath": "planning/slides/planning-ex-nlg.en.xhtml"
    },
    {
        "slideContent": "\nApplication: Business Process Templates at SAP\n\n   \n\n\n▷Input: model of behavior of activities on business objects, process endpoint.\n\n\n▷Output: Process template leading to this point.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-16\n",
        "sectionId": "5f883ad1",
        "archive": "courses/FAU/AI/course",
        "filepath": "planning/slides/planning-ex-SAP.en.xhtml"
    },
    {
        "slideContent": "\nApplication: Automatic Hacking\n\n\n\n\n\n\n\n\n\n▷Input: Network configuration, location of sensible data.\n\n\n▷Output: Sequence of exploits giving access to that data.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-16\n",
        "sectionId": "5f883ad1",
        "archive": "courses/FAU/AI/course",
        "filepath": "planning/slides/planning-ex-autohack.en.xhtml"
    },
    {
        "slideContent": "\nReminder: General Problem Solving, Pros and Cons\n\n▷Powerful\n                  In some applications, generality is absolutely necessary.\n(E.g. SAP)\n\n\n▷Quick\n                  Rapid prototyping: 10s\nlines\n                  of problem description vs. 1000s\nlines\n                  of C++ code.\n(E.g. language generation)\n\n\n▷Flexible\n                  Adapt/maintain\nthe description.\n(E.g. network security)\n\n\n▷Intelligent\n                  Determines automatically how to solve a complex problem\nefficiently!\n(The ultimate goal, no?!)\n\n\n▷Efficiency loss\n                  Without any domain-specific knowledge about\nchess, you don’t beat Kasparov ...\n\n▷Trade-off between “automatic and general” vs. “manual work but\nefficient”.\n\n\n▷Research Question\n                  How to make fully automatic\nalgorithms\nefficient?\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-15\n",
        "sectionId": "5f883ad1",
        "archive": "courses/FAU/AI/course",
        "filepath": "search/slides/gps-procons.en.xhtml"
    },
    {
        "slideContent": "\nSearch vs. planning\n\n▷Consider the task\nget milk, bananas, and a cordless drill.\n\n\n▷Standard\nsearch algorithms\n            seem to fail miserably:\n\n\n\n\nAfter-the-fact\nheuristic/goal test inadequate\n\n\n▷Planning systems do the following:\n\n\n1.open up action and goal representation to allow selection\n\n\n2.divide-and-conquer by subgoaling\n\n\n▷relax requirement for sequential construction of solutions\n\n\nSearch Planning States 𝙻𝚒𝚜𝚙 data structures Logical sentences Actions 𝙻𝚒𝚜𝚙 code Preconditions/outcomes Goal 𝙻𝚒𝚜𝚙 code Logical sentence (conjunction)Plan Sequence from 𝑆0 Constraints on actions \n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-16\n",
        "sectionId": "5f883ad1",
        "archive": "courses/FAU/AI/course",
        "filepath": "planning/slides/search-vs-planning.en.xhtml"
    },
    {
        "slideContent": "\nReminder: Greedy Best-First Search and\n𝐴*\n\n▷Recall\n                Our\nheuristic\nsearch algorithms(duplicate pruning\n                    omitted for simplicity)\n\n\nfunction Greedy_Best―First_Search (problem)\nreturns a solution, or failure\n𝑛 := node with 𝑛.state=problem.InitialState\n𝑓𝑟𝑜𝑛𝑡𝑖𝑒𝑟 := priority queue ordered by ascending ℎ, initially [𝑛]\nloop do\nif Empty?(𝑓𝑟𝑜𝑛𝑡𝑖𝑒𝑟) then return failure\n𝑛 := Pop(𝑓𝑟𝑜𝑛𝑡𝑖𝑒𝑟)\nif problem.GoalTest(𝑛.state) then return Solution(𝑛)\nfor each action 𝑎 in problem.Actions(𝑛.state) do\n𝑛' := ChildNode(problem,𝑛,𝑎)\nInsert(𝑛', ℎ(𝑛'), 𝑓𝑟𝑜𝑛𝑡𝑖𝑒𝑟)\n\nFor\n𝐴*\n\n\n▷order\n𝑓𝑟𝑜𝑛𝑡𝑖𝑒𝑟\n                by\n𝑔+ℎ\n                instead of\nℎ\n(line 4)\n\n\n▷insert\n𝑔(𝑛')+ℎ(𝑛')\n                instead of\nℎ(𝑛')\n                to\n𝑓𝑟𝑜𝑛𝑡𝑖𝑒𝑟\n(last line)\n\n\n▷Is greedy best-first search optimal? No\n⤳\nsatisficing planning.\n\n\n▷Is\n𝐴*\n            optimal? Yes, but only if\nℎ\n            is\nadmissible\n⤳\noptimal planning,\nwith such\nℎ.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-15\n",
        "sectionId": "5f883ad1",
        "archive": "courses/FAU/AI/course",
        "filepath": "planning/slides/heuristic-search-reminder.en.xhtml"
    },
    {
        "slideContent": "\nps. “Making Fully Automatic Algorithms\nEfficient”\n\n▷\n\n\n\n\n\n\n\n▷𝑛\n                                    blocks,\n1\n                                    hand.\n\n\n▷A single\naction\n                                    either takes a block with the hand or puts a block we’re holding onto some other block/the table.\n\n\n\n\n \n\nblocks states 1 1 2 3 3 13 4 73 5 501 6 4051 7 37633 8 394353 blocks states 9 4596553 10 58941091 11 824073141 12 12470162233 13 202976401213 14 3535017524403 15 65573803186921 16 1290434218669921 \n\n\n▷\nState spaces\n                  typically are huge even for simple problems.\n\n\n▷In other words\n                  Even solving “simple problems” automatically (without help from a human) requires a form of\nintelligence.\n\n\n▷\n                  With blind search, even the largest\nsuper computer\n                  in the world won’t scale beyond 20 blocks!\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-16\n",
        "sectionId": "5f883ad1",
        "archive": "courses/FAU/AI/course",
        "filepath": "search/slides/gps-efficient.en.xhtml"
    },
    {
        "slideContent": "\nAlgorithmic Problems in Planning\n\n▷\n                  We speak of\nsatisficing planning\n                  ifInput: A planning task Π.Output: A plan for Π, or “unsolvable” if no plan for Π exists. and of\noptimal planning\n                  ifInput: A planning task Π.Output: An optimal plan for Π, or “unsolvable” if no plan for Π exists. \n\n\n▷The techniques successful for either one of these are almost\ndisjoint. And\nsatisficing planning\n              is\nmuch\n              more\nefficient\n              in practice.\n\n\n▷\n                  Programs solving these problems are called (optimal)\nplanner,\nplanning system, or\nplanning tool.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "5f883ad1",
        "archive": "courses/FAU/AI/course",
        "filepath": "planning/slides/planners.en.xhtml"
    },
    {
        "slideContent": "\nOur Agenda for This Topic\n\n▷Now\n                Background,\nplanning languages,\ncomplexity.\n\n\n▷Sets up the framework.\nComputational complexity\n                is essential to distinguish different\nalgorithmic\n                problems, and for the design of\nheuristic functions.\n(see next)\n\n\n▷Next\n                How to automatically generate a\nheuristic function, given\nplanning language\n                input?\n\n\n▷Focussing on\nheuristic search\n                as the solution method, this is the main question that needs to be answered.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-15\n",
        "sectionId": "5f883ad1",
        "archive": "courses/FAU/AI/course",
        "filepath": "planning/slides/planning-agenda.en.xhtml",
        "video_name": "AI1_25thDec.m4v",
        "start_time": 2241.41,
        "end_time": 2303.01
    },
    {
        "slideContent": "\nOur Agenda for This Chapter\n\n1.The History of Planning: How did this come about?\n\n\n▷Gives you some background, and motivates our choice to focus on\nheuristic search.\n\n\n2.The STRIPS Planning Formalism: Which concrete planning formalism will we be using?\n\n\n▷Lays the framework we’ll be looking at.\n\n\n3.The PDDL Language: What do the input files for off-the-shelf planning software look like?\n\n\n▷So you can actually play around with such software.\n(Exercises!)\n\n\n4.Planning Complexity: How\ncomplex\n            is\nplanning?\n\n\n▷The price of generality is complexity, and here’s what that “price” is, exactly.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-15\n",
        "sectionId": "5f883ad1",
        "archive": "courses/FAU/AI/course",
        "filepath": "planning/slides/planning-framework-agenda.en.xhtml"
    },
    {
        "slideContent": "\nPlanning History: In the Beginning ...\n\n▷In the beginning\nMan invented Robots:\n\n\n▷“Planning” as in “the making of plans by an autonomous robot”.\n\n\n▷Shakey the Robot(Full video\nhere)\n\n\n▷In a little more detail\n\n▷[NS63] introduced\ngeneral problem solving.\n\n\n▷...not much happened (well not much we still speak of today) ...\n\n\n▷1966-72, Stanford Research Institute developed a robot named “Shakey”.\n\n\n▷They needed a “planning” component taking decisions.\n\n\n▷They took inspiration from general problem solving and theorem proving, and called the resulting\nalgorithm\nSTRIPS.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-15\n",
        "sectionId": "6005a675",
        "archive": "courses/FAU/AI/course",
        "filepath": "planning/slides/early-history.en.xhtml"
    },
    {
        "slideContent": "\nHistory of Planning Algorithms\n\n▷Compilation into Logics/Theorem Proving\n\n▷e.g.\n∃𝑠0,𝑎,𝑠1.𝑎𝑡(𝐴,𝑠0)∧𝑒𝑥𝑒𝑐𝑢𝑡𝑒(𝑠0,𝑎,𝑠1)∧𝑎𝑡(𝐵,𝑠1)\n\n\n▷Popular when: Stone Age — 1990.\n\n\n▷Approach:\nFrom\nplanning task\n                  description, generate PL1 formula\n𝜑\n                  that is satisfiable iff there exists a plan; use a theorem prover on\n𝜑.\n\n\n▷Keywords/cites: Situation calculus, frame problem, ...\n\n▷Partial order planning\n\n\n▷e.g.\n𝑜𝑝𝑒𝑛={𝑎𝑡(𝐵)}; apply\n𝑚𝑜𝑣𝑒(𝐴,𝐵);\n⤳\n𝑜𝑝𝑒𝑛={𝑎𝑡(𝐴)}\n            ...\n\n▷Popular when: 1990 — 1995.\n\n\n▷Approach:\nStarting at goal, extend partially ordered set of\nactions\n              by inserting achievers for open sub-goals, or by adding ordering constraints to avoid conflicts.\n\n\n▷Keywords/cites:\nUCPOP\n            [PW92],\ncausal links, flaw selection strategies, ...\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-16\n",
        "sectionId": "6005a675",
        "archive": "courses/FAU/AI/course",
        "filepath": "planning/slides/algo-history.en.xhtml"
    },
    {
        "slideContent": "\nHistory of Planning Algorithms, ctd.\n\n▷GraphPlan\n\n\n▷e.g.\n𝐹0=𝑎𝑡(𝐴);𝐴0={𝑚𝑜𝑣𝑒(𝐴,𝐵)};𝐹1={𝑎𝑡(𝐵)};mutex\n𝐴0={𝑚𝑜𝑣𝑒(𝐴,𝐵),𝑚𝑜𝑣𝑒(𝐴,𝐶)}.\n\n\n▷Popular when: 1995 — 2000.\n\n\n▷Approach:\nIn a forward phase, build a layered “planning graph” whose “time steps” capture which pairs of action can achieve which pairs of facts; in a backward phase, search this graph starting at goals and excluding options proved to not be feasible.\n\n\n▷Keywords/cites: [BF95;\nBF97;\nKoe+97], action/fact mutexes, step-optimal\nplans, ...\n\nPlanning as SAT\n\n\n▷▷SAT variables\n𝑎𝑡(𝐴)0,\n𝑎𝑡(𝐵)0,\n𝑚𝑜𝑣𝑒(𝐴,𝐵)0,\n𝑚𝑜𝑣𝑒(𝐴,𝐶)0,\n𝑎𝑡(𝐴)1,\n𝑎𝑡(𝐵)1;\nclauses\n                to encode transition behavior e.g.\n𝑎𝑡(𝐵)1𝖥∨𝑚𝑜𝑣𝑒(𝐴,𝐵)0𝖳;\nunit clauses\n                to encode initial state\n𝑎𝑡(𝐴)0𝖳,\n𝑎𝑡(𝐵)0𝖳;\nunit clauses\n                to encode goal\n𝑎𝑡(𝐵)1𝖳.\n\n\n▷Popular when: 1996 — today.\n\n\n▷Approach:\nFrom\nplanning task\n                  description, generate propositional CNF formula\n𝜑𝑘\n                  that is\nsatisfiable\n                  iff there exists a\nplan\n                  with\n𝑘\n                  steps; use a\nSAT\n                  solver on\n𝜑𝑘, for different values of\n𝑘.\n\n\n▷Keywords/cites: [KS92;\nKS98;\nRHN06;\nRin10], SAT encoding schemes, BlackBox, ...\n\n\nMichael Kohlhase:\nArtificial Intelligence 122024-12-16\n",
        "sectionId": "6005a675",
        "archive": "courses/FAU/AI/course",
        "filepath": "planning/slides/algo-history.en.xhtml"
    },
    {
        "slideContent": "\nHistory of Planning Algorithms, ctd.\n\n▷Planning as\nHeuristic Search\n\n\n▷init\n𝑎𝑡(𝐴); apply\n𝑚𝑜𝑣𝑒(𝐴,𝐵); generates state\n𝑎𝑡(𝐵); ...\n\n▷Popular when: 1999 — today.\n\n\n▷Approach: Devise a method\nℛ\n                to simplify (“relax”) any\nplanning task\nΠ; given\nΠ, solve\nℛ(Π)\n                to generate a\nheuristic\n                function\nℎ\n                for informed search.\n\n\n▷Keywords/cites: [BG99;\nHG00;\nBG01;\nHN01;\nEde01;\nGSS03;\nHel06;\nHHH07;\nHG08;\nKD09;\nHD09;\nRW10;\nNHH11;\nKHH12a;\nKHH12b;\nKHD13;\nDHK15], critical path heuristics, ignoring delete lists, relaxed plans, landmark heuristics, abstractions, partial delete relaxation, ...\n\n\nMichael Kohlhase:\nArtificial Intelligence 132024-12-16\n",
        "sectionId": "6005a675",
        "archive": "courses/FAU/AI/course",
        "filepath": "planning/slides/algo-history.en.xhtml"
    },
    {
        "slideContent": "\nThe International Planning Competition (IPC)\n\n▷\n                  The\nInternational Planning Competition\n                  (IPC) is an event for\nbenchmarking\nplanners(http://ipc.icaps conference.org/)\n\n\n▷How: Run competing planners on a set of\nbenchmarks.\n\n\n▷When: Runs every two years since 2000, annually since 2014.\n\n\n▷What:\nOptimal\n                  track vs.,satisficing\n                  track; others:\nuncertainty,\nlearning, ...\n\n▷Prerequisite/Result\n\n\n▷Standard representation language:\nPDDL\n                  [McD+98;\nFL03;\nHE05;\nGer+09]\n\n\n▷Problem Corpus:\n≈50\ndomains,\n≫1000\ninstances,\n74\n                  (!!) planners in 2011\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-16\n",
        "sectionId": "6005a675",
        "archive": "courses/FAU/AI/course",
        "filepath": "planning/slides/IPCompetition.en.xhtml"
    },
    {
        "slideContent": "\nInternational Planning Competition\n\n▷Question\n                If planners\n𝑥\n                and\n𝑦\n                compete in IPC’YY, and\n𝑥\n                wins, is\n𝑥\n                “better than”\n𝑦?\n\n\n▷Answerreserved for the plenary sessions\n⤳\n                be there!\n\n▷Generallyreserved for the plenary sessions\n⤳\n                be there!\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-15\n",
        "sectionId": "6005a675",
        "archive": "courses/FAU/AI/course",
        "filepath": "planning/quest/ipc.en.xhtml"
    },
    {
        "slideContent": "\nPlanning History, p.s.: Planning is Non-Trivial!\n\n▷\n                  The\nSussman anomaly\n                      is a simple blocksworld planning problem:\n\n\n\n\nSimple planners that split the goal into subgoals\non(𝐴,𝐵)\n                  and\non(𝐵,𝐶)\n                  fail:\n\n\n\n▷If we pursue\non(𝐴,𝐵)\n                                    by unstacking\n𝐶, and moving\n𝐴\n                                    onto\n𝐵, we achieve the first subgoal, but cannot achieve the second without undoing the first.\n\n\n▷If we pursue\non(𝐵,𝐶)\n                                    by moving\n𝐵\n                                    onto\n𝐶, we achieve the second subgoal, but cannot achieve the first without undoing the second.\n\n\n\n\n\n\n\n\n \n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "6005a675",
        "archive": "courses/FAU/AI/course",
        "filepath": "planning/slides/sussman-anomaly.en.xhtml"
    },
    {
        "slideContent": "\nSTRIPS Planning\n\n▷\nSTRIPS\n                  = Stanford Research Institute Problem Solver.\n\n\nSTRIPS\n                    is the simplest possible (reasonably expressive) logics based\nplanning language.\n\n\n▷STRIPS\n              has only\npropositional variables\n              as\natomic\nformulae.\n\n\n▷Its\npreconditions/effects/goals are as canonical as imaginable:\n\n\n▷Preconditions, goals:\nconjunctions\n              of\natoms.\n\n\n▷Effects:\nconjunctions\n              of\nliterals\n\n\n▷We use the common special-case notation for this simple formalism.\n\n\n▷I’ll outline some extensions beyond\nSTRIPS\n                  later on, when we discuss\nPDDL.\n\n\n▷Historical note\nSTRIPS\n                  [FN71] was originally a\nplanner\n                  (cf. Shakey), whose language actually wasn’t quite that simple.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "8840b987",
        "archive": "courses/FAU/AI/course",
        "filepath": "planning/slides/strips-nutshell.en.xhtml"
    },
    {
        "slideContent": "\nSTRIPS Planning: Syntax\n\n▷\n                    A\nSTRIPS task\n                    is a quadruple\n〈𝑃,𝐴,𝐼,𝐺〉\n                    where:\n\n\n▷𝑃\n                    is a\nfinite\n                    set of\nfacts:\natomic\nproposition\n                    in\nPL0\n                    or\nPLnq.\n\n\n▷𝐴\n                    is a\nfinite\n                    set of\nactions; each\n𝑎∊𝐴\n                    is a triple\n𝑎=〈pre𝑎,add𝑎,del𝑎〉\n                    of\nsubsets\n                    of\n𝑃\n                    referred to as the\naction’s\npreconditions,\nadd list, and\ndelete list\n                    respectively; we require that\nadd𝑎∩del𝑎=∅.\n\n\n▷𝐼⊆𝑃\n                    is the\ninitial state.\n\n\n▷𝐺⊆𝑃\n                    is the\ngoal state.\n\n\nWe will often give each\naction\n𝑎∊𝐴\n                    a name (a string), and identify\n𝑎\n                    with that name.\n\n\n▷Note\n                    We assume, for simplicity, that every action has cost\n1.\n(Unit costs, cf.\n??)\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "8840b987",
        "archive": "courses/FAU/AI/course",
        "filepath": "planning/slides/strips-syntax.en.xhtml"
    },
    {
        "slideContent": "\n“TSP” in Australia\n\n▷Salesman Travelling in Australia\n\n\n\n\nStrictly speaking, this is not actually a\nTSP\n                  problem instance; simplified/adapted for illustration.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "8840b987",
        "archive": "courses/FAU/AI/course",
        "filepath": "planning/slides/tsp-australia-ex.en.xhtml"
    },
    {
        "slideContent": "\nSTRIPS Encoding of “TSP”\n\n▷continuing\n\n\n\n\n▷Facts\n𝑃:\n{at(𝑥),vis(𝑥)|𝑥∊{Sy,Ad,Br,Pe,Da}}.\n\n\n▷Initial state\n𝐼:\n{at(Sy),vis(Sy)}.\n\n\n▷Goal state\n𝐺:{at(Sy)}∪{vis(𝑥)|𝑥∊{Sy,Ad,Br,Pe,Da}}.\n\n\n▷Actions\n𝑎∊𝐴:\ndrv(𝑥,𝑦)\n                  where\n𝑥\n                  and\n𝑦\n                  have a road.\n\nPreconditions\npre𝑎:\n{at(𝑥)}.\n\nAdd list\nadd𝑎:\n{at(𝑦),vis(𝑦)}.\n\nDelete list\ndel𝑎:\n{at(𝑥)}.\n\n\n▷Plan:\n〈drv(Sy,Br),drv(Br,Sy),drv(Sy,Ad),drv(Ad,Pe),drv(Pe,Ad),......,drv(Ad,Da),drv(Da,Ad),drv(Ad,Sy)〉\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 122024-12-14\n",
        "sectionId": "8840b987",
        "archive": "courses/FAU/AI/course",
        "filepath": "planning/slides/tsp-australia-ex.en.xhtml"
    },
    {
        "slideContent": "\nSTRIPS Planning: Semantics\n\n▷Idea\n                  We define a\nplan\n                  for a\nSTRIPS task\nΠ\n                  as a\nsolution\n                  to an\ninduced\nsearch problem\nΘΠ.\n(save work by reduction)\n\n\n▷\n                  Let\nΠ:=〈𝑃,𝐴,𝐼,𝐺〉\n                  be a\nSTRIPS task. The\nsearch problem\ninduced\n                  by\nΠ\n                  is\nΘΠ=〈𝑆𝑃,𝐴,𝑇,𝐼,𝑆𝐺〉\n                  where:\n\n\n▷The\nstates\n                  (also\nworld state)\n𝑆𝑃:=𝒫(𝑃)\n                  are the\nsubsets\n                  of\n𝑃.\n\n\n▷𝐴\n                  is just\nΠ’s\naction.(so we can define\nplans\n                      easily)\n\n\n▷The\ntransition model\n𝑇𝐴\n                  is\n{𝑠\n\n−\n\n\n−\n\n→\n𝑎apply(𝑠,𝑎)|pre𝑎⊆𝑠}.\n\nIf\npre𝑎⊆𝑠, then\n𝑎∊𝐴\n                  is\napplicable\n                  in\n𝑠\n                  and\napply(𝑠,𝑎):=(𝑠∪add𝑎)\\del𝑎. If\npre𝑎⊈𝑠, then\napply(𝑠,𝑎)\n                  is\nundefined.\n\n\n▷𝐼\n                  is\nΠ’s\ninitial state.\n\n\n▷The\ngoal states\n𝑆𝐺={𝑠∊𝑆𝑃|𝐺⊆𝑠}\n                  are those that satisfy\nΠ’s\ngoal state.\n\n\nAn (optimal)\nplan\n                  for\nΠ\n                  is an (optimal)\nsolution\n                  for\nΘΠ, i.e., a path from\n𝑠\n                  to some\n𝑠'∊𝑆𝐺.\nΠ\n                  is\nsolvable\n                  if a\nplan\n                  for\nΠ\n                  exists.\n\n\n▷For a\nplan\n𝑎=〈𝑎1,...,𝑎𝑛〉, we define\napply(𝑠,𝑎):=apply(...apply(apply(𝑠,𝑎1),𝑎2)...,𝑎𝑛)if each\n𝑎𝑖\n                  is\napplicable\n                  in the respective state; else,\napply(𝑠,𝑎)\n                  is\nundefined.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "8840b987",
        "archive": "courses/FAU/AI/course",
        "filepath": "planning/slides/strips-semantics.en.xhtml"
    },
    {
        "slideContent": "\nSTRIPS Encoding of Simplified\nTSP\n\n▷Simplified\ntraveling salesman problem\n                    in Australia\n\n\n\n\nLet\nTSP−\n                  be the\nSTRIPS task,\n〈𝑃,𝐴,𝐼,𝐺〉, where\n\n\n▷Facts\n𝑃:\n{at(𝑥),vis(𝑥)|𝑥∊{Sy,Ad,Br}}.\n\n\n▷Initial state\nstate\n𝐼:\n{at(Sy),vis(Sy)}.\n\n\n▷Goal state\n𝐺:\n{vis(𝑥)|𝑥∊{Sy,Ad,Br}}(note: noat(Sy))\n\n\n▷Actions\n𝐴:\n𝑎∊𝐴:\ndrv(𝑥,𝑦)\n                  where\n𝑥\n𝑦\n                  have a road.\n\n\n▷preconditions\npre𝑎:\n{at(𝑥)}.\n\n\n▷add list\nadd𝑎:\n{at(𝑦),vis(𝑦)}.\n\n\n▷delete list\ndel𝑎:\n{at(𝑥)}.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-15\n",
        "sectionId": "8840b987",
        "archive": "courses/FAU/AI/course",
        "filepath": "planning/slides/tsp-australia-simplified.en.xhtml"
    },
    {
        "slideContent": "\nQuestionaire: State Space of\nTSP−\n\n▷The\nstate space\n              of the\nsearch problem\nΘTSP−\n              induced by\nTSP−\n              from\n??\n              is\n\n\n\n\n\n\n  \n  \n\n\n\n\nat(Sy)vis(Sy)  \n\n\nat(Br)vis(Sy)vis(Br)  \n\nat(Ad)vis(Sy)vis(Ad)  \n\nat(Sy)vis(Sy)vis(Br)  \n\nat(Sy)vis(Sy)vis(Ad)  \n\n\n\n\nat(Ad)vis(Sy)vis(Br)vis(Ad)  \n\n\n\n\n\nat(Br)vis(Sy)vis(Ad)vis(Br)  \n\n\nat(Sy)vis(Sy)vis(Ad)vis(Br)  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ndrv(Sy,Br)  \n\n\n\n\n\n\n\n\n\n\ndrv(Sy,Ad)  \n\n\n\n\n\n\n\n\n\n\ndrv(Br,Sy)  \n\n\n\n\n\n\n\n\n\n\ndrv(Ad,Sy)  \n\n\n\n\n\n\n\n\n\n\ndrv(Sy,Ad)  \n\n\n\n\n\n\n\n\n\n\ndrv(Sy,Br)  \n\n\n\n\n\n\n\n\n\n\ndrv(Br,Sy)  \n\n\n\n\n\n\n\n\n\n\ndrv(Ad,Sy)  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuestion\n                  Are there any\nplans\n                  for\nTSP−\n                  in this\ngraph?\n\n\n▷\n\n▷Answer\n                  Yes, two —\nplans\n                  for\nTSP−\n                  are\nsolutions\n                  for\nΘTSP−, dashed node\n=^\n𝐼, thick nodes\n=^\n𝐺:\n\n\n▷drv(Sy,Br),drv(Br,Sy),drv(Sy,Ad)\n(upper path)\n\n\n▷drv(Sy,Ad),drv(Ad,Sy),drv(Sy,Br).(lower path)\n\n\n▷Question\n                  Is the\ngraph\n                  above actually the\nstate space\ninduced\n                  by ?\n\n\n▷Answer\n                  No, only the part reachable from\n𝐼.\nThe\nstate space\n                      of\nΘTSP−\n                      also includes e.g. the states\n{vis(Sy)}\n                      and\n{at(Sy),at(Br)}.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 122024-12-15\n",
        "sectionId": "8840b987",
        "archive": "courses/FAU/AI/course",
        "filepath": "planning/slides/tsp-australia-simplified.en.xhtml"
    },
    {
        "slideContent": "\nThe Blocksworld\n\n▷\n                  The\nblocks world\n                  is a simple planning domain: a set of wooden blocks of various shapes and colors sit on a table. The goal is to build one or more vertical stacks of blocks. Only one block may be moved at a time: it may either be placed on the table or placed atop another block.\n\n\n▷\n\n\n\n\n▷Facts:\non(𝑥,𝑦),\nonTable(𝑥),\nclear(𝑥),\nholding(𝑥),\narmEmpty.\n\n\n▷initial state:\n{onTable(𝐸),clear(𝐸),...,onTable(𝐶),on(𝐷,𝐶),clear(𝐷),armEmpty}.\n\n\n▷Goal state:\n{on(𝐸,𝐶),on(𝐶,𝐴),on(𝐵,𝐷)}.\n\n\n▷Actions:\nstack(𝑥,𝑦),\nunstack(𝑥,𝑦),\nputdown(𝑥),\npickup(𝑥).\n\n\n▷stack(𝑥,𝑦)?\n\npre:{holding(𝑥),clear(𝑦)}\n\nadd:{on(𝑥,𝑦),armEmpty,𝑐𝑙𝑒𝑎𝑟𝑥}\n\ndel:{holding(𝑥),clear(𝑦)}.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "8840b987",
        "archive": "courses/FAU/AI/course",
        "filepath": "planning/slides/strips-blocksworld.en.xhtml"
    },
    {
        "slideContent": "\nSTRIPS for the Blocksworld\n\n▷Question\n                Which are correct encodings (ones that are part of\nsome\n                correct overall model) of the STRIPS Blocksworld\npickup(𝑥)\n                action schema?\n\n\n(A) \n{onTable(𝑥),clear(𝑥),armEmpty}{holding(𝑥)}{onTable(𝑥)}\n\n(B) \n{onTable(𝑥),clear(𝑥),armEmpty}{holding(𝑥)}{armEmpty}\n\n(C) \n{onTable(𝑥),clear(𝑥),armEmpty}{holding(𝑥)}{onTable(𝑥),armEmpty,clear(𝑥)}\n(D) \n{onTable(𝑥),clear(𝑥),armEmpty}{holding(𝑥)}{onTable(𝑥),armEmpty}\n\n\n\n\nRecall: an actions\n𝑎\n                represented by a tuple\n〈pre𝑎,add𝑎,del𝑎〉\n                of lists of facts.\n\n\n▷Hint\n                The only differences between them are the delete lists\n\n\n▷Answerreserved for the plenary sessions\n⤳\n                be there!\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-16\n",
        "sectionId": "8840b987",
        "archive": "courses/FAU/AI/course",
        "filepath": "planning/quest/strips-blocksworld.en.xhtml"
    },
    {
        "slideContent": "\nMiconic-10: A Real-World Example\n\n▷\n                  Elevator control as a planning problem; details at [KS00]Specify mobility needs before boarding, let a planner schedule/otimize trips\n\n\n\n\n\n\n▷VIP: Served first.\n\n\n▷D: Lift may only go\ndown\n                                    when inside; similar for U.\n\n\n▷NA: Never-alone\n\n\n▷AT: Attendant.\n\n\n▷A, B: Never together in the same elevator\n\n\n▷P: Normal passenger\n\n\n\n\n\n\n\n \n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-15\n",
        "sectionId": "8840b987",
        "archive": "courses/FAU/AI/course",
        "filepath": "planning/slides/miconic-hard.en.xhtml"
    },
    {
        "slideContent": "\nPlanning History, p.s.: Planning is Non-Trivial!\n\n▷\n                  The\nSussman anomaly\n                      is a simple blocksworld planning problem:\n\n\n\n\nSimple planners that split the goal into subgoals\non(𝐴,𝐵)\n                  and\non(𝐵,𝐶)\n                  fail:\n\n\n\n▷If we pursue\non(𝐴,𝐵)\n                                    by unstacking\n𝐶, and moving\n𝐴\n                                    onto\n𝐵, we achieve the first subgoal, but cannot achieve the second without undoing the first.\n\n\n▷If we pursue\non(𝐵,𝐶)\n                                    by moving\n𝐵\n                                    onto\n𝐶, we achieve the second subgoal, but cannot achieve the first without undoing the second.\n\n\n\n\n\n\n\n\n \n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "a3550d54",
        "archive": "courses/FAU/AI/course",
        "filepath": "planning/slides/sussman-anomaly.en.xhtml"
    },
    {
        "slideContent": "\nPartial Order Planning\n\n▷\n                  Any\nalgorithm\n                  that can place two\nactions\n                  into a\nplan\n                  without specifying which comes first is called as\npartial order planning.\n\n\n▷Ideas\n                  for\npartial order planning:\n\n\n▷Organize the planning steps in a DAG that supports multiple paths from initial to goal state\n\n\n▷nodes (steps) are labeled with\nactions(actions\n                      can occur multiply)\n\n\n▷edges with propositions added by source and presupposed by target\n\n\nacyclicity of the graph induces a partial ordering on steps. q\n\n\n▷additional temporal constraints resolve subgoal interactions and induce a linear order.\n\n\n▷Advantages\n                  of\npartial order planning:\n\n\n▷problems can be decomposed\n⤳\n                  can work well with non-cooperative environments.\n\n\n▷efficient\n                  by least-commitment strategy\n\n\n▷causal links (edges) pinpoint unworkable subplans early.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-15\n",
        "sectionId": "a3550d54",
        "archive": "courses/FAU/AI/course",
        "filepath": "planning/slides/poplanning.en.xhtml"
    },
    {
        "slideContent": "\nPartially Ordered Plans\n\n▷\n                  Let\n〈𝑃,𝐴,𝐼,𝐺〉\n                  be a\nSTRIPS task, then a\npartially ordered plan\n𝒫=〈𝑉,𝐸〉\n                  is a\nlabeled\nDAG, where the\nnodes\n                  in\n𝑉\n                  (called\nsteps) are labeled with\nactions\n                  from\n𝐴, or are a\n\n\n▷start step, which has\nlabel\n                  “effect”\n𝐼, or a\n\n\n▷finish step, which has label “precondition”\n𝐺.\n\n\nEvery\nedge\n(𝑆,𝑇)∊𝐸\n                  is either\nlabeled\n                  by:\n\n\n▷A\nnon-empty\nset\n𝑝⊆𝑃\n                  of\nfacts\n                  that are\neffects\n                  of the\naction\n                  of\n𝑆\n                  and the\npreconditions\n                  of that of\n𝑇. We call such a labeled edge a\ncausal link\n                  and write it\n𝑆\n\n−\n→𝑝\n𝑇.\n\n\n▷≺, then call it a\ntemporal constraint\n                  and write it as\n𝑆≺𝑇.\n\n\nAn\nopen condition\n                  is a\nprecondition\n                  of a\nstep\n                  not yet\ncausally linked.\n\n\n▷\n                  Let\nΠ\n                  be a\npartially ordered plan, then we call a\nstep\n𝑈\npossibly intervening\n                  in a\ncausal link\n𝑆\n\n−\n→𝑝\n𝑇, iff\nΠ∪{𝑆≺𝑈,𝑈≺𝑇}\n                  is\nacyclic.\n\n\n▷\n                  A\nprecondition\n                  is\nachieved\n                  iff it is the\neffect\n                  of an earlier\nstep\n                  and no\npossibly intervening\nstep\n                  undoes it.\n\n\n▷\n                  A\npartially ordered plan\nΠ\n                  is called\ncomplete\n                  iff every\nprecondition\n                  is\nachieved.\n\n\n▷\nPartial order planning\n                  is the process of computing\ncomplete\n                  and\nacyclic\npartially ordered plans\n                  for a given\nplanning task.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "a3550d54",
        "archive": "courses/FAU/AI/course",
        "filepath": "planning/slides/poplans.en.xhtml"
    },
    {
        "slideContent": "\nA Notation for\nSTRIPS\n              Actions\n\n▷Notation\n                  In diagrams, we often write\nSTRIPS\nactions\n                  into boxes with\npreconditions\n                  above and\neffects\n                  below.\n\n\n▷\n\n\n\n▷Actions:\n𝐵𝑢𝑦(𝑥)\n\n\n▷Preconditions:\n𝐴𝑡(𝑝),\n𝑆𝑒𝑙𝑙𝑠(𝑝,𝑥)\n\n\n▷Effects:\n𝐻𝑎𝑣𝑒(𝑥)\n\n\n\n\n𝐴𝑡(𝑝)𝑆𝑒𝑙𝑙𝑠(𝑝,𝑥)\n𝐵𝑢𝑦(𝑥)\n𝐻𝑎𝑣𝑒(𝑥)\n\n\n\n\n \n\n▷Notation\n                  A\ncausal link\n𝑆\n\n−\n→𝑝\n𝑇\n                  can also be denoted by a direct arrow between the\neffects\n𝑝\n                  of\n𝑆\n                  and the\npreconditions\n𝑝\n                  of\n𝑇\n                  in the\nSTRIPS\n                  action notation above.\n\nShow\ntemporal constraints\n                  as dashed arrows.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "a3550d54",
        "archive": "courses/FAU/AI/course",
        "filepath": "planning/slides/stripsops.en.xhtml"
    },
    {
        "slideContent": "\nPlanning Process\n\n▷\nPartial order planning\n                  is search in the space of partial plans via the following operations:\n\n\n▷add link\n                  from an existing action to an open precondition,\n\n\n▷add step\n                  (an action with links to other\nsteps) to fulfil an open condition,\n\n\n▷order\n                  one\nstep\n                  wrt. another to remove possible conflicts.\n\n\n▷IdeaGradually move from incomplete/vague plans to complete, correct plans.backtrack\n                  if an open condition is unachievable or if a conflict is unresolvable.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-15\n",
        "sectionId": "a3550d54",
        "archive": "courses/FAU/AI/course",
        "filepath": "planning/slides/poplan-process.en.xhtml"
    },
    {
        "slideContent": "\nExample: Shopping for Bananas, Milk, and a Cordless Drill\n\n\n\n\n\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-16\n",
        "sectionId": "a3550d54",
        "archive": "courses/FAU/AI/course",
        "filepath": "planning/slides/poplan-ex.en.xhtml"
    },
    {
        "slideContent": "\nClobbering and Promotion/Demotion\n\n▷\n                  In a\npartially ordered plan, a\nstep\n𝐶\nclobbers\n                  a\ncausal link\n𝐿:=𝑆\n\n−\n→𝑝\n𝑇, iff it destroys the condition\n𝑝\n                  achieved by\n𝐿.\n\n\n▷\n                  If\n𝐶\nclobbers\n𝑆\n\n−\n→𝑝\n𝑇\n                  in a\npartially ordered plan\nΠ, then we can solve the induced conflict by\n\n\n▷demotion: add a\ntemporal constraint\n𝐶≺𝑆\n                  to\nΠ, or\n\n\n▷promotion: add\n𝑇≺𝐶\n                  to\nΠ.\n\n\n▷\n𝐺𝑜(𝐻𝑜𝑚𝑒)\nclobbers\n𝐴𝑡(𝑆𝑢𝑝𝑒𝑟𝑚𝑎𝑟𝑘𝑒𝑡):\n\n\n\n\n\n\n\n𝐴𝑡(𝑆𝑀)\n𝐵𝑢𝑦(𝑀𝑖𝑙𝑘)\n\n  \n\n\n𝐺𝑜(𝑆𝑀)\n𝐴𝑡(𝑆𝑀)\n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n𝐺𝑜(𝐻𝑜𝑚𝑒)\n𝐴𝑡(𝐻𝑜𝑚𝑒)\n  \n\n\n\n\n\n\n\n\n\n\n\n\n\ndemotion =^ put before   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\npromotion =^ put after   \n\n\n\n\n\n\n\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "a3550d54",
        "archive": "courses/FAU/AI/course",
        "filepath": "planning/slides/clobbering.en.xhtml"
    },
    {
        "slideContent": "\nPOP algorithm sketch\n\n▷\n                  The\nPOP\nalgorithm\n                  for constructing\ncomplete\npartially ordered plans:\n\n\nfunction POP (initial, goal, operators) : plan\nplan:= Make―Minimal―Plan(initial, goal)\nloop do\nif Solution?(goal,plan) then return plan\n𝑆𝑛𝑒𝑒𝑑,𝑐 := Select―Subgoal(plan)\nChoose―Operator(plan, operators, 𝑆𝑛𝑒𝑒𝑑,c)\nResolve―Threats(plan)\nend\n\nfunction Select―Subgoal (plan, 𝑆𝑛𝑒𝑒𝑑, 𝑐)\npick a plan step 𝑆𝑛𝑒𝑒𝑑 from Steps(plan)\nwith a precondition 𝑐 that has not been achieved\nreturn 𝑆𝑛𝑒𝑒𝑑, 𝑐\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "a3550d54",
        "archive": "courses/FAU/AI/course",
        "filepath": "planning/slides/poplan-algo.en.xhtml"
    },
    {
        "slideContent": "\nPOP algorithm contd.\n\n▷\n                  The missing parts for the\nPOP\nalgorithm.\n\n\nfunction Choose―Operator (plan, operators, 𝑆𝑛𝑒𝑒𝑑, c)\nchoose a step 𝑆𝑎𝑑𝑑 from operators or Steps(plan) that has 𝑐 as an effect\nif there is no such step then fail\nadd the ausal―link 𝑆𝑎𝑑𝑑\n\n−\n→𝑐\n𝑆𝑛𝑒𝑒𝑑 to Links(plan)\nadd the temporal―constraint 𝑆𝑎𝑑𝑑≺𝑆𝑛𝑒𝑒𝑑 to Orderings(plan)\nif 𝑆𝑎𝑑𝑑 is a newly added \\step from operators then\nadd 𝑆𝑎𝑑𝑑 to Steps(plan)\nadd 𝑆𝑡𝑎𝑟𝑡≺𝑆𝑎𝑑𝑑≺𝐹𝑖𝑛𝑖𝑠ℎ to Orderings(plan)\n\nfunction Resolve―Threats (plan)\nfor each 𝑆𝑡ℎ𝑟𝑒𝑎𝑡 that threatens a causal―link 𝑆𝑖\n\n−\n→𝑐\n𝑆𝑗 in Links(plan) do\nchoose either\ndemotion: Add 𝑆𝑡ℎ𝑟𝑒𝑎𝑡≺𝑆𝑖 to Orderings(plan)\npromotion: Add 𝑆𝑗≺𝑆𝑡ℎ𝑟𝑒𝑎𝑡 to Orderings(plan)\nif not Consistent(plan) then fail\n\n\nMichael Kohlhase:\nArtificial Intelligence 122024-12-14\n",
        "sectionId": "a3550d54",
        "archive": "courses/FAU/AI/course",
        "filepath": "planning/slides/poplan-algo.en.xhtml"
    },
    {
        "slideContent": "\nProperties of POP\n\n▷\n                  Nondeterministic\nalgorithm:\nbacktracks\n                  at\nchoice points\n                      on failure:\n\n\n▷choice of\n𝑆𝑎𝑑𝑑\n                      to achieve\n𝑆𝑛𝑒𝑒𝑑,\n\n\n▷choice of demotion or promotion for clobberer,\n\n\n▷selection of\n𝑆𝑛𝑒𝑒𝑑\n                      is irrevocable.\n\n\n▷\n                  POP is\nsound,\ncomplete, and\nsystematic\n                      i.e. no repetition\n\n\n▷There are extensions for disjunction, universals, negation, conditionals.\n\n\n▷It can be made\nefficient\n              with good\nheuristics\n              derived from problem description.\n\n\n▷Particularly good for problems with many loosely related subgoals.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "a3550d54",
        "archive": "courses/FAU/AI/course",
        "filepath": "planning/slides/poplan-props.en.xhtml"
    },
    {
        "slideContent": "\nExample: Solving the Sussman Anomaly\n\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-15\n",
        "sectionId": "a3550d54",
        "archive": "courses/FAU/AI/course",
        "filepath": "planning/slides/poplan-blocks.en.xhtml"
    },
    {
        "slideContent": "\nExample: Solving the Sussman Anomaly (contd.)\n\n▷\n                  Solving the\nSussman anomaly\n\n\n\n\n\n\n\n\n𝑆𝑡𝑎𝑟𝑡\n𝑂𝑛(𝐶,𝐴)𝑂𝑛(𝐴,𝑇)𝐶𝑙(𝐵)𝑂𝑛(𝐵,𝑇)𝐶𝑙(𝐶)\n  \n\n𝑂𝑛(𝐴,𝐵)𝑂𝑛(𝐴,𝐵)𝑂𝑛(𝐵,𝐶)𝑂𝑛(𝐵,𝐶)\n𝐹𝑖𝑛𝑖𝑠ℎ\n\n  \nInitializing the partial order plan with with Start and Finish.  \n\n\n\n\n\n\n\n\n\n\n\n\n𝑆𝑡𝑎𝑟𝑡\n𝑂𝑛(𝐶,𝐴)𝑂𝑛(𝐴,𝑇)𝐶𝑙(𝐵)𝑂𝑛(𝐵,𝑇)𝐶𝑙(𝐶)\n  \n\n𝐶𝑙(𝐵)𝐶𝑙(𝐶)\n𝑀𝑜𝑣𝑒(𝐵,𝐶)\n¬𝐶𝑙(𝐶),𝑂𝑛(𝐵,𝐶)\n  \n\n𝑂𝑛(𝐴,𝐵)𝑂𝑛(𝐴,𝐵)𝑂𝑛(𝐵,𝐶)𝑂𝑛(𝐵,𝐶)\n𝐹𝑖𝑛𝑖𝑠ℎ\n\n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRefining for the subgoal 𝑂𝑛(𝐵,𝐶).  \n\n\n\n\n\n\n\n\n\n\n\n\n𝑆𝑡𝑎𝑟𝑡\n𝑂𝑛(𝐶,𝐴)𝑂𝑛(𝐴,𝑇)𝐶𝑙(𝐵)𝑂𝑛(𝐵,𝑇)𝐶𝑙(𝐶)\n  \n\n𝐶𝑙(𝐵)𝐶𝑙(𝐶)\n𝑀𝑜𝑣𝑒(𝐵,𝐶)\n¬𝐶𝑙(𝐶),𝑂𝑛(𝐵,𝐶)\n  \n\n𝐶𝑙(𝐴)𝐶𝑙(𝐴)𝐶𝑙(𝐵)\n𝑀𝑜𝑣𝑒(𝐴,𝐵)\n¬𝐶𝑙(𝐵)𝑂𝑛(𝐴,𝐵)\n  \n\n𝑂𝑛(𝐴,𝐵)𝑂𝑛(𝐴,𝐵)𝑂𝑛(𝐵,𝐶)𝑂𝑛(𝐵,𝐶)\n𝐹𝑖𝑛𝑖𝑠ℎ\n\n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRefining for the subgoal 𝑂𝑁(𝐴,𝐶).  \n\n\n\n\n\n\n\n\n\n\n\n\n𝑆𝑡𝑎𝑟𝑡\n𝑂𝑛(𝐶,𝐴)𝑂𝑛(𝐴,𝑇)𝐶𝑙(𝐵)𝑂𝑛(𝐵,𝑇)𝐶𝑙(𝐶)\n  \n\n𝐶𝑙(𝐵)𝐶𝑙(𝐶)\n𝑀𝑜𝑣𝑒(𝐵,𝐶)\n¬𝐶𝑙(𝐶),𝑂𝑛(𝐵,𝐶)\n  \n\n𝐶𝑙(𝐴)𝐶𝑙(𝐴)𝐶𝑙(𝐵)\n𝑀𝑜𝑣𝑒(𝐴,𝐵)\n¬𝐶𝑙(𝐵)𝑂𝑛(𝐴,𝐵)\n  \n\n𝐶𝑙(𝐶)\n𝑀𝑜𝑣𝑒(𝐶,𝑇)\n𝐶𝑙(𝐴)𝑂𝑛(𝐶,𝑇)\n  \n\n𝑂𝑛(𝐴,𝐵)𝑂𝑛(𝐴,𝐵)𝑂𝑛(𝐵,𝐶)𝑂𝑛(𝐵,𝐶)\n𝐹𝑖𝑛𝑖𝑠ℎ\n\n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRefining for the subgoal 𝐶𝑙(𝐴).  \n\n\n\n\n\n\n\n\n\n\n\n\n𝑆𝑡𝑎𝑟𝑡\n𝑂𝑛(𝐶,𝐴)𝑂𝑛(𝐴,𝑇)𝐶𝑙(𝐵)𝑂𝑛(𝐵,𝑇)𝐶𝑙(𝐶)\n  \n\n𝐶𝑙(𝐵)𝐶𝑙(𝐶)\n𝑀𝑜𝑣𝑒(𝐵,𝐶)\n¬𝐶𝑙(𝐶),𝑂𝑛(𝐵,𝐶)\n  \n\n𝐶𝑙(𝐴)𝐶𝑙(𝐴)𝐶𝑙(𝐵)\n𝑀𝑜𝑣𝑒(𝐴,𝐵)\n¬𝐶𝑙(𝐵)𝑂𝑛(𝐴,𝐵)\n  \n\n𝐶𝑙(𝐶)\n𝑀𝑜𝑣𝑒(𝐶,𝑇)\n𝐶𝑙(𝐴)𝑂𝑛(𝐶,𝑇)\n  \n\n𝑂𝑛(𝐴,𝐵)𝑂𝑛(𝐴,𝐵)𝑂𝑛(𝐵,𝐶)𝑂𝑛(𝐵,𝐶)\n𝐹𝑖𝑛𝑖𝑠ℎ\n\n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n𝑀𝑜𝑣𝑒(𝐴,𝐵) clobbers 𝐶𝑙(𝐵) ⤳ demote.  \n\n\n\n\n\n\n\n\n\n\n\n\n𝑆𝑡𝑎𝑟𝑡\n𝑂𝑛(𝐶,𝐴)𝑂𝑛(𝐴,𝑇)𝐶𝑙(𝐵)𝑂𝑛(𝐵,𝑇)𝐶𝑙(𝐶)\n  \n\n𝐶𝑙(𝐵)𝐶𝑙(𝐶)\n𝑀𝑜𝑣𝑒(𝐵,𝐶)\n¬𝐶𝑙(𝐶),𝑂𝑛(𝐵,𝐶)\n  \n\n𝐶𝑙(𝐴)𝐶𝑙(𝐴)𝐶𝑙(𝐵)\n𝑀𝑜𝑣𝑒(𝐴,𝐵)\n¬𝐶𝑙(𝐵)𝑂𝑛(𝐴,𝐵)\n  \n\n𝐶𝑙(𝐶)\n𝑀𝑜𝑣𝑒(𝐶,𝑇)\n𝐶𝑙(𝐴)𝑂𝑛(𝐶,𝑇)\n  \n\n𝑂𝑛(𝐴,𝐵)𝑂𝑛(𝐴,𝐵)𝑂𝑛(𝐵,𝐶)𝑂𝑛(𝐵,𝐶)\n𝐹𝑖𝑛𝑖𝑠ℎ\n\n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n𝑀𝑜𝑣𝑒(𝐵,𝐶) clobbers 𝐶𝑙(𝐶) ⤳ demote.  \n\n\n\n\n\n\n\n\n\n\n\n\n𝑆𝑡𝑎𝑟𝑡\n𝑂𝑛(𝐶,𝐴)𝑂𝑛(𝐴,𝑇)𝐶𝑙(𝐵)𝑂𝑛(𝐵,𝑇)𝐶𝑙(𝐶)\n  \n\n𝐶𝑙(𝐵)𝐶𝑙(𝐶)\n𝑀𝑜𝑣𝑒(𝐵,𝐶)\n¬𝐶𝑙(𝐶),𝑂𝑛(𝐵,𝐶)\n  \n\n𝐶𝑙(𝐴)𝐶𝑙(𝐴)𝐶𝑙(𝐵)\n𝑀𝑜𝑣𝑒(𝐴,𝐵)\n¬𝐶𝑙(𝐵)𝑂𝑛(𝐴,𝐵)\n  \n\n𝐶𝑙(𝐶)\n𝑀𝑜𝑣𝑒(𝐶,𝑇)\n𝐶𝑙(𝐴)𝑂𝑛(𝐶,𝑇)\n  \n\n𝑂𝑛(𝐴,𝐵)𝑂𝑛(𝐴,𝐵)𝑂𝑛(𝐵,𝐶)𝑂𝑛(𝐵,𝐶)\n𝐹𝑖𝑛𝑖𝑠ℎ\n\n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA totally ordered plan.  \n\n\n\n\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 122024-12-15\n",
        "sectionId": "a3550d54",
        "archive": "courses/FAU/AI/course",
        "filepath": "planning/slides/poplan-blocks.en.xhtml"
    },
    {
        "slideContent": "\nPDDL: Planning Domain Description Language\n\n▷\n                  The\nPlanning Domain Description Language\n                  (PDDL) is a standardized representation language for planning\nbenchmarks\n                  in various extensions of the\nSTRIPS\n                  formalism.\n\n\n▷\nPDDL\n                  is not a propositional language\n\n\n▷Representation is lifted, using\nobject variables\n                  to be instantiated from a\nfinite\n                  set of\nobjects.\n(Similar to predicate logic)\n\n\n▷Action schemas\n                  parameterized by\nobjects.\n\n\n▷Predicates\n                  to be instantiated with\nobjects.\n\n\n▷\n                  A\nPDDL planning task\n                  comes in two pieces\n\n\n▷The\nproblem file\n                  gives the objects, the initial state, and the goal state.\n\n\n▷The\ndomain file\n                  gives the predicates and the\nactions.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "f96c230f",
        "archive": "courses/FAU/AI/course",
        "filepath": "planning/slides/pddl.en.xhtml"
    },
    {
        "slideContent": "\nThe Blocksworld in PDDL: Domain File\n\n\n\n(define (domain blocksworld)\n(:predicates (clear ?x) (holding ?x) (on ?x ?y)\n(on―table ?x) (arm―empty))\n(:action stack\n:parameters (?x ?y)\n:precondition (and (clear ?y) (holding ?x))\n:effect (and (arm―empty) (on ?x ?y)\n(not (clear ?y)) (not (holding ?x))))\n...)\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-15\n",
        "sectionId": "f96c230f",
        "archive": "courses/FAU/AI/course",
        "filepath": "planning/slides/pddl-ex-blocksworld.en.xhtml"
    },
    {
        "slideContent": "\nThe Blocksworld in PDDL: Problem File\n\n\n\n(define (problem bw―abcde)\n(:domain blocksworld)\n(:objects a b c d e)\n(:init (on―table a) (clear a)\n(on―table b) (clear b)\n(on―table e) (clear e)\n(on―table c) (on d c) (clear d)\n(arm―empty))\n(:goal (and (on e c) (on c a) (on b d))))\n\n\nMichael Kohlhase:\nArtificial Intelligence 122024-12-15\n",
        "sectionId": "f96c230f",
        "archive": "courses/FAU/AI/course",
        "filepath": "planning/slides/pddl-ex-blocksworld.en.xhtml"
    },
    {
        "slideContent": "\nMiconic-ADL “Stop” Action Schema in PDDL\n\n\n(:action stop\n:parameters (?f ― floor)\n:precondition (and (lift―at ?f)\n(imply\n(exists\n(?p ― conflict―A)\n(or (and (not (served ?p))\n(origin ?p ?f))\n(and (boarded ?p)\n(not (destin ?p ?f)))))\n(forall\n(?q ― conflict―B)\n(and (or (destin ?q ?f)\n(not (boarded ?q)))\n(or (served ?q)\n(not (origin ?q ?f))))))\n(imply (exists\n(?p ― conflict―B)\n(or (and (not (served ?p))\n(origin ?p ?f))\n(and (boarded ?p)\n(not (destin ?p ?f)))))\n(forall\n(?q ― conflict―A)\n(and (or (destin ?q ?f)\n(not (boarded ?q)))\n(or (served ?q)\n(not (origin ?q ?f))))))\n\n\n\n(imply\n(exists\n(?p ― never―alone)\n(or (and (origin ?p ?f)\n(not (served ?p)))\n(and (boarded ?p)\n(not (destin ?p ?f)))))\n(exists\n(?q ― attendant)\n(or (and (boarded ?q)\n(not (destin ?q ?f)))\n(and (not (served ?q))\n(origin ?q ?f)))))\n(forall\n(?p ― going―nonstop)\n(imply (boarded ?p) (destin ?p ?f)))\n(or (forall\n(?p ― vip) (served ?p))\n(exists\n(?p ― vip)\n(or (origin ?p ?f) (destin ?p ?f))))\n(forall\n(?p ― passenger)\n(imply\n(no―access ?p ?f) (not (boarded ?p)))))\n)\n\n\n\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-15\n",
        "sectionId": "f96c230f",
        "archive": "courses/FAU/AI/course",
        "filepath": "planning/slides/pddl-ex-miconic.en.xhtml"
    },
    {
        "slideContent": "\nPlanning Domain Description Language\n\n▷QuestionWhat is\nPDDL\n                good for?\n\n\n(A)Nothing.\n\n\n(B)Free beer.\n\n\n(C)Those\nAI\n                planning guys.\n\n\n(D)Being lazy at work.\n\n\n▷Answerreserved for the plenary sessions\n⤳\n                be there!\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "f96c230f",
        "archive": "courses/FAU/AI/course",
        "filepath": "planning/quest/pddl.en.xhtml"
    },
    {
        "slideContent": "\nSummary\n\n▷General problem solving attempts to develop solvers that perform well across a large class of problems.\n\n\n▷Planning, as considered here, is a form of general problem solving dedicated to the class of classical search problems. (Actually, we also address inaccessible, stochastic, dynamic, continuous, and multi-agent settings.)\n\n\n▷Heuristic search\n            planning has dominated the\nInternational Planning Competition\n            (IPC). We focus on it here.\n\n\n▷STRIPS\n            is the simplest possible, while reasonably expressive, language for our purposes. It uses Boolean variables (facts), and defines\nactions\n            in terms of precondition, add list, and delete list.\n\n\n▷PDDL is the de-facto standard language for describing planning problems.\n\n\n▷Plan existence (bounded or not) is\n𝐏𝐒𝐏𝐀𝐂𝐄-complete to decide for\nSTRIPS. If we bound\nplans\n            polynomially, we get down to\n𝐍𝐏-completeness.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-16\n",
        "sectionId": "4ec79229",
        "archive": "courses/FAU/AI/course",
        "filepath": "planning/slides/framework-summary.en.xhtml"
    },
    {
        "slideContent": "\nReminder: Our Agenda for This Topic\n\n▷??: Background,\nplanning languages,\ncomplexity.\n\n\n▷Sets up the framework.\ncomputational complexity\n            is essential to distinguish different\nalgorithmic\n            problems, and for the design of\nheuristic functions.\n\n\nThis Chapter\n                How to automatically generate a\nheuristic function, given\nplanning language\n                input?\n\n\n▷▷Focussing on\nheuristic search\n                as the solution method, this is the main question that needs to be answered.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "b9bde042",
        "archive": "courses/FAU/AI/course",
        "filepath": "planning/slides/algorithms-agenda.en.xhtml"
    },
    {
        "slideContent": "\nReminder: Search\n\n▷Starting at\ninitial state, produce all\nsuccessor\nstates\n            step by step:\n\n\n\n\nIn\nplanning, this is referred to as\nforward search, or\nforward state-space search.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-16\n",
        "sectionId": "b9bde042",
        "archive": "courses/FAU/AI/course",
        "filepath": "planning/slides/search-reminder.en.xhtml"
    },
    {
        "slideContent": "\nSearch in the State Space?\n\n\n\n▷Use\nheuristic function\n            to guide the search towards the goal!\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 122024-12-16\n",
        "sectionId": "b9bde042",
        "archive": "courses/FAU/AI/course",
        "filepath": "planning/slides/search-reminder.en.xhtml"
    },
    {
        "slideContent": "\nReminder: Informed Search\n\n\n\n\n\n\n\n\n\n  \n\ngoal  \n\n  \ninit  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncost estimate h   \n\n\n\n\n\ncost estimate h   \n\n\n\n\n\ncost estimate h   \n\n\n\n\n\ncost estimate h   \n\n\n\n\n\n\n\n\n▷Heuristic function\nℎ\n            estimates the cost of an optimal path from a\nstate\n𝑠\n            to the\ngoal state; search prefers to expand\nstates\n𝑠\n            with small\nℎ(𝑠).\n\n\n▷Live Demo vs. Breadth-First Search:\n\n\nhttp://qiao.github.io/PathFinding.js/visual/\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 132024-12-16\n",
        "sectionId": "b9bde042",
        "archive": "courses/FAU/AI/course",
        "filepath": "planning/slides/search-reminder.en.xhtml"
    },
    {
        "slideContent": "\nReminder: Heuristic Functions\n\n▷\n                  Let\nΠ\n                  be a\nSTRIPS task\n                  with states\n𝑆. A\nheuristic function, short\nheuristic, for\nΠ\n                  is a function\nℎ:𝑆→ℕ∪{∞}\n                  so that\nℎ(𝑠)=0\n                  whenever\n𝑠\n                  is a goal state.\n\n\n▷Exactly like our definition from\n??. Except, because we assume unit costs here, we use\nℕ\n              instead of\nℝ+.\n\n\n▷\n                  Let\nΠ\n                  be a\nSTRIPS task\n                  with states\n𝑆. The\nperfect heuristic\nℎ*\n                  assigns every\n𝑠∊𝑆\n                  the length of a shortest path from\n𝑠\n                  to a goal state, or\n∞\n                  if no such path exists. A\nheuristic\nℎ\n                  for\nΠ\n                  is\nadmissible\n                  if, for all\n𝑠∊𝑆, we have\nℎ(𝑠)≤ℎ*(𝑠).\n\n\n▷Exactly like our definition from\n??, except for path\nlength\n              instead of path\ncost\n              (cf. above).\n\n\n▷In all cases, we attempt to approximate\nℎ*(𝑠), the length of an optimal plan for\n𝑠. Some\nalgorithms\n              guarantee to lower bound\nℎ*(𝑠).\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "b9bde042",
        "archive": "courses/FAU/AI/course",
        "filepath": "planning/slides/planning-heuristics.en.xhtml"
    },
    {
        "slideContent": "\nOur (Refined) Agenda for This Chapter\n\n▷How to Relax\n                How to relax a problem?\n\n\n▷Basic principle for generating\nheuristic functions.\n\n\n▷The Delete RelaxationHow to relax a planning problem?\n\n\n▷The delete relaxation is the most successful method for the\nautomatic\n                generation of\nheuristic functions. It is a key ingredient to almost all\nIPC\n                winners of the last decade. It relaxes\nSTRIPS tasks\n                by ignoring the delete lists.\n\n\n▷The\nℎ+\n              Heuristic:\n            What is the resulting\nheuristic function?\n\n\n▷ℎ+\n            is the “ideal”\ndelete relaxation\nheuristic.\n\n\n▷Approximating\nℎ+:\n            How to actually compute a\nheuristic?\n\n\n▷Turns out that, in practice, we must approximate\nℎ+.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-15\n",
        "sectionId": "b9bde042",
        "archive": "courses/FAU/AI/course",
        "filepath": "planning/slides/algorithms-agenda-refined.en.xhtml"
    },
    {
        "slideContent": "\nHow to Relax\n\n▷Recall\n                  We introduced the concept of a\nrelaxed\nsearch problem\n                  (allow cheating) to derive\nheuristics\n                  from them.\n\n\n▷Observation\n                  This can be generalized to arbitrary\nproblem solving.\n\n\n▷The General Case\n\n\n\n\n\n\n\n𝒫  \n\n𝒫'  \n\nℕ∪{∞}  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n\n\n\n\n\nℛ  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nℎ𝒫*  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nℎ𝒫'*  \n\n\n\n\n\n\n1.You have a class\n𝒫\n                  of problems, whose\nperfect heuristic\nℎ𝒫*\n                  you wish to estimate.\n\n\n2.You define a class\n𝒫'\n                  of\nsimpler problems, whose\nperfect heuristic\nℎ𝒫'*\n                  can be used to estimate\nℎ𝒫*.\n\n\n3.You define a transformation — the\nrelaxation mapping\nℛ\n                  — that maps instances\nΠ∊𝒫\n                  into instances\nΠ'∊𝒫'.\n\n\n4.Given\nΠ∊𝒫, you let\nΠ':=ℛ(Π), and estimate\nℎ*𝒫(Π)\n                  by\nℎ*𝒫'(Π').\n\n\n▷\n                  For\nplanning tasks, we speak of\nrelaxed planning.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "7b17932c",
        "archive": "courses/FAU/AI/course",
        "filepath": "planning/slides/relaxing-nutshell.en.xhtml"
    },
    {
        "slideContent": "\nReminder: Heuristic Functions from Relaxed Problems\n\n\n\n▷Problem\nΠ: Find a route from Saarbrücken to Edinburgh.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "7b17932c",
        "archive": "courses/FAU/AI/course",
        "filepath": "planning/slides/relaxing-edsb.en.xhtml"
    },
    {
        "slideContent": "\nReminder: Heuristic Functions from Relaxed Problems\n\n\n\n▷Relaxed Problem\nΠ': Throw away the map.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 122024-12-14\n",
        "sectionId": "7b17932c",
        "archive": "courses/FAU/AI/course",
        "filepath": "planning/slides/relaxing-edsb.en.xhtml"
    },
    {
        "slideContent": "\nReminder: Heuristic Functions from Relaxed Problems\n\n\n\n▷Heuristic function\nℎ: Straight line distance.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 132024-12-14\n",
        "sectionId": "7b17932c",
        "archive": "courses/FAU/AI/course",
        "filepath": "planning/slides/relaxing-edsb.en.xhtml"
    },
    {
        "slideContent": "\nRelaxation in Route-Finding\n\n\n\n▷Problem class\n𝒫: Route finding.\n\n\n▷Perfect\nheuristic\nℎ𝒫*\n              for\n𝒫: Length of a shortest route.\n\n\n▷Simpler problem class\n𝒫': Route finding on an empty map.\n\n\n▷Perfect\nheuristic\nℎ𝒫'*\n              for\n𝒫': Straight-line distance.\n\n\n▷Transformation\nℛ: Throw away the map.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "7b17932c",
        "archive": "courses/FAU/AI/course",
        "filepath": "planning/slides/relaxing-routefinding.en.xhtml"
    },
    {
        "slideContent": "\nHow to Relax in Planning? (A Reminder!)\n\n▷Logistics\n\n\n\n\n▷facts\n𝑃:\n{truck(𝑥)|𝑥∊{𝐴,𝐵,𝐶,𝐷}}∪{pack(𝑥)|𝑥∊{𝐴,𝐵,𝐶,𝐷,𝑇}}.\n\n\n▷initial state\n𝐼:\n{truck(𝐴),pack(𝐶)}.\n\n\n▷goal state\n𝐺:\n{truck(𝐴),pack(𝐷)}.\n\n\n▷actions\n𝐴: (Notated as “precondition\n⇒\n                adds,\n¬\n                deletes”)\n\n\n▷drive(𝑥,𝑦), where\n𝑥\n                and\n𝑦\n                have a road: “truck(𝑥)⇒truck(𝑦),¬truck(𝑥)”.\n\n\n▷load(𝑥): “truck(𝑥),pack(𝑥)⇒pack(𝑇),¬pack(𝑥)”.\n\n\n▷unload(𝑥): “truck(𝑥),pack(𝑇)⇒pack(𝑥),¬pack(𝑇)”.\n\n\n▷“Only-Adds” Relaxation\n                Drop the preconditions and deletes.\n\n\n▷“drive(𝑥,𝑦):\n⇒truck(𝑦)”;\n\n\n▷“load(𝑥):\n⇒pack(𝑇)”;\n\n\n▷“unload(𝑥):\n⇒pack(𝑥)”.\n\n\n▷Heuristics\n            value for\n𝐼\n            is?\n\n\n▷ℎℛ(𝐼)=1: A plan for the relaxed task is\n〈unload(𝐷)〉.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-15\n",
        "sectionId": "7b17932c",
        "archive": "courses/FAU/AI/course",
        "filepath": "planning/slides/relaxing-planning.en.xhtml"
    },
    {
        "slideContent": "\nHow to Relax During Search: Overview\n\n▷Attention\n                  Search uses the real (un-relaxed)\nΠ. The relaxation is applied (e.g., in Only-Adds, the simplified\nactions\n                  are used)\nonly within the call to\nℎ(𝑠)!!!\n\n\n\n\n\n\nProblem Π  \nSolution to Π  \n\nHeuristic search on Π  \n\nℛ  \n\nℎ𝒫'*  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nstate 𝑠  \n\n\n\n\n\n\n\n\n\n\nℛ(Π𝑠)  \n\n\n\n\n\n\n\n\n\n\nℎ(𝑠)=ℎ*𝒫'(ℛ(Π𝑠))  \n\n\n\n\n  \n\n\n\n\n\n\n\n▷Here,\nΠ𝑠\n                  is\nΠ\n                  with initial state replaced by\n𝑠, i.e.,\nΠ:=〈𝑃,𝐴,𝐼,𝐺〉\n                  changed to\nΠ𝑠:=〈𝑃,𝐴,{𝑠},𝐺〉: The task of finding a\nplan\n                  for search state\n𝑠.\n\n\n▷A common student error is to instead apply the relaxation once to the whole problem, then doing the whole search “within the relaxation”.\n\n\n▷The next slide illustrates the correct search process in detail.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-16\n",
        "sectionId": "7b17932c",
        "archive": "courses/FAU/AI/course",
        "filepath": "planning/slides/relaxing-onlyadd.en.xhtml"
    },
    {
        "slideContent": "\nHow to Relax During Search: Only-Adds\n\n\n\n\n\n\nReal problem:\n\n\n▷Initial state\n𝐼:\n𝐴𝐶; goal\n𝐺:\n𝐴𝐷.\n\n\n▷Actions\n𝐴:\npre,add,del.\n\n\n▷𝑑𝑟𝑋𝑌,𝑙𝑜𝑋,𝑢𝑙𝑋.\n\n\n\n\n\nGreedy best-first search:(tie-breaking: alphabetic)\n\n\n\n\n\n\nWe are here  \n\n\n\n\n  \n𝐴𝐶  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRelaxed problem:\n\n\n▷State\n𝑠:\n𝐴𝐶; goal\n𝐺:\n𝐴𝐷.\n\n\n▷Actions\n𝐴:\nadd.\n\n\n▷ℎℛ(𝑠)=1:\n〈𝑢𝑙𝐷〉.\n\n\n\n\n\nGreedy best-first search:(tie-breaking: alphabetic)\n\n\n\n\n\n\nWe are here  \n\n\n\n\n  \n𝐴𝐶  \n\n\n\n\n  \n𝐴𝐶  \n1  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRelaxed problem:\n\n\n▷State\n𝑠:\n𝐴𝐶; goal\n𝐺:\n𝐴𝐷.\n\n\n▷Actions\n𝐴:\nadd.\n\n\n▷ℎℛ(𝑠)=1:\n〈𝑢𝑙𝐷〉.\n\n\n\n\n\nGreedy best-first search:(tie-breaking: alphabetic)\n\n\n\n\n\n\nWe are here  \n\n\n\n\n  \n𝐴𝐶  \n1  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nReal problem:\n\n\n▷State\n𝑠:\n𝐵𝐶; goal\n𝐺:\n𝐴𝐷.\n\n\n▷Actions\n𝐴:\npre,add,del.\n\n\n▷𝐴𝐶\n\n−\n\n\n−\n\n→\n𝑑𝑟𝐴𝐵𝐵𝐶.\n\n\n\n\n\nGreedy best-first search:(tie-breaking: alphabetic)\n\n\n\n\n\n\nWe are here  \n\n\n\n\n  \n𝐴𝐶  \n1  \n\n\n\n\n  \n\n𝐵𝐶  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐴𝐵  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRelaxed problem:\n\n\n▷State\n𝑠:\n𝐵𝐶; goal\n𝐺:\n𝐴𝐷.\n\n\n▷Actions\n𝐴:\nadd.\n\n\n▷ℎℛ(𝑠)=2:\n〈𝑑𝑟𝐵𝐴,𝑢𝑙𝐷〉.\n\n\n\n\n\nGreedy best-first search:(tie-breaking: alphabetic)\n\n\n\n\n\n\nWe are here  \n\n\n\n\n  \n𝐴𝐶  \n1  \n\n\n\n\n  \n\n𝐵𝐶  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐴𝐵  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRelaxed problem:\n\n\n▷State\n𝑠:\n𝐵𝐶; goal\n𝐺:\n𝐴𝐷.\n\n\n▷Actions\n𝐴:\nadd.\n\n\n▷ℎℛ(𝑠)=2:\n〈𝑑𝑟𝐵𝐴,𝑢𝑙𝐷〉.\n\n\n\n\n\nGreedy best-first search:(tie-breaking: alphabetic)\n\n\n\n\n\n\nWe are here  \n\n\n\n\n  \n𝐴𝐶  \n1  \n\n\n\n\n  \n\n𝐵𝐶  \n2  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐴𝐵  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nReal problem:\n\n\n▷State\n𝑠:\n𝐶𝐶; goal\n𝐺:\n𝐴𝐷.\n\n\n▷Actions\n𝐴:\npre,add,del.\n\n\n▷𝐵𝐶\n\n−\n\n\n−\n\n→\n𝑑𝑟𝐵𝐶𝐶𝐶.\n\n\n\n\n\nGreedy best-first search:(tie-breaking: alphabetic)\n\n\n\n\n\n\nWe are here  \n\n\n\n\n  \n𝐴𝐶  \n1  \n\n\n\n\n  \n\n𝐵𝐶  \n2  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐴𝐵  \n\n\n\n\n  \n\n𝐶𝐶  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐵𝐶  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRelaxed problem:\n\n\n▷State\n𝑠:\n𝐶𝐶; goal\n𝐺:\n𝐴𝐷.\n\n\n▷Actions\n𝐴:\nadd.\n\n\n▷ℎℛ(𝑠)=2:\n〈𝑑𝑟𝐵𝐴,𝑢𝑙𝐷〉.\n\n\n\n\n\nGreedy best-first search:(tie-breaking: alphabetic)\n\n\n\n\n\n\nWe are here  \n\n\n\n\n  \n𝐴𝐶  \n1  \n\n\n\n\n  \n\n𝐵𝐶  \n2  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐴𝐵  \n\n\n\n\n  \n\n𝐶𝐶  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐵𝐶  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRelaxed problem:\n\n\n▷State\n𝑠:\n𝐶𝐶; goal\n𝐺:\n𝐴𝐷.\n\n\n▷Actions\n𝐴:\nadd.\n\n\n▷ℎℛ(𝑠)=2:\n〈𝑑𝑟𝐵𝐴,𝑢𝑙𝐷〉.\n\n\n\n\n\nGreedy best-first search:(tie-breaking: alphabetic)\n\n\n\n\n\n\nWe are here  \n\n\n\n\n  \n𝐴𝐶  \n1  \n\n\n\n\n  \n\n𝐵𝐶  \n2  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐴𝐵  \n\n\n\n\n  \n\n𝐶𝐶  \n2  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐵𝐶  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nReal problem:\n\n\n▷State\n𝑠:\n𝐴𝐶; goal\n𝐺:\n𝐴𝐷.\n\n\n▷Actions\n𝐴:\npre,add,del.\n\n\n▷𝐵𝐶\n\n−\n\n\n−\n\n→\n𝑑𝑟𝐵𝐴𝐴𝐶.\n\n\n\n\n\nGreedy best-first search:(tie-breaking: alphabetic)\n\n\n\n\n\n\nWe are here  \n\n\n\n\n  \n𝐴𝐶  \n1  \n\n\n\n\n  \n\n𝐵𝐶  \n2  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐴𝐵  \n\n\n\n\n  \n\n𝐶𝐶  \n2  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐵𝐶  \n\n\n\n\n  \n\n𝐴𝐶  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐵𝐴  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nReal problem:\n\n\n▷State\n𝑠:\n𝐴𝐶; goal\n𝐺:\n𝐴𝐷.\n\n\n▷Actions\n𝐴:\npre,add,del.\n\n\n▷Duplicate state,\nprune.\n\n\n\n\n\nGreedy best-first search:(tie-breaking: alphabetic)\n\n\n\n\n\n\nWe are here  \n\n\n\n\n  \n𝐴𝐶  \n1  \n\n\n\n\n  \n\n𝐵𝐶  \n2  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐴𝐵  \n\n\n\n\n  \n\n𝐶𝐶  \n2  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐵𝐶  \n\n\n\n\n  \n\n𝐴𝐶  \nD  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐵𝐴  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nReal problem:\n\n▷State\n𝑠:\n𝐷𝐶; goal\n𝐺:\n𝐴𝐷.\n\n\n▷Actions\n𝐴:\npre,add,del.\n\n\n▷𝐶𝐶\n\n−\n\n\n−\n\n→\n𝑑𝑟𝐶𝐷𝐷𝐶.\n\n\n\n\n\nGreedy best-first search:(tie-breaking: alphabetic)\n\n\n\n\n\n\nWe are here  \n\n\n\n\n  \n𝐴𝐶  \n1  \n\n\n\n\n  \n\n𝐵𝐶  \n2  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐴𝐵  \n\n\n\n\n  \n\n𝐶𝐶  \n2  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐵𝐶  \n\n\n\n\n  \n\n𝐴𝐶  \nD  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐵𝐴  \n\n\n\n\n  \n\n𝐷𝐶  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐶𝐷  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRelaxed problem:\n\n\n▷State\n𝑠:\n𝐷𝐶; goal\n𝐺:\n𝐴𝐷.\n\n\n▷Actions\n𝐴:\nadd.\n\n\n▷ℎℛ(𝑠)=2:\n〈𝑑𝑟𝐵𝐴,𝑢𝑙𝐷〉.\n\n\n\n\n\nGreedy best-first search:(tie-breaking: alphabetic)\n\n\n\n\n\n\nWe are here  \n\n\n\n\n  \n𝐴𝐶  \n1  \n\n\n\n\n  \n\n𝐵𝐶  \n2  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐴𝐵  \n\n\n\n\n  \n\n𝐶𝐶  \n2  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐵𝐶  \n\n\n\n\n  \n\n𝐴𝐶  \nD  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐵𝐴  \n\n\n\n\n  \n\n𝐷𝐶  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐶𝐷  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRelaxed problem:\n\n\n▷State\n𝑠:\n𝐷𝐶; goal\n𝐺:\n𝐴𝐷.\n\n\n▷Actions\n𝐴:\nadd.\n\n\n▷ℎℛ(𝑠)=2:\n〈𝑑𝑟𝐵𝐴,𝑢𝑙𝐷〉.\n\n\n\n\n\nGreedy best-first search:(tie-breaking: alphabetic)\n\n\n\n\n\n\nWe are here  \n\n\n\n\n  \n𝐴𝐶  \n1  \n\n\n\n\n  \n\n𝐵𝐶  \n2  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐴𝐵  \n\n\n\n\n  \n\n𝐶𝐶  \n2  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐵𝐶  \n\n\n\n\n  \n\n𝐴𝐶  \nD  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐵𝐴  \n\n\n\n\n  \n\n𝐷𝐶  \n2  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐶𝐷  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nReal problem:\n\n\n▷State\n𝑠:\n𝐶𝑇; goal\n𝐺:\n𝐴𝐷.\n\n\n▷Actions\n𝐴:\npre,add,del.\n\n\n▷𝐶𝐶\n\n−\n\n\n−\n\n→\n𝑙𝑜𝐶𝐶𝑇.\n\n\n\n\n\nGreedy best-first search:(tie-breaking: alphabetic)\n\n\n\n\n\n\nWe are here  \n\n\n\n\n  \n𝐴𝐶  \n1  \n\n\n\n\n  \n\n𝐵𝐶  \n2  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐴𝐵  \n\n\n\n\n  \n\n𝐶𝐶  \n2  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐵𝐶  \n\n\n\n\n  \n\n𝐴𝐶  \nD  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐵𝐴  \n\n\n\n\n  \n\n𝐷𝐶  \n2  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐶𝐷  \n\n\n\n\n  \n\n𝐶𝑇  \n\n\n\n\n\n\n\n\n\n\n\n𝑙𝑜𝐶  \n\n\n\n\n\n\n\n\n\n\n\nRelaxed problem:\n\n\n▷State\n𝑠:\n𝐶𝑇; goal\n𝐺:\n𝐴𝐷.\n\n\n▷Actions\n𝐴:\nadd.\n\n\n▷ℎℛ(𝑠)=2:\n〈𝑑𝑟𝐵𝐴,𝑢𝑙𝐷〉.\n\n\n\n\n\nGreedy best-first search:(tie-breaking: alphabetic)\n\n\n\n\n\n\nWe are here  \n\n\n\n\n  \n𝐴𝐶  \n1  \n\n\n\n\n  \n\n𝐵𝐶  \n2  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐴𝐵  \n\n\n\n\n  \n\n𝐶𝐶  \n2  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐵𝐶  \n\n\n\n\n  \n\n𝐴𝐶  \nD  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐵𝐴  \n\n\n\n\n  \n\n𝐷𝐶  \n2  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐶𝐷  \n\n\n\n\n  \n\n𝐶𝑇  \n\n\n\n\n\n\n\n\n\n\n\n𝑙𝑜𝐶  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRelaxed problem:\n\n\n▷State\n𝑠:\n𝐶𝑇; goal\n𝐺:\n𝐴𝐷.\n\n\n▷Actions\n𝐴:\nadd.\n\n\n▷ℎℛ(𝑠)=2:\n〈𝑑𝑟𝐵𝐴,𝑢𝑙𝐷〉.\n\n\n\n\n\nGreedy best-first search:(tie-breaking: alphabetic)\n\n\n\n\n\n\nWe are here  \n\n\n\n\n  \n𝐴𝐶  \n1  \n\n\n\n\n  \n\n𝐵𝐶  \n2  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐴𝐵  \n\n\n\n\n  \n\n𝐶𝐶  \n2  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐵𝐶  \n\n\n\n\n  \n\n𝐴𝐶  \nD  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐵𝐴  \n\n\n\n\n  \n\n𝐷𝐶  \n2  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐶𝐷  \n\n\n\n\n  \n\n𝐶𝑇  \n2  \n\n\n\n\n\n\n\n\n\n\n\n𝑙𝑜𝐶  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nReal problem:\n\n\n▷State\n𝑠:\n𝐵𝐶; goal\n𝐺:\n𝐴𝐷.\n\n\n▷Actions\n𝐴:\npre,add,del.\n\n\n▷𝐶𝐶\n\n−\n\n\n−\n\n→\n𝑑𝑟𝐶𝐵𝐵𝐶.\n\n\n\n\n\nGreedy best-first search:(tie-breaking: alphabetic)\n\n\n\n\n\n\nWe are here  \n\n\n\n\n  \n𝐴𝐶  \n1  \n\n\n\n\n  \n\n𝐵𝐶  \n2  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐴𝐵  \n\n\n\n\n  \n\n𝐶𝐶  \n2  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐵𝐶  \n\n\n\n\n  \n\n𝐴𝐶  \nD  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐵𝐴  \n\n\n\n\n  \n\n𝐷𝐶  \n2  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐶𝐷  \n\n\n\n\n  \n\n𝐶𝑇  \n2  \n\n\n\n\n\n\n\n\n\n\n\n𝑙𝑜𝐶  \n\n\n\n\n  \n\n𝐵𝐶  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐶𝐵  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nReal problem:\n\n\n▷State\n𝑠:\n𝐵𝐶; goal\n𝐺:\n𝐴𝐷.\n\n\n▷Actions\n𝐴:\npre,add,del.\n\n\n▷Duplicate state,\nprune.\n\n\n\n\n\nGreedy best-first search:(tie-breaking: alphabetic)\n\n\n\n\n\n\nWe are here  \n\n\n\n\n  \n𝐴𝐶  \n1  \n\n\n\n\n  \n\n𝐵𝐶  \n2  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐴𝐵  \n\n\n\n\n  \n\n𝐶𝐶  \n2  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐵𝐶  \n\n\n\n\n  \n\n𝐴𝐶  \nD  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐵𝐴  \n\n\n\n\n  \n\n𝐷𝐶  \n2  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐶𝐷  \n\n\n\n\n  \n\n𝐶𝑇  \n2  \n\n\n\n\n\n\n\n\n\n\n\n𝑙𝑜𝐶  \n\n\n\n\n  \n\n𝐵𝐶  \nD  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐶𝐵  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nReal problem:\n\n\n▷State\n𝑠:\n𝐶𝑇; goal\n𝐺:\n𝐴𝐷.\n\n\n▷Actions\n𝐴:\npre,add,del.\n\n\n▷Successors:\n𝐵𝑇,\n𝐷𝑇,\n𝐶𝐶.\n\n\n\n\n\nGreedy best-first search:(tie-breaking: alphabetic)\n\n\n\n\n\n\nWe are here  \n\n\n\n\n  \n𝐴𝐶  \n1  \n\n\n\n\n  \n\n𝐵𝐶  \n2  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐴𝐵  \n\n\n\n\n  \n\n𝐶𝐶  \n2  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐵𝐶  \n\n\n\n\n  \n\n𝐴𝐶  \nD  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐵𝐴  \n\n\n\n\n  \n\n𝐷𝐶  \n2  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐶𝐷  \n\n\n\n\n  \n\n𝐶𝑇  \n2  \n\n\n\n\n\n\n\n\n\n\n\n𝑙𝑜𝐶  \n\n\n\n\n  \n\n𝐵𝐶  \nD  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐶𝐵  \n\n\n\n\n  \n\n𝐵𝑇  \n2  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐶𝐵  \n\n\n\n\n  \n\n𝐷𝑇  \n2  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐶𝐷  \n\n\n\n\n  \n\n𝐶𝐶  \nD  \n\n\n\n\n\n\n\n\n\n\n\n𝑢𝑙𝐶  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nReal problem:\n\n\n▷State\n𝑠:\n𝐵𝑇; goal\n𝐺:\n𝐴𝐷.\n\n\n▷Actions\n𝐴:\npre,add,del.\n\n\n▷Successors:\n𝐴𝑇,\n𝐵𝐵,\n𝐶𝑇.\n\n\n\n\n\nGreedy best-first search:(tie-breaking: alphabetic)\n\n\n\n\n\n\nWe are here  \n\n\n\n\n  \n𝐴𝐶  \n1  \n\n\n\n\n  \n\n𝐵𝐶  \n2  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐴𝐵  \n\n\n\n\n  \n\n𝐶𝐶  \n2  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐵𝐶  \n\n\n\n\n  \n\n𝐴𝐶  \nD  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐵𝐴  \n\n\n\n\n  \n\n𝐷𝐶  \n2  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐶𝐷  \n\n\n\n\n  \n\n𝐶𝑇  \n2  \n\n\n\n\n\n\n\n\n\n\n\n𝑙𝑜𝐶  \n\n\n\n\n  \n\n𝐵𝐶  \nD  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐶𝐵  \n\n\n\n\n  \n\n𝐵𝑇  \n2  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐶𝐵  \n\n\n\n\n  \n\n𝐷𝑇  \n2  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐶𝐷  \n\n\n\n\n  \n\n𝐶𝐶  \nD  \n\n\n\n\n\n\n\n\n\n\n\n𝑢𝑙𝐶  \n\n\n\n\n  \n\n𝐴𝑇  \n1  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐵𝐴  \n\n\n\n\n  \n\n𝐵𝐵  \n2  \n\n\n\n\n\n\n\n\n\n\n\n𝑢𝑙𝐵  \n\n\n\n\n  \n\n𝐶𝑇  \nD  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐵𝐶  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nReal problem:\n\n\n▷State\n𝑠:\n𝐴𝑇; goal\n𝐺:\n𝐴𝐷.\n\n\n▷Actions\n𝐴:\npre,add,del.\n\n\n▷Successors:\n𝐴𝐴,\n𝐵𝑇.\n\n\n\n\n\nGreedy best-first search:(tie-breaking: alphabetic)\n\n\n\n\n\n\nWe are here  \n\n\n\n\n  \n𝐴𝐶  \n1  \n\n\n\n\n  \n\n𝐵𝐶  \n2  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐴𝐵  \n\n\n\n\n  \n\n𝐶𝐶  \n2  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐵𝐶  \n\n\n\n\n  \n\n𝐴𝐶  \nD  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐵𝐴  \n\n\n\n\n  \n\n𝐷𝐶  \n2  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐶𝐷  \n\n\n\n\n  \n\n𝐶𝑇  \n2  \n\n\n\n\n\n\n\n\n\n\n\n𝑙𝑜𝐶  \n\n\n\n\n  \n\n𝐵𝐶  \nD  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐶𝐵  \n\n\n\n\n  \n\n𝐵𝑇  \n2  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐶𝐵  \n\n\n\n\n  \n\n𝐷𝑇  \n2  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐶𝐷  \n\n\n\n\n  \n\n𝐶𝐶  \nD  \n\n\n\n\n\n\n\n\n\n\n\n𝑢𝑙𝐶  \n\n\n\n\n  \n\n𝐴𝑇  \n1  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐵𝐴  \n\n\n\n\n  \n\n𝐵𝐵  \n2  \n\n\n\n\n\n\n\n\n\n\n\n𝑢𝑙𝐵  \n\n\n\n\n  \n\n𝐶𝑇  \nD  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐵𝐶  \n\n\n\n\n  \n\n𝐴𝐴  \n1  \n\n\n\n\n\n\n\n\n\n\n\n𝑢𝑙𝐴  \n\n\n\n\n  \n\n𝐵𝑇  \nD  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐴𝐵  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nReal problem:\n\n\n▷State\n𝑠:\n𝐴𝐴; goal\n𝐺:\n𝐴𝐷.\n\n\n▷Actions\n𝐴:\npre,add,del.\n\n\n▷Successors:\n𝐵𝐴,\n𝐴𝑇.\n\n\n\n\n\nGreedy best-first search:(tie-breaking: alphabetic)\n\n\n\n\n\n\nWe are here  \n\n\n\n\n  \n𝐴𝐶  \n1  \n\n\n\n\n  \n\n𝐵𝐶  \n2  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐴𝐵  \n\n\n\n\n  \n\n𝐶𝐶  \n2  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐵𝐶  \n\n\n\n\n  \n\n𝐴𝐶  \nD  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐵𝐴  \n\n\n\n\n  \n\n𝐷𝐶  \n2  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐶𝐷  \n\n\n\n\n  \n\n𝐶𝑇  \n2  \n\n\n\n\n\n\n\n\n\n\n\n𝑙𝑜𝐶  \n\n\n\n\n  \n\n𝐵𝐶  \nD  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐶𝐵  \n\n\n\n\n  \n\n𝐵𝑇  \n2  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐶𝐵  \n\n\n\n\n  \n\n𝐷𝑇  \n2  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐶𝐷  \n\n\n\n\n  \n\n𝐶𝐶  \nD  \n\n\n\n\n\n\n\n\n\n\n\n𝑢𝑙𝐶  \n\n\n\n\n  \n\n𝐴𝑇  \n1  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐵𝐴  \n\n\n\n\n  \n\n𝐵𝐵  \n2  \n\n\n\n\n\n\n\n\n\n\n\n𝑢𝑙𝐵  \n\n\n\n\n  \n\n𝐶𝑇  \nD  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐵𝐶  \n\n\n\n\n  \n\n𝐴𝐴  \n1  \n\n\n\n\n\n\n\n\n\n\n\n𝑢𝑙𝐴  \n\n\n\n\n  \n\n𝐵𝑇  \nD  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐴𝐵  \n\n\n\n\n  \n\n𝐵𝐴  \n2  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐴𝐵  \n\n\n\n\n  \n\n𝐴𝑇  \nD  \n\n\n\n\n\n\n\n\n\n\n\n𝑙𝑜𝐴  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nReal problem:\n\n\n▷State\n𝑠:\n𝐵𝐴; goal\n𝐺:\n𝐴𝐷.\n\n\n▷Actions\n𝐴:\npre,add,del.\n\n\n▷Successors:\n𝐶𝐴,\n𝐴𝐴.\n\n\n\n\n\nGreedy best-first search:(tie-breaking: alphabetic)\n\n\n\n\n\n\nWe are here  \n\n\n\n\n  \n𝐴𝐶  \n1  \n\n\n\n\n  \n\n𝐵𝐶  \n2  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐴𝐵  \n\n\n\n\n  \n\n𝐶𝐶  \n2  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐵𝐶  \n\n\n\n\n  \n\n𝐴𝐶  \nD  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐵𝐴  \n\n\n\n\n  \n\n𝐷𝐶  \n2  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐶𝐷  \n\n\n\n\n  \n\n𝐶𝑇  \n2  \n\n\n\n\n\n\n\n\n\n\n\n𝑙𝑜𝐶  \n\n\n\n\n  \n\n𝐵𝐶  \nD  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐶𝐵  \n\n\n\n\n  \n\n𝐵𝑇  \n2  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐶𝐵  \n\n\n\n\n  \n\n𝐷𝑇  \n2  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐶𝐷  \n\n\n\n\n  \n\n𝐶𝐶  \nD  \n\n\n\n\n\n\n\n\n\n\n\n𝑢𝑙𝐶  \n\n\n\n\n  \n\n𝐴𝑇  \n1  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐵𝐴  \n\n\n\n\n  \n\n𝐵𝐵  \n2  \n\n\n\n\n\n\n\n\n\n\n\n𝑢𝑙𝐵  \n\n\n\n\n  \n\n𝐶𝑇  \nD  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐵𝐶  \n\n\n\n\n  \n\n𝐴𝐴  \n1  \n\n\n\n\n\n\n\n\n\n\n\n𝑢𝑙𝐴  \n\n\n\n\n  \n\n𝐵𝑇  \nD  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐴𝐵  \n\n\n\n\n  \n\n𝐵𝐴  \n2  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐴𝐵  \n\n\n\n\n  \n\n𝐴𝑇  \nD  \n\n\n\n\n\n\n\n\n\n\n\n𝑙𝑜𝐴  \n\n\n\n\n  \n\n𝐶𝐴  \n2  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐵𝐶  \n\n\n\n\n  \n\n𝐴𝐴  \nD  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐵𝐴  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nReal problem:\n\n\n▷State\n𝑠:\n𝐵𝐴; goal\n𝐺:\n𝐴𝐷.\n\n\n▷Actions\n𝐴:\npre,add,del.\n\n\n▷Successors:\n𝐶𝐴,\n𝐴𝐴.\n\n\n\n\n\nGreedy best-first search:(tie-breaking: alphabetic)\n\n\n\n\n\n\nWe are here  \n\n\n\n\n  \n𝐴𝐶  \n1  \n\n\n\n\n  \n\n𝐵𝐶  \n2  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐴𝐵  \n\n\n\n\n  \n\n𝐶𝐶  \n2  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐵𝐶  \n\n\n\n\n  \n\n𝐴𝐶  \nD  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐵𝐴  \n\n\n\n\n  \n\n𝐷𝐶  \n2  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐶𝐷  \n\n\n\n\n  \n\n𝐶𝑇  \n2  \n\n\n\n\n\n\n\n\n\n\n\n𝑙𝑜𝐶  \n\n\n\n\n  \n\n𝐵𝐶  \nD  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐶𝐵  \n\n\n\n\n  \n\n𝐵𝑇  \n2  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐶𝐵  \n\n\n\n\n  \n\n𝐷𝑇  \n2  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐶𝐷  \n\n\n\n\n  \n\n𝐶𝐶  \nD  \n\n\n\n\n\n\n\n\n\n\n\n𝑢𝑙𝐶  \n\n\n\n\n  \n\n𝐴𝑇  \n1  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐵𝐴  \n\n\n\n\n  \n\n𝐵𝐵  \n2  \n\n\n\n\n\n\n\n\n\n\n\n𝑢𝑙𝐵  \n\n\n\n\n  \n\n𝐶𝑇  \nD  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐵𝐶  \n\n\n\n\n  \n\n𝐴𝐴  \n1  \n\n\n\n\n\n\n\n\n\n\n\n𝑢𝑙𝐴  \n\n\n\n\n  \n\n𝐵𝑇  \nD  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐴𝐵  \n\n\n\n\n  \n\n𝐵𝐴  \n2  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐴𝐵  \n\n\n\n\n  \n\n𝐴𝑇  \nD  \n\n\n\n\n\n\n\n\n\n\n\n𝑙𝑜𝐴  \n\n\n\n\n  \n\n𝐶𝐴  \n2  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐵𝐶  \n\n\n\n\n  \n\n𝐴𝐴  \nD  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐵𝐴  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n\n\n\n\n\n  \n\n\n\n\n\n  \n\n\n\n\n\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-15\n",
        "sectionId": "7b17932c",
        "archive": "courses/FAU/AI/course",
        "filepath": "planning/slides/relaxing-onlyadd-ex.en.xhtml"
    },
    {
        "slideContent": "\nOnly-Adds is a “Native” Relaxation\n\n▷Native Relaxations\n                Confusing special case where\n𝒫'⊆𝒫.\n\n\n\n\n\n\n\n𝒫  \n\n𝒫'⊆𝒫  \n\nℕ∪{∞}  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n\n\n\n\n\nℛ  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nℎ𝒫*  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nℎ𝒫'*  \n\n\n\n\n\n\n▷Problem class\n𝒫:\nSTRIPS tasks.\n\n\n▷Perfect heuristic\nℎ𝒫*\n                  for\n𝒫: Length\nℎ*\n                of a shortest plan.\n\n\n▷Transformation\nℛ:\n                Drop the\npreconditions\n                and\ndelete lists.\n\n\n▷Simpler problem class\n𝒫'\n                is a special case of\n𝒫,\n𝒫'⊆𝒫:\nSTRIPS tasks\n                with empty preconditions and delete lists.\n\n\n▷Perfect\nheuristic\n                for\n𝒫': Shortest plan for only-adds\nSTRIPS task.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "7b17932c",
        "archive": "courses/FAU/AI/course",
        "filepath": "planning/slides/onlyadd-native-relaxation.en.xhtml"
    },
    {
        "slideContent": "\nHow the Delete Relaxation Changes the World (I)\n\n▷Relaxation mapping\nℛ\n            saying that:\n\n\n“When the world changes, its previous state remains true as well.”\n\nReal world:\n                (before)\n\n\n\nReal world:\n                (after)\n\n\n\n\nRelaxed world:\n                (before)\n\n\n\nRelaxed world:\n                (after)\n\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-15\n",
        "sectionId": "bdf676b1",
        "archive": "courses/FAU/AI/course",
        "filepath": "planning/slides/delete-relaxation-intuition.en.xhtml"
    },
    {
        "slideContent": "\nHow the Delete Relaxation Changes the World (II)\n\n▷Relaxation mapping\nℛ\n            saying that:\n\n\nReal world:\n                (before)\n\n\n\nReal world:\n                (after)\n\n\n\nRelaxed world:\n                (before)\n\n\n\nRelaxed world:\n                (after)\n\n\n\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 122024-12-15\n",
        "sectionId": "bdf676b1",
        "archive": "courses/FAU/AI/course",
        "filepath": "planning/slides/delete-relaxation-intuition.en.xhtml"
    },
    {
        "slideContent": "\nHow the Delete Relaxation Changes the World (III)\n\n▷Relaxation mapping\nℛ\n            saying that:\n\n\nReal world:\n\n\n\nRelaxed world:\n\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 132024-12-15\n",
        "sectionId": "bdf676b1",
        "archive": "courses/FAU/AI/course",
        "filepath": "planning/slides/delete-relaxation-intuition.en.xhtml"
    },
    {
        "slideContent": "\nThe Delete Relaxation\n\n▷Delete Relaxation\n                  Let\nΠ:=〈𝑃,𝐴,𝐼,𝐺〉\n                  be a\nSTRIPS task. The\ndelete relaxation\n                  of\nΠ\n                  is the task\nΠ+=〈𝑃,𝐴+,𝐼,𝐺〉\n                  where\n𝐴+:={𝑎+|𝑎∊𝐴}\n                  with\npre𝑎+:=pre𝑎,\nadd𝑎+:=add𝑎, and\ndel𝑎+:=∅.\n\n\n▷In other words, the class of simpler problems\n𝒫'\n              is the set of all\nSTRIPS tasks\n              with\nempty\ndelete lists, and the\nrelaxation mapping\nℛ\n              drops the\ndelete lists.\n\n\n▷Relaxed Plan\n                  Let\nΠ:=〈𝑃,𝐴,𝐼,𝐺〉\n                  be a\nSTRIPS task, and let\n𝑠\n                  be a\nstate. A\nrelaxed plan\n                  for\n𝑠\n                  is a\nplan\n                  for\n〈𝑃,𝐴,𝑠,𝐺〉+. A\nrelaxed plan\n                  for\n𝐼\n                  is called a\nrelaxed plan\n                  for\nΠ.\n\n\n▷A\nrelaxed plan\n              for\n𝑠\n              is an\naction\n              sequence that solves\n𝑠\n              when pretending that all\ndelete lists\n              are\nempty.\n\n\n▷Also called\ndelete-relaxed\nplan: “relaxation” is often used to mean\ndelete relaxation\n                  by default.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "bdf676b1",
        "archive": "courses/FAU/AI/course",
        "filepath": "planning/slides/delete-relaxation.en.xhtml"
    },
    {
        "slideContent": "\nA Relaxed Plan for “TSP” in Australia\n\n\n\n1.Initial state:\n{at(Sy),vis(Sy)}.\n\n\n2.drv(Sy,Br)+:\n{at(Br),vis(Br),at(Sy),vis(Sy)}.\n\n\n3.drv(Sy,Ad)+:\n{at(Ad),vis(Ad),at(Br),vis(Br),at(Sy),vis(Sy)}.\n\n\n4.drv(Ad,Pe)+:\n{at(Pe),vis(Pe),at(Ad),vis(Ad),at(Br),vis(Br),at(Sy),vis(Sy)}.\n\n\n5.drv(Ad,Da)+:\n{at(Da),vis(Da),at(Pe),vis(Pe),at(Ad),vis(Ad),at(Br),vis(Br),at(Sy),vis(Sy)}.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "bdf676b1",
        "archive": "courses/FAU/AI/course",
        "filepath": "planning/slides/relaxed-plan-australia-ex.en.xhtml"
    },
    {
        "slideContent": "\nA Relaxed Plan for “Logistics”\n\n\n\n▷Facts\n𝑃:\n{truck(𝑥)|𝑥∊{𝐴,𝐵,𝐶,𝐷}}∪{pack(𝑥)|𝑥∊{𝐴,𝐵,𝐶,𝐷,𝑇}}.\n\n\n▷Initial state\n𝐼:\n{truck(𝐴),pack(𝐶)}.\n\n\n▷Goal\n𝐺:\n{truck(𝐴),pack(𝐷)}.\n\n\n▷Relaxed\nactions\n𝐴+: (Notated as “precondition\n⇒\n            adds”)\n\n\n▷drive(𝑥,𝑦)+: “truck(𝑥)⇒truck(𝑦)”.\n\n\n▷load(𝑥)+: “truck(𝑥),pack(𝑥)⇒pack(𝑇)”.\n\n\n▷unload(𝑥)+: “truck(𝑥),pack(𝑇)⇒pack(𝑥)”.\n\n\nRelaxed plan:\n〈drive(𝐴,𝐵)+,drive(𝐵,𝐶)+,load(𝐶)+,drive(𝐶,𝐷)+,unload(𝐷)+〉\n\n▷We don’t need to drive the truck back, because “it is still at\n𝐴”.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "bdf676b1",
        "archive": "courses/FAU/AI/course",
        "filepath": "planning/slides/relaxed-plan-logistics-ex.en.xhtml"
    },
    {
        "slideContent": "\n𝐏𝐥𝐚𝐧𝐄𝐱+\n\n▷Relaxed Plan Existence Problem\n                  By\n𝐏𝐥𝐚𝐧𝐄𝐱+, we denote the problem of deciding, given a\nSTRIPS task\nΠ:=〈𝑃,𝐴,𝐼,𝐺〉, whether or not there exists a\nrelaxed plan\n                  for\nΠ.\n\n\n▷This is easier than\n𝐏𝐥𝐚𝐧𝐄𝐱\n              for general\nSTRIPS!\n\n\n▷𝐏𝐥𝐚𝐧𝐄𝐱+\n                    is Easy\n𝐏𝐥𝐚𝐧𝐄𝐱+\n                  is in\n𝐏.\n\n\n▷Proof:\nThe following\nalgorithm\n                  decides\n𝐏𝐥𝐚𝐧𝐄𝐱+\n\n\n\n1.\n\nvar 𝐹 := 𝐼\nwhile 𝐺⊈𝐹 do\n𝐹' := 𝐹∪⋃𝑎∊𝐴:pre𝑎⊆𝐹add𝑎\nif 𝐹'=𝐹 then return ‘‘unsolvable’’ endif (*)\n𝐹 := 𝐹'\nendwhile\nreturn ‘‘solvable’’\n\n\n\n2.The\nalgorithm\nterminates\n                    after at most\n|𝑃|\n                    iterations, and thus runs in\npolynomial time.\n\n\n\n\n3.Correctness: See slide\n??\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "bdf676b1",
        "archive": "courses/FAU/AI/course",
        "filepath": "planning/slides/planexplus-algo.en.xhtml"
    },
    {
        "slideContent": "\nDeciding\n𝐏𝐥𝐚𝐧𝐄𝐱+\n              in “TSP” in Australia\n\n\n\nIterations on\n𝐹:\n\n\n1.{at(Sy),vis(Sy)}\n\n\n2.∪\n{at(Ad),vis(Ad),at(Br),vis(Br)}\n\n\n3.∪\n{at(Da),vis(Da),at(Pe),vis(Pe)}\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-15\n",
        "sectionId": "bdf676b1",
        "archive": "courses/FAU/AI/course",
        "filepath": "planning/slides/planexplus-australia.en.xhtml"
    },
    {
        "slideContent": "\nDeciding\n𝐏𝐥𝐚𝐧𝐄𝐱+\n              in “Logistics”\n\n▷The solvable Case\n\n\n\n\n\n\n\nIterations on\n𝐹:\n\n\n1.{truck(𝐴),pack(𝐶)}\n\n\n2.∪{truck(𝐵)}\n\n\n3.∪{truck(𝐶)}\n\n\n4.∪{truck(𝐷),pack(𝑇)}\n\n\n5.∪{pack(𝐴),pack(𝐵),pack(𝐷)}\n\n\n\n\n \n\n▷The unsolvable Case\n\n\n\n\n\n\nIterations on\n𝐹:\n\n\n1.{truck(𝐴),pack(𝐶)}\n\n\n2.∪{truck(𝐵)}\n\n\n3.∪{truck(𝐶)}\n\n\n4.∪{pack(𝑇)}\n\n\n5.∪{pack(𝐴),pack(𝐵)}\n\n\n6.∪∅\n\n\n\n\n \n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-15\n",
        "sectionId": "bdf676b1",
        "archive": "courses/FAU/AI/course",
        "filepath": "planning/slides/planexplus-logistics.en.xhtml"
    },
    {
        "slideContent": "\n𝐏𝐥𝐚𝐧𝐄𝐱+\n            Algorithm: Proof\n\nProof:\nTo show: The\nalgorithm\n              returns “solvable” iff there is a relaxed plan for\nΠ.\n\n\n\n1.Denote by\n𝐹𝑖\n                  the content of\n𝐹\n                  after the\n𝑖th iteration of the while-loop,\n\n\n\n\n2.All\n𝑎∊𝐴0\n                  are applicable in\n𝐼, all\n𝑎∊𝐴1\n                  are applicable in\napply(𝐼,𝐴0+), and so forth.\n\n\n\n\n3.Thus\n𝐹𝑖=apply(𝐼,〈𝐴0+,...,𝐴𝑖−1+〉). (Within each\n𝐴𝑗+, we can sequence the\nactions\n                  in any order.)\n\n\n4.Direction “⇒”\n\nIf “solvable” is returned after iteration\n𝑛\n                      then\n𝐺⊆𝐹𝑛=\napply(𝐼,〈𝐴0+,...,𝐴𝑛−1+〉)\n                      so\n〈𝐴0+,...,𝐴𝑛−1+〉\n                      can be sequenced to a relaxed plan which shows the claim.\n\n\n5.Direction “⇐”\n\n\n\n5.1.Let\n〈𝑎0+,...,𝑎𝑛−1+〉\n                      be a relaxed plan, hence\n𝐺⊆apply(𝐼,〈𝑎0+,...,𝑎𝑛−1+〉).\n\n\n\n\n5.2.Assume, for the moment, that we drop line (*) from the\nalgorithm. It is then easy to see that\n𝑎𝑖∊𝐴𝑖\n                      and\napply(𝐼,〈𝑎0+,...,𝑎𝑖−1+〉)⊆𝐹𝑖, for all\n𝑖.\n\n\n\n\n5.3.We get\n𝐺⊆apply(𝐼,〈𝑎0+,...,𝑎𝑛−1+〉)\n⊆𝐹𝑛, and the\nalgorithm\n                      returns “solvable” as desired.\n\n\n\n\n5.4.Assume to the contrary of the claim that, in an iteration\n𝑖<𝑛, (*) fires. Then\n𝐺⊈𝐹\n                      and\n𝐹=𝐹'. But, with\n𝐹=𝐹',\n𝐹=𝐹𝑗\n                      for all\n𝑗>𝑖, and we get\n𝐺⊈𝐹𝑛\n                      in\ncontradiction.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-15\n",
        "sectionId": "bdf676b1",
        "archive": "courses/FAU/AI/course",
        "filepath": "planning/slides/planexplus-correct.en.xhtml"
    },
    {
        "slideContent": "\nHold on a Sec — Where are we?\n\n\n\n\n\n\n𝒫  \n\n𝒫'⊆𝒫  \n\nℕ∪{∞}  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n\n\n\n\n\nℛ  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nℎ𝒫*  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nℎ𝒫'*  \n\n\n\n\n\n\n▷𝒫:\nSTRIPS tasks;\nℎ𝒫*: Length\nℎ*\n            of a shortest plan.\n\n\n▷𝒫'⊆𝒫:\nSTRIPS tasks\n            with empty\ndelete lists.\n\n\n▷ℛ: Drop the\ndelete lists.\n\n\n▷Heuristic function: Length of a shortest\nrelaxed\nplan\n            (ℎ*◦ℛ).\n\n\n▷𝐏𝐥𝐚𝐧𝐄𝐱+\n            is not actually what we’re looking for.\n𝐏𝐥𝐚𝐧𝐄𝐱+\n=^\n            relaxed plan\nexistence; we want relaxed plan\nlength\nℎ*◦ℛ.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-16\n",
        "sectionId": "d4dfff65",
        "archive": "courses/FAU/AI/course",
        "filepath": "planning/slides/hplus-where.en.xhtml"
    },
    {
        "slideContent": "\nℎ+: The Ideal Delete Relaxation Heuristic\n\n▷Optimal Relaxed Plan\n                  Let\n〈𝑃,𝐴,𝐼,𝐺〉\n                  be a\nSTRIPS task, and let\n𝑠\n                  be a\nstate. A\noptimal relaxed plan\n                  for\n𝑠\n                  is an\noptimal plan\n                  for\n〈𝑃,𝐴,{𝑠},𝐺〉+.\n\n\n▷Same as slide\n??, just adding the word “optimal”.\n\n\n▷Here’s what we’re looking for:\n\n\n▷\n                  Let\nΠ:=〈𝑃,𝐴,𝐼,𝐺〉\n                  be a\nSTRIPS task\n                  with\nstates\n𝑆. The\nideal delete relaxation heuristic\nℎ+\n                  for\nΠ\n                  is the\nfunction\nℎ+:𝑆→ℕ∪{∞}\n                  where\nℎ+(𝑠)\n                  is the\nlength\n                  of an\noptimal relaxed plan\n                  for\n𝑠\n                  if a\nrelaxed plan\n                  for\n𝑠\n                  exists, and\nℎ+(𝑠)=∞\n                  otherwise.\n\n\n▷In other words,\nℎ+=ℎ*◦ℛ, cf. previous slide.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "d4dfff65",
        "archive": "courses/FAU/AI/course",
        "filepath": "planning/slides/hplus.en.xhtml"
    },
    {
        "slideContent": "\nℎ+\n              is\nAdmissible\n\n▷\n                  Let\nΠ:=〈𝑃,𝐴,𝐼,𝐺〉\n                  be a\nSTRIPS task, and let\n𝑠\n                  be a state. If\n〈𝑎1,...,𝑎𝑛〉\n                  is a plan for\nΠ𝑠:=〈𝑃,𝐴,{𝑠},𝐺〉, then\n〈map(/𝑚𝑛𝑡/𝑠𝑑𝑏1/𝑏𝑢𝑖𝑙𝑑𝑠𝑒𝑟𝑣𝑒𝑟/𝑀𝑎𝑡ℎ𝐻𝑢𝑏,𝑎1+,...,𝑎𝑛+)𝑎1+,...,𝑎𝑛+〉\n                  is a plan for\nΠ+.\n\n\n▷Proof sketch:\n                Show by\ninduction\n                over\n0≤𝑖≤𝑛\n                thatapply(𝑠,〈𝑎1,...,𝑎𝑖〉)⊆apply(𝑠,〈𝑎1+,...,𝑎𝑖+〉).\n\n\n▷If we ignore deletes, the states along the plan can only get bigger.\n\n\n▷\nℎ+\n                  is\nAdmissible.\n\n\n▷Proof:\n\n\n\n\n1.Let\nΠ:=〈𝑃,𝐴,𝐼,𝐺〉\n                    be a\nSTRIPS task\n                    with states\n𝑃, and let\n𝑠∊𝑃.\n\n\n\n\n2.ℎ+(𝑠)\n                    is defined as optimal plan length in\nΠ𝑠+.\n\n\n\n\n3.With the lemma above, any\nplan\n                    for\nΠ\n                    also constitutes a plan for\nΠ𝑠+.\n\n\n\n\n4.Thus optimal plan length in\nΠ𝑠+\n                    can only be shorter than that in\nΠ𝑠𝑖, and the claim follows.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-15\n",
        "sectionId": "d4dfff65",
        "archive": "courses/FAU/AI/course",
        "filepath": "planning/slides/hplus-admissible.en.xhtml"
    },
    {
        "slideContent": "\nHow to Relax During Search: Ignoring Deletes\n\n\n\n\n\n\n\nReal problem:\n\n\n▷Initial state\n𝐼:\n𝐴𝐶; goal\n𝐺:\n𝐴𝐷.\n\n\n▷Actions\n𝐴:\npre,add,del.\n\n\n▷𝑑𝑟𝑋𝑌,𝑙𝑜𝑋,𝑢𝑙𝑋.\n\n\n\n\n\n\nGreedy best-first search:\n(tie-breaking: alphabetic)\n\n\n\n\n\n\nWe are here  \n\n\n\n\n  \n𝐴𝐶  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRelaxed problem:\n\n\n▷State\n𝑠:\n𝐴𝐶; goal\n𝐺:\n𝐴𝐷.\n\n\n▷Actions\n𝐴:\npre,add.\n\n\n▷ℎ+(𝑠)=5: e.g.\n〈𝑑𝑟𝐴𝐵,𝑑𝑟𝐵𝐶,𝑑𝑟𝐶𝐷,𝑙𝑜𝐶,𝑢𝑙𝐷〉.\n\n\n\n\n\nGreedy best-first search:\n(tie-breaking: alphabetic)\n\n\n\n\n\n\nWe are here  \n\n\n\n\n  \n𝐴𝐶  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRelaxed problem:\n\n\n▷State\n𝑠:\n𝐴𝐶; goal\n𝐺:\n𝐴𝐷.\n\n\n▷Actions\n𝐴:\npre,add.\n\n\n▷ℎ+(𝑠)=5: e.g.\n〈𝑑𝑟𝐴𝐵,𝑑𝑟𝐵𝐶,𝑑𝑟𝐶𝐷,𝑙𝑜𝐶,𝑢𝑙𝐷〉.\n\n\n\n\n\nGreedy best-first search:\n(tie-breaking: alphabetic)\n\n\n\n\n\n\nWe are here  \n\n\n\n\n  \n𝐴𝐶  \n5  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nReal problem:\n\n\n▷State\n𝑠:\n𝐵𝐶; goal\n𝐺:\n𝐴𝐷.\n\n\n▷Actions\n𝐴:\npre,add,del.\n\n\n▷𝐴𝐶\n\n−\n\n\n−\n\n→\n𝑑𝑟𝐴𝐵𝐵𝐶.\n\n\n\n\n\n\nGreedy best-first search:\n(tie-breaking: alphabetic)\n\n\n\n\n\n\nWe are here  \n\n\n\n\n  \n𝐴𝐶  \n5  \n\n\n\n\n  \n\n𝐵𝐶  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐴𝐵  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRelaxed problem:\n\n\n▷State\n𝑠:\n𝐵𝐶; goal\n𝐺:\n𝐴𝐷.\n\n\n▷Actions\n𝐴:\npre,add.\n\n\n▷ℎ+(𝑠)=5: e.g.\n〈𝑑𝑟𝐵𝐴,𝑑𝑟𝐵𝐶,𝑑𝑟𝐶𝐷,𝑙𝑜𝐶,𝑢𝑙𝐷〉.\n\n\n\n\n\nGreedy best-first search:\n(tie-breaking: alphabetic)\n\n\n\n\n\n\nWe are here  \n\n\n\n\n  \n𝐴𝐶  \n5  \n\n\n\n\n  \n\n𝐵𝐶  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐴𝐵  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRelaxed problem:\n\n\n▷State\n𝑠:\n𝐵𝐶; goal\n𝐺:\n𝐴𝐷.\n\n\n▷Actions\n𝐴:\npre,add.\n\n\n▷ℎ+(𝑠)=5: e.g.\n〈𝑑𝑟𝐵𝐴,𝑑𝑟𝐵𝐶,𝑑𝑟𝐶𝐷,𝑙𝑜𝐶,𝑢𝑙𝐷〉.\n\n\n\n\n\nGreedy best-first search:\n(tie-breaking: alphabetic)\n\n\n\n\n\n\nWe are here  \n\n\n\n\n  \n𝐴𝐶  \n5  \n\n\n\n\n  \n\n𝐵𝐶  \n5  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐴𝐵  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nReal problem:\n\n\n▷State\n𝑠:\n𝐶𝐶; goal\n𝐺:\n𝐴𝐷.\n\n\n▷Actions\n𝐴:\npre,add,del.\n\n\n▷𝐵𝐶\n\n−\n\n\n−\n\n→\n𝑑𝑟𝐵𝐶𝐶𝐶.\n\n\n\n\n\n\nGreedy best-first search:\n(tie-breaking: alphabetic)\n\n\n\n\n\n\nWe are here  \n\n\n\n\n  \n𝐴𝐶  \n5  \n\n\n\n\n  \n\n𝐵𝐶  \n5  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐴𝐵  \n\n\n\n\n  \n\n𝐶𝐶  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐵𝐶  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRelaxed problem:\n\n\n▷State\n𝑠:\n𝐶𝐶; goal\n𝐺:\n𝐴𝐷.\n\n\n▷Actions\n𝐴:\npre,add.\n\n\n▷ℎ+(𝑠)=5: e.g.\n〈𝑑𝑟𝐶𝐵,𝑑𝑟𝐵𝐴,𝑑𝑟𝐶𝐷,𝑙𝑜𝐶,𝑢𝑙𝐷〉.\n\n\n\n\n\nGreedy best-first search:\n(tie-breaking: alphabetic)\n\n\n\n\n\n\nWe are here  \n\n\n\n\n  \n𝐴𝐶  \n5  \n\n\n\n\n  \n\n𝐵𝐶  \n5  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐴𝐵  \n\n\n\n\n  \n\n𝐶𝐶  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐵𝐶  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRelaxed problem:\n\n\n▷State\n𝑠:\n𝐶𝐶; goal\n𝐺:\n𝐴𝐷.\n\n\n▷Actions\n𝐴:\npre,add.\n\n\n▷ℎ+(𝑠)=5: e.g.\n〈𝑑𝑟𝐶𝐵,𝑑𝑟𝐵𝐴,𝑑𝑟𝐶𝐷,𝑙𝑜𝐶,𝑢𝑙𝐷〉.\n\n\n\n\n\nGreedy best-first search:\n(tie-breaking: alphabetic)\n\n\n\n\n\n\nWe are here  \n\n\n\n\n  \n𝐴𝐶  \n\n\n\n\n  \n\n𝐵𝐶  \n5  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐴𝐵  \n\n\n\n\n  \n\n𝐶𝐶  \n5  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐵𝐶  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nReal problem:\n\n\n▷State\n𝑠:\n𝐴𝐶; goal\n𝐺:\n𝐴𝐷.\n\n\n▷Actions\n𝐴:\npre,add,del.\n\n\n▷𝐵𝐶\n\n−\n\n\n−\n\n→\n𝑑𝑟𝐵𝐴𝐴𝐶.\n\n\n\n\n\n\nGreedy best-first search:\n(tie-breaking: alphabetic)\n\n\n\n\n\n\nWe are here  \n\n\n\n\n  \n𝐴𝐶  \n5  \n\n\n\n\n  \n\n𝐵𝐶  \n5  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐴𝐵  \n\n\n\n\n  \n\n𝐶𝐶  \n5  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐵𝐶  \n\n\n\n\n  \n\n𝐴𝐶  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐵𝐴  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nReal problem:\n\n\n▷State\n𝑠:\n𝐴𝐶; goal\n𝐺:\n𝐴𝐷.\n\n\n▷Actions\n𝐴:\npre,add,del.\n\n\n▷Duplicate\nstate,\nprune.\n\n\n\n\n\n\nGreedy best-first search:\n(tie-breaking: alphabetic)\n\n\n\n\n\n\nWe are here  \n\n\n\n\n  \n𝐴𝐶  \n5  \n\n\n\n\n  \n\n𝐵𝐶  \n5  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐴𝐵  \n\n\n\n\n  \n\n𝐶𝐶  \n5  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐵𝐶  \n\n\n\n\n  \n\n𝐴𝐶  \nD  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐵𝐴  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nReal problem:\n\n\n▷State\n𝑠:\n𝐷𝐶; goal\n𝐺:\n𝐴𝐷.\n\n\n▷Actions\n𝐴:\npre,add,del.\n\n\n▷𝐶𝐶\n\n−\n\n\n−\n\n→\n𝑑𝑟𝐶𝐷𝐷𝐶.\n\n\n\n\n\n\nGreedy best-first search:\n(tie-breaking: alphabetic)\n\n\n\n\n\n\nWe are here  \n\n\n\n\n  \n𝐴𝐶  \n5  \n\n\n\n\n  \n\n𝐵𝐶  \n5  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐴𝐵  \n\n\n\n\n  \n\n𝐶𝐶  \n5  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐵𝐶  \n\n\n\n\n  \n\n𝐴𝐶  \nD  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐵𝐴  \n\n\n\n\n  \n\n𝐷𝐶  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐶𝐷  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRelaxed problem:\n\n\n▷State\n𝑠:\n𝐷𝐶; goal\n𝐺:\n𝐴𝐷.\n\n\n▷Actions\n𝐴:\npre,add.\n\n\n▷ℎ+(𝑠)=5: e.g.\n〈𝑑𝑟𝐷𝐶,𝑑𝑟𝐶𝐵,𝑑𝑟𝐵𝐴,𝑙𝑜𝐶,𝑢𝑙𝐷〉.\n\n\n\n\n\nGreedy best-first search:\n(tie-breaking: alphabetic)\n\n\n\n\n\n\nWe are here  \n\n\n\n\n  \n𝐴𝐶  \n5  \n\n\n\n\n  \n\n𝐵𝐶  \n5  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐴𝐵  \n\n\n\n\n  \n\n𝐶𝐶  \n5  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐵𝐶  \n\n\n\n\n  \n\n𝐴𝐶  \nD  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐵𝐴  \n\n\n\n\n  \n\n𝐷𝐶  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐶𝐷  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRelaxed problem:\n\n\n▷State\n𝑠:\n𝐷𝐶; goal\n𝐺:\n𝐴𝐷.\n\n\n▷Actions\n𝐴:\npre,add.\n\n\n▷ℎ+(𝑠)=5: e.g.\n〈𝑑𝑟𝐷𝐶,𝑑𝑟𝐶𝐵,𝑑𝑟𝐵𝐴,𝑙𝑜𝐶,𝑢𝑙𝐷〉.\n\n\n\n\n\nGreedy best-first search:\n(tie-breaking: alphabetic)\n\n\n\n\n\n\nWe are here  \n\n\n\n\n  \n𝐴𝐶  \n5  \n\n\n\n\n  \n\n𝐵𝐶  \n5  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐴𝐵  \n\n\n\n\n  \n\n𝐶𝐶  \n5  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐵𝐶  \n\n\n\n\n  \n\n𝐴𝐶  \nD  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐵𝐴  \n\n\n\n\n  \n\n𝐷𝐶  \n5  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐶𝐷  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nReal problem:\n\n\n▷State\n𝑠:\n𝐶𝑇; goal\n𝐺:\n𝐴𝐷.\n\n\n▷Actions\n𝐴:\npre,add,del.\n\n\n▷𝐶𝐶\n\n−\n\n\n−\n\n→\n𝑙𝑜𝐶𝐶𝑇.\n\n\n\n\n\n\nGreedy best-first search:\n(tie-breaking: alphabetic)\n\n\n\n\n\n\nWe are here  \n\n\n\n\n  \n𝐴𝐶  \n5  \n\n\n\n\n  \n\n𝐵𝐶  \n5  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐴𝐵  \n\n\n\n\n  \n\n𝐶𝐶  \n5  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐵𝐶  \n\n\n\n\n  \n\n𝐴𝐶  \nD  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐵𝐴  \n\n\n\n\n  \n\n𝐷𝐶  \n5  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐶𝐷  \n\n\n\n\n  \n\n𝐶𝑇  \n\n\n\n\n\n\n\n\n\n\n\n𝑙𝑜𝐶  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRelaxed problem:\n\n\n▷State\n𝑠:\n𝐶𝑇; goal\n𝐺:\n𝐴𝐷.\n\n\n▷Actions\n𝐴:\npre,add.\n\n\n▷ℎ+(𝑠)=4: e.g.\n〈𝑑𝑟𝐶𝐵,𝑑𝑟𝐵𝐴,𝑑𝑟𝐶𝐷,𝑢𝑙𝐷〉.\n\n\n\n\n\nGreedy best-first search:\n(tie-breaking: alphabetic)\n\n\n\n\n\n\nWe are here  \n\n\n\n\n  \n𝐴𝐶  \n5  \n\n\n\n\n  \n\n𝐵𝐶  \n5  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐴𝐵  \n\n\n\n\n  \n\n𝐶𝐶  \n5  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐵𝐶  \n\n\n\n\n  \n\n𝐴𝐶  \nD  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐵𝐴  \n\n\n\n\n  \n\n𝐷𝐶  \n5  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐶𝐷  \n\n\n\n\n  \n\n𝐶𝑇  \n\n\n\n\n\n\n\n\n\n\n\n𝑙𝑜𝐶  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRelaxed problem:\n\n\n▷State\n𝑠:\n𝐶𝑇; goal\n𝐺:\n𝐴𝐷.\n\n\n▷Actions\n𝐴:\npre,add.\n\n\n▷ℎ+(𝑠)=4: e.g.\n〈𝑑𝑟𝐶𝐵,𝑑𝑟𝐵𝐴,𝑑𝑟𝐶𝐷,𝑢𝑙𝐷〉.\n\n\n\n\n\nGreedy best-first search:\n(tie-breaking: alphabetic)\n\n\n\n\n\n\nWe are here  \n\n\n\n\n  \n𝐴𝐶  \n5  \n\n\n\n\n  \n\n𝐵𝐶  \n5  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐴𝐵  \n\n\n\n\n  \n\n𝐶𝐶  \n5  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐵𝐶  \n\n\n\n\n  \n\n𝐴𝐶  \nD  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐵𝐴  \n\n\n\n\n  \n\n𝐷𝐶  \n5  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐶𝐷  \n\n\n\n\n  \n\n𝐶𝑇  \n4  \n\n\n\n\n\n\n\n\n\n\n\n𝑙𝑜𝐶  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nReal problem:\n\n\n▷State\n𝑠:\n𝐵𝐶; goal\n𝐺:\n𝐴𝐷.\n\n\n▷Actions\n𝐴:\npre,add,del.\n\n\n▷𝐶𝐶\n\n−\n\n\n−\n\n→\n𝑑𝑟𝐶𝐵𝐵𝐶.\n\n\n\n\n\n\nGreedy best-first search:\n(tie-breaking: alphabetic)\n\n\n\n\n\n\nWe are here  \n\n\n\n\n  \n𝐴𝐶  \n5  \n\n\n\n\n  \n\n𝐵𝐶  \n5  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐴𝐵  \n\n\n\n\n  \n\n𝐶𝐶  \n5  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐵𝐶  \n\n\n\n\n  \n\n𝐴𝐶  \nD  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐵𝐴  \n\n\n\n\n  \n\n𝐷𝐶  \n5  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐶𝐷  \n\n\n\n\n  \n\n𝐶𝑇  \n4  \n\n\n\n\n\n\n\n\n\n\n\n𝑙𝑜𝐶  \n\n\n\n\n  \n\n𝐵𝐶  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐶𝐵  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nReal problem:\n\n\n▷State\n𝑠:\n𝐵𝐶; goal\n𝐺:\n𝐴𝐷.\n\n\n▷Actions\n𝐴:\npre,add,del.\n\n\n▷Duplicate state,\nprune.\n\n\n\n\n\n\nGreedy best-first search:\n(tie-breaking: alphabetic)\n\n\n\n\n\n\nWe are here  \n\n\n\n\n  \n𝐴𝐶  \n5  \n\n\n\n\n  \n\n𝐵𝐶  \n5  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐴𝐵  \n\n\n\n\n  \n\n𝐶𝐶  \n5  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐵𝐶  \n\n\n\n\n  \n\n𝐴𝐶  \nD  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐵𝐴  \n\n\n\n\n  \n\n𝐷𝐶  \n5  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐶𝐷  \n\n\n\n\n  \n\n𝐶𝑇  \n4  \n\n\n\n\n\n\n\n\n\n\n\n𝑙𝑜𝐶  \n\n\n\n\n  \n\n𝐵𝐶  \nD  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐶𝐵  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nReal problem:\n\n\n▷State\n𝑠:\n𝐶𝑇; goal\n𝐺:\n𝐴𝐷.\n\n\n▷Actions\n𝐴:\npre,add,del.\n\n\n▷Successors:\n𝐵𝑇,\n𝐷𝑇,\n𝐶𝐶.\n\n\n\n\n\n\nGreedy best-first search:\n(tie-breaking: alphabetic)\n\n\n\n\n\n\nWe are here  \n\n\n\n\n  \n𝐴𝐶  \n5  \n\n\n\n\n  \n\n𝐵𝐶  \n5  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐴𝐵  \n\n\n\n\n  \n\n𝐶𝐶  \n5  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐵𝐶  \n\n\n\n\n  \n\n𝐴𝐶  \nD  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐵𝐴  \n\n\n\n\n  \n\n𝐷𝐶  \n5  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐶𝐷  \n\n\n\n\n  \n\n𝐶𝑇  \n4  \n\n\n\n\n\n\n\n\n\n\n\n𝑙𝑜𝐶  \n\n\n\n\n  \n\n𝐵𝐶  \nD  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐶𝐵  \n\n\n\n\n  \n\n𝐵𝑇  \n4  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐶𝐵  \n\n\n\n\n  \n\n𝐷𝑇  \n4  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐶𝐷  \n\n\n\n\n  \n\n𝐶𝐶  \nD  \n\n\n\n\n\n\n\n\n\n\n\n𝑢𝑙𝐶  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nReal problem:\n\n\n▷State\n𝑠:\n𝐵𝑇; goal\n𝐺:\n𝐴𝐷.\n\n\n▷Actions\n𝐴:\npre,add,del.\n\n\n▷Successors:\n𝐴𝑇,\n𝐵𝐵,\n𝐶𝑇.\n\n\n\n\n\n\nGreedy best-first search:\n(tie-breaking: alphabetic)\n\n\n\n\n\n\nWe are here  \n\n\n\n\n  \n𝐴𝐶  \n5  \n\n\n\n\n  \n\n𝐵𝐶  \n5  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐴𝐵  \n\n\n\n\n  \n\n𝐶𝐶  \n5  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐵𝐶  \n\n\n\n\n  \n\n𝐴𝐶  \nD  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐵𝐴  \n\n\n\n\n  \n\n𝐷𝐶  \n5  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐶𝐷  \n\n\n\n\n  \n\n𝐶𝑇  \n4  \n\n\n\n\n\n\n\n\n\n\n\n𝑙𝑜𝐶  \n\n\n\n\n  \n\n𝐵𝐶  \nD  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐶𝐵  \n\n\n\n\n  \n\n𝐵𝑇  \n4  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐶𝐵  \n\n\n\n\n  \n\n𝐷𝑇  \n4  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐶𝐷  \n\n\n\n\n  \n\n𝐶𝐶  \nD  \n\n\n\n\n\n\n\n\n\n\n\n𝑢𝑙𝐶  \n\n\n\n\n  \n\n𝐴𝑇  \n4  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐵𝐴  \n\n\n\n\n  \n\n𝐵𝐵  \n5  \n\n\n\n\n\n\n\n\n\n\n\n𝑢𝑙𝐵  \n\n\n\n\n  \n\n𝐶𝑇  \nD  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐵𝐶  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nReal problem:\n\n\n▷State\n𝑠:\n𝐴𝑇; goal\n𝐺:\n𝐴𝐷.\n\n\n▷Actions\n𝐴:\npre,add,del.\n\n\n▷Successors:\n𝐴𝐴,\n𝐵𝑇.\n\n\n\n\n\n\nGreedy best-first search:\n(tie-breaking: alphabetic)\n\n\n\n\n\n\nWe are here  \n\n\n\n\n  \n𝐴𝐶  \n5  \n\n\n\n\n  \n\n𝐵𝐶  \n5  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐴𝐵  \n\n\n\n\n  \n\n𝐶𝐶  \n5  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐵𝐶  \n\n\n\n\n  \n\n𝐴𝐶  \nD  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐵𝐴  \n\n\n\n\n  \n\n𝐷𝐶  \n5  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐶𝐷  \n\n\n\n\n  \n\n𝐶𝑇  \n4  \n\n\n\n\n\n\n\n\n\n\n\n𝑙𝑜𝐶  \n\n\n\n\n  \n\n𝐵𝐶  \nD  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐶𝐵  \n\n\n\n\n  \n\n𝐵𝑇  \n4  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐶𝐵  \n\n\n\n\n  \n\n𝐷𝑇  \n4  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐶𝐷  \n\n\n\n\n  \n\n𝐶𝐶  \nD  \n\n\n\n\n\n\n\n\n\n\n\n𝑢𝑙𝐶  \n\n\n\n\n  \n\n𝐴𝑇  \n4  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐵𝐴  \n\n\n\n\n  \n\n𝐵𝐵  \n5  \n\n\n\n\n\n\n\n\n\n\n\n𝑢𝑙𝐵  \n\n\n\n\n  \n\n𝐶𝑇  \nD  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐵𝐶  \n\n\n\n\n  \n\n𝐴𝐴  \n5  \n\n\n\n\n\n\n\n\n\n\n\n𝑢𝑙𝐴  \n\n\n\n\n  \n\n𝐵𝑇  \nD  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐴𝐵  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nReal problem:\n\n\n▷State\n𝑠:\n𝐷𝑇; goal\n𝐺:\n𝐴𝐷.\n\n\n▷Actions\n𝐴:\npre,add,del.\n\n\n▷Successors:\n𝐷𝐷,\n𝐶𝑇.\n\n\n\n\n\n\nGreedy best-first search:\n(tie-breaking: alphabetic)\n\n\n\n\n\n\nWe are here  \n\n\n\n\n  \n𝐴𝐶  \n5  \n\n\n\n\n  \n\n𝐵𝐶  \n5  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐴𝐵  \n\n\n\n\n  \n\n𝐶𝐶  \n5  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐵𝐶  \n\n\n\n\n  \n\n𝐴𝐶  \nD  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐵𝐴  \n\n\n\n\n  \n\n𝐷𝐶  \n5  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐶𝐷  \n\n\n\n\n  \n\n𝐶𝑇  \n4  \n\n\n\n\n\n\n\n\n\n\n\n𝑙𝑜𝐶  \n\n\n\n\n  \n\n𝐵𝐶  \nD  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐶𝐵  \n\n\n\n\n  \n\n𝐵𝑇  \n4  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐶𝐵  \n\n\n\n\n  \n\n𝐷𝑇  \n4  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐶𝐷  \n\n\n\n\n  \n\n𝐶𝐶  \nD  \n\n\n\n\n\n\n\n\n\n\n\n𝑢𝑙𝐶  \n\n\n\n\n  \n\n𝐴𝑇  \n4  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐵𝐴  \n\n\n\n\n  \n\n𝐵𝐵  \n5  \n\n\n\n\n\n\n\n\n\n\n\n𝑢𝑙𝐵  \n\n\n\n\n  \n\n𝐶𝑇  \nD  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐵𝐶  \n\n\n\n\n  \n\n𝐴𝐴  \n5  \n\n\n\n\n\n\n\n\n\n\n\n𝑢𝑙𝐴  \n\n\n\n\n  \n\n𝐵𝑇  \nD  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐴𝐵  \n\n\n\n\n  \n\n𝐷𝐷  \n3  \n\n\n\n\n\n\n\n\n\n\n\n𝑢𝑙𝐷  \n\n\n\n\n  \n\n𝐶𝑇  \nD  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐷𝐶  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nReal problem:\n\n\n▷State\n𝑠:\n𝐷𝐷; goal\n𝐺:\n𝐴𝐷.\n\n\n▷Actions\n𝐴:\npre,add,del.\n\n\n▷Successors:\n𝐶𝐷,\n𝐷𝑇.\n\n\n\n\n\n\nGreedy best-first search:\n(tie-breaking: alphabetic)\n\n\n\n\n\n\nWe are here  \n\n\n\n\n  \n𝐴𝐶  \n5  \n\n\n\n\n  \n\n𝐵𝐶  \n5  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐴𝐵  \n\n\n\n\n  \n\n𝐶𝐶  \n5  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐵𝐶  \n\n\n\n\n  \n\n𝐴𝐶  \nD  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐵𝐴  \n\n\n\n\n  \n\n𝐷𝐶  \n5  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐶𝐷  \n\n\n\n\n  \n\n𝐶𝑇  \n4  \n\n\n\n\n\n\n\n\n\n\n\n𝑙𝑜𝐶  \n\n\n\n\n  \n\n𝐵𝐶  \nD  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐶𝐵  \n\n\n\n\n  \n\n𝐵𝑇  \n4  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐶𝐵  \n\n\n\n\n  \n\n𝐷𝑇  \n4  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐶𝐷  \n\n\n\n\n  \n\n𝐶𝐶  \nD  \n\n\n\n\n\n\n\n\n\n\n\n𝑢𝑙𝐶  \n\n\n\n\n  \n\n𝐴𝑇  \n4  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐵𝐴  \n\n\n\n\n  \n\n𝐵𝐵  \n5  \n\n\n\n\n\n\n\n\n\n\n\n𝑢𝑙𝐵  \n\n\n\n\n  \n\n𝐶𝑇  \nD  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐵𝐶  \n\n\n\n\n  \n\n𝐴𝐴  \n5  \n\n\n\n\n\n\n\n\n\n\n\n𝑢𝑙𝐴  \n\n\n\n\n  \n\n𝐵𝑇  \nD  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐴𝐵  \n\n\n\n\n  \n\n𝐷𝐷  \n3  \n\n\n\n\n\n\n\n\n\n\n\n𝑢𝑙𝐷  \n\n\n\n\n  \n\n𝐶𝑇  \nD  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐷𝐶  \n\n\n\n\n  \n\n𝐶𝐷  \n2  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐷𝐶  \n\n\n\n\n  \n\n𝐷𝑇  \nD  \n\n\n\n\n\n\n\n\n\n\n\n𝑙𝑜𝐷  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nReal problem:\n\n\n▷State\n𝑠:\n𝐶𝐷; goal\n𝐺:\n𝐴𝐷.\n\n\n▷Actions\n𝐴:\npre,add,del.\n\n\n▷Successors:\n𝐵𝐷,\n𝐷𝐷.\n\n\n\n\n\n\nGreedy best-first search:\n(tie-breaking: alphabetic)\n\n\n\n\n\n\nWe are here  \n\n\n\n\n  \n𝐴𝐶  \n5  \n\n\n\n\n  \n\n𝐵𝐶  \n5  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐴𝐵  \n\n\n\n\n  \n\n𝐶𝐶  \n5  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐵𝐶  \n\n\n\n\n  \n\n𝐴𝐶  \nD  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐵𝐴  \n\n\n\n\n  \n\n𝐷𝐶  \n5  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐶𝐷  \n\n\n\n\n  \n\n𝐶𝑇  \n4  \n\n\n\n\n\n\n\n\n\n\n\n𝑙𝑜𝐶  \n\n\n\n\n  \n\n𝐵𝐶  \nD  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐶𝐵  \n\n\n\n\n  \n\n𝐵𝑇  \n4  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐶𝐵  \n\n\n\n\n  \n\n𝐷𝑇  \n4  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐶𝐷  \n\n\n\n\n  \n\n𝐶𝐶  \nD  \n\n\n\n\n\n\n\n\n\n\n\n𝑢𝑙𝐶  \n\n\n\n\n  \n\n𝐴𝑇  \n4  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐵𝐴  \n\n\n\n\n  \n\n𝐵𝐵  \n5  \n\n\n\n\n\n\n\n\n\n\n\n𝑢𝑙𝐵  \n\n\n\n\n  \n\n𝐶𝑇  \nD  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐵𝐶  \n\n\n\n\n  \n\n𝐴𝐴  \n5  \n\n\n\n\n\n\n\n\n\n\n\n𝑢𝑙𝐴  \n\n\n\n\n  \n\n𝐵𝑇  \nD  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐴𝐵  \n\n\n\n\n  \n\n𝐷𝐷  \n3  \n\n\n\n\n\n\n\n\n\n\n\n𝑢𝑙𝐷  \n\n\n\n\n  \n\n𝐶𝑇  \nD  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐷𝐶  \n\n\n\n\n  \n\n𝐶𝐷  \n2  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐷𝐶  \n\n\n\n\n  \n\n𝐷𝑇  \nD  \n\n\n\n\n\n\n\n\n\n\n\n𝑙𝑜𝐷  \n\n\n\n\n  \n\n𝐵𝐷  \n1  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐶𝐵  \n\n\n\n\n  \n\n𝐷𝐷  \nD  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐶𝐷  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nReal problem:\n\n\n▷State\n𝑠:\n𝐵𝐷; goal\n𝐺:\n𝐴𝐷.\n\n\n▷Actions\n𝐴:\npre,add,del.\n\n\n▷Successors:\n𝐴𝐷,\n𝐶𝐷.\n\n\n\n\n\n\nGreedy best-first search:\n(tie-breaking: alphabetic)\n\n\n\n\n\n\nWe are here  \n\n\n\n\n  \n𝐴𝐶  \n5  \n\n\n\n\n  \n\n𝐵𝐶  \n5  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐴𝐵  \n\n\n\n\n  \n\n𝐶𝐶  \n5  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐵𝐶  \n\n\n\n\n  \n\n𝐴𝐶  \nD  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐵𝐴  \n\n\n\n\n  \n\n𝐷𝐶  \n5  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐶𝐷  \n\n\n\n\n  \n\n𝐶𝑇  \n4  \n\n\n\n\n\n\n\n\n\n\n\n𝑙𝑜𝐶  \n\n\n\n\n  \n\n𝐵𝐶  \nD  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐶𝐵  \n\n\n\n\n  \n\n𝐵𝑇  \n4  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐶𝐵  \n\n\n\n\n  \n\n𝐷𝑇  \n4  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐶𝐷  \n\n\n\n\n  \n\n𝐶𝐶  \nD  \n\n\n\n\n\n\n\n\n\n\n\n𝑢𝑙𝐶  \n\n\n\n\n  \n\n𝐴𝑇  \n4  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐵𝐴  \n\n\n\n\n  \n\n𝐵𝐵  \n5  \n\n\n\n\n\n\n\n\n\n\n\n𝑢𝑙𝐵  \n\n\n\n\n  \n\n𝐶𝑇  \nD  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐵𝐶  \n\n\n\n\n  \n\n𝐴𝐴  \n5  \n\n\n\n\n\n\n\n\n\n\n\n𝑢𝑙𝐴  \n\n\n\n\n  \n\n𝐵𝑇  \nD  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐴𝐵  \n\n\n\n\n  \n\n𝐷𝐷  \n3  \n\n\n\n\n\n\n\n\n\n\n\n𝑢𝑙𝐷  \n\n\n\n\n  \n\n𝐶𝑇  \nD  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐷𝐶  \n\n\n\n\n  \n\n𝐶𝐷  \n2  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐷𝐶  \n\n\n\n\n  \n\n𝐷𝑇  \nD  \n\n\n\n\n\n\n\n\n\n\n\n𝑙𝑜𝐷  \n\n\n\n\n  \n\n𝐵𝐷  \n1  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐶𝐵  \n\n\n\n\n  \n\n𝐷𝐷  \nD  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐶𝐷  \n\n\n\n\n  \n\n𝐴𝐷  \n0  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐵𝐴  \n\n\n\n\n  \n\n𝐶𝐷  \nD  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐵𝐶  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nReal problem:\n\n\n▷State\n𝑠:\n𝐴𝐷; goal\n𝐺:\n𝐴𝐷.\n\n\n▷Actions\n𝐴:\npre,add,del.\n\n\n▷Goal state!\n\n\n\n\n\n\nGreedy best-first search:\n(tie-breaking: alphabetic)\n\n\n\n\n\n\nWe are here  \n\n\n\n\n  \n𝐴𝐶  \n5  \n\n\n\n\n  \n\n𝐵𝐶  \n5  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐴𝐵  \n\n\n\n\n  \n\n𝐶𝐶  \n5  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐵𝐶  \n\n\n\n\n  \n\n𝐴𝐶  \nD  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐵𝐴  \n\n\n\n\n  \n\n𝐷𝐶  \n5  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐶𝐷  \n\n\n\n\n  \n\n𝐶𝑇  \n4  \n\n\n\n\n\n\n\n\n\n\n\n𝑙𝑜𝐶  \n\n\n\n\n  \n\n𝐵𝐶  \nD  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐶𝐵  \n\n\n\n\n  \n\n𝐵𝑇  \n4  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐶𝐵  \n\n\n\n\n  \n\n𝐷𝑇  \n4  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐶𝐷  \n\n\n\n\n  \n\n𝐶𝐶  \nD  \n\n\n\n\n\n\n\n\n\n\n\n𝑢𝑙𝐶  \n\n\n\n\n  \n\n𝐴𝑇  \n4  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐵𝐴  \n\n\n\n\n  \n\n𝐵𝐵  \n5  \n\n\n\n\n\n\n\n\n\n\n\n𝑢𝑙𝐵  \n\n\n\n\n  \n\n𝐶𝑇  \nD  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐵𝐶  \n\n\n\n\n  \n\n𝐴𝐴  \n5  \n\n\n\n\n\n\n\n\n\n\n\n𝑢𝑙𝐴  \n\n\n\n\n  \n\n𝐵𝑇  \nD  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐴𝐵  \n\n\n\n\n  \n\n𝐷𝐷  \n3  \n\n\n\n\n\n\n\n\n\n\n\n𝑢𝑙𝐷  \n\n\n\n\n  \n\n𝐶𝑇  \nD  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐷𝐶  \n\n\n\n\n  \n\n𝐶𝐷  \n2  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐷𝐶  \n\n\n\n\n  \n\n𝐷𝑇  \nD  \n\n\n\n\n\n\n\n\n\n\n\n𝑙𝑜𝐷  \n\n\n\n\n  \n\n𝐵𝐷  \n1  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐶𝐵  \n\n\n\n\n  \n\n𝐷𝐷  \nD  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐶𝐷  \n\n\n\n\n  \n\n𝐴𝐷  \n0  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐵𝐴  \n\n\n\n\n  \n\n𝐶𝐷  \nD  \n\n\n\n\n\n\n\n\n\n\n\n𝑑𝑟𝐵𝐶  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-15\n",
        "sectionId": "d4dfff65",
        "archive": "courses/FAU/AI/course",
        "filepath": "planning/slides/hplus-tsp-australia-ex.en.xhtml"
    },
    {
        "slideContent": "\nℎ+\n            in the Blocksworld\n\n▷\n\n▷Optimal plan:\n〈putdown(𝐴),unstack(𝐵,𝐷),stack(𝐵,𝐶),pickup(𝐴),stack(𝐴,𝐵)〉.\n\n\n▷Optimal relaxed plan:\n〈stack(𝐴,𝐵),unstack(𝐵,𝐷),stack(𝐵,𝐶)〉.\n\n\n▷Observation\nWhat can we say about the “search space surface” at the initial state here?\n\n\n▷The\ninitial state\n            lies on a\nlocal minimum\n            under\nℎ+, together with the\nsuccessor state\n𝑠\n            where we stacked\n𝐴\n            onto\n𝐵. All direct other neighbors of these two\nstates\n            have a strictly higher\nℎ+\nvalue.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "d4dfff65",
        "archive": "courses/FAU/AI/course",
        "filepath": "planning/slides/hplus-blocks.en.xhtml"
    },
    {
        "slideContent": "\nSummary\n\n▷Heuristic search\n            on classical\nsearch problems\n            relies on a\nfunction\nℎ\n            mapping\nstates\n𝑠\n            to an estimate\nℎ(𝑠)\n            of their\ngoal state\n            distance. Such\nfunctions\nℎ\n            are derived by solving\nrelaxed problems.\n\n\n▷In\nplanning, the\nrelaxed\n            problems are generated and solved automatically. There are four known families of suitable relaxation methods:\nabstractions,\nlandmarks,\ncritical paths, and\nignoring deletes\n            (aka\ndelete relaxation).\n\n\n▷The\ndelete relaxation\n            consists in dropping the\ndeletes\n            from\nSTRIPS tasks. A\nrelaxed plan\n            is a\nplan\n            for such a\nrelaxed\ntask.\nℎ+(𝑠)\n            is the length of an optimal relaxed plan for\nstate\n𝑠.\nℎ+\n            is\n𝐍𝐏-hard to compute.\n\n\n▷ℎ𝐹𝐹\n            approximates\nℎ+\n            by computing some, not necessarily optimal, relaxed plan. That is done by a forward pass (building a\nrelaxed planning graph), followed by a backward pass (extracting a relaxed plan).\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-15\n",
        "sectionId": "e62ded26",
        "archive": "courses/FAU/AI/course",
        "filepath": "planning/slides/algorithms-summary.en.xhtml"
    },
    {
        "slideContent": "\nTopics We Didn’t Cover Here\n\n▷Abstractions, Landmarks, Critical-Path Heuristics, Cost Partitions, Compilability between Heuristic Functions, Planning Competitions:\n\n\n▷Tractable\n              fragments:\n            Planning sub-classes that can be solved in polynomial time. Often identified by properties of the “causal graph” and “domain transition graphs”.\n\n\n▷Planning as SAT:\n            Compile length-𝑘\n            bounded plan existence into satisfiability of a CNF formula\n𝜑. Extensive literature on how to obtain small\n𝜑, how to schedule different values of\n𝑘, how to modify the underlying SAT solver.\n\n\n▷Compilations:\n            Formal framework for determining whether planning formalism\n𝑋\n            is (or is not) at least as expressive as planning formalism\n𝑌.\n\n\n▷Admissible\npruning/decomposition methods:\n            Partial-order reduction, symmetry reduction, simulation-based dominance\npruning,\nfactored\nplanning, decoupled search.\n\n\n▷Hand-tailored planning:\n            Automatic planning is the extreme case where the\ncomputer\n            is given no domain knowledge other than “physics”. We can instead allow the user to provide search control knowledge, trading off modeling effort against search performance.\n\n\n▷Numeric planning,\ntemporal planning,\nplanning under\nuncertainty\n            ...\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-16\n",
        "sectionId": "e62ded26",
        "archive": "courses/FAU/AI/course",
        "filepath": "planning/slides/algorithms-notcovered.en.xhtml"
    },
    {
        "slideContent": "\nOutline\n\n▷So Far\n                we made idealizing/simplifying assumptions:The\nenvironment\n                is\nfully observable\n                and\ndeterministic.\n\n\n▷Outline\n                In this\ndocument\n                we will lift some of them\n\n\n▷The real world (things go wrong)\n\n\n▷Agents and Belief States\n\n\n▷Conditional planning\n\n\n▷Monitoring and replanning\n\n\n▷Note\n                The considerations in this\ndocument\n                apply to both search and planning.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "c2c19229",
        "archive": "courses/FAU/AI/course",
        "filepath": "planning/slides/acting-outline.en.xhtml"
    },
    {
        "slideContent": "\nAI-1 Survey on ALeA\n\n▷Online survey evaluating ALeA from 7.02.24 to 29.02.24 24:00\n(Feb last)\n\n\n▷Works on all common devices (mobile phone, notebook, etc.)\n\n\n▷Is in english Takes about 10 - 20 min\ndepending on proficiency in english and using ALeA\n\n\n▷Questions about how ALeA is used, what it is like usig ALeA, and questions about demography\n\n\n▷Token is generated at the end of the survey\n(SAVE THIS CODE!)\n\n\n▷Completed survey count as a successfull\nprepquiz\n            in AI1!\n\n\n▷Look for Quiz 15 in the usual place\n(single question)\n\n\n▷just submit the token to get full points\n\n\n▷The token can also be used to exercise the rights of the GDPR.\n\n\n▷Survey has no timelimit and is free, anonymous, can be paused and continued later on and can be cancelled.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-16\n",
        "sectionId": "c2c19229",
        "archive": "courses/FAU/AI/course",
        "filepath": "course/notes/survey.en.xhtml"
    },
    {
        "slideContent": "\nFind the Survey Here\n\n\n\nhttps://ddi-survey.cs.fau.de/limesurvey/ALeA\n\n\nThis URL will also be posted on the forum tonight.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 122024-12-16\n",
        "sectionId": "c2c19229",
        "archive": "courses/FAU/AI/course",
        "filepath": "course/notes/survey.en.xhtml"
    },
    {
        "slideContent": "\nThe real world\n\n▷\n                We have a flat tire — what to do?\n\n\n\n\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-15\n",
        "sectionId": "8d114f03",
        "archive": "courses/FAU/AI/course",
        "filepath": "planning/slides/real-world.en.xhtml"
    },
    {
        "slideContent": "\nGenerally: Things go wrong (in the real world)\n\n▷Incomplete Information\n\n\n▷Unknown\npreconditions, e.g.,\n𝐼𝑛𝑡𝑎𝑐𝑡(𝑆𝑝𝑎𝑟𝑒)?\n\n\n▷Disjunctive\neffects, e.g.,\n𝐼𝑛𝑓𝑙𝑎𝑡𝑒(𝑥)\n                  causes\n𝐼𝑛𝑓𝑙𝑎𝑡𝑒𝑑(𝑥)∨𝑆𝑙𝑜𝑤𝐻𝑖𝑠𝑠(𝑥)∨𝐵𝑢𝑟𝑠𝑡(𝑥)∨𝐵𝑟𝑜𝑘𝑒𝑛𝑃𝑢𝑚𝑝∨...\n\n\n▷Incorrect Information\n\n\n▷Current\nstate\n                  incorrect,\ne.g., spare NOT intact\n\n\n▷Missing/incorrect\neffects\n                  in\nactions.\n\n\n▷\n                  The\nqualification problem\n                  in planning is that we can never finish listing all the required\npreconditions\n                  and possible conditional\neffects\n                  of\nactions.\n\n\n▷Root CauseThe\nenvironment\n                  is\npartially observable\n                  and/or\nnon-deterministic.\n\n\n▷Technical Problem\n                  We cannot know the “current state of the world”, but search/planning\nalgorithms\n                  are based on this assumption.\n\n\n▷Idea\n                  Adapt search/planning\nalgorithms\n                  to work with “sets of possible states”.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "8d114f03",
        "archive": "courses/FAU/AI/course",
        "filepath": "planning/slides/things-go-wrong.en.xhtml"
    },
    {
        "slideContent": "\nWhat can we do if things (can) go wrong?\n\n▷One SolutionSensorless planning:\nplans\n                that work regardless of state/outcome.\n\n\n▷Problem\n                Such\nplans\n                may not exist!(but they often do in practice)\n\n\n▷Another SolutionConditional plans:\n\n\n▷Plan to obtain information,(observation\nactions)\n\n\n▷Subplan for each contingency.\n\n\n▷A conditional Plan(AAA\n=^\n                    ADAC)[𝐶ℎ𝑒𝑐𝑘(𝑇1),if𝐼𝑛𝑡𝑎𝑐𝑡(𝑇1)then𝐼𝑛𝑓𝑙𝑎𝑡𝑒(𝑇1)else𝐶𝑎𝑙𝑙𝐴𝐴𝐴fi]\n\n\n▷Problem\n                Expensive because it\nplans\n                for many unlikely cases.\n\n\n▷Still another Solution\nExecution monitoring/replanning\n\n\n▷Assume normal states/outcomes, check progress\nduring execution, replan if necessary.\n\n\n▷Problem\n                Unanticipated outcomes may lead to failure.\n(e.g., no AAA card)\n\n\n▷\n                We really need a combination; plan for likely/serious eventualities, deal with others when they arise, as they must eventually.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-15\n",
        "sectionId": "8d114f03",
        "archive": "courses/FAU/AI/course",
        "filepath": "planning/slides/uncertainty-solutions.en.xhtml"
    },
    {
        "slideContent": "\nThe Furniture-Coloring Example: Specification\n\n▷Coloring Furniture\n\n\n\nPaint a chair and a table in matching colors.\n\n\n▷The initial state is:\n\n\n▷we have two cans of paint of unknown color,\n\n\n▷the color of the furniture is unknown as well,\n\n\n▷only the table is in the agent’s field of view.\n\n\n▷Actions:\n\n\n▷remove lid from can\n\n\n▷paint object with paint from open can.\n\n\n\n\n\n\n\n \n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-16\n",
        "sectionId": "b433c9c0",
        "archive": "courses/FAU/AI/course",
        "filepath": "planning/slides/coloring-ex.en.xhtml"
    },
    {
        "slideContent": "\nThe Furniture-Coloring Example: PDDL\n\n▷Formalization in\nPDDL\n\n\n▷The\nPDDL\ndomain file\n                  is as expected\n(actions\n                      below)\n\n\n(define (domain furniture―coloring)\n(:predicates (object ?x) (can ?x) (inview ?x) (color ?x ?y))\n...)\n\n▷The\nPDDL\nproblem file\n                  has a “free” variable\n?c\n                  for the (undetermined) joint color.\n\n\n(define (problem tc―coloring)\n(:domain furniture―objects)\n(:objects table chair c1 c2)\n(:init (object table) (object chair) (can c1) (can c2) (inview table))\n(:goal (color chair ?c) (color table ?c)))\n\n▷Two action schemata:\nremove can lid to open\n                  and\npaint with open can\n\n\n(:action remove―lid\n:parameters (?x)\n:precondition (can ?x)\n:effect (open can))\n(:action paint\n:parameters (?x ?y)\n:precondition (and (object ?x) (can ?y) (color ?y ?c) (open ?y))\n:effect (color ?x ?c))\n\nhas a universal variable\n?c\n                  for the\npaint\n                  action\n\n⇝\n\n                  we cannot just give\npaint\n                  a color argument in a partially observable environment.\n\n\n▷Sensorless Plan: Open one can, paint chair and table in its color.\n\n\n▷Note: Contingent planning can create better plans, but needs perception\n\n\n▷Two percept schemata:\ncolor of an object\n                  and\ncolor in a can\n\n\n(:percept color\n:parameters (?x ?c)\n:precondition (and (object ?x) (inview ?x)))\n(:percept can―color\n:parameters (?x ?c)\n:precondition (and (can ?x) (inview ?x) (open ?x)))\n\nTo perceive the color of an object, it must be in view, a can must also be open.Note: In a fully observable world, the percepts would not have preconditions.\n\n\n▷An action schema:\nlook at an object\n                  that causes it to come into view.\n\n\n(:action lookat\n:parameters (?x)\n:precond: (and (inview ?y) and (notequal ?x ?y))\n:effect (and (inview ?x) (not (inview ?y))))\n\n▷Contingent Plan:\n\n\n1.look at furniture to determine color, if same\n⤳\n                  done.\n\n\n2.else, look at open and look at paint in cans\n\n\n3.if paint in one can is the same as an object, paint the other with this color\n\n\n4.else paint both in any color\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 122024-12-16\n",
        "sectionId": "b433c9c0",
        "archive": "courses/FAU/AI/course",
        "filepath": "planning/slides/coloring-ex.en.xhtml"
    },
    {
        "slideContent": "\nConditional Plans\n\n▷\nConditional plans\n                  extend the possible\nactions\n                  in\nplans\n                  by\nconditional steps\n                  that execute\nsub plans\n                  conditionally whether\n𝐾+𝑃⊨𝐶, where\n𝐾+𝑃\n                  is the current knowledge base + the\npercepts.\n\n\n▷\nConditional plans\n                  can contain\n\n\n▷conditional step:\n[...,if𝐶then𝑃𝑙𝑎𝑛𝐴else𝑃𝑙𝑎𝑛𝐵fi,...],\n\n\n▷while step:\n[...,while𝐶do𝑃𝑙𝑎𝑛done,...], and\n\n\n▷the\nempty plan\n∅\n                  to make modeling easier.\n\n\n▷\n                  If the possible\npercepts\n                  are limited to determining the current state in a\nconditional plan, then we speak of a\ncontingency plan.\n\n\n▷Note\n                  Need\nsome plan\n                  for\nevery possible percept! Compare to\n\n\ngame playing:\nsome response\n                  for\nevery opponent\n                  move.\n\n\nbackchaining:\nsome rule\n                  such that\nevery premise\n                  satisfied.\n\n\n▷Idea\n                  Use an AND—OR tree search(very similar to backward chaining\nalgorithm)\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "d20fbd9b",
        "archive": "courses/FAU/AI/course",
        "filepath": "planning/slides/conditional-planning.en.xhtml"
    },
    {
        "slideContent": "\nContingency Planning: The Erratic Vacuum Cleaner\n\n▷Erratic vacuum world\n\n\n\nA variant\n𝑠𝑢𝑐𝑘\n                                  action:if square is\n\n\n▷𝑑𝑖𝑟𝑡𝑦: clean the square, sometimes remove dirt in adjacent square.\n\n\n▷𝑐𝑙𝑒𝑎𝑛: sometimes deposits dirt on the carpet.\n\n\n\n\n\n\n\nSolution:\n[𝑠𝑢𝑐𝑘,if𝑆𝑡𝑎𝑡𝑒=5then[𝑟𝑖𝑔ℎ𝑡,𝑠𝑢𝑐𝑘]else[]fi]\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-15\n",
        "sectionId": "d20fbd9b",
        "archive": "courses/FAU/AI/course",
        "filepath": "planning/slides/erratic.en.xhtml"
    },
    {
        "slideContent": "\nConditional AND-OR Search (Data Structure)\n\n▷Idea\n                  Use\nAND-OR trees\n                  as\ndata structures\n                  for representing problems (or goals) that can be reduced to to conjunctions and disjunctions of subproblems (or subgoals).\n\n\n▷\n                  An\nAND-OR graph\n                  is a is a\ngraph\n                  whose\nnon-terminal\nnodes\n                  are partitioned into\nAND nodes\n                  and\nOR nodes. A\nvaluation\n                  of an\nAND-OR graph\n𝑇\n                  is an assignment of\n𝖳\n                  or\n𝖥\n                  to the nodes of\n𝑇. A\nvaluation\n                  of the\nterminal\nnodes\n                  of\n𝑇\n                  can be extended by all\nnodes\n                  recursively: Assign\n𝖳\n                  to an\n\n\n▷OR node, iff at least one of its\nchildren\n                  is\n𝖳.\n\n\n▷AND node, iff all of its\nchildren\n                  are\n𝖳.\n\n\nA\nsolution\n                  for\n𝑇\n                  is a\nvaluation\n                  that\nassigns\n𝖳\n                  to the\ninitial\nnodes\n                  of\n𝑇.\n\n\n▷Idea\n                  A\nplanning task\n                  with non deterministic\nactions\n                  generates a\nAND-OR graph\n𝑇. A\nsolution\n                  that assigns\n𝖳\n                  to a\nterminal\nnode, iff it is a goal node. Corresponds to a\nconditional plan.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "d20fbd9b",
        "archive": "courses/FAU/AI/course",
        "filepath": "planning/slides/and-or-search.en.xhtml"
    },
    {
        "slideContent": "\nConditional AND-OR Search (Example)\n\n▷\n                  An\nAND-OR tree\n                  is a\nAND-OR graph\n                  that is also a\ntree.Notation:\nAND nodes\n                  are written with arcs connecting the\nchild\nedges.\n\n\n▷An AND-OR-tree\n\n\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 122024-12-14\n",
        "sectionId": "d20fbd9b",
        "archive": "courses/FAU/AI/course",
        "filepath": "planning/slides/and-or-search.en.xhtml"
    },
    {
        "slideContent": "\nConditional AND-OR Search (Algorithm)\n\n▷\nAND-OR search\n                  is an\nalgorithm\n                  for searching AND—OR graphs generated by nondeterministic environments.\n\n\nfunction AND/OR―GRAPH―SEARCH(𝑝𝑟𝑜𝑏) returns a conditional plan, or fail\nOR―SEARCH(𝑝𝑟𝑜𝑏.INITIAL―STATE, 𝑝𝑟𝑜𝑏, [])\nfunction OR―SEARCH(𝑠𝑡𝑎𝑡𝑒,𝑝𝑟𝑜𝑏,𝑝𝑎𝑡ℎ) returns a conditional plan, or fail\nif 𝑝𝑟𝑜𝑏.GOAL―TEST(𝑠𝑡𝑎𝑡𝑒) then return the empty plan\nif 𝑠𝑡𝑎𝑡𝑒 is on 𝑝𝑎𝑡ℎ then return fail\nfor each 𝑎𝑐𝑡𝑖𝑜𝑛 in 𝑝𝑟𝑜𝑏.ACTIONS(𝑠𝑡𝑎𝑡𝑒) do\n𝑝𝑙𝑎𝑛 := AND―SEARCH(RESULTS(𝑠𝑡𝑎𝑡𝑒,𝑎𝑐𝑡𝑖𝑜𝑛),𝑝𝑟𝑜𝑏,[𝑠𝑡𝑎𝑡𝑒 | 𝑝𝑎𝑡ℎ])\nif 𝑝𝑙𝑎𝑛 ≠ fail then return [𝑎𝑐𝑡𝑖𝑜𝑛 | 𝑝𝑙𝑎𝑛]\nreturn fail\nfunction AND―SEARCH(𝑠𝑡𝑎𝑡𝑒𝑠,𝑝𝑟𝑜𝑏,𝑝𝑎𝑡ℎ) returns a conditional plan, or fail\nfor each 𝑠𝑖 in 𝑠𝑡𝑎𝑡𝑒𝑠 do\n𝑝𝑖 := OR―SEARCH(𝑠𝑖,𝑝𝑟𝑜𝑏,𝑝𝑎𝑡ℎ)\nif 𝑝𝑖 = fail then return fail\nreturn [if 𝑠1 then 𝑝1 else if 𝑠2 then 𝑝2 else ... if 𝑠𝑛−1 then 𝑝𝑛−1 else 𝑝𝑛]\n\n▷Cycle Handling\n                  If a state has been seen before\n⤳\nfail\n\n\n▷fail\n                  does not mean\nthere is no solution, but\n\n\n▷if there is a non-cyclic solution, then it is reachable by an earlier incarnation!\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 132024-12-14\n",
        "sectionId": "d20fbd9b",
        "archive": "courses/FAU/AI/course",
        "filepath": "planning/slides/and-or-search.en.xhtml"
    },
    {
        "slideContent": "\nThe Slippery Vacuum Cleaner (try, try, try, ...try again)\n\n▷Slippery Vacuum World\n\n\n\nMoving sometimes fails⤳\nAND-OR graph\n\n\n\n\n\n\n\n                Two possible solutions\n(depending on what our plan language allows)\n\n\n▷[𝐿1:𝑙𝑒𝑓𝑡,if𝐴𝑡𝑅then𝐿1else[if𝐶𝑙𝑒𝑎𝑛𝐿then∅else𝑠𝑢𝑐𝑘fi]fi]\n                or\n\n\n▷[while𝐴𝑡𝑅do[𝑙𝑒𝑓𝑡]done,if𝐶𝑙𝑒𝑎𝑛𝐿then∅else𝑠𝑢𝑐𝑘fi]\n\n\n▷We have an\ninfinite loop\n            but\nplan\n            eventually works unless action always fails.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-15\n",
        "sectionId": "d20fbd9b",
        "archive": "courses/FAU/AI/course",
        "filepath": "planning/slides/slippery.en.xhtml"
    },
    {
        "slideContent": "\nWorld Models for Uncertainty\n\n▷Problem\n                  We do not know with certainty what state the world is in!\n\n\n▷Idea\n                  Just keep track of all the possible\nstates\n                  it could be in.\n\n\n▷\n                  A\nmodel-based agent\n                  has a\nworld model\n                  consisting of\n\n\n▷a\nbelief state\n                  that has information about the possible\nstates\n                  the world may be in, and\n\n\n▷a\nsensor model\n                  that updates the\nbelief state\n                  based on\nsensor\n                  information\n\n\n▷a\ntransition model\n                  that updates the\nbelief state\n                  based on\nactions.\n\n\n▷Idea\n                  The\nagent\nenvironment\n                  determines what the\nworld model\n                  can be.\n\n\n▷\n                  In a\nfully observable,\ndeterministic\nenvironment,\n\n\n▷we can observe the initial\nstate\n                  and subsequent\nstates\n                  are given by the\nactions\n                  alone.\n\n\n▷thus\nthe\nbelief state\n                      is a\nsingleton\n                      (we call its member the\nworld state)\n                  and the\ntransition model\n                  is\na function from\nstates\n                      and\nactions\n                      to\nstates: a\ntransition function.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "4ff670cc",
        "archive": "courses/FAU/AI/course",
        "filepath": "rational-agents/slides/world-models.en.xhtml"
    },
    {
        "slideContent": "\nWorld Models by Agent Type in AI-1\n\n▷Search-based Agents\n                In a\nfully observable,\ndeterministic\nenvironment\n\n\n▷goal-based agent\n                with\nworld state\n=^\n                “current state”\n\n\n▷no inference.(goal\n=^\n                    goal state from\nsearch problem)\n\n\n▷CSP-based Agents\n                In a\nfully observable,\ndeterministic\nenvironment\n\n\n▷goal-based agent\n                withworld state\n=^\n                constraint network,\n\n\n▷inference\n=^\n                constraint propagation.(goal\n=^\n                    satisfying assignment)\n\n\n▷Logic-based Agents\n                In a\nfully observable,\ndeterministic\nenvironment\n\n\n▷model-based agent\n                with\nworld state\n=^\n                logical formula\n\n\n▷inference\n=^\n                e.g. DPLL or resolution.\n\n▷Planning Agents\n                In a\nfully observable,\ndeterministic,\nenvironment\n\n\n▷goal-based agent\n                with\nworld state\n=^\n                PL0,\ntransition model\n=^\n                STRIPS,\n\n\n▷inference\n=^\n                state/plan space search.(goal: complete plan/execution)\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-15\n",
        "sectionId": "4ff670cc",
        "archive": "courses/FAU/AI/course",
        "filepath": "rational-agents/slides/world-model-agents.en.xhtml"
    },
    {
        "slideContent": "\nWorld Models for Complex Environments\n\n▷\n                  In a\nfully observable, but\nstochastic\nenvironment,\n\n\n▷the\nbelief state\n                  must deal with a set of possible\nstates.\n\n\n▷⤳\n                  generalize the\ntransition function\n                  to a\ntransition relation.\n\n\n▷NoteThis even applies to\nonline\nproblem solving, where we can just perceive the\nstate.\n(e.g. when we want to optimize utility)\n\n\n▷\n                  In a\ndeterministic, but\npartially observable\nenvironment,\n\n\n▷the\nbelief state\n                  must deal with a set of possible\nstates.\n\n\n▷we can use\ntransition functions.\n\n\n▷We need a\nsensor model, which predicts the influence of\npercepts\n                      on the\nbelief state\n                      — during update.\n\n\n▷In a\nstochastic,\npartially observable\nenvironment,\n\n\n▷mix the ideas from the last two.(sensor model\n                  +\ntransition relation)\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "4ff670cc",
        "archive": "courses/FAU/AI/course",
        "filepath": "rational-agents/slides/belief-models.en.xhtml"
    },
    {
        "slideContent": "\nPreview: New World Models (Belief)\n⤳\n            new Agent Types\n\n▷Probabilistic AgentsIn a\npartially observable\nenvironment\n\n\n▷belief state\n=^\nBayesian networks,\n\n\n▷inference\n=^\nprobabilistic inference.\n\n\n▷Decision-Theoretic Agents\n                In a\npartially observable,\nstochastic\nenvironment\n\n\n▷belief state\n                +\ntransition model\n=^\ndecision networks,\n\n\n▷inference\n=^\nmaximizing expected utility.\n\n\n▷We will study them in detail this\nsemester.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 212024-12-16\n",
        "sectionId": "4ff670cc",
        "archive": "courses/FAU/AI/course",
        "filepath": "rational-agents/slides/world-model-agents2.en.xhtml"
    },
    {
        "slideContent": "\nConformant/Sensorless Planning\n\n▷\nConformant\n                  or\nsensorless planning\n                  tries to find\nplans\n                  that work without any sensing.\n(not even the initial state)\n\n\n▷Sensorless Vacuum Cleaner World\nStates integer dirt and robot locationsActions𝑙𝑒𝑓𝑡,𝑟𝑖𝑔ℎ𝑡,𝑠𝑢𝑐𝑘,𝑛𝑜𝑂𝑝Goal states𝑛𝑜𝑡𝑑𝑖𝑟𝑡𝑦?\n\n\n▷\n                  In a sensorless world we do not know the initial state.(or any state after)\n\n\n▷\nSensorless planning\n                  must search in the space of\nbelief states\n                  (sets of possible actual states).\n\n\n▷Searching the Belief State Space\n\n▷Start in\n{1,2,3,4,5,6,7,8}\n\n\n▷Solution:\n[𝑟𝑖𝑔ℎ𝑡,𝑠𝑢𝑐𝑘,𝑙𝑒𝑓𝑡,𝑠𝑢𝑐𝑘]\n𝑟𝑖𝑔ℎ𝑡→\n{2,4,6,8}\n𝑠𝑢𝑐𝑘→\n{4,8}\n𝑙𝑒𝑓𝑡→\n{3,7}\n𝑠𝑢𝑐𝑘→\n{7}\n\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-15\n",
        "sectionId": "5e987a",
        "archive": "courses/FAU/AI/course",
        "filepath": "planning/slides/conformant-planning.en.xhtml"
    },
    {
        "slideContent": "\nSearch in the Belief State Space: Let’s Do the Math\n\n▷Recap\n                  We describe an\nsearch problem\nΠ:=〈𝒮,𝒜,𝒯,ℐ,𝒢〉\n                  via its\nstates\n𝒮,\nactions\n𝒜, and\ntransition model\n𝒯:𝒜×𝒮→𝒫(𝒜),\ngoal states\n𝒢, and\ninitial state\nℐ.\n\n\n▷Problem\n                  What is the corresponding sensorless problem?\n\n\n▷Let’ think\n                  Let\nΠ:=〈𝒮,𝒜,𝒯,ℐ,𝒢〉\n                  be a (physical) problem\n\n\n▷States\n𝒮𝑏: The\nbelief states\n                  are the\n2|𝒮|\n                  subsets of\n𝒮.\n\n\n▷The\ninitial state\nℐ𝑏\n                  is just\n𝒮(no information)\n\n\n▷Goal states\n𝒢𝑏:={𝑆∊𝒮𝑏|𝑆⊆𝒢}(all possible states must be physical goal states)\n\n\n▷Actions\n𝒜𝑏: we just take\n𝒜.\n(that’s the point!)\n\n\n▷Transition model\n𝒯𝑏:𝒜𝑏×𝒮𝑏→𝒫(𝒜𝑏): i.e. what is\n𝒯𝑏(𝑎,𝑆)\n                  for\n𝑎∊𝒜\n                  and\n𝑆⊆𝒮? This is slightly tricky as\n𝑎\n                  need not be\napplicable\n                  to all\n𝑠∊𝑆.\n\n\n1.if\nactions\n                  are harmless to the environment, take\n𝒯𝑏(𝑎,𝑆):=⋃𝑠∊𝑆𝒯(𝑎,𝑠).\n\n\n2.if not, better take\n𝒯𝑏(𝑎,𝑆):=⋂𝑠∊𝑆𝒯(𝑎,𝑠).(the safe bet)\n\n\n▷\n                  In belief-state space the problem is always fully observable!\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-16\n",
        "sectionId": "5e987a",
        "archive": "courses/FAU/AI/course",
        "filepath": "planning/slides/conformant-search.en.xhtml"
    },
    {
        "slideContent": "\nState Space vs. Belief State Space\n\n▷State/Belief State Space in the Vacuum World\n                In the vacuum world all\nactions\n                are always applicable(1./2. equal)\n\n\n\n\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-16\n",
        "sectionId": "5e987a",
        "archive": "courses/FAU/AI/course",
        "filepath": "planning/slides/vacuum-belief-space.en.xhtml"
    },
    {
        "slideContent": "\nEvaluating Conformant Planning\n\n▷Upshot\n                We can build belief-space problem formulations automatically,\n\n\n▷but they are exponentially bigger in theory, in practice they are often similar;\n\n\n▷e.g. 12 reachable\nbelief states\n                out of\n28=256\n                for vacuum example.\n\n\n▷Problem\nBelief states\n                are HUGE; e.g. initial\nbelief state\n                for the\n10×10\n                vacuum world contains\n100·2100≈1032\n                physical states\n\n\n▷Idea\n                Use planning techniques: compact descriptions for\n\n              \n\n▷belief states;\ne.g.\nall\n                    for initial state or\nnot leftmost column\n                    after\n𝑙𝑒𝑓𝑡.\n\n\n▷actions\n                as\nbelief state\n                to\nbelief state\n                operations.\n\n\n▷This actually works\n                Therefore we talk about\nconformant planning!\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-16\n",
        "sectionId": "5e987a",
        "archive": "courses/FAU/AI/course",
        "filepath": "planning/slides/conformant-eval.en.xhtml"
    },
    {
        "slideContent": "\nConditional planning (Motivation)\n\n▷Note\n                  So far, we have never used the\nagent’s\nsensors.\n\n\n▷In\n??, since the\nenvironment\n                  was observable and deterministic we could just use\noffline\n                  planning.\n\n\n▷In\n??\n                  because we chose to.\n\n\n▷Note\n                  If the world is nondeterministic or partially observable then percepts usually provide information, i.e., split up the\nbelief state\n\n\n\n\n▷Idea\n                  This can systematically be used in search/planning via belief-state search, but we need to rethink/specialize the\nTransition model.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "1885429a",
        "archive": "courses/FAU/AI/course",
        "filepath": "planning/slides/cplan-motivation.en.xhtml"
    },
    {
        "slideContent": "\nA Transition Model for Belief-State Search\n\n▷We extend the ideas from slide\n??\n              to include partial observability.\n\n\n▷\n                  Given a (physical)\nsearch problem\nΠ:=〈𝒮,𝒜,𝒯,ℐ,𝒢〉, we define the\nbelief state search problem\n                  induced by\nΠ\n                  to be\n〈𝒫(𝒮),𝒜,𝒯𝑏,𝒮,{𝑆∊𝒮𝑏|𝑆⊆𝒢}〉, where the\ntransition model\n𝒯𝑏\n                  is constructed in three stages:\n\n\n▷The\nprediction\n                  stage: given a\nbelief state\n𝑏\n                  and an action\n𝑎\n                  we define\n𝑏^:=PRED(𝑏,𝑎)\n                  for some function\nPRED:𝒫(𝒮)×𝒜→𝒫(𝒮).\n\n\n▷The\nobservation prediction\n                  stage determines the set of possible percepts that could be observed in the predicted belief state:\nPossPERC(𝑏^)={PERC(𝑠)|𝑠∊𝑏^}.\n\n\n▷The\nupdate\n                  stage determines, for each possible percept, the resulting belief state:\nUPDATE(𝑏^,𝑜):={𝑠|\n𝑜=PERC(𝑠) and 𝑠∊𝑏^\n}\n\n\nThe functions\nPRED\n                  and\nPERC\n                  are the main parameters of this model. We define\nRESULT(𝑏,𝑎):={UPDATE(PRED(𝑏,𝑎),𝑜)|PossPERC(PRED(𝑏,𝑎))}\n\n\n▷\n                  We always have\nUPDATE(𝑏^,𝑜)⊆𝑏^.\n\n\n▷\n                  If sensing is deterministic,\nbelief states\n                  for different possible\npercepts\n                  are\ndisjoint, forming a\npartition\n                  of the original predicted belief state.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "1885429a",
        "archive": "courses/FAU/AI/course",
        "filepath": "planning/slides/belief-state-problem.en.xhtml"
    },
    {
        "slideContent": "\nExample: Local Sensing Vacuum Worlds\n\n▷Transitions in the Vacuum World\n                  Deterministic World:\n\n\n\n\nThe action\n𝑅𝑖𝑔ℎ𝑡\n                  is deterministic, sensing\ndisambiguates\n                  to\nsingletons\n                  Slippery World:\n\n\n\n\nThe action\n𝑅𝑖𝑔ℎ𝑡\n                  is non-deterministic, sensing\ndisambiguates\n                  somewhat\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 122024-12-14\n",
        "sectionId": "1885429a",
        "archive": "courses/FAU/AI/course",
        "filepath": "planning/slides/belief-state-problem.en.xhtml"
    },
    {
        "slideContent": "\nBelief-State Search with Percepts\n\n▷Observation\n                  The belief-state\ntransition model\n                  induces an\nAND-OR graph.\n\n\n▷Idea\n                  Use\nAND-OR search\n                  in non deterministic environments.\n\n\n▷\nAND-OR graph\n                  for initial percept\n[𝐴,𝐷𝑖𝑟𝑡𝑦].\n\n\n\n\nSolution:\n[𝑆𝑢𝑐𝑘,𝑅𝑖𝑔ℎ𝑡,if𝐵𝑠𝑡𝑎𝑡𝑒={6}then𝑆𝑢𝑐𝑘else[]fi]\n\n\n▷Note\n                  Belief-state-problem\n⤳\nconditional step\n                  tests on belief-state percept\n(plan would not be executable in a partially observable environment otherwise)\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "1885429a",
        "archive": "courses/FAU/AI/course",
        "filepath": "planning/slides/belief-state-search.en.xhtml"
    },
    {
        "slideContent": "\nExample: Agent Localization\n\n▷\n                  An agent inhabits a maze of which it has an accurate map. It has four sensors that can (reliably) detect walls. The\n𝑀𝑜𝑣𝑒\n                  action is non-deterministic, moving the agent randomly into one of the adjacent squares.\n\n\n1.Initial belief state\n⤳\n𝑏^1\n                  all possible locations.\n\n\n2.Initial percept:\n𝑁𝑊𝑆\n                  (walls north, west, and south)\n⤳\n𝑏^2=UPDATE(𝑏^1,𝑁𝑊𝑆)\n\n\n\n\n3.Agent executes\n𝑀𝑜𝑣𝑒\n⤳\n𝑏^3=PRED(𝑏^2,𝑀𝑜𝑣𝑒)=\none step away from these.\n\n\n4.Next percept:\n𝑁𝑆\n⤳\n𝑏^4=UPDATE(𝑏^3,𝑁𝑆)\n\n\n\n\nAll in all,\n𝑏^4=UPDATE(PRED(UPDATE(𝑏^1,𝑁𝑊𝑆),𝑀𝑜𝑣𝑒),𝑁𝑆)\n                  localizes the agent.\n\n\n▷Observation\nPRED\n                  enlarges the belief state, while\nUPDATE\n                  shrinks it again.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 122024-12-14\n",
        "sectionId": "1885429a",
        "archive": "courses/FAU/AI/course",
        "filepath": "planning/slides/belief-state-search.en.xhtml"
    },
    {
        "slideContent": "\nContingent Planning\n\n▷\n                  The generation of plan with conditional branching based on percepts is called\ncontingent planning, solutions are called\ncontingent plans.\n\n\n▷Appropriate for partially observable or non-deterministic environments.\n\n\n▷\n                  Continuing\n??.\nOne of the possible\ncontingent plan\n                  is\n\n\n((lookat table) (lookat chair)\n(if (and (color table c) (color chair c)) (noop)\n((removelid c1) (lookat c1) (removelid c2) (lookat c2)\n(if (and (color table c) (color can c)) ((paint chair can))\n(if (and (color chair c) (color can c)) ((paint table can))\n((paint chair c1) (paint table c1)))))))\n\n▷Note\n                  Variables in this plan are existential; e.g. in\n\n\n▷line 2: If there is come joint color\n𝑐\n                      of the table and chair\n⤳\n                      done.\n\n\n▷line 4/5: Condition can be satisfied by\n[𝑐1/𝑐𝑎𝑛]\n                      or\n[𝑐2/𝑐𝑎𝑛]\n⤳\n                      instantiate accordingly.\n\n\n▷\n                  During\nplan execution\n                  the agent maintains the\nbelief state\n𝑏, chooses the branch depending on whether\n𝑏⊨𝑐\n                  for the condition\n𝑐.\n\n\n▷Note\n                  The planner must make sure\n𝑏⊨𝑐\n                  can always be decided.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-16\n",
        "sectionId": "1885429a",
        "archive": "courses/FAU/AI/course",
        "filepath": "planning/slides/contingent-planning.en.xhtml"
    },
    {
        "slideContent": "\nContingent Planning: Calculating the Belief State\n\n▷Problem\n                  How do we compute the\nbelief state?\n\n\n▷Recall\n                  Given a belief state\n𝑏, the new belief state\n𝑏^\n                  is computed based on prediction with the action\n𝑎\n                  and the refinement with the percept\n𝑝.\n\n\n▷Here\nGiven an action\n𝑎\n                  and percepts\n𝑝=𝑝1∧...∧𝑝𝑛, we have\n\n\n▷𝑏^=𝑏\\del𝑎∪add𝑎(as for the sensorless agent)\n\n\n▷If\n𝑛=1\n                  and\n(:percept 𝑝1 :precondition 𝑐)\n                  is the only percept axiom, also add\n𝑝\n                  and\n𝑐\n                  to\n𝑏^.\n(add\n𝑐\n                      as otherwise\n𝑝\n                      impossible)\n\n\n▷If\n𝑛>1\n                  and\n(:percept 𝑝𝑖 :precondition 𝑐𝑖)\n                  are the percept axioms, also add\n𝑝\n                  and\n𝑐1∨...∨𝑐𝑛\n                  to\n𝑏^.(belief state\n                      no longer\nconjunction\n                      of\nliterals\n🙁)\n\n\n▷Idea\n                  Given such a mechanism for generating (exact or approximate) updated belief states, we can generate\ncontingent plans\n                  with an extension of\nAND-OR search\n                  over belief states.\n\n\n▷Extension\n                  This also works for non-deterministic\nactions: we extend the representation of effects to disjunctions.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 122024-12-16\n",
        "sectionId": "1885429a",
        "archive": "courses/FAU/AI/course",
        "filepath": "planning/slides/contingent-planning.en.xhtml"
    },
    {
        "slideContent": "\nOnline Search and Replanning\n\n▷Note\n                  So far we have concentrated on\noffline\nproblem solving, where the agent only acts (plan execution) after search/planning terminates.\n\n\n▷Recall\n                  In\nonline\nproblem solving\n                  an\nagent\n                  interleaves computation and action: it computes one action at a time based on incoming perceptions.\n\n\n▷\nOnline\nproblem solving\n                  is helpful in\n\n\n▷dynamic\n                  or\nsemidynamic\nenvironments.\n(long computation times can be harmful)\n\n\n▷stochastic\nenvironments.\n(solve contingencies only when they arise)\n\n\n▷\nOnline\nproblem solving\n                  is necessary in unknown\nenvironments\n⤳\n                  exploration problem.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "ca3512c1",
        "archive": "courses/FAU/AI/course",
        "filepath": "planning/slides/online-intro.en.xhtml"
    },
    {
        "slideContent": "\nOnline Search Problems\n\n▷Observation\nOnline\nproblem solving\n                  even makes sense in\ndeterministic,\nfully observable\nenvironments.\n\n\n▷\n                  A\nonline search problem\n                  consists of a set\n𝑆\n                  of states, and\n\n\n▷a function\nActions(𝑠)\n                  that returns a list of\nactions\n                  allowed in state\n𝑠.\n\n\n▷the step cost function\n𝑐, where\n𝑐(𝑠,𝑎,𝑠')\n                  is the cost of executing action\n𝑎\n                  in state\n𝑠\n                  with outcome\n𝑠'.\n(cost unknown before executing\n𝑎)\n\n\n▷a goal test\nGoalTest.\n\n\n▷NoteWe can only determine\nRESULT(𝑠,𝑎)\n                  by being in\n𝑠\n                  and executing\n𝑎.\n\n\n▷\n                  The\ncompetitive ratio\n                  of an\nonline\nproblem solving\nagent\n                  is the quotient of\n\n\n▷offline performance, i.e. cost of optimal solutions with full information and\n\n\n▷online performance, i.e. the actual cost induced by\nonline\nproblem solving.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "ca3512c1",
        "archive": "courses/FAU/AI/course",
        "filepath": "planning/slides/online-search-problem.en.xhtml"
    },
    {
        "slideContent": "\nOnline Search Problems (Example)\n\n▷A simple maze problem\n\n\n\nThe agent starts at\n𝑆\n                                  and must reach\n𝐺\n                                  but knows nothing of the environment. In particular not that\n\n\n▷Up(1,1)\n                                  results in\n(1,2)\n                                  and\n\n\n▷Down(1,1)\n                                  results in\n(1,1)(i.e. back)\n\n\n\n\n\n\n\n \n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-15\n",
        "sectionId": "ca3512c1",
        "archive": "courses/FAU/AI/course",
        "filepath": "planning/slides/online-search-problem-ex.en.xhtml"
    },
    {
        "slideContent": "\nOnline Search Obstacles (Dead Ends)\n\n▷\n                  We call a state a\ndead end, iff no state is reachable from it by an action. An action that leads to a\ndead end\n                  is called\nirreversible.\n\n\n▷Note\n                  With\nirreversible\nactions\n                  the\ncompetitive ratio\n                  can be\ninfinite.\n\n\n▷\n                  No\nonline\nalgorithm\n                  can avoid\ndead ends\n                  in all\nstate spaces.\n\n\n▷\n                  Two state spaces that lead an online agent into\ndead ends:\n\n\n\n\n\nAny agent will fail in at least one of the spaces.\n\n\n▷\n                  We call\n??\n                  an\nadversary argument.\n\n\n▷\n                  Forcing an online agent into an arbitrarily inefficient route:\n\n\n\nWhichever choice the agent makes the adversary can block with a long, thin wall\n\n\n\n\n\n\n\n\n\n\n▷Observation\nDead ends\n                  are a real problem for robots: ramps, stairs, cliffs, ...\n\n▷\n                  A state space is called\nsafely explorable, iff a goal state is reachable from every reachable state.\n\n\n▷\n                  We will always assume this in the following.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-15\n",
        "sectionId": "ca3512c1",
        "archive": "courses/FAU/AI/course",
        "filepath": "planning/slides/dead-ends.en.xhtml"
    },
    {
        "slideContent": "\nOnline Search Agents\n\n▷Observation\nOnline\n                  and\noffline\n                  search\nalgorithms\n                  differ considerably:\n\n\n▷For an\noffline\n                  agent, the environment is visible a priori.\n\n\n▷An\nonline\n                  agent builds a “map” of the environment from percepts in visited states.\n\n\nTherefore, e.g.\n𝐴*\n                  can expand any node in the\nfringe, but an\nonline\nagent\n                  must go there to explore it.\n\n\n▷Intuition\n                  It seems best to expand nodes in “local order” to avoid spurious travel.\n\n\n▷Idea\nDepth first search\n                  seems a good fit.\n(must only travel for\nbacktracking)\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-16\n",
        "sectionId": "ca3512c1",
        "archive": "courses/FAU/AI/course",
        "filepath": "planning/slides/online-search.en.xhtml"
    },
    {
        "slideContent": "\nOnline DFS Search Agent\n\n▷\n                  The\nonline depth first search algorithm:\n\n\nfunction ONLINE―DFS―AGENT(𝑠') returns an action\ninputs: 𝑠', a percept that identifies the current state\npersistent: 𝑟𝑒𝑠𝑢𝑙𝑡, a table mapping (𝑠,𝑎) to 𝑠', initially empty\n𝑢𝑛𝑡𝑟𝑖𝑒𝑑, a table mapping 𝑠 to a list of untried actions\n𝑢𝑛𝑏𝑎𝑐𝑘𝑡𝑟𝑎𝑐𝑘𝑒𝑑, a table mapping 𝑠 to a list backtracks not tried\n𝑠, 𝑎, the previous state and action, initially null\nif GoalTest(𝑠') then return stop\nif 𝑠'∉𝑢𝑛𝑡𝑟𝑖𝑒𝑑 then 𝑢𝑛𝑡𝑟𝑖𝑒𝑑[𝑠'] := Actions(𝑠')\nif s is not null then\n𝑟𝑒𝑠𝑢𝑙𝑡[𝑠,𝑎] := 𝑠'\nadd 𝑠 to the front of 𝑢𝑛𝑏𝑎𝑐𝑘𝑡𝑟𝑎𝑐𝑘𝑒𝑑[𝑠']\nif 𝑢𝑛𝑡𝑟𝑖𝑒𝑑[𝑠'] is empty then\nif 𝑢𝑛𝑏𝑎𝑐𝑘𝑡𝑟𝑎𝑐𝑘𝑒𝑑[𝑠'] is empty then return stop\nelse 𝑎 := an action 𝑏 such that 𝑟𝑒𝑠𝑢𝑙𝑡[𝑠',𝑏]=𝑝𝑜𝑝(𝑢𝑛𝑏𝑎𝑐𝑘𝑡𝑟𝑎𝑐𝑘𝑒𝑑[𝑠'])\nelse 𝑎 := 𝑝𝑜𝑝(𝑢𝑛𝑡𝑟𝑖𝑒𝑑[𝑠'])\n𝑠 := 𝑠'\nreturn 𝑎\n\n▷Note\n𝑟𝑒𝑠𝑢𝑙𝑡\n                  is the “environment map” constructed as the agent explores.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 122024-12-16\n",
        "sectionId": "ca3512c1",
        "archive": "courses/FAU/AI/course",
        "filepath": "planning/slides/online-search.en.xhtml"
    },
    {
        "slideContent": "\nReplanning (Ideas)\n\n▷Idea\n                  We can turn a\nplanner\n𝑃\n                  into an\nonline\nproblem solver\n                  by adding an\naction\nRePlan(𝑔)\n                      without preconditions that re-starts\n𝑃\n                      in the current state with goal\n𝑔.\n\n\n▷Observation\nReplanning\n                  induces a tradeoff between pre-planning and re-planning.\n\n\n▷\n                  The plan\n[RePlan(𝑔)]\n                  is a (trivially) complete plan for any goal\n𝑔.(not helpful)\n\n\n▷\n                  A plan with sub-plans for every contingency (e.g. what to do if a meteor strikes) may be too costly/large.(wasted effort)\n\n\n▷\n                  But when a tire blows while driving into the desert, we want to have water pre-planned.\n(due diligence against catastrophies)\n\n\n▷Observation\n                  In\nstochastic\n                  or\npartially observable\nenvironments\n                  we also need some form of execution monitoring to determine the need for replanning (plan repair).\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-15\n",
        "sectionId": "e4ca1cc5",
        "archive": "courses/FAU/AI/course",
        "filepath": "planning/slides/replan.en.xhtml"
    },
    {
        "slideContent": "\nReplanning for Plan Repair\n\n▷Generally\nReplanning\n                  when the agent’s model of the world is incorrect.\n\n\n▷Plan Repair by Replanning\n                  Given a\nplan\n                  from\n𝑆\n                  to\n𝐺.\n\n\n\n\n▷The\nagent\n                  executes\n𝑤ℎ𝑜𝑙𝑒𝑝𝑙𝑎𝑛\nstep\n                  by\nstep,\nmonitoring\n                  the rest (𝑝𝑙𝑎𝑛).\n\n\n▷After a few\nsteps\n                  the\nagent\n                  expects to be in\n𝐸, but observes\nstate\n𝑂.\n\n\n▷Replanning: by calling the\nplanner\n                  recursively\n\n\n▷find\nstate\n𝑃\n                  in\n𝑤ℎ𝑜𝑙𝑒𝑝𝑙𝑎𝑛\n                  and a plan\n𝑟𝑒𝑝𝑎𝑖𝑟\n                  from\n𝑂\n                  to\n𝑃.\n(𝑃\n                      may be\n𝐺)\n\n\n▷minimize\n                  the cost of\n𝑟𝑒𝑝𝑎𝑖𝑟+𝑐𝑜𝑛𝑡𝑖𝑛𝑢𝑎𝑡𝑖𝑜𝑛\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-16\n",
        "sectionId": "e4ca1cc5",
        "archive": "courses/FAU/AI/course",
        "filepath": "planning/slides/plan-repair.en.xhtml"
    },
    {
        "slideContent": "\nFactors in World Model Failure\n⤳\n              Monitoring\n\n▷Generally\n                  The agent’s world model can be incorrect, because\n\n\n▷an action has a missing precondition(need a screwdriver for\nremove―lid)\n\n\n▷an action misses an effect(painting a table gets paint on the floor)\n\n\n▷it is missing a state variable(amount of paint in a can: no paint\n⤳\n                      no color)\n\n\n▷no provisions for exogenous events\n(someone knocks over a paint can)\n\n\n▷Observation\n                  Without a way for monitoring for these, planning is very brittle.\n\n\n▷\n                  There are three levels of\nexecution monitoring: before executing an action\n\n\n▷action monitoring\n                  checks whether all preconditions still hold.\n\n\n▷plan monitoring\n                  checks that the remaining plan will still succeed.\n\n\n▷goal monitoring\n                  checks whether there is a better set of goals it could try to achieve.\n\n\n▷Note\n??\n                  was a case of\naction monitoring\n                  leading to replanning.\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-15\n",
        "sectionId": "e4ca1cc5",
        "archive": "courses/FAU/AI/course",
        "filepath": "planning/slides/execution-monitoring.en.xhtml"
    },
    {
        "slideContent": "\nIntegrated Execution Monitoring and Planning\n\n▷Problem\n                  Need to upgrade planing data structures by bookkeeping for\nexecution monitoring.\n\n\n▷Observation\n                  With their\ncausal links,\npartially ordered plans\n                  already have most of the infrastructure for\naction monitoring:Preconditions of remaining\nplan=^\n                  all preconditions of remaining\nsteps\n                  not\nachieved\n                  by remaining\nsteps=^\n                  all\ncausal link\n                  “crossing current time point”\n\n\n▷Idea\n                  On failure, resume planning (e.g. by\nPOP) to\nachieve\n                  open conditions from current state.\n\n\n▷\nIPEM\n                  (Integrated Planning, Execution, and Monitoring):\n\n\n▷keep updating\n𝑆𝑡𝑎𝑟𝑡\n                  to match current state\n\n\n▷links from\nactions\n                  replaced by links from\n𝑆𝑡𝑎𝑟𝑡\n                  when done\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-15\n",
        "sectionId": "e4ca1cc5",
        "archive": "courses/FAU/AI/course",
        "filepath": "planning/slides/ipem.en.xhtml"
    },
    {
        "slideContent": "\nExecution Monitoring Example\n\n▷Shopping for a drill, milk, and bananas\n                Start/end at home, drill sold by hardware store, milk/bananas by supermarket.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-15\n",
        "sectionId": "e4ca1cc5",
        "archive": "courses/FAU/AI/course",
        "filepath": "planning/slides/ipem-ex.en.xhtml"
    },
    {
        "slideContent": "\nTopics of AI-1 (Winter Semester)\n\n▷Getting Started\n\n\n▷What is\nArtificial Intelligence?(situating ourselves)\n\n\n▷Logic programming\n              in\nProlog(An influential\nparadigm)\n\n\n▷Intelligent Agents(a unifying framework)\n\n\n▷Problem Solving\n\n\n▷Problem Solving and\nsearch(Black Box World States and Actions)\n\n\n▷Adversarial search\n              (Game playing)(A nice application of\nsearch)\n\n\n▷constraint satisfaction problems\n(Factored World States)\n\n\n▷Knowledge and Reasoning\n\n\n▷Formal Logic as the\nmathematics\n              of Meaning\n\n\n▷Propositional logic\n              and\nsatisfiability(Atomic Propositions)\n\n\n▷First-order logic\n              and\ntheorem proving(Quantification)\n\n\n▷Logic programming(Logic + Search⤳\n                  Programming)\n\n\n▷Description logics\n              and\nsemantic web\n\n\n▷Planning\n\n\n▷Planning Frameworks\n\n\n▷Planning Algorithms\n\n\n▷Planning and Acting in the real world\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "c1e3967a",
        "archive": "courses/FAU/AI/course",
        "filepath": "course/slides/ai1-topics.en.xhtml"
    },
    {
        "slideContent": "\nRational Agents as an Evaluation Framework for AI\n\n▷Agents interact with the environment\n\n\n\n\nGeneral agent schema\n\n\n\n\nSimple Reflex Agents\n\n\n\n\nReflex Agents with State\n\n\n\n\nGoal-Based Agents\n\n\n\n\nUtility-Based Agent\n\n\n\n\nLearning Agents\n\n\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-16\n",
        "sectionId": "c1e3967a",
        "archive": "courses/FAU/AI/course",
        "filepath": "rational-agents/slides/agents-overview.en.xhtml"
    },
    {
        "slideContent": "\nRational Agent\n\n▷Idea\n                  Try to design\nagents\n                  that are successful(do the right thing)\n\n\n▷\n                  An\nagent\n                  is called\nrational, if it chooses whichever\naction\nmaximizes\n                  the expected value of the performance measure given the\npercept\n                  sequence to date. This is called the\nMEU principle.\n\n\n▷Note\n                  A\nrational\nagent\n                  need not be perfect\n\n\n▷only needs to\nmaximize\nexpected value\n(rational\n≠\n                      omniscient)\n\n\n▷need not predict e.g. very unlikely but catastrophic events in the future\n\n\n▷percepts\n                  may not supply all relevant information(Rational\n≠\n                      clairvoyant)\n\n\n▷if we cannot perceive things we do not need to react to them.\n\n\n▷but we may need to try to find out about hidden dangers(exploration)\n\n\n▷action\n                  outcomes may not be as expected(rational\n≠\n                      successful)\n\n\n▷but we may need to take\naction\n                  to ensure that they do (more often)(learning)\n\n\n▷Rational\n⤳\n              exploration, learning, autonomy\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-15\n",
        "sectionId": "c1e3967a",
        "archive": "courses/FAU/AI/course",
        "filepath": "rational-agents/slides/rationality-recap.en.xhtml"
    },
    {
        "slideContent": "\nSymbolic AI: Adding Knowledge to Algorithms\n\n▷Problem Solving(Black Box States, Transitions,\nHeuristics)\n\n\n▷Framework: Problem Solving and Search(basic tree/graph walking)\n\n\n▷Variant: Game playing (Adversarial search)(minimax\n                +\n𝛼𝛽-Pruning)\n\n\n▷Constraint Satisfaction Problems(heuristic search\n                over partial assignments)\n\n\n▷States as partial variable assignments, transitions as assignment\n\n\n▷Heuristics\n            informed by current restrictions, constraint graph\n\n\n▷Inference as constraint propagation(transferring possible values across arcs)\n\n\n▷Describing world states by formal language(and drawing inferences)\n\n\n▷Propositional logic\n            and\nDPLL(deciding\nentailment\nefficiently)\n\n\n▷First-order logic\n            and\nATP(reasoning about\ninfinite\n                domains)\n\n\n▷Digression:\nLogic programming(logic + search)\n\n\n▷Description logics\n            as moderately expressive, but\ndecidable\n            logics\n\n\n▷Planning: Problem Solving using white-box world/action descriptions\n\n\n▷Framework: describing world states in logic as sets of propositions and actions by preconditions and add/delete lists\n\n\n▷Algorithms: e.g\nheuristic search\n            by problem relaxations\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-14\n",
        "sectionId": "c1e3967a",
        "archive": "courses/FAU/AI/course",
        "filepath": "course/slides/ai1-hindsight.en.xhtml"
    },
    {
        "slideContent": "\nTopics of AI-2 (Summer Semester)\n\n▷Uncertain\n            Knowledge and Reasoning\n\n\n▷Uncertainty\n\n\n▷Probabilistic reasoning\n\n\n▷Making Decisions in Episodic Environments\n\n\n▷Problem Solving in Sequential Environments\n\n\n▷Foundations of\nmachine learning\n\n\n▷Learning from Observations\n\n\n▷Knowledge in Learning\n\n\n▷Statistical Learning Methods\n\n\n▷Communication(If there is time)\n\n\n▷Natural Language Processing\n\n\n▷Natural Language\n            for Communication\n\n\n\nMichael Kohlhase:\nArtificial Intelligence 112024-12-16\n",
        "sectionId": "c1e3967a",
        "archive": "courses/FAU/AI/course",
        "filepath": "course/slides/ai2-topics.en.xhtml"
    }
]